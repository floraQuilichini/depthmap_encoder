{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.set_printoptions(precision=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, depthmap_dir, mask_dir, segmentation_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            depthmap_dir (string): Directory with all the depthmaps.\n",
    "            mask_dir (string): Directory with all the masks.\n",
    "            segmentation_dir (string): Directory with all the segmentation of the depthmaps.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.depthmap_dir = depthmap_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.segmentation_dir = segmentation_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        path, dirs, files = next(os.walk(self.depthmap_dir))\n",
    "        file_count = len(files)\n",
    "        return file_count\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        path_d, dirs_d, files_d = next(os.walk(self.depthmap_dir))\n",
    "        img_d_name = os.path.join(self.depthmap_dir, files_d[idx])\n",
    "        image_d = io.imread(img_d_name)\n",
    "        \n",
    "        path_m, dirs_m, files_m = next(os.walk(self.mask_dir))\n",
    "        img_m_name = os.path.join(self.mask_dir, files_m[idx])\n",
    "        image_m = io.imread(img_m_name)\n",
    "        \n",
    "        path_s, dirs_s, files_s = next(os.walk(self.segmentation_dir))\n",
    "        img_s_name = os.path.join(self.segmentation_dir, files_s[idx])\n",
    "        image_s = io.imread(img_s_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image_d = self.transform(image_d)\n",
    "            image_m = self.transform(image_m)\n",
    "            image_s = self.transform(image_s)\n",
    "\n",
    "        return image_d, image_m, image_s\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        if h!= new_h:\n",
    "            top = np.random.randint(0, h - new_h)\n",
    "        else:\n",
    "            top = 0\n",
    "        if w!= new_w:\n",
    "            left = np.random.randint(0, w - new_w)\n",
    "        else:\n",
    "            left = 0\n",
    "     \n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "        \n",
    "        image = np.expand_dims(image, axis=2)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class Downsample(object):\n",
    "    \"\"\"Downsample the image\n",
    "\n",
    "    Args:\n",
    "        downsampling_factor (int or tuple): Desired downsampling factor for rows and columns.\n",
    "        If the downsampling factor is an int, then both rows and columns are sampled by the same factor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, downsampling_factor):\n",
    "        assert isinstance(downsampling_factor, (int, tuple))\n",
    "        if isinstance(downsampling_factor, int):\n",
    "            self.downsampling_factor = (downsampling_factor, downsampling_factor)\n",
    "        else:\n",
    "            assert len(downsampling_factor) == 2\n",
    "            self.downsampling_factor = downsampling_factor\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        down_fact_h, down_fact_w = self.downsampling_factor\n",
    "        image = image[::down_fact_h,\n",
    "                      ::down_fact_w]\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class ConvertDepthToColor(object):\n",
    "    \"\"\" convert a 1xmxn 16-bits depthmap to a 2xmxn 8-bits colormap\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if len(image.shape[:]) <3:\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "            \n",
    "        h, w = image.shape[:2]\n",
    "        image_r_color= np.zeros((h,w,1), dtype=int)\n",
    "        image_g_color= np.zeros((h,w,1), dtype=int)\n",
    "        image_g_color[(image > 2**8 - 1)] = image[(image > 2**8 - 1)] >> 8\n",
    "        image_r_color = image - (image_g_color <<8)\n",
    "\n",
    "        return np.concatenate((image_r_color, image_g_color), axis=2)\n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in images to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, images):\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        images = images.transpose((2, 0, 1))\n",
    "        images = images.astype(float)\n",
    "        return torch.from_numpy(images)\n",
    "    \n",
    "\n",
    "    \n",
    "class ConvertColorToDepth(object):\n",
    "    \"\"\" convert a 2xmxn 8-bits colormap to a 1xmxn 16-bits depthmap\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, color_image):\n",
    "            \n",
    "        depth_image = color_image[:, 0, :, :]\n",
    "        depth_image += color_image[:, 1, :, :] << 8\n",
    "\n",
    "        return depth_image\n",
    "\n",
    "    \n",
    "def show_image_batch(images_batch):\n",
    "    \"\"\"Show image for a batch of samples.\"\"\"\n",
    "    if images_batch.size(1) == 1:\n",
    "        images_batch_normed = images_batch/torch.max(images_batch)\n",
    "        grid = utils.make_grid(images_batch_normed)\n",
    "        plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "        plt.title('Batch from dataloader')\n",
    "    else:\n",
    "        print(images_batch.size())\n",
    "        images_b_batch = torch.zeros(images_batch.size(0), 1, images_batch.size(2) , images_batch.size(3))\n",
    "        images_color_batch = torch.cat((images_batch, images_b_batch), 1) \n",
    "        print(images_color_batch.size())\n",
    "        grid = utils.make_grid(images_color_batch)\n",
    "        plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "        plt.title('Batch from dataloader')\n",
    "\n",
    "\n",
    "        \n",
    "def standardize_input(x):\n",
    "    mean_channels = torch.mean(1.0*x, [2,3])\n",
    "    mean_channels_images = (mean_channels.repeat_interleave(x.size()[2]*x.size()[3])).view(x.size()[0], x.size()[1], x.size()[2], x.size()[3])\n",
    "    x_centered = x - mean_channels_images\n",
    "    var = torch.sum(x_centered**2, (2, 3))/(x.size()[2]*x.size()[3])\n",
    "    x_standardized = x_centered / torch.sqrt(var.view(x_centered.size()[0], x_centered.size()[1], 1, 1))\n",
    "    return x_standardized, mean_channels, var\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyConv(nn.Module):\n",
    "    def __init__(self, n_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1):\n",
    "        super(MyConv, self).__init__()\n",
    "\n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_size_number = kernel_size * kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = (dilation, dilation)\n",
    "        self.padding = (padding, padding)\n",
    "        self.stride = (stride, stride)\n",
    "        self.n_channels = n_channels\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_channels, 1, self.n_channels, self.kernel_size_number)).cuda()\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.out_channels, 1)).cuda()\n",
    "        \n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        width = self.calculateNewWidth(x)\n",
    "        height = self.calculateNewHeight(x)\n",
    "        result = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        result_seg = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        \n",
    "        \n",
    "        windows_depth = self.calculateWindows(x)\n",
    "        windows_depth_seg = windows_depth\n",
    "        \n",
    "        \n",
    "        # compute result\n",
    "        #ponderation = torch.sum(windows_seg, (2,3))\n",
    "        #ponderation = torch.sqrt(torch.sum(self.weight**2, (2,3))).view(self.weight.size()[0], self.weight.size()[1], 1, 1)\n",
    "        #ponderation = self.kernel_size_number * self.n_channels \n",
    "        #ponderation = torch.sqrt(torch.sum(self.weight**2, (2,3))).view(self.weight.size()[0], self.weight.size()[1], 1, 1)\n",
    "        #ponderation = 1\n",
    "        print(\"weights size : \", self.weight.size())\n",
    "        #print(\"ponderation size : \", ponderation.size())\n",
    "        #print(\"weights without param: \", self.weight/ponderation)\n",
    "        #self.weight = torch.nn.Parameter(self.weight/ponderation)\n",
    "        print(\"weights param: \", self.weight)\n",
    "        \n",
    "        \"\"\"\n",
    "        for i in range(self.out_channels):\n",
    "            print(\"sum weights : \",  torch.sum(torch.abs(weights_n[i, :,:,:,]), (2,3)))\n",
    "        \"\"\"\n",
    "        result = torch.sum(windows_depth_seg * self.weight/ponderation , (2, 3)) + self.bias\n",
    "        result = result.reshape(self.out_channels, x.shape[0], width, height)\n",
    "        result = (result.transpose(0, 1))\n",
    "\n",
    "        return result \n",
    "        \n",
    "    def calculateWindows(self, x):\n",
    "        windows = F.unfold(\n",
    "            x, kernel_size=self.kernel_size, padding=self.padding, dilation=self.dilation, stride=self.stride\n",
    "        )\n",
    "\n",
    "        windows = windows.transpose(1, 2).contiguous().view(1, -1, x.shape[1], self.kernel_size_number)\n",
    "        #windows = windows.transpose(0, 1)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def calculateNewWidth(self, x):\n",
    "        return (\n",
    "            (x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "            // self.stride[0]\n",
    "        ) + 1\n",
    "\n",
    "    def calculateNewHeight(self, x):\n",
    "        return (\n",
    "            (x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "            // self.stride[1]\n",
    "        ) + 1\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "class MyConvWithSeg(nn.Module):\n",
    "    def __init__(self, n_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1):\n",
    "        super(MyConvWithSeg, self).__init__()\n",
    "\n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_size_number = kernel_size * kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = (dilation, dilation)\n",
    "        self.padding = (padding, padding)\n",
    "        self.stride = (stride, stride)\n",
    "        self.n_channels = n_channels\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_channels, 1, self.n_channels, self.kernel_size_number)).cuda()\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.out_channels, 1)).cuda()\n",
    "        \n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, seg):\n",
    "        width = self.calculateNewWidth(x)\n",
    "        height = self.calculateNewHeight(x)\n",
    "        result = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        result_seg = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        min_over_seg = torch.amin(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        max_over_seg = torch.amax(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        \n",
    "        seg = (seg - min_over_seg)/(max_over_seg - min_over_seg)\n",
    "        windows_depth = self.calculateWindows(x)\n",
    "        windows_seg = self.calculateWindows(seg)\n",
    "        windows_seg_cp =  windows_seg.clone()\n",
    "        print(\"windows seg size : \", windows_seg.size())\n",
    "        windows_seg[windows_seg < 1] = -1\n",
    "        windows_seg_centers = windows_seg[0, :, :, windows_seg.size()[3]//2].view(1, windows_seg.size()[1], windows_seg.size()[2], 1)\n",
    "        windows_seg = windows_seg * windows_seg_centers\n",
    "        windows_seg[windows_seg < 1] = 0 \n",
    "        windows_depth_seg = windows_depth * windows_seg\n",
    "        \n",
    "        # compute result\n",
    "        ponderation = torch.sqrt(torch.sum(self.weight**2, (2,3))).view(self.weight.size()[0], self.weight.size()[1], 1, 1)\n",
    "        #print(\"weights size : \", self.weight.size())\n",
    "        #print(\"ponderation size : \", ponderation.size())\n",
    "        weight_n = self.weight/ponderation\n",
    "        \n",
    "        result = torch.sum(windows_depth_seg * weight_n , (2, 3)) + self.bias\n",
    "        result = result.reshape(self.out_channels, x.shape[0], width, height)\n",
    "        result = (result.transpose(0, 1))\n",
    "        \n",
    "        \n",
    "        # compute result_seg\n",
    "        windows_seg_seg = windows_seg_cp * windows_seg\n",
    "        print(\"windows_seg_seg max, : \", torch.max(windows_seg_seg))\n",
    "        print(\"windows_seg_seg min, : \", torch.min(windows_seg_seg))\n",
    "        result_seg = result_seg.reshape(self.out_channels, seg.shape[0], width, height)\n",
    "        result_seg = (result_seg.transpose(0, 1))\n",
    "        thresh = (torch.max(result_seg) + torch.min(result_seg))/2.0\n",
    "        #result_seg = (result_seg > thresh).float()\n",
    "        \n",
    "\n",
    "        return result\n",
    "        \n",
    "        \n",
    "    def calculateWindows(self, x):\n",
    "        windows = F.unfold(\n",
    "            x, kernel_size=self.kernel_size, padding=self.padding, dilation=self.dilation, stride=self.stride\n",
    "        )\n",
    "\n",
    "        windows = windows.transpose(1, 2).contiguous().view(1, -1, x.shape[1], self.kernel_size_number)\n",
    "        #windows = windows.transpose(0, 1)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def calculateNewWidth(self, x):\n",
    "        return (\n",
    "            (x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "            // self.stride[0]\n",
    "        ) + 1\n",
    "\n",
    "    def calculateNewHeight(self, x):\n",
    "        return (\n",
    "            (x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "            // self.stride[1]\n",
    "        ) + 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class MyConvWithSeg(nn.Module):\n",
    "    def __init__(self, n_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1):\n",
    "        super(MyConvWithSeg, self).__init__()\n",
    "\n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_size_number = kernel_size * kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = (dilation, dilation)\n",
    "        self.padding = (padding, padding)\n",
    "        self.stride = (stride, stride)\n",
    "        self.n_channels = n_channels\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_channels, 1, self.n_channels, self.kernel_size_number)).cuda()\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.out_channels, 1)).cuda()\n",
    "        \n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, seg):\n",
    "        width = self.calculateNewWidth(x)\n",
    "        height = self.calculateNewHeight(x)\n",
    "        result = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        result_seg = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        min_over_seg = torch.amin(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        max_over_seg = torch.amax(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        seg = (seg - min_over_seg)/(max_over_seg - min_over_seg)\n",
    "        seg = (seg > 0.5).float()\n",
    "        \n",
    "        \n",
    "        windows_depth = self.calculateWindows(x)\n",
    "        windows_seg = self.calculateWindows(seg)\n",
    "        windows_seg[windows_seg<1] = -1\n",
    "        windows_seg_centers = windows_seg[0, :, :, windows_seg.size()[3]//2].view(1, windows_seg.size()[1], windows_seg.size()[2], 1)\n",
    "        windows_seg = windows_seg * windows_seg_centers\n",
    "        windows_seg[windows_seg<1] = 0\n",
    "        windows_depth_seg = windows_depth * windows_seg\n",
    "        windows_depth_seg = windows_depth\n",
    "        \n",
    "        # compute result\n",
    "        #ponderation = torch.sqrt(torch.sum(self.weight**2, (2,3))).view(self.weight.size()[0], self.weight.size()[1], 1, 1)\n",
    "        \"\"\"\n",
    "        print(\"weights size : \", self.weight.size())\n",
    "        print(\"ponderation size : \", ponderation.size())\n",
    "        \"\"\"\n",
    "        #weight_n = self.weight/ponderation\n",
    "        \"\"\"\n",
    "        for i in range(self.out_channels):\n",
    "            print(\"sum weights : \",  torch.sum(torch.abs(weights_n[i, :,:,:,]), (2,3)))\n",
    "        \"\"\"\n",
    "        \n",
    "        result = torch.sum(windows_depth_seg * self.weight , (2, 3)) + self.bias\n",
    "        result = result.reshape(self.out_channels, x.shape[0], width, height)\n",
    "        result = (result.transpose(0, 1))\n",
    "\n",
    "        \n",
    "        \n",
    "        # compute result_seg\n",
    "        windows_seg_seg = self.calculateWindows(seg) * windows_seg\n",
    "        result_seg = torch.sum(windows_seg_seg *  self.weight, (2, 3)) + self.bias\n",
    "        result_seg = result_seg.reshape(self.out_channels, x.shape[0], width, height)\n",
    "        result_seg = (result_seg.transpose(0, 1))\n",
    "        \n",
    "        return result, result_seg\n",
    "\n",
    "        \n",
    "    def calculateWindows(self, x):\n",
    "        windows = F.unfold(\n",
    "            x, kernel_size=self.kernel_size, padding=self.padding, dilation=self.dilation, stride=self.stride\n",
    "        )\n",
    "\n",
    "        windows = windows.transpose(1, 2).contiguous().view(1, -1, x.shape[1], self.kernel_size_number)\n",
    "        #windows = windows.transpose(0, 1)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def calculateNewWidth(self, x):\n",
    "        return (\n",
    "            (x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "            // self.stride[0]\n",
    "        ) + 1\n",
    "\n",
    "    def calculateNewHeight(self, x):\n",
    "        return (\n",
    "            (x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "            // self.stride[1]\n",
    "        ) + 1    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class MyConv2d_par(nn.Module):\n",
    "    def __init__(self, n_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1):\n",
    "        super(MyConv2d_par, self).__init__()\n",
    "\n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_size_number = kernel_size * kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = (dilation, dilation)\n",
    "        self.padding = (padding, padding)\n",
    "        self.stride = (stride, stride)\n",
    "        self.n_channels = n_channels\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_channels, 1, self.n_channels, self.kernel_size_number))\n",
    "        #self.weight.data.uniform_(0, 1)\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.out_channels, 1))\n",
    "        #self.bias.data.uniform_(0, 1)\n",
    "        \n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    \n",
    "    def forward(self, x): #, x_segmented):\n",
    "        if x.is_cuda:\n",
    "            self.weight = self.weight.cuda()\n",
    "        width = self.calculateNewWidth(x)\n",
    "        height = self.calculateNewHeight(x)\n",
    "        result = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        result_seg = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        \n",
    "        \n",
    "        windows_depth = self.calculateWindows(x)\n",
    "        \n",
    "        windows_seg = self.calculateWindows(x_segmented)\n",
    "        windows_seg[windows_seg < 1] = -1\n",
    "        windows_seg_centers = windows_seg[0, :, :, windows_seg.size()[3]//2].view(1, windows_seg.size()[1], windows_seg.size()[2], 1)\n",
    "        windows_seg = windows_seg * windows_seg_centers\n",
    "        windows_seg[windows_seg < 1] = 0 \n",
    "        windows_depth_seg = windows_depth * windows_seg\n",
    "        \n",
    "        windows_depth_seg = windows_depth\n",
    "        \n",
    "        \n",
    "        # compute result\n",
    "        #ponderation = torch.sum(windows_seg, (2,3))\n",
    "        #ponderation = torch.sqrt(torch.sum(self.weight**2, (2,3))).view(self.weight.size()[0], self.weight.size()[1], 1, 1)\n",
    "        ponderation = torch.sum(torch.abs(self.weight), (2,3)).view(self.weight.size()[0], self.weight.size()[1], 1, 1)\n",
    "        print(\"weights size : \", self.weight.size())\n",
    "        print(\"ponderation size : \", ponderation.size())\n",
    "        #ponderation = self.kernel_size_number * self.n_channels \n",
    "        self.weight = self.weight/ponderation\n",
    "        \"\"\"\n",
    "        for i in range(self.out_channels):\n",
    "            print(\"sum weights : \",  torch.sum(torch.abs(weights_n[i, :,:,:,]), (2,3)))\n",
    "        \"\"\"\n",
    "        result = torch.sum(windows_depth_seg * self.weight , (2, 3)) + self.bias\n",
    "        #result = (result.transpose(0, 1)).reshape(x.shape[0], self.out_channels, width, height)\n",
    "        result = result.reshape(self.out_channels, x.shape[0], width, height)\n",
    "        result = (result.transpose(0, 1))\n",
    "        \n",
    "        # compute result_seg\n",
    "        windows_seg_seg = self.calculateWindows(x_segmented) * windows_seg\n",
    "        #result_seg = (result_seg.transpose(0, 1)).reshape(x_segmented.shape[0], self.out_channels, width, height)\n",
    "        result_seg = result_seg.reshape(self.out_channels, x_segmented.shape[0], width, height)\n",
    "        result_seg = (result_seg.transpose(0, 1))\n",
    "        #result_seg = torch.clamp(result_seg, min=0, max=1)\n",
    "        thresh = (torch.max(result_seg) + torch.min(result_seg))/2.0\n",
    "        result_seg = (result_seg > thresh).int()\n",
    "\n",
    "\n",
    "        return result, result_seg\n",
    "        \n",
    "    def calculateWindows(self, x):\n",
    "        windows = F.unfold(\n",
    "            x, kernel_size=self.kernel_size, padding=self.padding, dilation=self.dilation, stride=self.stride\n",
    "        )\n",
    "\n",
    "        windows = windows.transpose(1, 2).contiguous().view(1, -1, x.shape[1], self.kernel_size_number)\n",
    "        #windows = windows.transpose(0, 1)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def calculateNewWidth(self, x):\n",
    "        return (\n",
    "            (x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "            // self.stride[0]\n",
    "        ) + 1\n",
    "\n",
    "    def calculateNewHeight(self, x):\n",
    "        return (\n",
    "            (x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "            // self.stride[1]\n",
    "        ) + 1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class MyConv2d_test(nn.Module):\n",
    "    def __init__(self, n_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1):\n",
    "        super(MyConv2d_test, self).__init__()\n",
    "\n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_size_number = kernel_size * kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = (dilation, dilation)\n",
    "        self.padding = (padding, padding)\n",
    "        self.stride = (stride, stride)\n",
    "        self.n_channels = n_channels\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_channels, 1, self.n_channels, self.kernel_size_number))\n",
    "        #self.weight.data.uniform_(0, 1)\n",
    "        self.bias = nn.Parameter(torch.Tensor(self.out_channels, 1))\n",
    "        #self.bias.data.uniform_(0, 1)\n",
    "        \n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.is_cuda:\n",
    "            self.weight = self.weight.cuda()\n",
    "        width = self.calculateNewWidth(x)\n",
    "        height = self.calculateNewHeight(x)\n",
    "        result = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        result_seg = torch.zeros(\n",
    "            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=device\n",
    "        )\n",
    "        \n",
    "        \n",
    "        windows_depth = self.calculateWindows(x)\n",
    "        \n",
    "        \n",
    "        # compute result\n",
    "        ponderation = self.kernel_size_number\n",
    "        result = torch.sum(windows_depth * self.weight , (2, 3))/ponderation + self.bias\n",
    "        #result = (result.transpose(0, 1)).reshape(x.shape[0], self.out_channels, width, height)\n",
    "        result = result.reshape(x.shape[0], self.out_channels, width, height)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    def calculateWindows(self, x):\n",
    "        windows = F.unfold(\n",
    "            x, kernel_size=self.kernel_size, padding=self.padding, dilation=self.dilation, stride=self.stride\n",
    "        )\n",
    "\n",
    "        windows = windows.transpose(1, 2).contiguous().view(1, -1, x.shape[1], self.kernel_size_number)\n",
    "        #windows = windows.transpose(0, 1)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def calculateNewWidth(self, x):\n",
    "        return (\n",
    "            (x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "            // self.stride[0]\n",
    "        ) + 1\n",
    "\n",
    "    def calculateNewHeight(self, x):\n",
    "        return (\n",
    "            (x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "            // self.stride[1]\n",
    "        ) + 1\n",
    "    \n",
    "    \n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "\n",
    "class stackedCustomConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(stackedCustomConv, self).__init__()\n",
    "       \n",
    "        self.conv1 = MyConvWithSeg(1, 2, 5, stride=1, padding=2)  \n",
    "        self.conv2 = MyConvWithSeg(2, 3, 5, stride=1, padding=2)\n",
    "    \n",
    "        \n",
    "    def forward(self, x, seg):\n",
    "        min_over_seg = torch.amin(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        max_over_seg = torch.amax(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        seg =  (seg - min_over_seg)/(max_over_seg - min_over_seg)\n",
    "        seg = (seg > -0.1).float()\n",
    "        x1, seg = self.conv1(x, seg)\n",
    "        min_over_seg = torch.amin(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        max_over_seg = torch.amax(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        seg =  (seg - min_over_seg)/(max_over_seg - min_over_seg)\n",
    "        seg = (seg > -0.1).float()\n",
    "        seg1 = seg.clone()\n",
    "        #x = F.relu(x)\n",
    "        x2, seg = self.conv2(x1, seg)\n",
    "        #x = F.relu(x)\n",
    "        min_over_seg = torch.amin(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        max_over_seg = torch.amax(seg, dim=(1, 2, 3)).view(seg.size()[0], 1, 1, 1)\n",
    "        seg =  (seg - min_over_seg)/(max_over_seg - min_over_seg)\n",
    "        seg = (seg > -0.1).float()\n",
    "        seg2 = seg.clone()\n",
    "        \n",
    "        return x1, x2, seg1, seg2\n",
    "\n",
    "\n",
    "class stackedPyConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(stackedPyConv, self).__init__()\n",
    "       \n",
    "        self.conv1 = nn.Conv2d(1, 2, 5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(2, 3, 5, stride=1, padding=2)\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        #x = F.relu(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test image size :  torch.Size([3, 1, 480, 640])\n",
      "windows seg size :  torch.Size([1, 921600, 1, 25])\n",
      "windows seg centers size :  torch.Size([1, 921600, 1, 1])\n",
      "weights size :  torch.Size([5, 1, 1, 25])\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "\n",
    "test_dataset = ImageDataset(depthmap_dir='D:/autoencoder_data/depthmaps/test/dilated', \n",
    "                                mask_dir='D:/autoencoder_data/depthmaps/test/mask',\n",
    "                                segmentation_dir='D:/autoencoder_data/depthmaps/test/segmentation_roipoly',\n",
    "                                transform=transforms.Compose([RandomCrop((480, 640)), ToTensor()])\n",
    "                                 )\n",
    "\n",
    "test_image = torch.cat((test_dataset[0][0].unsqueeze(0).float(), test_dataset[1][0].unsqueeze(0).float(), test_dataset[2][0].unsqueeze(0).float()),0)\n",
    "print(\"test image size : \", test_image.size())\n",
    "test_mask = torch.cat((test_dataset[0][1].unsqueeze(0).float(), test_dataset[1][1].unsqueeze(0).float(), test_dataset[2][1].unsqueeze(0).float()), 0)\n",
    "test_seg = torch.cat((test_dataset[0][2].unsqueeze(0).float(), test_dataset[1][2].unsqueeze(0).float(), test_dataset[2][2].unsqueeze(0).float()), 0)\n",
    "\n",
    "custom_model = MyConvWithSeg(1, 5, 5, stride=1, padding=2)\n",
    "filtered_image = custom_model(test_image, test_seg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test image size :  torch.Size([3, 1, 480, 640])\n",
      "max standardized im :  tensor(3.422230243683, device='cuda:0')\n",
      "min standardized im :  tensor(-1.465722799301, device='cuda:0')\n",
      "filtered_image size :  torch.Size([3, 2, 480, 640])\n",
      "max :  tensor(2.252671957016, device='cuda:0')\n",
      "min :  tensor(-1.236501574516, device='cuda:0')\n",
      "max :  tensor(2.321158885956, device='cuda:0')\n",
      "min :  tensor(-1.112887620926, device='cuda:0')\n",
      "max :  tensor(1.784883499146, device='cuda:0')\n",
      "min :  tensor(-2.201747417450, device='cuda:0')\n",
      "max :  tensor(1.365611314774, device='cuda:0')\n",
      "min :  tensor(-1.229936242104, device='cuda:0')\n",
      "max :  tensor(1.416213870049, device='cuda:0')\n",
      "min :  tensor(-1.525655746460, device='cuda:0')\n",
      "max :  tensor(1.307808160782, device='cuda:0')\n",
      "min :  tensor(-1.582606673241, device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9b19a3b6ab92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_image1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;31m#cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"img\" + str(i)+\".png\", (torch.squeeze(filtered_image)[i, :, :]).int().cpu().numpy().astype(np.uint16))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 1 with size 2"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = get_device()\n",
    "test_dataset = ImageDataset(depthmap_dir='D:/autoencoder_data/depthmaps/test/dilated', \n",
    "                                mask_dir='D:/autoencoder_data/depthmaps/test/mask',\n",
    "                                segmentation_dir='D:/autoencoder_data/depthmaps/test/segmentation_roipoly',\n",
    "                                transform=transforms.Compose([RandomCrop((480, 640)), ToTensor()])\n",
    "                                 )\n",
    "\n",
    "test_image = torch.cat((test_dataset[0][0].unsqueeze(0).float(), test_dataset[1][0].unsqueeze(0).float(), test_dataset[2][0].unsqueeze(0).float()),0)\n",
    "print(\"test image size : \", test_image.size())\n",
    "test_mask = torch.cat((test_dataset[0][1].unsqueeze(0).float(), test_dataset[1][1].unsqueeze(0).float(), test_dataset[2][1].unsqueeze(0).float()), 0)\n",
    "test_seg = torch.cat((test_dataset[0][2].unsqueeze(0).float(), test_dataset[1][2].unsqueeze(0).float(), test_dataset[2][2].unsqueeze(0).float()), 0)\n",
    "\n",
    "\n",
    "[test_image_standardized, mean_channels, std_channels] = standardize_input(test_image.cuda())\n",
    "print(\"max standardized im : \", torch.max(test_image_standardized))\n",
    "print(\"min standardized im : \", torch.min(test_image_standardized))\n",
    "custom_model = stackedCustomConv()\n",
    "filtered_image1, filtered_image2, filtered_seg1, filtered_seg2 = custom_model(test_image_standardized, test_seg.cuda())\n",
    "#filtered_image1 = custom_model(test_image_standardized, test_seg.cuda())\n",
    "\n",
    "print(\"filtered_image size : \", filtered_image1.size())\n",
    "\n",
    "size_batch = test_image.size()[0]\n",
    "out_channel = 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=size_batch, ncols=out_channel, sharex=True, sharey=True, figsize=(8, 2))\n",
    "with torch.no_grad():\n",
    "    for i in range(out_channel):\n",
    "        for j in range(size_batch):\n",
    "            ax = fig.add_subplot(size_batch, out_channel, i+1 + j*out_channel, xticks=[], yticks=[])\n",
    "            plt.imshow((torch.squeeze(filtered_image1[j, i, :, :])).int().cpu())\n",
    "            #cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"img\" + str(i)+\".png\", (torch.squeeze(filtered_image)[i, :, :]).int().cpu().numpy().astype(np.uint16))\n",
    "\n",
    "            # make 8-bit image\n",
    "            im_max = torch.max((torch.squeeze(filtered_image1[j, i, :, :])))\n",
    "            print(\"max : \", im_max)\n",
    "            im_min = torch.min((torch.squeeze(filtered_image1[j, i, :, :])))\n",
    "            print(\"min : \", im_min)\n",
    "            image_8b = (( (torch.squeeze(filtered_image1[j, i, :, :])) - im_min)/(im_max - im_min)*255).int()\n",
    "            cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\me\\\\\" + \"1_img\" + str(j)+ \"_\"+  str(i)+ \".png\", (image_8b.cpu().numpy().astype(np.uint8)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max :  tensor(2.510167121887, device='cuda:0')\n",
      "min :  tensor(-3.069689273834, device='cuda:0')\n",
      "max :  tensor(2.356209278107, device='cuda:0')\n",
      "min :  tensor(-3.375744819641, device='cuda:0')\n",
      "max :  tensor(2.505375385284, device='cuda:0')\n",
      "min :  tensor(-2.925806999207, device='cuda:0')\n",
      "max :  tensor(2.612173557281, device='cuda:0')\n",
      "min :  tensor(-2.758672952652, device='cuda:0')\n",
      "max :  tensor(3.194631338120, device='cuda:0')\n",
      "min :  tensor(-1.730158090591, device='cuda:0')\n",
      "max :  tensor(2.228067874908, device='cuda:0')\n",
      "min :  tensor(-2.521572828293, device='cuda:0')\n",
      "max :  tensor(2.524357557297, device='cuda:0')\n",
      "min :  tensor(-4.989957332611, device='cuda:0')\n",
      "max :  tensor(2.440435886383, device='cuda:0')\n",
      "min :  tensor(-4.278882503510, device='cuda:0')\n",
      "max :  tensor(2.848528862000, device='cuda:0')\n",
      "min :  tensor(-4.185708045959, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size_batch = test_image.size()[0]\n",
    "out_channel = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=size_batch, ncols=out_channel, sharex=True, sharey=True, figsize=(8, 2))\n",
    "with torch.no_grad():\n",
    "    for i in range(out_channel):\n",
    "        for j in range(size_batch):\n",
    "            ax = fig.add_subplot(size_batch, out_channel, i+1 + j*out_channel, xticks=[], yticks=[])\n",
    "            plt.imshow((torch.squeeze(filtered_image2[j, i, :, :])).int().cpu())\n",
    "            #cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"img\" + str(i)+\".png\", (torch.squeeze(filtered_image)[i, :, :]).int().cpu().numpy().astype(np.uint16))\n",
    "\n",
    "            # make 8-bit image\n",
    "            im_max = torch.max((torch.squeeze(filtered_image2[j, i, :, :])))\n",
    "            print(\"max : \", im_max)\n",
    "            im_min = torch.min((torch.squeeze(filtered_image2[j, i, :, :])))\n",
    "            print(\"min : \", im_min)\n",
    "            image_8b = (( (torch.squeeze(filtered_image2[j, i, :, :])) - im_min)/(im_max - im_min)*255).int()\n",
    "            cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\me\\\\\" + \"2_img\" + str(j)+ \"_\"+  str(i)+ \".png\", (image_8b.cpu().numpy().astype(np.uint8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max :  tensor(0., device='cuda:0')\n",
      "min :  tensor(0., device='cuda:0')\n",
      "max :  tensor(0., device='cuda:0')\n",
      "min :  tensor(0., device='cuda:0')\n",
      "max :  tensor(0., device='cuda:0')\n",
      "min :  tensor(0., device='cuda:0')\n",
      "max :  tensor(0., device='cuda:0')\n",
      "min :  tensor(0., device='cuda:0')\n",
      "max :  tensor(0., device='cuda:0')\n",
      "min :  tensor(0., device='cuda:0')\n",
      "max :  tensor(0., device='cuda:0')\n",
      "min :  tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size_batch = test_seg.size()[0]\n",
    "out_channel = 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=size_batch, ncols=out_channel, sharex=True, sharey=True, figsize=(8, 2))\n",
    "with torch.no_grad():\n",
    "    for i in range(out_channel):\n",
    "        for j in range(size_batch):\n",
    "            ax = fig.add_subplot(size_batch, out_channel, i+1 + j*out_channel, xticks=[], yticks=[])\n",
    "            plt.imshow((torch.squeeze(filtered_seg1[j, i, :, :])).int().cpu())\n",
    "            #cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"img\" + str(i)+\".png\", (torch.squeeze(filtered_image)[i, :, :]).int().cpu().numpy().astype(np.uint16))\n",
    "\n",
    "            # make 8-bit image\n",
    "            im_max = torch.max((torch.squeeze(filtered_seg1[j, i, :, :])))\n",
    "            print(\"max : \", im_max)\n",
    "            im_min = torch.min((torch.squeeze(filtered_seg1[j, i, :, :])))\n",
    "            print(\"min : \", im_min)\n",
    "            image_8b = (( (torch.squeeze(filtered_seg1[j, i, :, :])) - im_min)/(im_max - im_min)*255).int()\n",
    "            cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\me\\\\\" + \"1_seg\" + str(j)+ \"_\"+  str(i)+ \".png\", (image_8b.cpu().numpy().astype(np.uint8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_seg2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7bc84c17dc89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_seg2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;31m#cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"img\" + str(i)+\".png\", (torch.squeeze(filtered_image)[i, :, :]).int().cpu().numpy().astype(np.uint16))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_seg2' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size_batch = test_seg.size()[0]\n",
    "out_channel = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=size_batch, ncols=out_channel, sharex=True, sharey=True, figsize=(8, 2))\n",
    "with torch.no_grad():\n",
    "    for i in range(out_channel):\n",
    "        for j in range(size_batch):\n",
    "            ax = fig.add_subplot(size_batch, out_channel, i+1 + j*out_channel, xticks=[], yticks=[])\n",
    "            plt.imshow((torch.squeeze(filtered_seg2[j, i, :, :])).int().cpu())\n",
    "            #cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"img\" + str(i)+\".png\", (torch.squeeze(filtered_image)[i, :, :]).int().cpu().numpy().astype(np.uint16))\n",
    "\n",
    "            # make 8-bit image\n",
    "            im_max = torch.max((torch.squeeze(filtered_seg2[j, i, :, :])))\n",
    "            print(\"max : \", im_max)\n",
    "            im_min = torch.min((torch.squeeze(filtered_seg2[j, i, :, :])))\n",
    "            print(\"min : \", im_min)\n",
    "            image_8b = (( (torch.squeeze(filtered_seg2[j, i, :, :])) - im_min)/(im_max - im_min)*255).int()\n",
    "            cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\me\\\\\" + \"2_seg\" + str(j)+ \"_\"+  str(i)+ \".png\", (image_8b.cpu().numpy().astype(np.uint8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max :  tensor(1.484234571457, device='cuda:0')\n",
      "min :  tensor(-0.591008841991, device='cuda:0')\n",
      "max :  tensor(1.351230502129, device='cuda:0')\n",
      "min :  tensor(-0.517472445965, device='cuda:0')\n",
      "max :  tensor(1.442975997925, device='cuda:0')\n",
      "min :  tensor(-0.860609471798, device='cuda:0')\n",
      "max :  tensor(0.771845400333, device='cuda:0')\n",
      "min :  tensor(-0.962147474289, device='cuda:0')\n",
      "max :  tensor(1.060355901718, device='cuda:0')\n",
      "min :  tensor(-1.173315286636, device='cuda:0')\n",
      "max :  tensor(0.924049437046, device='cuda:0')\n",
      "min :  tensor(-0.896401703358, device='cuda:0')\n",
      "max :  tensor(2.154980182648, device='cuda:0')\n",
      "min :  tensor(-1.090263247490, device='cuda:0')\n",
      "max :  tensor(1.798285365105, device='cuda:0')\n",
      "min :  tensor(-0.843926906586, device='cuda:0')\n",
      "max :  tensor(1.972466468811, device='cuda:0')\n",
      "min :  tensor(-1.306116580963, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pytorch_model = stackedPyConv()\n",
    "\n",
    "pytorch_model.conv1.weight = nn.Parameter((custom_model.conv1.weight).view(2, 1, 5, 5))\n",
    "pytorch_model.conv1.bias = nn.Parameter(torch.squeeze((custom_model.conv1.bias)))\n",
    "pytorch_model.conv2.weight = nn.Parameter((custom_model.conv2.weight).view(3, 2, 5, 5))\n",
    "pytorch_model.conv2.bias = nn.Parameter(torch.squeeze((custom_model.conv2.bias)))\n",
    "\n",
    "filtered_image = pytorch_model(test_image_standardized)\n",
    "\n",
    "\n",
    "size_batch = test_image.size()[0]\n",
    "out_channel = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=size_batch, ncols=out_channel, sharex=True, sharey=True, figsize=(8, 2))\n",
    "with torch.no_grad():\n",
    "    for i in range(out_channel):\n",
    "        for j in range(size_batch):\n",
    "            ax = fig.add_subplot(size_batch, out_channel, i+1 + j*out_channel, xticks=[], yticks=[])\n",
    "            plt.imshow((torch.squeeze(filtered_image[j, i, :, :])).int().cpu())\n",
    "            #cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"img\" + str(i)+\".png\", (torch.squeeze(filtered_image)[i, :, :]).int().cpu().numpy().astype(np.uint16))\n",
    "\n",
    "            # make 8-bit image\n",
    "            im_max = torch.max((torch.squeeze(filtered_image[j, i, :, :])))\n",
    "            print(\"max : \", im_max)\n",
    "            im_min = torch.min((torch.squeeze(filtered_image[j, i, :, :])))\n",
    "            print(\"min : \", im_min)\n",
    "            image_8b = (( (torch.squeeze(filtered_image[j, i, :, :])) - im_min)/(im_max - im_min)*255).int()\n",
    "            cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\py\\\\\" + \"img\" + str(j)+ \"_\"+  str(i)+ \".png\", (image_8b.cpu().numpy().astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_channels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d4a478315724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mconv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv weigths size : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv1 weigths size : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'in_channels' is not defined"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(in_channels, out_channels, size_filter, stride=1, padding=1)\n",
    "conv2 = nn.Conv2d(out_channels, out_channels, size_filter, stride=1, padding=1)\n",
    "\n",
    "print(\"conv weigths size : \", conv.weight.size())\n",
    "print(\"conv1 weigths size : \", conv1.weight.size())\n",
    "print(\"conv bias size : \", conv.bias.size())\n",
    "print(\"conv1 bias size : \", conv1.bias.size())\n",
    "conv1.weight = nn.Parameter((conv.weight).view(out_channels, in_channels, size_filter, size_filter))\n",
    "conv1.bias = nn.Parameter(conv.bias.view(out_channels))\n",
    "conv2.weight = nn.Parameter((conv_bis.weight).view(out_channels, out_channels, size_filter, size_filter))\n",
    "conv2.bias = nn.Parameter(conv_bis.bias.view(out_channels))\n",
    "[test_image_standardized, mean_channels, std_channels] = standardize_input(test_image)\n",
    "print(\"images size : \", test_image_standardized.size())\n",
    "filtered_image = conv1(test_image_standardized)\n",
    "filtered_image_bis = conv2(filtered_image) \n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=out_channels, sharex=True, sharey=True, figsize=(8, 2))\n",
    "with torch.no_grad():            \n",
    "    for i in range(out_channels):\n",
    "        for j in range(size_batch):\n",
    "            ax = fig.add_subplot(size_batch, out_channels, i+1 + out_channels*j, xticks=[], yticks=[])\n",
    "            plt.imshow((torch.squeeze(filtered_image_bis[j, i, :, :])).int().cpu())\n",
    "            # make 8-bit image\n",
    "            im_max = torch.max((torch.squeeze(filtered_image_bis[j, i, :, :])))\n",
    "            print(\"max : \", im_max)\n",
    "            im_min = torch.min((torch.squeeze(filtered_image_bis[j, i, :, :])))\n",
    "            print(\"min : \", im_min)\n",
    "            image_8b = (( (torch.squeeze(filtered_image_bis[j, i, :, :])) - im_min)/(im_max - im_min)*255).int()\n",
    "            cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\py\\\\\" + \"img\" + str(j)+ \"_\"+ str(i) + \".png\", (image_8b.cpu().numpy().astype(np.uint8)))\n",
    "\"\"\"        \n",
    "with torch.no_grad():\n",
    "        filtered_image3 = (torch.squeeze(filtered_image)[2, :, :]).int().cpu().numpy()\n",
    "        cv2.imwrite(\"C:\\\\Users\\\\root\\\\Desktop\\\\filtered_image3.png\", filtered_image3.astype(np.uint16))\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True, figsize=(8, 2))\n",
    "ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[])\n",
    "test_image = ( (test_image - torch.min(test_image))/(torch.max(test_image) - torch.min(test_image))*255).int()\n",
    "plt.imshow((torch.squeeze(test_image)).permute(1, 2, 0).cpu())\n",
    "\n",
    "cv2.imwrite(\"D:\\\\autoencoder_data\\\\test\\\\\" + \"gt_img.png\", ((torch.squeeze(test_image)).permute(1, 2, 0).cpu().numpy().astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
