{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch.autograd as ag\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "torch.set_printoptions(precision=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "0 torch.Size([22, 3, 128, 128])\n",
      "1 torch.Size([22, 3, 128, 128])\n",
      "2 torch.Size([22, 3, 128, 128])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntransform = transforms.Compose([\\n    transforms.Pad(12, padding_mode='reflect'),\\n    transforms.ToTensor()])\\n\\ntrainset = torchvision.datasets.Flickr8k(root='./data/flickr', ann_file = './data/flickr/file.csv', transform=transform)\\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        path, dirs, files = next(os.walk(self.root_dir))\n",
    "        file_count = len(files)\n",
    "        return file_count\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        path, dirs, files = next(os.walk(self.root_dir))\n",
    "        img_name = os.path.join(self.root_dir, files[idx])\n",
    "        image = io.imread(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "\n",
    "        return image\n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in images to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, images):\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        images = images.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(images)\n",
    "\n",
    "    \n",
    "def show_image_batch(images_batch):\n",
    "    \"\"\"Show image for a batch of samples.\"\"\"\n",
    "    batch_size = len(images_batch)\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "    plt.title('Batch from dataloader')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Load training dataset\n",
    "\n",
    "#mirror_padding_transform = transforms.Compose([transforms.ToPILImage(), transforms.Pad(padding=12, padding_mode='reflect'), transforms.ToTensor()])\n",
    "transformed_dataset = ImageDataset(root_dir='./data/intensity/', \n",
    "                                           transform=transforms.Compose([\n",
    "                                            RandomCrop(128), ToTensor()])\n",
    "                                  )\n",
    "print(transformed_dataset[1].size())\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=22, shuffle=True, num_workers=0)\n",
    "\n",
    "for i_batch, batch_images in enumerate(dataloader):\n",
    "    print(i_batch, batch_images.size())\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 2:\n",
    "        plt.figure()\n",
    "        show_image_batch(batch_images)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(12, padding_mode='reflect'),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.Flickr8k(root='./data/flickr', ann_file = './data/flickr/file.csv', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass GaussianDistribution(torch.autograd.Function):\\n    @staticmethod\\n    def forward(ctx, input, var, phi, nScale, nChannel):\\n        batch_size = input.size(0)\\n        h = input.size(-1)\\n        w = input.size(-2)\\n        ctx.save_for_backward(input, var, phi)\\n        #print(\"input : \", input)\\n        coeff = torch.sqrt(1.0 / (2 * np.pi * var))\\n        #print(\"coeff : \", coeff)\\n        input_resized = input.repeat((nScale, 1, 1, 1, 1))\\n        #print(\"input : \", input_resized)\\n        exponent = (-0.5*(input_resized ** 2)/var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w))\\n        #print(\"exponent : \", exponent)\\n        coeffs_resized = coeff.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        #print(\"coeffs : \", coeffs_resized)\\n        gaussian = coeffs_resized * torch.exp(exponent)\\n        #print(\"gaussian : \", gaussian)\\n        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        phi_gaussian = phi_resized*gaussian\\n        sum_phi_gaussian = phi_gaussian.sum(dim=0)\\n        #print(\"sum over scales : \", sum_phi_gaussian)\\n        result = -torch.log2(sum_phi_gaussian).sum()\\n\\n        return result\\n\\n    @staticmethod\\n    def backward(ctx, grad_output):\\n        input, var, phi = ctx.saved_tensors\\n        batch_size = input.size(0)\\n        h = input.size(-1)\\n        w = input.size(-2)\\n        nChannel = var.size(1)\\n        nScale = var.size(0)\\n        \\n        \\n        var_resized = var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        input_resized = input.repeat((nScale, 1, 1, 1, 1))\\n        \\n        d_phi = -torch.log2(1.0/torch.sqrt(2.0*np.pi*var_resized)*(torch.exp(-0.5*input_resized**2/var_resized))).sum(dim = [3, 4])\\n        d_var = -torch.log2(phi_resized*(1.0/(np.sqrt(2.0*np.pi)*var_resized)*torch.exp(-0.5*input_resized**2/var_resized))*(1.0 + input_resized**2/var_resized)).sum(dim = [3, 4])\\n        d_xq = -torch.log2((phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\\n        print(\"d_xq : \", (phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\\n        \\n        return grad_output*d_phi, grad_output*d_var, grad_output*d_xq\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define additionnnal functions\n",
    "def periodic_shuffling(T, C):\n",
    "    T_copy = T.clone()\n",
    "    batch_size = T.size()[0]\n",
    "    H = T.size()[2]\n",
    "    W = T.size()[3]\n",
    "    T = T.view(batch_size, C, H*2, W*2)\n",
    "    \"\"\"\n",
    "    for k in range(C):\n",
    "        for i in range(2*H):\n",
    "            for j in range(2*W):\n",
    "                T[:, k, i, j] = T_copy[:, C*((j&1)<<1)+C*(i&1)+k, i>>1, j>>1]\n",
    "    \"\"\"\n",
    "                \n",
    "    T[:, :, ::2, ::2] = T_copy[:, 0:C, :, :]\n",
    "    T[:, :, 1::2, ::2] = T_copy[:, C:2*C, :, :]\n",
    "    T[:, :, ::2, 1::2] = T_copy[:, 2*C:3*C, :, :]\n",
    "    T[:, :, 1::2, 1::2] = T_copy[:, 3*C:4*C, :, :]\n",
    "\n",
    "    return T\n",
    "    \n",
    "    \n",
    "def mirror_padding(x, padding_size):\n",
    "    up_line = x[:, :, 0:padding_size, :].flip(2)\n",
    "    left_col = x[:, :, :, 0:padding_size].flip(3)\n",
    "    right_col = x[:, :, :, -padding_size:].flip(3)\n",
    "    bottom_line = x[:, :, -padding_size:, :].flip(2)\n",
    "    left_up_corner = left_col[:, :, 0:padding_size, :].flip(2)\n",
    "    right_up_corner = right_col[:, :, 0:padding_size, :].flip(2)\n",
    "    left_bottom_corner = left_col[:, :, -padding_size:, :].flip(2)\n",
    "    right_bottom_corner = right_col[:, :, -padding_size:, :].flip(2)\n",
    "\n",
    "    x_mirror_pad = torch.cat((torch.cat((left_up_corner, up_line, right_up_corner), 3), torch.cat((left_col, x, right_col), 3), torch.cat((left_bottom_corner, bottom_line, right_bottom_corner), 3)), 2)\n",
    "    return x_mirror_pad\n",
    "    \n",
    "\n",
    "def normalize_input(x):\n",
    "    mean_channels = torch.mean(1.0*x, [2,3])\n",
    "    mean_channels_images = (mean_channels.repeat_interleave(x.size()[2]*x.size()[3])).view(x.size()[0], x.size()[1], x.size()[2], x.size()[3])\n",
    "    x_centered = x - mean_channels_images\n",
    "    max_value = torch.max(x)\n",
    "    min_value = torch.min(x)\n",
    "    radius = max(max_value, abs(min_value))\n",
    "    x_centered_normalized = x_centered/radius\n",
    "    return x_centered_normalized, radius, mean_channels\n",
    "    \n",
    "def denormalize_output(x, radius, mean_channels):\n",
    "    x_denormalized = x*radius\n",
    "    mean_channels_images = (mean_channels.repeat_interleave(x.size()[2]*x.size()[3])).view(x.size()[0], x.size()[1], x.size()[2], x.size()[3])\n",
    "    x_denormalized_centered = x_denormalized + mean_channels_images\n",
    "    return x_denormalized_centered\n",
    "\n",
    "\n",
    "\n",
    "def compute_gsm(x, var, phi, nScale):\n",
    "    gsm = 0.0\n",
    "    \n",
    "    phi = torch.abs(phi)\n",
    "    var = torch.abs(var)\n",
    "    phi_s_sum = torch.sum(phi, 0).unsqueeze(0)\n",
    "    phi_norm = phi/phi_s_sum\n",
    "    \n",
    "    for s in range(nScale):\n",
    "        var_s = var[s, :].view(1, -1, 1, 1)\n",
    "        phi_s = phi_norm[s, :].view(1, -1, 1, 1)\n",
    "        gaussian = phi_s*(1.0/(torch.sqrt(2*np.pi*var_s)))*torch.exp(-0.5*(x**2/var_s))\n",
    "        gsm += gaussian\n",
    "    return gsm\n",
    "\n",
    "\n",
    "def sum_gsm(x, var, phi, nScale):\n",
    "    gsm = 0.0\n",
    "    \n",
    "    phi = torch.abs(phi)\n",
    "    var = torch.abs(var)\n",
    "    phi_s_sum = torch.sum(phi, 0).unsqueeze(0)\n",
    "    phi_norm = phi/phi_s_sum\n",
    "    \n",
    "    for s in range(nScale):\n",
    "        var_s = var[s, :].view(1, -1, 1, 1)\n",
    "        phi_s = phi_norm[s, :].view(1, -1, 1, 1)\n",
    "        gaussian = phi_s*(1.0/(torch.sqrt(2*np.pi*var_s)))*torch.exp(-0.5*(x**2/var_s))\n",
    "        gsm += gaussian\n",
    "    #gsm_sum = (torch.log2(gsm)).sum()\n",
    "    gsm_sum = gsm.sum()\n",
    "    return gsm_sum\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    h = x.size(-1)\n",
    "    w = x.size(-2)\n",
    "    #print(\"input : \", input)\n",
    "    coeff = torch.sqrt(1.0 / (2 * np.pi * var))\n",
    "    #print(\"coeff : \", coeff)\n",
    "    x_resized = x.repeat((nScale, 1, 1, 1, 1))\n",
    "    #print(\"input : \", input_resized)\n",
    "    exponent = (-0.5*(x_resized ** 2)/var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w))\n",
    "    #print(\"exponent : \", exponent)\n",
    "    coeffs_resized = coeff.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "    #print(\"coeffs : \", coeffs_resized)\n",
    "    gaussian = coeffs_resized * torch.exp(exponent)\n",
    "    #print(\"gaussian : \", gaussian)\n",
    "    phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "    phi_gaussian = phi_resized*gaussian\n",
    "    sum_phi_gaussian = phi_gaussian.sum(dim=0)\n",
    "    #print(\"sum over scales : \", sum_phi_gaussian)\n",
    "    result = -torch.log2(sum_phi_gaussian).sum()\n",
    "\n",
    "    return result\n",
    "    \"\"\"\n",
    "    \n",
    "def compute_mask(nb_ones, dims):\n",
    "    mask = torch.zeros(dims)\n",
    "    indices = np.arange(nb_ones)\n",
    "    mask_flatten = mask.view(-1, 1, 1, 1)\n",
    "    mask_flatten[indices] = 1\n",
    "    mask_reshaped = mask_flatten.view(dims)\n",
    "    return mask_reshaped\n",
    "\n",
    "\n",
    "def entropy_rate(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.01, 0.01).cuda()        \n",
    "    gsm_sum = torch.zeros(len(u)).cuda()\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm_sum_i = sum_gsm(x, var, phi, 6)\n",
    "        gsm_sum[i] = gsm_sum_i\n",
    "\n",
    "    integral_u = torch.trapz(gsm_sum, u)\n",
    "    #print(\"gsm sum : \", gsm_sum)\n",
    "    #print(\"integral over u : \", integral_u)\n",
    "    entropy = -torch.log2(integral_u)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n",
    "def mean_bit_per_px(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.05, 0.05).cuda()   \n",
    "    gsm_stacked = []\n",
    "    #u_stacked = []\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm = compute_gsm(x, var, phi, 6)\n",
    "        gsm_stacked.append(gsm)\n",
    "        #u_stacked.append(torch.ones(gsm.size()).cuda()*u[i])\n",
    "    \n",
    "    gsms = torch.stack(gsm_stacked, dim=0)\n",
    "    #us = torch.stack(u_stacked, dim=0)\n",
    "    integral_u = torch.trapz(gsms, dx=0.05, dim=0)\n",
    "    nb_bits = (-torch.log2(torch.clamp(integral_u, min=np.exp(-10**2), max=1))).sum()\n",
    "    if nb_bits < 0:\n",
    "        #print(\"integral u : \", integral_u)\n",
    "        print(\"nb_bits : \", nb_bits)\n",
    "    return nb_bits/reduce(lambda x, y: x*y, list(x_quantized.size()))\n",
    "\n",
    "\"\"\"\n",
    "def entropy_rate(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.05, 0.05).cuda()   \n",
    "    sum_log_gsm = torch.zeros(len(u)).cuda()\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm = compute_gsm(x, var, phi, 6)\n",
    "        sum_log_gsm[i] = (-torch.log2(gsm)).sum()\n",
    "    \n",
    "    entropy = torch.trapz(sum_log_gsm, u)\n",
    "    if entropy < 0:\n",
    "        print(\"negative entropy\")\n",
    "    return entropy\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def clip(x):\n",
    "    x_n = (x - torch.min(x))/(torch.max(x) - torch.min(x))\n",
    "    x_clipped = torch.round(255*x_n).float()\n",
    "    return x_clipped\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MyQuantization(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.round(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output\n",
    "\n",
    "        \n",
    "        \n",
    "class MyClipping(torch.autograd.Function):\n",
    "  \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.round(input).clamp(min=0, max=255)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input = ctx.saved_tensors\n",
    "        return grad_output\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "class GaussianDistribution(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, var, phi, nScale, nChannel):\n",
    "        batch_size = input.size(0)\n",
    "        h = input.size(-1)\n",
    "        w = input.size(-2)\n",
    "        ctx.save_for_backward(input, var, phi)\n",
    "        #print(\"input : \", input)\n",
    "        coeff = torch.sqrt(1.0 / (2 * np.pi * var))\n",
    "        #print(\"coeff : \", coeff)\n",
    "        input_resized = input.repeat((nScale, 1, 1, 1, 1))\n",
    "        #print(\"input : \", input_resized)\n",
    "        exponent = (-0.5*(input_resized ** 2)/var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w))\n",
    "        #print(\"exponent : \", exponent)\n",
    "        coeffs_resized = coeff.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        #print(\"coeffs : \", coeffs_resized)\n",
    "        gaussian = coeffs_resized * torch.exp(exponent)\n",
    "        #print(\"gaussian : \", gaussian)\n",
    "        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        phi_gaussian = phi_resized*gaussian\n",
    "        sum_phi_gaussian = phi_gaussian.sum(dim=0)\n",
    "        #print(\"sum over scales : \", sum_phi_gaussian)\n",
    "        result = -torch.log2(sum_phi_gaussian).sum()\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, var, phi = ctx.saved_tensors\n",
    "        batch_size = input.size(0)\n",
    "        h = input.size(-1)\n",
    "        w = input.size(-2)\n",
    "        nChannel = var.size(1)\n",
    "        nScale = var.size(0)\n",
    "        \n",
    "        \n",
    "        var_resized = var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        input_resized = input.repeat((nScale, 1, 1, 1, 1))\n",
    "        \n",
    "        d_phi = -torch.log2(1.0/torch.sqrt(2.0*np.pi*var_resized)*(torch.exp(-0.5*input_resized**2/var_resized))).sum(dim = [3, 4])\n",
    "        d_var = -torch.log2(phi_resized*(1.0/(np.sqrt(2.0*np.pi)*var_resized)*torch.exp(-0.5*input_resized**2/var_resized))*(1.0 + input_resized**2/var_resized)).sum(dim = [3, 4])\n",
    "        d_xq = -torch.log2((phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\n",
    "        print(\"d_xq : \", (phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\n",
    "        \n",
    "        return grad_output*d_phi, grad_output*d_var, grad_output*d_xq\n",
    "\"\"\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Convolutional Autoencoder with integrated classifer\n",
    "    #taille de l'image d'entrée : 256*256\n",
    "class LossyCompAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossyCompAutoencoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "            # input block\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5, stride=2, padding=0)  \n",
    "        self.conv2 = nn.Conv2d(64, 128, 5, stride=2, padding=0)\n",
    "            # residual block \n",
    "        self.resConv = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "            # output block\n",
    "        self.conv3 = nn.Conv2d(128, 96, 5, stride=2, padding=0)\n",
    "        self.quantization = MyQuantization.apply\n",
    "        #self.gaussian_distribution = GaussianDistribution.apply\n",
    "        \n",
    "\n",
    "       \n",
    "        #Decoder\n",
    "            # subpixel 1\n",
    "        self.subpix1 = nn.Conv2d(96, 512, 3, stride=1, padding=1)\n",
    "            # subpixel 2\n",
    "        self.subpix2 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "            # subpixel 3\n",
    "        self.subpix3 = nn.Conv2d(256//4, 12, 3, stride=1, padding=1)\n",
    "            #residual block\n",
    "        self.deconv1 = nn.Conv2d(512//4, 128, 3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.clip = MyClipping.apply\n",
    "        \n",
    "        #Bit-rate      \n",
    "        self.var = nn.Parameter(torch.Tensor(6, 96))\n",
    "        self.phi = nn.Parameter(torch.Tensor(6, 96))\n",
    "        self.var.data.uniform_(0, 1)\n",
    "        self.phi.data.uniform_(0, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.gsm_pi = torch.nn.Parameter(torch.randn(6, 96))\n",
    "        self.gsm_sigma = torch.nn.Parameter(torch.randn(6, 96))\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask= 1, return_xq=False):\n",
    "        #encoder\n",
    "            # normalization\n",
    "        x, radius, mean_channels = normalize_input(x)\n",
    "            # mirror padding\n",
    "        x = mirror_padding(x, 14)\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            x_copy = x.cpu()\n",
    "            show_image_batch(x_copy)\n",
    "        \"\"\"\n",
    "            # input blocks\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x_c1 = x.clone()\n",
    "            # residual block 1\n",
    "        x = F.relu(self.resConv(x))\n",
    "        x = self.resConv(x)\n",
    "        x += x_c1\n",
    "        x_c2 = x.clone()\n",
    "            # residual block 2\n",
    "        x = F.relu(self.resConv(x))\n",
    "        x = self.resConv(x)\n",
    "        x += x_c2\n",
    "        x_c3 = x.clone()\n",
    "            # residual block 3\n",
    "        x = F.relu(self.resConv(x))\n",
    "        x = self.resConv(x)\n",
    "        x += x_c3\n",
    "            # output block\n",
    "        x = self.conv3(x)\n",
    "            # quantization\n",
    "        x = self.quantization(x)\n",
    "            # add mask for incremental training\n",
    "        x = x*mask\n",
    "        x_quantized = x\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        w = x_quantized.size()[2]\n",
    "        h = x_quantized.size()[3]\n",
    "        gsm = 0.0\n",
    "        for i in range(6)\n",
    "            mi = torch.flatten(x_quantized),torch.diagonal(self.gsm_sigma[s, :].repeat(w*h, 1).squeeze(0))\n",
    "            gsm += \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        #decoder\n",
    "            # subpixel 1\n",
    "        x = self.subpix1(x)\n",
    "        x = periodic_shuffling(x, 512//4)\n",
    "        x_c4 = x.clone()\n",
    "            # residual block 1\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = self.deconv2(x)\n",
    "        x += x_c4\n",
    "        x_c5 = x.clone()\n",
    "               # residual block 2\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = self.deconv2(x)\n",
    "        x += x_c5\n",
    "        x_c6 = x.clone()\n",
    "               # residual block 3\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = self.deconv2(x)\n",
    "        x += x_c6\n",
    "                # subpixel 2\n",
    "        x = self.subpix2(x)\n",
    "        x = F.relu(periodic_shuffling(x, 256//4))\n",
    "                # subpixel 3\n",
    "        x = self.subpix3(x)\n",
    "        x = periodic_shuffling(x, 12//4)\n",
    "                # denormalization\n",
    "        x = denormalize_output(x, radius, mean_channels)\n",
    "                # clipping\n",
    "        x = self.clip(x)\n",
    "\n",
    "        \n",
    "        if return_xq:\n",
    "            return x, x_quantized\n",
    "        else:\n",
    "            return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossyCompAutoencoder(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (resConv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 96, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (subpix1): Conv2d(96, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (subpix2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (subpix3): Conv2d(64, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (deconv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (deconv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "20\n",
      "[Parameter containing:\n",
      "tensor([[0.433917, 0.300561, 0.115457, 0.611158, 0.503199, 0.867046, 0.081413,\n",
      "         0.994191, 0.341177, 0.254626, 0.992581, 0.395400, 0.635579, 0.179447,\n",
      "         0.560953, 0.969822, 0.135934, 0.138402, 0.719406, 0.352917, 0.165131,\n",
      "         0.318904, 0.925729, 0.926519, 0.971557, 0.755813, 0.272945, 0.686835,\n",
      "         0.240829, 0.905103, 0.797390, 0.763012, 0.232060, 0.228218, 0.845708,\n",
      "         0.965169, 0.672259, 0.382998, 0.822027, 0.045329, 0.886572, 0.063115,\n",
      "         0.105807, 0.903246, 0.467528, 0.588878, 0.655388, 0.690164, 0.763729,\n",
      "         0.654764, 0.156481, 0.300116, 0.886713, 0.471975, 0.259799, 0.587165,\n",
      "         0.290907, 0.376236, 0.604416, 0.646301, 0.148865, 0.813576, 0.961739,\n",
      "         0.087750, 0.831949, 0.135932, 0.944746, 0.624000, 0.043058, 0.961566,\n",
      "         0.087885, 0.630216, 0.352916, 0.843873, 0.177084, 0.988915, 0.020346,\n",
      "         0.510329, 0.198042, 0.764840, 0.389885, 0.339271, 0.329548, 0.348365,\n",
      "         0.611461, 0.190903, 0.467784, 0.561184, 0.475057, 0.871008, 0.968977,\n",
      "         0.244407, 0.936262, 0.309352, 0.954896, 0.343450],\n",
      "        [0.243971, 0.716230, 0.186527, 0.240855, 0.985152, 0.830412, 0.489001,\n",
      "         0.682492, 0.107708, 0.419871, 0.093895, 0.690405, 0.542501, 0.098352,\n",
      "         0.566836, 0.077287, 0.864782, 0.520972, 0.861979, 0.895666, 0.033279,\n",
      "         0.338275, 0.461010, 0.749941, 0.199226, 0.045465, 0.370070, 0.178391,\n",
      "         0.688788, 0.292535, 0.582427, 0.693102, 0.869870, 0.590396, 0.458931,\n",
      "         0.606463, 0.857893, 0.310542, 0.527004, 0.306415, 0.761583, 0.498224,\n",
      "         0.541318, 0.985235, 0.045926, 0.118475, 0.899980, 0.622986, 0.394672,\n",
      "         0.403460, 0.117723, 0.214884, 0.568856, 0.213720, 0.836559, 0.096460,\n",
      "         0.814127, 0.259095, 0.074402, 0.177494, 0.658512, 0.750827, 0.124682,\n",
      "         0.372503, 0.183680, 0.254699, 0.203448, 0.363176, 0.944101, 0.104987,\n",
      "         0.173666, 0.029414, 0.861022, 0.287077, 0.184817, 0.881131, 0.596784,\n",
      "         0.707617, 0.082366, 0.366133, 0.161191, 0.585467, 0.131209, 0.942047,\n",
      "         0.756142, 0.999337, 0.551555, 0.810176, 0.707451, 0.104290, 0.192350,\n",
      "         0.214252, 0.466915, 0.110856, 0.139363, 0.070667],\n",
      "        [0.651757, 0.044995, 0.470055, 0.102259, 0.576597, 0.352942, 0.637048,\n",
      "         0.158957, 0.817551, 0.564752, 0.634974, 0.731174, 0.215267, 0.736974,\n",
      "         0.429205, 0.583687, 0.089813, 0.907748, 0.640208, 0.074233, 0.162798,\n",
      "         0.464448, 0.650074, 0.464821, 0.860386, 0.815859, 0.668449, 0.862245,\n",
      "         0.122639, 0.059481, 0.087108, 0.220252, 0.247722, 0.909753, 0.385256,\n",
      "         0.183855, 0.192525, 0.526893, 0.155818, 0.650793, 0.280079, 0.108245,\n",
      "         0.512290, 0.535496, 0.574033, 0.964297, 0.416770, 0.858419, 0.541745,\n",
      "         0.515568, 0.782130, 0.127488, 0.875722, 0.479046, 0.006993, 0.742701,\n",
      "         0.141535, 0.148053, 0.214865, 0.317769, 0.330331, 0.455885, 0.680871,\n",
      "         0.239612, 0.060194, 0.270850, 0.908904, 0.009929, 0.100823, 0.782245,\n",
      "         0.543261, 0.267058, 0.307256, 0.375364, 0.712862, 0.330238, 0.560638,\n",
      "         0.488905, 0.070950, 0.507864, 0.932290, 0.664825, 0.289005, 0.681345,\n",
      "         0.524277, 0.943611, 0.498254, 0.525189, 0.340954, 0.355088, 0.563177,\n",
      "         0.692852, 0.295359, 0.390622, 0.874660, 0.640447],\n",
      "        [0.565760, 0.105207, 0.874264, 0.777030, 0.247681, 0.533317, 0.120617,\n",
      "         0.604461, 0.798626, 0.336304, 0.830187, 0.891560, 0.230368, 0.703067,\n",
      "         0.033699, 0.907135, 0.557863, 0.216317, 0.778890, 0.089664, 0.300870,\n",
      "         0.674764, 0.687337, 0.611423, 0.149578, 0.432684, 0.768895, 0.344160,\n",
      "         0.304447, 0.702088, 0.429972, 0.216573, 0.369903, 0.771880, 0.917497,\n",
      "         0.632206, 0.865449, 0.481209, 0.160826, 0.859534, 0.055943, 0.616804,\n",
      "         0.331360, 0.261319, 0.442003, 0.804205, 0.559381, 0.379559, 0.363546,\n",
      "         0.400567, 0.435578, 0.464497, 0.875690, 0.420368, 0.783262, 0.713375,\n",
      "         0.534668, 0.384920, 0.092853, 0.322012, 0.373750, 0.565566, 0.662219,\n",
      "         0.013454, 0.506105, 0.249958, 0.544223, 0.035859, 0.140638, 0.500490,\n",
      "         0.803073, 0.835046, 0.590358, 0.515546, 0.193891, 0.415544, 0.597282,\n",
      "         0.728843, 0.346383, 0.466259, 0.840381, 0.970291, 0.778009, 0.260662,\n",
      "         0.364993, 0.022081, 0.359932, 0.670826, 0.082093, 0.179682, 0.782588,\n",
      "         0.675176, 0.045440, 0.956194, 0.606312, 0.011767],\n",
      "        [0.522026, 0.298107, 0.583317, 0.986179, 0.893248, 0.855157, 0.974485,\n",
      "         0.040840, 0.843327, 0.011150, 0.880949, 0.764730, 0.278086, 0.145522,\n",
      "         0.558388, 0.117606, 0.074037, 0.494469, 0.700794, 0.211230, 0.598264,\n",
      "         0.287458, 0.002145, 0.473607, 0.520818, 0.812585, 0.644847, 0.489576,\n",
      "         0.969338, 0.722785, 0.810004, 0.974293, 0.707789, 0.757874, 0.457772,\n",
      "         0.154570, 0.370721, 0.086754, 0.234110, 0.664670, 0.212413, 0.347766,\n",
      "         0.665223, 0.069651, 0.060056, 0.488827, 0.077189, 0.948027, 0.478075,\n",
      "         0.699117, 0.803583, 0.506958, 0.606052, 0.425787, 0.648318, 0.607214,\n",
      "         0.533024, 0.991449, 0.102204, 0.571779, 0.605839, 0.089895, 0.853401,\n",
      "         0.332392, 0.410368, 0.735330, 0.026084, 0.822264, 0.060586, 0.711622,\n",
      "         0.757140, 0.776676, 0.984749, 0.132700, 0.537167, 0.670932, 0.395217,\n",
      "         0.392401, 0.163686, 0.510278, 0.009228, 0.884536, 0.732492, 0.153484,\n",
      "         0.772764, 0.648273, 0.455648, 0.962447, 0.106129, 0.855087, 0.454532,\n",
      "         0.774324, 0.914721, 0.150169, 0.220405, 0.748444],\n",
      "        [0.347567, 0.859226, 0.565523, 0.711792, 0.394926, 0.409442, 0.465704,\n",
      "         0.693589, 0.840583, 0.511579, 0.465682, 0.191868, 0.599424, 0.444475,\n",
      "         0.793955, 0.475515, 0.276739, 0.573729, 0.256793, 0.319792, 0.263889,\n",
      "         0.894233, 0.194947, 0.198469, 0.560985, 0.344440, 0.149879, 0.294863,\n",
      "         0.216644, 0.240284, 0.029803, 0.831919, 0.775991, 0.530998, 0.073920,\n",
      "         0.340174, 0.774155, 0.896271, 0.034941, 0.730812, 0.420486, 0.066539,\n",
      "         0.130343, 0.700313, 0.396343, 0.392401, 0.535194, 0.722107, 0.548237,\n",
      "         0.158445, 0.535175, 0.370513, 0.646232, 0.889652, 0.125467, 0.711511,\n",
      "         0.960028, 0.845893, 0.723935, 0.861858, 0.284223, 0.336582, 0.264503,\n",
      "         0.616974, 0.433285, 0.262927, 0.490885, 0.421415, 0.075667, 0.740592,\n",
      "         0.762721, 0.916852, 0.985389, 0.004320, 0.116231, 0.032935, 0.142661,\n",
      "         0.001649, 0.571949, 0.776849, 0.171805, 0.953884, 0.447892, 0.040564,\n",
      "         0.866983, 0.160118, 0.170707, 0.263083, 0.691048, 0.189195, 0.523639,\n",
      "         0.811029, 0.036728, 0.543347, 0.535644, 0.374600]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[4.389793e-01, 2.115843e-01, 4.176879e-01, 3.784935e-01, 3.793238e-01,\n",
      "         5.521641e-01, 8.874232e-01, 6.915923e-01, 8.670020e-02, 5.928512e-01,\n",
      "         1.675697e-01, 8.948330e-01, 9.121304e-01, 8.771091e-01, 6.186311e-01,\n",
      "         5.817425e-02, 3.412109e-01, 2.813644e-01, 6.371078e-01, 9.996912e-01,\n",
      "         2.645928e-01, 6.200203e-01, 3.667417e-01, 4.737137e-01, 8.720979e-01,\n",
      "         8.043195e-01, 3.917076e-01, 8.245267e-01, 9.732093e-01, 5.190239e-01,\n",
      "         8.666241e-01, 6.655870e-01, 5.004664e-01, 1.228908e-01, 9.735477e-02,\n",
      "         7.809371e-01, 8.854349e-01, 4.478031e-01, 4.985193e-01, 9.867721e-01,\n",
      "         6.521974e-01, 1.857383e-01, 9.504805e-01, 9.468336e-01, 6.351532e-01,\n",
      "         5.004913e-01, 5.485557e-01, 3.137086e-01, 5.285979e-01, 8.953227e-01,\n",
      "         5.574569e-01, 2.666876e-01, 3.942286e-01, 2.810510e-01, 5.038497e-01,\n",
      "         2.291963e-01, 7.771254e-02, 7.110926e-01, 1.197616e-01, 2.889961e-01,\n",
      "         2.838222e-01, 3.316546e-01, 9.005577e-01, 2.529567e-01, 4.466112e-01,\n",
      "         9.075843e-01, 9.698176e-01, 4.185615e-01, 5.884744e-01, 2.487663e-01,\n",
      "         8.768541e-01, 8.639197e-01, 6.246209e-01, 3.929719e-01, 9.732203e-01,\n",
      "         8.032194e-01, 7.562509e-01, 9.858376e-01, 2.046006e-01, 5.214690e-01,\n",
      "         4.644958e-01, 8.318607e-01, 6.483465e-01, 7.503564e-01, 7.686488e-01,\n",
      "         7.456005e-01, 6.856178e-01, 7.497560e-01, 5.172405e-01, 9.600753e-02,\n",
      "         8.511658e-01, 5.301914e-01, 9.615958e-01, 7.003240e-01, 2.035146e-01,\n",
      "         5.172800e-01],\n",
      "        [9.415159e-01, 2.567940e-01, 6.734082e-01, 7.194863e-01, 5.852399e-01,\n",
      "         9.313998e-01, 8.682584e-01, 8.072107e-01, 4.157646e-01, 8.817357e-02,\n",
      "         5.254803e-01, 8.455405e-01, 9.875280e-02, 3.222277e-01, 5.840522e-01,\n",
      "         4.028624e-01, 1.399307e-01, 8.144184e-01, 6.550583e-01, 2.128658e-01,\n",
      "         8.509426e-01, 2.344215e-02, 5.148507e-01, 6.983368e-01, 8.866457e-01,\n",
      "         3.954552e-01, 8.796731e-01, 9.758959e-01, 1.035320e-01, 7.006635e-01,\n",
      "         6.393470e-01, 2.181833e-01, 6.733117e-01, 6.416256e-01, 3.939823e-01,\n",
      "         8.576077e-01, 5.023791e-01, 2.079801e-01, 1.410480e-01, 6.973897e-01,\n",
      "         9.606473e-01, 2.119426e-01, 7.636952e-01, 7.317055e-01, 7.347817e-01,\n",
      "         6.701889e-01, 4.241852e-01, 3.364046e-01, 7.949774e-01, 4.490342e-01,\n",
      "         6.142364e-01, 1.371002e-01, 2.907634e-01, 2.175846e-01, 7.379060e-01,\n",
      "         9.196023e-01, 9.844179e-01, 5.057698e-01, 4.322692e-01, 3.936413e-01,\n",
      "         7.081401e-02, 8.804207e-01, 2.992563e-01, 6.721517e-01, 7.944937e-01,\n",
      "         2.808640e-01, 7.562628e-01, 9.807706e-01, 1.313806e-03, 7.914780e-01,\n",
      "         6.945281e-01, 4.545704e-01, 3.172524e-01, 8.777301e-01, 4.998485e-01,\n",
      "         6.906747e-01, 9.534581e-01, 3.916467e-01, 1.472572e-01, 8.857722e-01,\n",
      "         6.185068e-01, 4.676805e-01, 7.979966e-01, 5.687321e-01, 2.779776e-01,\n",
      "         3.150927e-01, 9.759659e-02, 2.927581e-01, 4.262823e-01, 8.690890e-01,\n",
      "         1.486318e-01, 5.801141e-01, 1.737450e-01, 2.285389e-01, 6.592183e-01,\n",
      "         1.893589e-01],\n",
      "        [9.000379e-01, 6.272964e-01, 5.022412e-01, 5.376153e-01, 2.748854e-01,\n",
      "         4.496946e-01, 7.607095e-01, 9.328701e-01, 9.203693e-01, 3.893374e-01,\n",
      "         7.271576e-01, 3.372799e-01, 8.972838e-01, 9.227824e-02, 8.561679e-01,\n",
      "         5.751377e-02, 5.109405e-01, 8.624506e-01, 2.196407e-01, 9.156404e-01,\n",
      "         6.124932e-01, 6.827261e-01, 4.889469e-01, 4.583560e-01, 6.762410e-01,\n",
      "         1.007602e-01, 3.524315e-01, 3.091016e-01, 9.005194e-01, 1.885096e-01,\n",
      "         2.019855e-01, 3.611537e-01, 1.409518e-01, 4.762895e-01, 6.388682e-01,\n",
      "         8.842087e-01, 3.732952e-01, 3.717281e-01, 7.586948e-01, 5.985224e-02,\n",
      "         3.113494e-01, 9.159761e-01, 9.211306e-01, 6.832695e-01, 8.326820e-01,\n",
      "         9.495817e-01, 9.598209e-01, 8.888981e-01, 6.412073e-01, 4.099371e-01,\n",
      "         7.417051e-01, 4.580100e-01, 5.803627e-01, 2.560450e-01, 5.907516e-01,\n",
      "         9.428741e-01, 9.354867e-01, 9.687408e-01, 9.284992e-01, 8.239815e-01,\n",
      "         6.929806e-01, 3.651307e-01, 8.770860e-01, 4.681428e-01, 8.666971e-01,\n",
      "         3.584154e-01, 8.797536e-01, 5.157393e-02, 7.542034e-01, 3.279834e-01,\n",
      "         1.409321e-01, 5.497209e-01, 6.331070e-01, 3.640702e-01, 4.612792e-01,\n",
      "         9.248632e-01, 8.663182e-01, 2.165354e-01, 4.369505e-01, 8.358295e-01,\n",
      "         5.786650e-01, 4.022586e-01, 6.969214e-01, 5.414672e-01, 6.514764e-01,\n",
      "         5.050280e-01, 8.146713e-01, 9.063589e-01, 4.001334e-01, 8.470573e-01,\n",
      "         1.609167e-01, 3.339953e-01, 6.128750e-01, 1.112832e-01, 2.987090e-01,\n",
      "         6.206408e-01],\n",
      "        [1.859212e-01, 8.594107e-01, 5.041724e-01, 6.866695e-01, 9.259607e-01,\n",
      "         7.081859e-01, 5.549412e-01, 5.130996e-01, 7.293614e-01, 9.474345e-01,\n",
      "         5.515829e-01, 1.929783e-01, 6.870917e-01, 3.684625e-01, 1.079052e-01,\n",
      "         4.357074e-01, 7.687819e-01, 7.390917e-01, 5.849713e-02, 2.452363e-01,\n",
      "         7.127601e-02, 3.628597e-01, 3.044094e-01, 3.065989e-01, 2.138261e-01,\n",
      "         9.158552e-01, 4.578621e-01, 4.075337e-01, 2.771295e-01, 7.463255e-01,\n",
      "         3.894371e-01, 7.398118e-01, 3.701529e-01, 2.425110e-01, 4.701356e-01,\n",
      "         4.593075e-01, 7.309340e-01, 6.263995e-01, 3.965672e-01, 1.508049e-01,\n",
      "         6.333050e-01, 8.085478e-01, 3.086687e-01, 8.092856e-01, 8.234857e-01,\n",
      "         8.798499e-01, 5.055121e-01, 8.795244e-01, 2.171972e-01, 4.229805e-01,\n",
      "         7.964342e-01, 5.205984e-01, 9.682763e-01, 3.514248e-01, 2.611864e-01,\n",
      "         3.741553e-01, 9.286739e-01, 5.361198e-01, 7.249139e-01, 2.666837e-02,\n",
      "         7.743340e-01, 1.727954e-01, 2.829030e-01, 7.777835e-01, 1.007809e-01,\n",
      "         8.298159e-04, 6.807716e-01, 1.049086e-01, 3.503436e-01, 5.239105e-01,\n",
      "         2.038366e-02, 2.365741e-01, 8.307987e-02, 8.236846e-01, 8.408074e-01,\n",
      "         6.821147e-01, 3.752722e-01, 2.039151e-01, 6.016639e-01, 4.391541e-01,\n",
      "         8.553596e-01, 1.952668e-01, 9.580110e-01, 5.546687e-01, 3.527188e-01,\n",
      "         1.149143e-01, 7.752034e-01, 4.315066e-01, 2.952093e-01, 4.541297e-01,\n",
      "         6.840680e-01, 1.166852e-01, 8.663827e-01, 3.510960e-01, 7.866218e-01,\n",
      "         2.050135e-01],\n",
      "        [4.082947e-01, 5.555410e-01, 9.769512e-01, 1.881700e-01, 3.611029e-01,\n",
      "         5.582247e-01, 8.496590e-01, 9.789085e-01, 5.469525e-01, 4.082277e-01,\n",
      "         1.379579e-01, 4.071649e-01, 9.435968e-01, 1.077259e-01, 3.187869e-01,\n",
      "         4.748197e-01, 8.571192e-01, 1.087556e-01, 9.342834e-01, 4.592235e-01,\n",
      "         9.846820e-01, 7.877046e-01, 7.215664e-01, 5.515450e-02, 7.218857e-01,\n",
      "         1.659369e-02, 8.741047e-01, 3.637041e-01, 1.101725e-01, 7.112114e-01,\n",
      "         7.302175e-01, 9.683874e-01, 8.615948e-01, 6.237888e-02, 7.367026e-01,\n",
      "         2.938209e-01, 7.568700e-01, 7.784933e-02, 2.888263e-01, 9.090409e-01,\n",
      "         2.911403e-01, 2.673417e-02, 9.293466e-01, 2.489883e-01, 4.011814e-01,\n",
      "         1.233115e-01, 5.644445e-01, 6.239088e-01, 1.388715e-01, 6.982037e-01,\n",
      "         4.661530e-02, 6.690515e-01, 8.008467e-01, 5.634985e-01, 2.091909e-01,\n",
      "         4.436791e-03, 8.281308e-02, 8.530799e-01, 2.554078e-01, 8.285740e-01,\n",
      "         5.457801e-01, 1.453795e-01, 5.518801e-01, 2.392559e-01, 3.144521e-02,\n",
      "         6.518961e-01, 8.739017e-01, 9.287053e-02, 1.397821e-01, 2.500632e-01,\n",
      "         7.407141e-01, 1.183987e-01, 4.352731e-02, 6.827586e-01, 8.499345e-01,\n",
      "         5.262804e-01, 8.445997e-01, 9.007961e-01, 9.606323e-01, 6.113313e-01,\n",
      "         9.301023e-01, 7.267424e-01, 4.380076e-01, 9.943841e-01, 5.426692e-01,\n",
      "         9.954250e-01, 8.754950e-01, 4.741424e-01, 1.628426e-01, 9.059795e-01,\n",
      "         3.300668e-01, 3.061479e-02, 8.695081e-01, 8.883995e-01, 9.499377e-02,\n",
      "         2.126474e-01],\n",
      "        [6.488224e-01, 3.567686e-01, 7.988334e-03, 5.035443e-01, 4.427630e-01,\n",
      "         9.271717e-01, 8.368729e-01, 5.394614e-01, 8.348331e-01, 1.113953e-01,\n",
      "         3.677026e-01, 9.225251e-01, 2.690946e-01, 6.069409e-01, 7.433171e-01,\n",
      "         6.090783e-01, 4.017784e-01, 3.644373e-01, 8.718194e-01, 4.242986e-01,\n",
      "         8.361637e-01, 6.233190e-01, 1.846139e-01, 8.745640e-01, 6.844969e-01,\n",
      "         5.560172e-02, 6.013471e-02, 5.603475e-01, 5.569279e-01, 8.089604e-01,\n",
      "         5.859271e-01, 5.048192e-02, 4.364119e-01, 2.062429e-01, 9.277627e-01,\n",
      "         4.759980e-01, 1.082692e-01, 5.764638e-01, 8.301320e-01, 5.984617e-01,\n",
      "         5.024521e-01, 2.561425e-01, 5.407301e-01, 9.028968e-01, 5.716398e-01,\n",
      "         5.863603e-01, 6.874573e-01, 2.541625e-02, 1.099864e-01, 5.852539e-01,\n",
      "         1.252295e-01, 6.008250e-02, 2.607299e-01, 1.570585e-01, 5.837607e-01,\n",
      "         3.513145e-02, 5.827788e-01, 8.038935e-01, 3.230645e-01, 8.237534e-01,\n",
      "         4.843098e-01, 7.258810e-01, 1.921346e-01, 4.987104e-01, 9.342099e-01,\n",
      "         7.760634e-01, 8.959471e-01, 5.832739e-01, 5.659896e-01, 7.922749e-01,\n",
      "         8.410990e-01, 4.371155e-01, 5.770615e-01, 8.959138e-01, 5.835544e-01,\n",
      "         5.402715e-01, 8.446395e-03, 3.487655e-01, 6.126617e-01, 4.133096e-01,\n",
      "         5.024023e-01, 6.439559e-01, 7.454479e-01, 2.390279e-01, 1.471751e-01,\n",
      "         1.429244e-01, 3.196914e-01, 2.868906e-01, 8.493031e-01, 4.075044e-02,\n",
      "         3.570908e-01, 3.258162e-01, 1.224267e-01, 3.492852e-01, 4.010895e-01,\n",
      "         5.834404e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.063139, -0.016444, -0.109911, -0.103976,  0.096996],\n",
      "          [-0.092814, -0.042468,  0.103928,  0.101220,  0.014236],\n",
      "          [ 0.047449,  0.104060, -0.112362, -0.092578,  0.013824],\n",
      "          [ 0.082677, -0.035656,  0.072501, -0.059321, -0.093899],\n",
      "          [ 0.031356,  0.072256,  0.085378,  0.103305,  0.022689]],\n",
      "\n",
      "         [[ 0.017169, -0.112471,  0.096845, -0.050381,  0.053208],\n",
      "          [-0.064900,  0.025094,  0.088986,  0.086525, -0.089754],\n",
      "          [-0.035780,  0.017735, -0.076665, -0.081023, -0.035232],\n",
      "          [-0.075131,  0.028194,  0.030066, -0.084957,  0.010646],\n",
      "          [-0.114251, -0.087133, -0.081180, -0.084050, -0.086338]],\n",
      "\n",
      "         [[ 0.044419, -0.095089,  0.085449, -0.057283, -0.022191],\n",
      "          [-0.109828,  0.081109,  0.035574, -0.110108,  0.097398],\n",
      "          [ 0.090602, -0.076688, -0.043308, -0.034508, -0.006636],\n",
      "          [ 0.015112, -0.016077, -0.083706, -0.035835, -0.011607],\n",
      "          [-0.096467, -0.077823,  0.021415, -0.088047, -0.016310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.110329, -0.078445,  0.073254,  0.073468, -0.074898],\n",
      "          [-0.088305,  0.025450,  0.000845, -0.104027,  0.080905],\n",
      "          [-0.064036, -0.077466, -0.004760,  0.049260,  0.029326],\n",
      "          [ 0.065834,  0.009935,  0.086728, -0.105313,  0.060187],\n",
      "          [ 0.016596,  0.057985,  0.062761,  0.114728,  0.024413]],\n",
      "\n",
      "         [[-0.080431, -0.101483,  0.045416, -0.000408,  0.102471],\n",
      "          [ 0.083794, -0.101423, -0.011344,  0.015277,  0.027310],\n",
      "          [ 0.043359,  0.011078, -0.040323, -0.007864, -0.102148],\n",
      "          [-0.060227, -0.074144,  0.046726, -0.022294, -0.073818],\n",
      "          [ 0.038309,  0.051589, -0.039057, -0.012389, -0.031769]],\n",
      "\n",
      "         [[ 0.022980,  0.023337,  0.081790,  0.023812,  0.064455],\n",
      "          [ 0.020933, -0.086177, -0.037429,  0.044684, -0.096073],\n",
      "          [-0.091295, -0.047143,  0.023314, -0.058315, -0.000712],\n",
      "          [ 0.047826,  0.069601,  0.058822,  0.047187,  0.078225],\n",
      "          [-0.019282, -0.021519,  0.071592, -0.072867,  0.106252]]],\n",
      "\n",
      "\n",
      "        [[[ 0.006566,  0.092104, -0.056831, -0.051782,  0.042468],\n",
      "          [-0.112130,  0.079542, -0.014117,  0.059147,  0.092668],\n",
      "          [-0.047467,  0.101804, -0.041358, -0.031592,  0.067225],\n",
      "          [-0.091016,  0.078261, -0.055852,  0.010268,  0.018309],\n",
      "          [ 0.039192,  0.013575,  0.090896, -0.052609,  0.007090]],\n",
      "\n",
      "         [[ 0.021353, -0.109084,  0.031156,  0.066059,  0.038038],\n",
      "          [ 0.005105,  0.036387,  0.048355,  0.027092,  0.073829],\n",
      "          [-0.100653,  0.113692, -0.066749,  0.074915, -0.071651],\n",
      "          [-0.095313,  0.105754, -0.101941,  0.104302,  0.008770],\n",
      "          [ 0.084264,  0.006432, -0.055540, -0.069627,  0.044463]],\n",
      "\n",
      "         [[-0.059259, -0.090683, -0.038436,  0.047966,  0.045683],\n",
      "          [ 0.032410, -0.071888, -0.070249, -0.099931,  0.079775],\n",
      "          [ 0.090622, -0.062110, -0.077848, -0.020724,  0.054019],\n",
      "          [-0.005459,  0.059640, -0.106912,  0.034810,  0.106060],\n",
      "          [-0.098103, -0.034070, -0.019509,  0.019415, -0.007924]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.058789, -0.081420,  0.079783, -0.016403,  0.069189],\n",
      "          [-0.015424,  0.100880,  0.078031,  0.096743, -0.099367],\n",
      "          [-0.060738, -0.068219,  0.104882,  0.098549,  0.096277],\n",
      "          [ 0.014736,  0.011846,  0.047448, -0.030034,  0.079399],\n",
      "          [ 0.025612, -0.048064,  0.024533,  0.011207, -0.114211]],\n",
      "\n",
      "         [[-0.094806, -0.039185, -0.079455,  0.067626,  0.109609],\n",
      "          [-0.018151,  0.051022,  0.007997,  0.013480,  0.007691],\n",
      "          [ 0.063665,  0.032267, -0.059852, -0.047844,  0.108657],\n",
      "          [ 0.073873,  0.097191,  0.031548,  0.080892,  0.028191],\n",
      "          [ 0.112915,  0.034037,  0.062870, -0.044313, -0.091525]],\n",
      "\n",
      "         [[ 0.083892, -0.032795,  0.086092, -0.110113,  0.029818],\n",
      "          [ 0.023210,  0.101685, -0.088023,  0.029481,  0.000489],\n",
      "          [-0.063817, -0.039311, -0.086047, -0.078994, -0.108609],\n",
      "          [ 0.032031, -0.082834, -0.105899,  0.061230, -0.076966],\n",
      "          [ 0.022378, -0.044111, -0.047318,  0.066565,  0.008397]]],\n",
      "\n",
      "\n",
      "        [[[-0.073104,  0.015207, -0.080678, -0.091750, -0.085616],\n",
      "          [-0.088963,  0.001527, -0.081154, -0.114930,  0.060129],\n",
      "          [ 0.029289, -0.023893,  0.065458,  0.043507, -0.038056],\n",
      "          [-0.021764, -0.097632,  0.047070,  0.113325,  0.009553],\n",
      "          [ 0.076479, -0.065348, -0.097660, -0.023276, -0.059602]],\n",
      "\n",
      "         [[ 0.012758, -0.055773,  0.021875,  0.060982,  0.113225],\n",
      "          [-0.057903,  0.103076,  0.111822, -0.079853,  0.046750],\n",
      "          [-0.073839,  0.027691,  0.064990,  0.093357, -0.025996],\n",
      "          [ 0.011178,  0.061115,  0.023251,  0.043401,  0.081698],\n",
      "          [-0.019634, -0.070455, -0.030941,  0.107018, -0.015824]],\n",
      "\n",
      "         [[ 0.040137, -0.100299,  0.038791, -0.100690, -0.072592],\n",
      "          [ 0.028603, -0.076811, -0.106012,  0.077902, -0.099574],\n",
      "          [-0.055395,  0.078995, -0.008264, -0.100904, -0.073550],\n",
      "          [ 0.107192,  0.069248, -0.054647,  0.099555,  0.069874],\n",
      "          [ 0.052711,  0.108856, -0.087170,  0.033711, -0.040337]]],\n",
      "\n",
      "\n",
      "        [[[-0.029807, -0.008161, -0.104770, -0.030788, -0.092517],\n",
      "          [-0.090480,  0.076471,  0.097529, -0.110064, -0.083251],\n",
      "          [-0.060041, -0.045586, -0.102004, -0.107872, -0.097687],\n",
      "          [-0.087404,  0.095454, -0.030140,  0.029980,  0.062185],\n",
      "          [-0.082998, -0.018659,  0.068949,  0.004023, -0.041104]],\n",
      "\n",
      "         [[-0.053392, -0.076894, -0.016957, -0.011996,  0.073000],\n",
      "          [-0.109413, -0.031167,  0.063471, -0.002357,  0.110833],\n",
      "          [-0.113899,  0.000904, -0.088748, -0.055938, -0.054512],\n",
      "          [ 0.040983,  0.021880,  0.041071, -0.029230, -0.103108],\n",
      "          [-0.055300, -0.063861, -0.051925, -0.074390, -0.085438]],\n",
      "\n",
      "         [[ 0.056464, -0.010932, -0.077841,  0.112287,  0.079166],\n",
      "          [ 0.039324, -0.088634, -0.115340, -0.041068,  0.003735],\n",
      "          [ 0.016612, -0.110232,  0.107352,  0.082988,  0.013891],\n",
      "          [-0.040523, -0.015470,  0.041349, -0.020230, -0.018212],\n",
      "          [ 0.098228, -0.004120, -0.098587,  0.082365,  0.025617]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.052498,  0.065916,  0.020627,  0.108503, -0.073905,  0.074964,\n",
      "        -0.082137,  0.015227, -0.031496, -0.038877, -0.083423, -0.111231,\n",
      "        -0.038280,  0.002908,  0.101726, -0.058239, -0.032482, -0.046695,\n",
      "        -0.082289,  0.074511,  0.075091, -0.059835, -0.043296,  0.076003,\n",
      "        -0.097100, -0.086401,  0.109118, -0.000580, -0.023907, -0.028089,\n",
      "        -0.094558,  0.011285, -0.061227,  0.094393,  0.059070,  0.044430,\n",
      "         0.018376,  0.025062, -0.034220, -0.069842,  0.049183, -0.025836,\n",
      "        -0.005501, -0.006986, -0.062594, -0.046801,  0.062325, -0.072631,\n",
      "        -0.111075, -0.075181, -0.046777,  0.081113, -0.038826, -0.057161,\n",
      "         0.015785,  0.103846, -0.032215, -0.037587, -0.042875, -0.011925,\n",
      "         0.043506, -0.002440, -0.020310,  0.040297], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 3.451562e-03,  6.919391e-04, -1.050417e-02, -8.221861e-03,\n",
      "           -1.873268e-02],\n",
      "          [-1.969847e-02, -2.260220e-02, -1.189674e-02,  2.321644e-02,\n",
      "            2.094071e-02],\n",
      "          [ 1.520680e-02, -2.114100e-02, -1.244195e-02,  9.384470e-03,\n",
      "            6.458225e-03],\n",
      "          [-5.716413e-03, -1.967653e-02, -2.368346e-02,  1.600183e-02,\n",
      "           -4.975468e-03],\n",
      "          [-1.849320e-02, -2.467510e-02, -1.151672e-02, -8.614084e-03,\n",
      "           -6.928632e-03]],\n",
      "\n",
      "         [[-3.105793e-04,  6.385835e-03, -1.639829e-02, -2.194922e-02,\n",
      "           -2.425469e-02],\n",
      "          [ 1.200536e-02, -2.461320e-03,  1.645309e-02,  1.118740e-02,\n",
      "           -2.178548e-02],\n",
      "          [ 2.225417e-02, -1.759507e-02, -5.160347e-03, -2.200398e-02,\n",
      "            1.833014e-02],\n",
      "          [-1.559690e-02, -2.543604e-03,  2.487886e-02,  9.529833e-04,\n",
      "            1.934357e-02],\n",
      "          [ 6.317334e-03, -1.535152e-02,  8.204011e-03,  5.418122e-03,\n",
      "           -2.493495e-02]],\n",
      "\n",
      "         [[ 3.234241e-03, -1.218824e-02, -4.364738e-03,  2.303195e-02,\n",
      "            8.405479e-03],\n",
      "          [ 2.001934e-02,  2.400078e-02,  7.901968e-03,  7.935775e-03,\n",
      "            8.018555e-03],\n",
      "          [-1.234680e-02,  1.542177e-02,  8.860452e-03,  1.646516e-02,\n",
      "            1.310393e-02],\n",
      "          [-1.873630e-02, -2.057741e-02,  1.076427e-02, -1.494662e-02,\n",
      "            9.904871e-03],\n",
      "          [ 3.200918e-04,  1.749036e-02, -2.104355e-02,  5.746007e-03,\n",
      "           -1.339203e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.240841e-03,  9.081239e-03, -1.627219e-02,  1.570076e-02,\n",
      "            2.375065e-02],\n",
      "          [ 8.430799e-03, -1.218172e-02, -3.305290e-03, -5.702462e-03,\n",
      "           -2.206352e-02],\n",
      "          [-8.003253e-03, -2.059843e-03,  4.622662e-03, -5.611753e-03,\n",
      "            1.600874e-02],\n",
      "          [ 1.496761e-02,  5.480614e-03, -1.061092e-02,  1.973045e-02,\n",
      "            9.522470e-03],\n",
      "          [-1.916570e-02, -4.736250e-03, -2.254248e-02, -1.888011e-02,\n",
      "           -8.424854e-03]],\n",
      "\n",
      "         [[ 1.269393e-02,  2.025077e-03,  1.789580e-02,  9.205339e-03,\n",
      "           -7.357087e-03],\n",
      "          [-8.405665e-03, -2.230960e-02, -3.698952e-04, -2.195736e-02,\n",
      "            1.003943e-02],\n",
      "          [ 1.009482e-02,  1.668498e-02, -1.310568e-03,  8.840008e-03,\n",
      "            4.545679e-03],\n",
      "          [-1.748792e-02,  6.765848e-03,  4.575998e-03, -2.124557e-02,\n",
      "            1.000795e-02],\n",
      "          [-2.020055e-03,  6.913679e-03,  2.212991e-02,  1.901591e-02,\n",
      "           -1.494880e-02]],\n",
      "\n",
      "         [[ 3.291523e-03,  1.540701e-02,  3.498798e-03,  6.204715e-03,\n",
      "            2.250793e-02],\n",
      "          [ 1.926465e-02,  1.029088e-02,  4.013231e-03,  4.048252e-03,\n",
      "           -1.664136e-03],\n",
      "          [ 1.068941e-02, -2.863139e-03, -1.654926e-02,  8.488474e-03,\n",
      "            9.519851e-03],\n",
      "          [-2.419529e-02, -1.248196e-02,  2.123587e-02, -2.130216e-02,\n",
      "           -1.674870e-02],\n",
      "          [-1.932553e-02, -2.169784e-03, -2.184767e-02, -1.617876e-02,\n",
      "           -1.127100e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.024110e-03,  1.429198e-02, -1.969095e-02,  7.960906e-03,\n",
      "            1.130037e-02],\n",
      "          [-7.667005e-03,  4.845440e-03, -1.334200e-03, -1.088903e-02,\n",
      "            1.046666e-02],\n",
      "          [-1.940626e-02,  1.899731e-02,  7.742701e-03, -1.489259e-02,\n",
      "           -1.151219e-02],\n",
      "          [ 1.760069e-02,  4.628684e-03, -8.395799e-04, -1.827307e-02,\n",
      "            1.050889e-03],\n",
      "          [-1.749187e-02,  1.989838e-02,  4.984016e-03,  1.127454e-02,\n",
      "           -2.466950e-02]],\n",
      "\n",
      "         [[-2.137892e-02,  2.300056e-02, -1.678749e-02,  1.839599e-02,\n",
      "            6.017467e-03],\n",
      "          [ 1.788875e-02, -1.300108e-03,  2.216219e-02,  1.453915e-02,\n",
      "           -8.402983e-03],\n",
      "          [-1.407045e-02, -1.001590e-02, -1.712175e-02,  1.464086e-02,\n",
      "           -2.191824e-02],\n",
      "          [ 1.220261e-02,  1.518670e-02, -2.347362e-02, -1.648545e-02,\n",
      "           -6.616548e-03],\n",
      "          [ 1.223200e-02,  8.298652e-03, -1.850350e-02, -1.509675e-02,\n",
      "           -1.484949e-02]],\n",
      "\n",
      "         [[-2.266701e-02,  1.574036e-02, -8.944813e-04,  1.645244e-02,\n",
      "            1.536599e-02],\n",
      "          [-9.759876e-03,  7.743487e-03,  2.092133e-02, -1.688671e-02,\n",
      "            2.278363e-03],\n",
      "          [ 1.591381e-02, -1.212489e-02, -1.193993e-02,  1.377901e-02,\n",
      "           -1.869885e-02],\n",
      "          [-1.392999e-02,  2.206834e-02,  1.864612e-02,  2.473417e-02,\n",
      "            1.934038e-02],\n",
      "          [-1.900095e-02, -1.131434e-02, -2.168396e-03,  3.035869e-03,\n",
      "            1.773403e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.155345e-03, -2.976349e-03,  4.991403e-03, -2.229093e-02,\n",
      "           -1.919684e-02],\n",
      "          [ 2.331548e-02,  1.449056e-02, -1.501049e-02, -5.518276e-03,\n",
      "           -2.185692e-02],\n",
      "          [-6.403515e-03,  1.031880e-02,  1.661597e-02, -1.221342e-02,\n",
      "            1.794952e-02],\n",
      "          [ 1.566154e-02,  1.932804e-03, -4.352938e-03, -1.465214e-02,\n",
      "            2.438126e-02],\n",
      "          [-7.441306e-03,  1.407334e-02, -1.546685e-02,  9.935515e-03,\n",
      "           -1.711687e-02]],\n",
      "\n",
      "         [[-4.522312e-03, -6.585876e-03,  9.284316e-03, -1.624425e-02,\n",
      "           -2.069261e-02],\n",
      "          [-7.155072e-03,  1.236797e-02, -2.146625e-02, -1.350341e-02,\n",
      "            2.365837e-02],\n",
      "          [-1.729853e-02,  1.961674e-02, -2.918268e-03,  3.825366e-03,\n",
      "            1.545538e-02],\n",
      "          [-5.626356e-03, -1.735304e-02, -5.876180e-03, -6.222989e-03,\n",
      "           -2.037327e-02],\n",
      "          [-2.497950e-02, -6.824469e-03,  1.488571e-02, -4.452676e-03,\n",
      "           -1.839421e-02]],\n",
      "\n",
      "         [[ 2.074846e-02,  1.489219e-02,  1.561008e-02,  4.715839e-03,\n",
      "           -3.822107e-03],\n",
      "          [ 1.364274e-02,  2.282491e-02, -1.231841e-02, -6.435713e-03,\n",
      "            1.934498e-02],\n",
      "          [-2.308881e-03, -2.005360e-02, -9.621212e-03,  2.009218e-02,\n",
      "           -1.610807e-02],\n",
      "          [-3.472157e-04, -2.472019e-02,  4.137898e-03, -1.848037e-02,\n",
      "           -1.837653e-02],\n",
      "          [ 6.222900e-03,  2.275214e-02,  4.859697e-03,  2.308503e-03,\n",
      "            1.096285e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.665429e-02,  2.383328e-02,  2.352928e-02, -7.760476e-03,\n",
      "           -1.346391e-02],\n",
      "          [-2.049986e-02, -9.072211e-03, -1.755128e-03,  4.633665e-03,\n",
      "           -2.398384e-02],\n",
      "          [-1.509042e-02, -1.978144e-03,  2.829965e-03, -2.382386e-02,\n",
      "            1.450088e-02],\n",
      "          [-2.299616e-02, -1.788048e-02,  2.297359e-02,  1.724167e-02,\n",
      "           -8.964265e-03],\n",
      "          [-9.324377e-03,  2.190651e-02, -6.447721e-03,  1.253622e-02,\n",
      "            3.463067e-04]],\n",
      "\n",
      "         [[-1.077551e-02,  1.100136e-02,  9.959491e-03, -1.227820e-03,\n",
      "           -1.222597e-02],\n",
      "          [-9.870467e-03,  6.968958e-03,  1.206675e-02, -2.115022e-02,\n",
      "           -3.342265e-03],\n",
      "          [ 2.128988e-02,  1.294026e-02, -3.706450e-03,  9.176781e-03,\n",
      "            8.257037e-03],\n",
      "          [-1.989918e-02, -2.393227e-02, -7.606726e-03,  2.071561e-02,\n",
      "            7.267373e-03],\n",
      "          [-1.455877e-02,  2.420926e-02,  1.731923e-02,  1.082861e-02,\n",
      "            4.751679e-03]],\n",
      "\n",
      "         [[ 9.088876e-03, -6.926846e-03,  1.689220e-02, -1.381785e-02,\n",
      "           -1.895294e-02],\n",
      "          [-2.109403e-02,  2.295967e-02, -7.206719e-03, -2.055194e-02,\n",
      "           -1.460025e-02],\n",
      "          [ 4.169550e-03,  1.589945e-02,  1.512676e-02,  9.336377e-03,\n",
      "           -1.449713e-03],\n",
      "          [-3.723860e-03,  1.175306e-02,  3.942210e-03,  2.045461e-02,\n",
      "            1.801435e-02],\n",
      "          [-7.203156e-03, -1.294292e-02,  7.057188e-03,  9.641228e-03,\n",
      "           -2.272651e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.942147e-02,  1.114802e-02,  1.444153e-02, -4.040226e-03,\n",
      "           -5.378481e-04],\n",
      "          [ 1.603554e-02,  4.442777e-03,  2.184746e-02,  6.441539e-03,\n",
      "           -3.269380e-03],\n",
      "          [ 2.419097e-02,  1.003335e-02,  1.229825e-02,  2.292113e-02,\n",
      "           -2.425000e-02],\n",
      "          [ 1.301983e-02, -4.906692e-04, -2.418810e-02, -2.346699e-02,\n",
      "            9.468438e-03],\n",
      "          [ 1.262739e-02,  2.379633e-02, -2.234373e-02, -2.485953e-02,\n",
      "            1.199052e-02]],\n",
      "\n",
      "         [[-1.834643e-02, -1.120640e-02, -1.566137e-02, -1.505457e-02,\n",
      "            1.082075e-02],\n",
      "          [-5.680244e-03, -1.613330e-03, -1.215946e-02, -1.039989e-04,\n",
      "           -1.259432e-02],\n",
      "          [-1.591531e-02, -9.760725e-03, -1.618353e-02,  2.218167e-02,\n",
      "            2.105352e-02],\n",
      "          [-2.442157e-02,  4.881784e-03, -1.742151e-02, -4.755910e-03,\n",
      "            8.796709e-03],\n",
      "          [-3.053641e-03, -2.483856e-02, -1.698165e-02, -2.168051e-02,\n",
      "            8.799860e-03]],\n",
      "\n",
      "         [[ 1.245891e-02,  5.742839e-03, -9.665585e-03, -2.215885e-02,\n",
      "           -2.115970e-03],\n",
      "          [ 2.363773e-02,  4.167784e-03,  1.134069e-02, -1.143379e-02,\n",
      "            2.243665e-02],\n",
      "          [-1.340752e-02, -1.194548e-02,  1.392283e-02, -7.508550e-03,\n",
      "           -1.701489e-03],\n",
      "          [ 5.501663e-03,  1.488805e-03, -1.066173e-02,  1.110072e-02,\n",
      "           -5.575839e-03],\n",
      "          [ 2.390148e-02, -1.671997e-02, -1.112154e-03,  5.609181e-03,\n",
      "            1.869817e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.223810e-02, -4.711032e-03,  4.371131e-03, -1.936578e-02,\n",
      "            5.230535e-03],\n",
      "          [ 9.197108e-04,  8.071540e-03,  1.979121e-02,  1.924193e-02,\n",
      "            1.010623e-03],\n",
      "          [-2.410588e-02, -1.170578e-02,  1.445107e-02,  3.910577e-03,\n",
      "            1.798627e-02],\n",
      "          [-1.868043e-02,  3.736991e-03,  1.759903e-02,  1.398479e-02,\n",
      "            6.861353e-03],\n",
      "          [ 1.963436e-02, -1.956547e-02, -1.368021e-02,  1.138912e-02,\n",
      "           -1.466426e-02]],\n",
      "\n",
      "         [[ 6.619686e-03,  2.332603e-02, -1.748664e-02,  2.254627e-02,\n",
      "            1.942568e-02],\n",
      "          [ 8.230908e-03,  9.387074e-03,  1.391902e-02,  1.711022e-02,\n",
      "            2.372318e-02],\n",
      "          [ 9.694437e-03,  2.458722e-02,  1.605723e-03,  1.590942e-02,\n",
      "            1.660040e-02],\n",
      "          [-2.307024e-02, -1.530110e-02,  2.425906e-02,  1.055869e-02,\n",
      "           -2.034903e-02],\n",
      "          [-1.572747e-03,  3.751924e-03, -1.809052e-02,  5.119551e-03,\n",
      "            6.789034e-03]],\n",
      "\n",
      "         [[ 1.314759e-02, -1.488687e-02, -1.330860e-02, -1.091192e-02,\n",
      "            1.756447e-02],\n",
      "          [ 2.120081e-04, -9.215575e-03,  1.270203e-02,  1.747548e-02,\n",
      "           -5.056465e-03],\n",
      "          [-2.063328e-02,  9.403529e-03, -2.069125e-02, -1.993132e-02,\n",
      "            4.658446e-03],\n",
      "          [ 1.097244e-02,  6.788796e-03,  1.467733e-02, -1.343420e-02,\n",
      "           -2.394223e-02],\n",
      "          [ 1.653976e-02,  3.815096e-03,  1.935368e-02,  6.526975e-03,\n",
      "            1.905207e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.598162e-03, -1.292588e-02, -1.794324e-02, -2.005197e-02,\n",
      "            1.599705e-02],\n",
      "          [-2.137581e-03,  7.913323e-03,  1.212818e-02, -2.131966e-02,\n",
      "            1.196288e-02],\n",
      "          [-8.645350e-03, -2.293576e-03, -8.797687e-03,  1.494350e-02,\n",
      "           -2.726331e-03],\n",
      "          [ 1.057002e-02,  4.720723e-03,  3.112812e-03,  9.166406e-03,\n",
      "            1.843968e-03],\n",
      "          [ 1.701231e-02,  9.776292e-03, -6.601796e-03,  1.623509e-02,\n",
      "            7.168477e-03]],\n",
      "\n",
      "         [[ 6.680904e-03,  1.332173e-02, -8.835457e-04, -2.172949e-02,\n",
      "            1.277217e-02],\n",
      "          [-1.992444e-02,  2.150011e-02,  6.458158e-03,  1.255725e-02,\n",
      "            1.435654e-02],\n",
      "          [-1.164431e-02, -1.984885e-02,  5.944993e-03,  4.227519e-03,\n",
      "            1.160347e-02],\n",
      "          [ 2.142458e-02, -8.257776e-04,  1.310078e-02,  2.221604e-02,\n",
      "           -4.487153e-03],\n",
      "          [ 2.155536e-02,  2.082275e-02,  1.212060e-02, -1.451001e-05,\n",
      "            8.354338e-03]],\n",
      "\n",
      "         [[ 2.096003e-02,  1.429123e-02, -1.593454e-02, -9.168396e-03,\n",
      "            1.140133e-02],\n",
      "          [-1.164700e-02, -7.055249e-03, -1.500979e-02, -1.692623e-02,\n",
      "            4.109964e-03],\n",
      "          [ 1.136772e-02, -2.008775e-02,  2.209032e-02,  1.684096e-02,\n",
      "            1.364534e-02],\n",
      "          [ 1.284567e-02,  3.419179e-03,  5.483124e-04, -1.472575e-02,\n",
      "           -4.756268e-03],\n",
      "          [ 1.196273e-02, -7.378940e-03, -2.525711e-03, -1.207716e-02,\n",
      "            1.303471e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.656129e-02,  5.493319e-03, -1.055664e-02, -1.201324e-02,\n",
      "            1.526882e-02],\n",
      "          [ 5.166326e-03,  1.878842e-02, -2.010043e-02, -1.594568e-03,\n",
      "            2.150918e-02],\n",
      "          [ 7.517522e-03, -5.222017e-03, -3.813580e-05, -1.360021e-02,\n",
      "           -2.346245e-02],\n",
      "          [ 8.336412e-03,  1.790979e-02, -1.509456e-02, -2.495229e-02,\n",
      "            1.009040e-02],\n",
      "          [-2.358773e-02,  7.746965e-04,  9.283593e-03, -1.229024e-02,\n",
      "            4.034335e-03]],\n",
      "\n",
      "         [[-1.396074e-02,  1.856645e-02,  3.790095e-03, -1.371097e-02,\n",
      "           -1.514741e-02],\n",
      "          [ 1.948755e-02, -1.261855e-02, -1.603653e-02, -1.794482e-03,\n",
      "           -2.400271e-02],\n",
      "          [ 1.028969e-02, -1.393414e-02,  1.949527e-02, -1.222397e-02,\n",
      "           -1.589992e-02],\n",
      "          [ 2.030642e-02, -2.320269e-02, -1.737642e-02,  2.192251e-02,\n",
      "            5.223548e-03],\n",
      "          [ 2.743712e-03, -2.427210e-02, -1.542102e-02,  5.964562e-05,\n",
      "            5.551871e-03]],\n",
      "\n",
      "         [[ 1.569309e-02,  1.699765e-02, -4.734868e-03, -2.043726e-02,\n",
      "           -9.710860e-03],\n",
      "          [ 3.550947e-03, -5.837630e-03, -1.248351e-02,  7.712804e-04,\n",
      "           -1.109876e-04],\n",
      "          [ 7.492211e-04, -4.773170e-03, -8.317824e-03,  2.206972e-02,\n",
      "           -2.933323e-03],\n",
      "          [-4.744958e-03, -3.910998e-03, -2.859438e-03,  1.915223e-02,\n",
      "            2.278592e-02],\n",
      "          [-9.848803e-03,  2.155694e-02, -1.548346e-02, -1.008307e-02,\n",
      "            1.627897e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.194323e-02, -1.039884e-02,  1.031773e-02, -2.136504e-02,\n",
      "           -1.174443e-02],\n",
      "          [-2.179250e-03,  9.328285e-03, -1.032242e-02,  1.427840e-02,\n",
      "            2.551347e-03],\n",
      "          [ 1.904029e-02, -2.224189e-02,  2.430558e-02,  2.478985e-02,\n",
      "           -1.334418e-02],\n",
      "          [ 2.463566e-02, -1.268079e-02,  2.189895e-02,  4.790101e-03,\n",
      "            6.999535e-03],\n",
      "          [ 2.390053e-03,  5.205372e-03, -2.271436e-02, -1.377769e-02,\n",
      "           -1.999729e-02]],\n",
      "\n",
      "         [[-1.316721e-03,  1.173230e-02,  2.419856e-02, -2.401038e-02,\n",
      "           -1.437117e-02],\n",
      "          [-1.017150e-02, -1.838363e-02, -6.644050e-03,  3.497496e-03,\n",
      "           -3.720650e-03],\n",
      "          [-2.150114e-02,  1.915769e-02, -6.888833e-03,  1.571322e-03,\n",
      "            2.008403e-03],\n",
      "          [-6.614381e-03,  1.343840e-02,  8.411733e-03, -5.715657e-03,\n",
      "           -2.102146e-02],\n",
      "          [-7.255264e-04,  3.450831e-03, -2.392026e-02,  8.331573e-03,\n",
      "            5.785206e-03]],\n",
      "\n",
      "         [[-1.793209e-03, -7.023327e-04,  1.211475e-02,  7.790675e-03,\n",
      "            6.535979e-03],\n",
      "          [-6.268397e-03,  2.151305e-03, -1.324536e-02,  1.196145e-02,\n",
      "           -1.159729e-02],\n",
      "          [-1.206540e-02, -1.120429e-02, -1.154998e-02,  1.798149e-02,\n",
      "           -1.851474e-02],\n",
      "          [ 1.183837e-02, -1.480635e-02, -2.463617e-02,  1.961291e-03,\n",
      "           -1.845720e-02],\n",
      "          [ 6.930204e-03, -1.647041e-02,  2.668709e-03, -2.421423e-02,\n",
      "            7.620512e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.405703e-02,  4.311215e-03,  6.747751e-03,  2.357308e-03,\n",
      "           -1.055350e-02],\n",
      "          [ 9.461222e-03,  2.177182e-02, -1.011540e-02,  1.868653e-02,\n",
      "           -1.466373e-03],\n",
      "          [-8.936271e-03, -1.009533e-02,  1.274206e-02, -5.930832e-03,\n",
      "           -8.394534e-03],\n",
      "          [ 1.949579e-02, -8.723054e-03, -1.782260e-02, -1.985603e-02,\n",
      "           -1.290604e-02],\n",
      "          [-1.563360e-02, -1.709338e-03,  1.528613e-02, -2.469116e-02,\n",
      "            1.251213e-02]],\n",
      "\n",
      "         [[-1.410646e-02,  2.204392e-03, -7.573646e-03, -1.022392e-02,\n",
      "           -3.814226e-03],\n",
      "          [-1.735694e-02,  2.072963e-02, -1.589662e-02,  6.972877e-03,\n",
      "            4.802188e-03],\n",
      "          [-1.062423e-03,  2.016156e-02, -4.082700e-03,  9.605231e-03,\n",
      "           -2.157303e-02],\n",
      "          [ 1.814208e-02,  2.203444e-02, -6.086081e-04, -2.020198e-02,\n",
      "            6.492874e-03],\n",
      "          [-1.634163e-02,  1.031987e-02,  1.602849e-02,  1.420475e-02,\n",
      "           -1.734471e-02]],\n",
      "\n",
      "         [[-9.419933e-03,  3.061503e-03,  7.419115e-03, -2.012032e-02,\n",
      "           -9.949043e-03],\n",
      "          [-9.681559e-03,  5.507683e-03, -1.087807e-02, -2.343457e-02,\n",
      "            5.886476e-03],\n",
      "          [ 1.368204e-03,  1.651897e-02, -1.928275e-02,  9.160055e-03,\n",
      "            1.475135e-02],\n",
      "          [-1.361732e-02,  1.051073e-02, -7.985989e-03,  1.194313e-02,\n",
      "            1.638090e-02],\n",
      "          [-2.322445e-02, -9.375552e-03,  6.423561e-03,  1.372343e-02,\n",
      "            2.159889e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.317302e-03,  2.214652e-02, -2.462833e-02, -1.014322e-02,\n",
      "            3.599133e-03],\n",
      "          [ 1.719194e-02,  1.129154e-02,  1.162179e-02, -1.633412e-02,\n",
      "            1.270567e-02],\n",
      "          [-9.309884e-03, -8.581057e-03, -2.200742e-02, -2.305143e-02,\n",
      "            2.270933e-02],\n",
      "          [ 9.987669e-03, -7.287722e-03, -2.435880e-02,  1.716630e-02,\n",
      "            1.680328e-02],\n",
      "          [-2.736008e-03, -1.566962e-02,  6.809644e-04, -4.046649e-03,\n",
      "            1.084194e-03]],\n",
      "\n",
      "         [[-6.861439e-03,  1.872615e-02, -2.122425e-02,  1.271109e-02,\n",
      "           -1.437826e-02],\n",
      "          [-1.306939e-02,  1.417955e-02, -1.835823e-02, -1.925732e-02,\n",
      "            3.686544e-03],\n",
      "          [ 9.528907e-03,  7.502036e-03,  1.799655e-02, -3.638957e-04,\n",
      "            2.169618e-02],\n",
      "          [-1.996641e-02, -8.718928e-03, -4.827749e-03,  2.116636e-02,\n",
      "           -1.700894e-02],\n",
      "          [-1.053934e-02,  2.258288e-02,  1.384369e-02,  8.732034e-03,\n",
      "            1.222603e-04]],\n",
      "\n",
      "         [[-2.013659e-02, -2.376117e-02,  1.154847e-02,  2.068277e-02,\n",
      "            1.961724e-02],\n",
      "          [-1.911901e-02,  1.590968e-02, -5.319983e-03, -1.317316e-02,\n",
      "            2.081528e-02],\n",
      "          [ 4.321158e-03, -1.384535e-02, -2.843190e-03, -1.694666e-02,\n",
      "            1.021712e-02],\n",
      "          [ 2.283266e-02, -1.521180e-02, -2.169814e-02, -2.253919e-02,\n",
      "            1.809653e-03],\n",
      "          [ 2.496392e-02,  1.876703e-02,  1.174307e-02, -1.701640e-02,\n",
      "            1.240151e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.023800,  0.015905, -0.020280,  0.006987,  0.001021, -0.018183,\n",
      "        -0.001688, -0.005339,  0.021355,  0.009103,  0.016455, -0.024573,\n",
      "         0.015935,  0.015899,  0.010009,  0.006327, -0.022780, -0.021153,\n",
      "        -0.019955,  0.016776, -0.023249,  0.004075,  0.008635, -0.016695,\n",
      "         0.011360, -0.017922,  0.013696,  0.019683, -0.014003,  0.016141,\n",
      "        -0.004542,  0.006724, -0.001419, -0.015481,  0.016224, -0.005870,\n",
      "         0.019174,  0.014550, -0.023859,  0.010735,  0.022717, -0.024771,\n",
      "         0.003651, -0.000894,  0.016715,  0.008116,  0.011011, -0.003290,\n",
      "        -0.018883,  0.013144, -0.002795, -0.016187, -0.016251,  0.013986,\n",
      "        -0.018236, -0.000131, -0.004713, -0.022920, -0.002322, -0.019626,\n",
      "        -0.015541,  0.006524, -0.009632, -0.002178,  0.016733, -0.011923,\n",
      "         0.012689,  0.015444,  0.003442, -0.015008, -0.019327,  0.005726,\n",
      "        -0.007704, -0.011771, -0.018211,  0.022811,  0.003949,  0.020144,\n",
      "        -0.005093,  0.000839,  0.001805, -0.009613, -0.007817,  0.014585,\n",
      "        -0.010827, -0.006791, -0.020496, -0.023678, -0.015431, -0.012575,\n",
      "         0.000632,  0.003762,  0.012072, -0.005892,  0.011817,  0.014036,\n",
      "         0.024124,  0.006378,  0.005173, -0.008474,  0.014009, -0.011980,\n",
      "         0.008999, -0.015198, -0.022990, -0.012486, -0.006203, -0.001196,\n",
      "        -0.020674, -0.005761, -0.008857,  0.003843, -0.003862,  0.020992,\n",
      "         0.005816,  0.013390,  0.002877,  0.020691,  0.008710,  0.005943,\n",
      "         0.020052,  0.022067,  0.024024, -0.016398, -0.001883, -0.018799,\n",
      "        -0.024479,  0.016452], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.028429,  0.025413, -0.025652],\n",
      "          [ 0.005139, -0.000640,  0.023653],\n",
      "          [-0.013441,  0.022438,  0.002560]],\n",
      "\n",
      "         [[-0.021227, -0.019465, -0.004997],\n",
      "          [ 0.005124, -0.014867,  0.019640],\n",
      "          [ 0.009222, -0.001630,  0.015331]],\n",
      "\n",
      "         [[-0.021533,  0.011061, -0.024846],\n",
      "          [-0.025266, -0.014931, -0.027648],\n",
      "          [ 0.001015, -0.028529,  0.020016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.003557,  0.015470,  0.001390],\n",
      "          [-0.027730,  0.019665,  0.027295],\n",
      "          [-0.028134,  0.013213, -0.010788]],\n",
      "\n",
      "         [[ 0.005184,  0.000617, -0.009183],\n",
      "          [ 0.015183,  0.016703, -0.024818],\n",
      "          [ 0.021730,  0.011103,  0.004756]],\n",
      "\n",
      "         [[-0.019873, -0.017790, -0.006437],\n",
      "          [-0.003610,  0.014737, -0.010149],\n",
      "          [-0.027956,  0.003508, -0.009966]]],\n",
      "\n",
      "\n",
      "        [[[-0.022260, -0.016637,  0.006432],\n",
      "          [-0.018892, -0.007609,  0.004346],\n",
      "          [-0.004529, -0.002594, -0.017050]],\n",
      "\n",
      "         [[-0.024733, -0.027148, -0.029277],\n",
      "          [-0.010091,  0.009466,  0.017744],\n",
      "          [ 0.001815, -0.024990,  0.006485]],\n",
      "\n",
      "         [[-0.028509,  0.010561, -0.019888],\n",
      "          [-0.014747, -0.016123,  0.019231],\n",
      "          [-0.020543,  0.000906, -0.028731]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.007592,  0.007864,  0.003926],\n",
      "          [-0.012798,  0.027833,  0.021371],\n",
      "          [ 0.018541,  0.011667, -0.021651]],\n",
      "\n",
      "         [[ 0.020490,  0.027484, -0.000508],\n",
      "          [ 0.018751, -0.003940,  0.021461],\n",
      "          [ 0.009779,  0.019218, -0.014833]],\n",
      "\n",
      "         [[ 0.006069, -0.023047,  0.011094],\n",
      "          [ 0.011657, -0.012167,  0.008594],\n",
      "          [ 0.014047, -0.000850, -0.001046]]],\n",
      "\n",
      "\n",
      "        [[[-0.014548, -0.006843,  0.011099],\n",
      "          [-0.016901,  0.010805,  0.003277],\n",
      "          [ 0.015004,  0.016079, -0.011596]],\n",
      "\n",
      "         [[-0.014562,  0.005712, -0.024069],\n",
      "          [-0.001757,  0.001016, -0.028992],\n",
      "          [-0.003824,  0.019884,  0.011620]],\n",
      "\n",
      "         [[ 0.002026, -0.007978,  0.007186],\n",
      "          [-0.003616,  0.009801, -0.026428],\n",
      "          [-0.024072,  0.004866,  0.016850]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.018739, -0.004450,  0.002181],\n",
      "          [ 0.012618,  0.005392,  0.015423],\n",
      "          [ 0.006283, -0.013201, -0.020738]],\n",
      "\n",
      "         [[ 0.011815, -0.013117,  0.020415],\n",
      "          [ 0.024168,  0.017951, -0.028654],\n",
      "          [ 0.012892,  0.008186,  0.027589]],\n",
      "\n",
      "         [[-0.026055, -0.019157,  0.010004],\n",
      "          [-0.010272,  0.000781,  0.026215],\n",
      "          [ 0.001449, -0.022324,  0.019741]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.024344,  0.013150, -0.008556],\n",
      "          [-0.002344,  0.025008, -0.013838],\n",
      "          [ 0.021359,  0.019251,  0.004546]],\n",
      "\n",
      "         [[ 0.021410, -0.021164,  0.016800],\n",
      "          [-0.005169,  0.001174, -0.008566],\n",
      "          [ 0.008402,  0.010216, -0.013884]],\n",
      "\n",
      "         [[ 0.027438, -0.019592,  0.021512],\n",
      "          [-0.020235,  0.014215, -0.011434],\n",
      "          [ 0.025817, -0.000148,  0.026839]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.025482, -0.027399,  0.020861],\n",
      "          [-0.003246, -0.026073, -0.013532],\n",
      "          [-0.016955, -0.020206,  0.008809]],\n",
      "\n",
      "         [[-0.013470,  0.011506, -0.003733],\n",
      "          [ 0.028964, -0.026527, -0.005398],\n",
      "          [-0.012853, -0.004673,  0.001451]],\n",
      "\n",
      "         [[ 0.015011, -0.028791, -0.011113],\n",
      "          [-0.023413, -0.019530,  0.008093],\n",
      "          [ 0.006133,  0.028727, -0.017949]]],\n",
      "\n",
      "\n",
      "        [[[ 0.002383,  0.024227, -0.018404],\n",
      "          [-0.002815,  0.019952,  0.017411],\n",
      "          [-0.021281, -0.002141,  0.019622]],\n",
      "\n",
      "         [[-0.019178, -0.007197, -0.026677],\n",
      "          [ 0.018503, -0.002724, -0.029133],\n",
      "          [ 0.006533, -0.018368, -0.026629]],\n",
      "\n",
      "         [[-0.023488,  0.024065, -0.011054],\n",
      "          [ 0.016188,  0.001758,  0.014672],\n",
      "          [-0.023492, -0.000552,  0.009501]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.000403,  0.020395, -0.008108],\n",
      "          [ 0.004456, -0.003135, -0.021837],\n",
      "          [ 0.013884,  0.001461, -0.016143]],\n",
      "\n",
      "         [[ 0.006130,  0.000464, -0.022599],\n",
      "          [-0.017904,  0.028776,  0.020075],\n",
      "          [ 0.002256, -0.027853,  0.004973]],\n",
      "\n",
      "         [[ 0.006098,  0.025086,  0.008204],\n",
      "          [ 0.020968, -0.014059, -0.010867],\n",
      "          [-0.018794,  0.019557, -0.002824]]],\n",
      "\n",
      "\n",
      "        [[[ 0.003019, -0.013078, -0.011988],\n",
      "          [-0.028027,  0.008636, -0.013891],\n",
      "          [ 0.009970,  0.018277,  0.028859]],\n",
      "\n",
      "         [[ 0.002211,  0.026904,  0.005671],\n",
      "          [ 0.013140,  0.026751, -0.006630],\n",
      "          [ 0.010997, -0.014371,  0.006340]],\n",
      "\n",
      "         [[ 0.002820, -0.010535, -0.015517],\n",
      "          [ 0.019115, -0.026194, -0.021607],\n",
      "          [ 0.027979,  0.022571, -0.012957]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.019888,  0.014365, -0.002147],\n",
      "          [ 0.002929,  0.015835, -0.012835],\n",
      "          [-0.005535,  0.022116,  0.014738]],\n",
      "\n",
      "         [[ 0.014906,  0.016415, -0.003274],\n",
      "          [ 0.004818,  0.016521, -0.005464],\n",
      "          [ 0.006487, -0.002993, -0.008047]],\n",
      "\n",
      "         [[ 0.016949, -0.008722, -0.020363],\n",
      "          [ 0.015752, -0.019992, -0.019405],\n",
      "          [-0.017898,  0.023497, -0.001395]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.014404, -0.015905, -0.004693, -0.004008,  0.027080,  0.021250,\n",
      "        -0.028284,  0.013468,  0.015405, -0.010459,  0.001587, -0.016139,\n",
      "        -0.020742, -0.002876, -0.015019, -0.014369, -0.013384, -0.025274,\n",
      "         0.022491, -0.004321, -0.015757, -0.011916,  0.024393,  0.000932,\n",
      "        -0.000525,  0.019485,  0.016520,  0.024866,  0.002674,  0.011054,\n",
      "        -0.013116,  0.017169,  0.016507,  0.024058,  0.002780, -0.016634,\n",
      "        -0.012377, -0.029212,  0.021991,  0.009722,  0.001250, -0.025258,\n",
      "         0.007583,  0.018421,  0.019678,  0.023786,  0.019044,  0.026056,\n",
      "         0.021853,  0.006881,  0.007819, -0.022327, -0.015311,  0.010694,\n",
      "        -0.019432, -0.002427, -0.024672,  0.025768,  0.013938, -0.003509,\n",
      "        -0.026500, -0.009099, -0.025490, -0.018853, -0.016760,  0.023411,\n",
      "         0.028626, -0.027796, -0.002736,  0.014140, -0.010668,  0.026300,\n",
      "        -0.025599, -0.009258,  0.016636,  0.021570,  0.018900, -0.009956,\n",
      "        -0.003673, -0.005982, -0.005036, -0.016696, -0.006671, -0.018633,\n",
      "         0.026194,  0.010592, -0.028109, -0.016849,  0.013079, -0.014683,\n",
      "        -0.012604, -0.026845,  0.013819, -0.002942, -0.010847,  0.022704,\n",
      "         0.018521,  0.013938,  0.019889, -0.029369, -0.010984,  0.027486,\n",
      "         0.016973,  0.024840,  0.008886,  0.022473, -0.012302,  0.006437,\n",
      "         0.011677,  0.023800,  0.008507, -0.020490, -0.026118,  0.015246,\n",
      "         0.005239, -0.026378,  0.002347,  0.024141,  0.007659,  0.005845,\n",
      "         0.025954, -0.019711,  0.024869, -0.022737, -0.011377,  0.011775,\n",
      "        -0.000347, -0.017537], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 8.898919e-03, -1.520611e-03, -1.168445e-02, -1.767653e-02,\n",
      "           -1.446480e-02],\n",
      "          [ 1.476426e-02, -2.732646e-03, -4.012473e-03, -6.666976e-03,\n",
      "           -3.526894e-03],\n",
      "          [-1.439926e-02, -1.118010e-02,  5.686866e-03,  4.084276e-03,\n",
      "           -1.682096e-02],\n",
      "          [-8.225118e-03, -3.342163e-03, -3.635461e-03, -1.421324e-02,\n",
      "            2.443200e-03],\n",
      "          [ 1.443510e-02,  1.469319e-02,  2.520610e-03, -8.077687e-03,\n",
      "            7.632095e-03]],\n",
      "\n",
      "         [[ 2.047811e-04,  9.288406e-03,  3.683696e-03,  1.540446e-02,\n",
      "            5.610468e-03],\n",
      "          [ 7.085992e-03,  6.360462e-03,  9.828569e-03, -9.770808e-03,\n",
      "           -8.947102e-03],\n",
      "          [-7.644669e-03,  1.569063e-02,  1.464147e-02, -3.410541e-04,\n",
      "           -9.497887e-03],\n",
      "          [ 7.920502e-03, -1.715619e-02, -1.475360e-02, -6.577333e-03,\n",
      "            1.099253e-02],\n",
      "          [ 1.138568e-02,  9.115599e-05, -3.423628e-03,  1.336768e-02,\n",
      "            4.690213e-03]],\n",
      "\n",
      "         [[-2.402145e-03,  8.427534e-03,  1.101958e-02,  1.713858e-02,\n",
      "           -2.162629e-03],\n",
      "          [-7.588468e-03, -3.726740e-03,  1.117447e-02, -1.093013e-02,\n",
      "            6.839825e-03],\n",
      "          [ 1.187002e-02, -1.195554e-02,  1.139891e-02,  3.746375e-04,\n",
      "           -2.010649e-03],\n",
      "          [ 1.168137e-02,  1.756356e-02, -1.253630e-02, -1.131182e-02,\n",
      "            4.841311e-03],\n",
      "          [-8.695411e-03, -1.318621e-02,  1.408629e-03, -1.538220e-02,\n",
      "           -6.162415e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.073501e-03, -9.147804e-04, -2.369843e-03, -1.705005e-02,\n",
      "           -1.008951e-02],\n",
      "          [ 1.186384e-02, -1.626041e-02, -5.324898e-03, -1.055833e-03,\n",
      "            3.558157e-03],\n",
      "          [ 8.209342e-03,  1.687879e-02,  9.836962e-03, -1.602119e-02,\n",
      "           -7.045115e-03],\n",
      "          [ 1.058543e-02, -1.447000e-02, -1.362235e-02, -1.324004e-02,\n",
      "           -1.737086e-03],\n",
      "          [ 9.139843e-03,  1.029661e-02,  4.482858e-03,  2.097346e-03,\n",
      "           -5.842653e-03]],\n",
      "\n",
      "         [[-1.168373e-02,  5.728493e-03, -1.268547e-02,  9.044107e-03,\n",
      "            1.445767e-02],\n",
      "          [ 1.380507e-03, -1.425944e-02,  7.891279e-03,  1.055975e-02,\n",
      "           -5.769944e-03],\n",
      "          [ 1.123634e-02, -1.197671e-02,  1.478408e-02,  4.460586e-03,\n",
      "           -1.382312e-03],\n",
      "          [-1.921102e-03, -1.652144e-03,  1.437129e-02,  1.184825e-02,\n",
      "           -3.815757e-03],\n",
      "          [-1.580479e-02,  1.252657e-02, -1.082429e-02, -6.734259e-03,\n",
      "            1.703517e-02]],\n",
      "\n",
      "         [[ 2.393182e-03, -1.313770e-02,  8.643765e-03, -3.829918e-03,\n",
      "            1.803016e-03],\n",
      "          [-1.563345e-02,  6.424244e-03, -2.059471e-04, -1.102219e-02,\n",
      "            6.497668e-03],\n",
      "          [-9.013804e-03,  5.194863e-03, -2.993804e-03,  1.501633e-02,\n",
      "           -2.474711e-03],\n",
      "          [ 1.171159e-03,  9.098504e-03,  1.152726e-02, -4.356629e-03,\n",
      "            1.534879e-02],\n",
      "          [ 8.982223e-03, -9.264166e-03,  1.259503e-02,  1.006256e-02,\n",
      "            8.557212e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.312046e-02, -2.611794e-03, -5.070643e-03, -3.810954e-03,\n",
      "            1.710121e-02],\n",
      "          [-1.456051e-02,  1.817197e-04,  1.539342e-03,  8.397581e-03,\n",
      "           -5.973532e-03],\n",
      "          [-6.760011e-03, -1.545003e-03, -4.400490e-03, -2.046727e-03,\n",
      "           -1.469361e-02],\n",
      "          [-1.216108e-03, -1.438218e-02,  2.765134e-04, -6.479733e-03,\n",
      "           -8.023744e-03],\n",
      "          [ 1.488536e-02, -1.475870e-02, -5.342054e-03,  6.158013e-03,\n",
      "            1.334334e-02]],\n",
      "\n",
      "         [[-8.694181e-03,  8.176569e-03,  1.735921e-02,  6.377429e-03,\n",
      "            8.835167e-03],\n",
      "          [ 8.698851e-04,  7.049534e-03, -8.239024e-03,  6.677546e-03,\n",
      "           -2.243565e-03],\n",
      "          [ 1.406725e-02,  9.613946e-03,  1.112856e-03, -4.710206e-03,\n",
      "            4.096696e-03],\n",
      "          [-1.524429e-02, -1.519026e-02,  1.228117e-02, -1.240263e-02,\n",
      "           -8.975503e-03],\n",
      "          [-1.252360e-02,  1.791434e-03,  5.158069e-03, -1.277928e-02,\n",
      "            2.744200e-03]],\n",
      "\n",
      "         [[ 9.697421e-03,  9.779964e-03,  1.497817e-02, -3.174001e-03,\n",
      "            6.227082e-03],\n",
      "          [ 4.183948e-03, -1.035608e-02, -1.560008e-02,  8.979585e-03,\n",
      "            4.311401e-03],\n",
      "          [ 1.740739e-02, -7.730612e-03,  7.506048e-03, -9.950122e-03,\n",
      "            1.328836e-02],\n",
      "          [-6.354668e-03,  1.625906e-02, -9.650886e-04, -1.704079e-02,\n",
      "           -1.045335e-02],\n",
      "          [ 1.012939e-02,  1.496807e-03,  1.643371e-02, -7.042795e-03,\n",
      "            7.757673e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.010195e-02, -6.497304e-03,  1.726534e-02,  1.665179e-02,\n",
      "           -1.743200e-02],\n",
      "          [-3.757632e-03, -1.739618e-02,  4.443763e-03,  1.039225e-02,\n",
      "           -1.656048e-02],\n",
      "          [ 1.285169e-04, -1.722596e-02, -8.535114e-03, -1.454188e-02,\n",
      "            9.165484e-03],\n",
      "          [-1.297821e-02,  1.282811e-02,  1.500302e-02, -1.596626e-02,\n",
      "           -5.834245e-03],\n",
      "          [ 8.435374e-03, -5.160290e-03,  7.816097e-03,  4.475234e-03,\n",
      "            1.622814e-02]],\n",
      "\n",
      "         [[-4.230030e-04,  2.703443e-05, -8.392573e-03,  7.302471e-03,\n",
      "            6.424909e-03],\n",
      "          [ 3.323790e-03,  6.301599e-03, -1.577052e-02,  4.156863e-03,\n",
      "           -3.543638e-03],\n",
      "          [ 2.360135e-03, -1.713577e-02,  5.035928e-03, -9.350315e-03,\n",
      "           -4.789537e-03],\n",
      "          [ 3.215753e-03,  5.082978e-03,  2.895217e-03, -1.400021e-02,\n",
      "           -9.654937e-03],\n",
      "          [-4.876285e-03, -5.648200e-03, -1.607425e-02, -3.126959e-03,\n",
      "            6.809384e-03]],\n",
      "\n",
      "         [[-1.077579e-02,  1.096940e-02,  1.338128e-03, -1.712356e-02,\n",
      "           -1.011814e-02],\n",
      "          [ 1.850752e-03,  1.147915e-02, -3.408141e-03,  1.757081e-02,\n",
      "           -2.238845e-03],\n",
      "          [-1.013390e-02,  6.656714e-03,  4.605196e-03,  2.665883e-03,\n",
      "           -8.773763e-03],\n",
      "          [ 1.426985e-03,  7.617835e-03, -8.011125e-04,  7.902414e-03,\n",
      "            5.513435e-03],\n",
      "          [-4.529836e-03,  1.606591e-02, -1.563225e-02, -5.350106e-03,\n",
      "            2.451960e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.154010e-02, -1.747681e-02,  7.354356e-04, -6.371140e-04,\n",
      "           -2.216212e-04],\n",
      "          [ 2.135308e-03,  5.804908e-03, -9.276821e-03,  4.974417e-04,\n",
      "           -4.436456e-03],\n",
      "          [-3.088243e-03,  1.123764e-02,  7.297104e-03,  1.029545e-02,\n",
      "           -7.188272e-03],\n",
      "          [-4.427731e-03, -8.517779e-03,  1.037661e-02,  6.035829e-03,\n",
      "           -1.340432e-02],\n",
      "          [-1.670340e-02,  3.488051e-03,  1.307571e-02,  3.945746e-03,\n",
      "           -1.711654e-02]],\n",
      "\n",
      "         [[ 1.609525e-02,  8.071214e-03, -7.785711e-03, -5.653105e-03,\n",
      "           -1.621146e-02],\n",
      "          [ 1.003699e-02,  9.600721e-03, -1.288984e-02,  6.238470e-03,\n",
      "            1.091499e-02],\n",
      "          [-9.747816e-03, -9.290546e-03, -6.809513e-03,  9.455264e-03,\n",
      "           -5.642795e-03],\n",
      "          [-1.543590e-02,  3.612233e-03, -8.763439e-03, -1.130770e-02,\n",
      "           -4.431855e-03],\n",
      "          [-3.430454e-03, -1.284284e-02, -6.782082e-03,  1.694441e-02,\n",
      "            1.759858e-02]],\n",
      "\n",
      "         [[ 5.346932e-03,  1.033613e-02,  2.824254e-04, -1.038895e-02,\n",
      "            9.022627e-03],\n",
      "          [-1.108656e-02,  8.153150e-03, -1.745034e-02, -1.305926e-02,\n",
      "           -5.130488e-04],\n",
      "          [-1.651151e-03, -9.004867e-03,  3.797002e-03, -5.076483e-03,\n",
      "           -1.347270e-02],\n",
      "          [-7.905986e-03, -9.566067e-03, -6.661415e-04,  9.292923e-04,\n",
      "           -6.321296e-03],\n",
      "          [ 1.375118e-03, -1.517099e-02, -2.003891e-03,  4.951671e-03,\n",
      "           -4.890393e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.485287e-02,  9.237645e-03,  1.229378e-02,  1.715829e-02,\n",
      "            1.363862e-02],\n",
      "          [-4.221640e-03,  1.032283e-02,  1.550730e-02, -1.556992e-02,\n",
      "           -5.118027e-04],\n",
      "          [ 4.695762e-03, -1.131403e-02,  3.019644e-03, -1.007926e-02,\n",
      "           -1.367024e-02],\n",
      "          [ 1.684895e-02,  1.063940e-02,  1.191054e-02,  4.946578e-03,\n",
      "           -1.197376e-02],\n",
      "          [-3.018733e-04, -1.116648e-03, -1.645041e-02,  8.656196e-03,\n",
      "            1.402487e-02]],\n",
      "\n",
      "         [[-2.617054e-04, -1.343300e-02, -1.002968e-02,  1.437599e-02,\n",
      "           -1.307189e-02],\n",
      "          [ 7.685950e-03,  2.871007e-03,  9.582285e-03, -1.290167e-02,\n",
      "           -8.604480e-03],\n",
      "          [ 6.225353e-03, -4.330378e-03,  4.523857e-03, -5.620849e-03,\n",
      "            6.666152e-03],\n",
      "          [ 7.722823e-03, -2.987875e-03,  9.630373e-03,  5.487278e-03,\n",
      "           -1.343469e-02],\n",
      "          [ 1.462463e-03,  7.865768e-03, -2.936708e-03, -2.646291e-03,\n",
      "           -8.862737e-03]],\n",
      "\n",
      "         [[-1.259764e-02,  1.329858e-02, -1.197793e-03, -8.576458e-03,\n",
      "           -1.305381e-03],\n",
      "          [-4.854647e-03, -7.601242e-03, -1.634597e-02, -2.790635e-03,\n",
      "            8.922596e-03],\n",
      "          [ 7.816650e-03, -9.163252e-03, -1.634570e-02, -9.860007e-03,\n",
      "            1.508990e-02],\n",
      "          [-5.295623e-03, -1.301356e-02, -8.481006e-03, -1.101779e-02,\n",
      "           -4.989879e-03],\n",
      "          [ 1.089463e-02,  1.026786e-02, -5.614449e-03,  1.119236e-02,\n",
      "           -4.984936e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.454435e-02, -1.256196e-02,  6.001623e-03, -9.531436e-03,\n",
      "           -1.052989e-02],\n",
      "          [ 9.901952e-03,  5.322183e-03,  1.180305e-02,  1.049232e-02,\n",
      "           -9.341645e-03],\n",
      "          [ 1.427370e-02, -1.674734e-02, -1.045504e-02,  7.264454e-03,\n",
      "            1.378406e-02],\n",
      "          [-1.272784e-02,  6.103620e-03, -8.522472e-03,  1.148913e-02,\n",
      "           -3.950426e-03],\n",
      "          [ 4.241671e-04,  1.269468e-02,  2.017815e-03, -4.624262e-03,\n",
      "           -9.989950e-03]],\n",
      "\n",
      "         [[-2.225815e-03,  1.260937e-02, -4.529183e-03,  1.547037e-02,\n",
      "           -7.231125e-03],\n",
      "          [-7.239562e-04,  7.649766e-03, -6.274553e-03, -7.482777e-03,\n",
      "           -1.452935e-02],\n",
      "          [ 1.609576e-02, -2.405178e-04,  1.196993e-02,  3.967013e-03,\n",
      "           -4.789497e-03],\n",
      "          [-2.125597e-03, -2.887744e-03,  1.224334e-02,  1.175783e-02,\n",
      "            1.642052e-02],\n",
      "          [ 1.276509e-02,  1.835827e-03, -1.221379e-02,  7.690649e-03,\n",
      "           -4.566902e-03]],\n",
      "\n",
      "         [[ 6.651511e-03,  4.167063e-03,  1.598361e-02,  9.590942e-03,\n",
      "            1.511443e-02],\n",
      "          [-7.755783e-03, -7.106758e-03,  1.442706e-02,  2.879264e-03,\n",
      "            1.388419e-02],\n",
      "          [-6.505885e-03,  1.696621e-02, -9.373110e-03, -1.187987e-02,\n",
      "           -1.123425e-02],\n",
      "          [-1.339003e-02,  1.305568e-02,  1.571161e-02, -8.573959e-03,\n",
      "            8.155070e-03],\n",
      "          [-6.909842e-03, -1.762908e-02,  1.760137e-02, -1.699113e-02,\n",
      "           -4.848626e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.942550e-03,  7.896423e-04,  3.869385e-03, -1.096795e-02,\n",
      "            1.723194e-03],\n",
      "          [-1.764939e-02,  8.488005e-03,  4.099626e-04,  2.122203e-03,\n",
      "           -9.104485e-03],\n",
      "          [ 8.700928e-03, -1.858143e-03, -3.568549e-03,  1.211297e-02,\n",
      "            1.675533e-03],\n",
      "          [ 7.688787e-03,  5.225929e-03, -1.534178e-02,  2.178526e-03,\n",
      "           -1.135571e-02],\n",
      "          [-1.908628e-03,  1.237485e-02, -2.172240e-03, -6.316747e-03,\n",
      "            1.117144e-02]],\n",
      "\n",
      "         [[-1.269905e-03,  1.873530e-03,  1.481353e-02,  1.311298e-02,\n",
      "            1.601153e-02],\n",
      "          [ 1.393207e-02, -6.024258e-03,  1.190535e-02, -8.521244e-03,\n",
      "           -9.293200e-03],\n",
      "          [-1.466836e-02,  9.604411e-03, -1.336068e-02,  7.027026e-03,\n",
      "            1.393634e-02],\n",
      "          [ 1.276016e-03,  6.657016e-03,  6.343758e-03,  1.029742e-02,\n",
      "            2.980486e-03],\n",
      "          [ 9.773020e-04,  1.356707e-02, -1.507154e-03, -7.513572e-03,\n",
      "           -1.636975e-02]],\n",
      "\n",
      "         [[-9.193109e-03, -1.227844e-02, -1.114654e-02,  7.607352e-03,\n",
      "           -7.762436e-03],\n",
      "          [ 1.391914e-02, -1.642825e-02, -9.346753e-04, -1.131222e-02,\n",
      "            7.584319e-05],\n",
      "          [ 4.315786e-03,  2.857711e-03, -3.019405e-03, -7.259260e-03,\n",
      "            1.433972e-02],\n",
      "          [-6.275375e-03, -1.119291e-02, -5.075745e-03, -1.541801e-02,\n",
      "           -9.367414e-03],\n",
      "          [ 2.736907e-03,  1.274243e-02, -8.659404e-03,  1.317247e-02,\n",
      "            7.107828e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.240926e-02,  1.099572e-02, -8.632560e-03,  1.520348e-02,\n",
      "           -7.996518e-03],\n",
      "          [ 4.316457e-03, -1.065956e-03, -1.283487e-02,  1.327997e-02,\n",
      "           -9.428790e-03],\n",
      "          [-1.260585e-02,  5.440848e-03, -1.108136e-02,  1.347048e-02,\n",
      "            4.846795e-03],\n",
      "          [-1.015618e-02, -1.407185e-02,  7.670153e-03, -6.222247e-03,\n",
      "           -1.723381e-02],\n",
      "          [-3.742740e-03, -1.496822e-04, -3.067079e-03,  1.767751e-02,\n",
      "            9.399408e-03]],\n",
      "\n",
      "         [[-9.786766e-04, -4.439838e-04, -1.244674e-02,  3.588354e-03,\n",
      "           -1.037964e-02],\n",
      "          [-1.203045e-02,  2.835287e-03, -3.713441e-03, -1.527144e-02,\n",
      "            6.106814e-03],\n",
      "          [-2.151110e-03,  4.996594e-03, -4.953964e-03,  6.506156e-03,\n",
      "            3.603868e-03],\n",
      "          [ 7.126667e-04,  8.918129e-03,  1.649516e-02,  7.205028e-04,\n",
      "           -6.026814e-03],\n",
      "          [-1.443937e-02,  1.113745e-02,  1.541263e-02, -6.127544e-05,\n",
      "            7.853359e-03]],\n",
      "\n",
      "         [[ 1.246275e-02,  1.498375e-03, -1.131940e-02,  9.842126e-03,\n",
      "            2.778862e-04],\n",
      "          [-1.595491e-02, -9.201018e-03,  2.333967e-03,  8.030059e-03,\n",
      "           -1.477562e-02],\n",
      "          [ 5.160218e-03, -1.931792e-03,  1.553946e-02,  9.860117e-03,\n",
      "           -1.684279e-02],\n",
      "          [ 1.757092e-02,  5.887127e-03, -5.710564e-03, -6.698187e-03,\n",
      "           -3.494284e-03],\n",
      "          [-1.971357e-03, -1.235795e-02,  7.688981e-03,  1.521514e-02,\n",
      "           -2.875568e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.940971e-03, -5.863548e-03, -7.639761e-03,  1.603006e-02,\n",
      "           -1.448790e-02],\n",
      "          [ 1.029663e-02, -1.566408e-02,  1.199768e-02,  1.434418e-02,\n",
      "            2.530670e-03],\n",
      "          [ 9.387961e-03,  1.458987e-02, -7.860932e-03,  1.360866e-02,\n",
      "            1.523293e-02],\n",
      "          [ 4.683044e-03, -5.156149e-03, -8.655016e-03, -6.813280e-03,\n",
      "           -2.232150e-03],\n",
      "          [-8.484996e-03,  8.838624e-03,  1.436567e-02,  1.090051e-02,\n",
      "           -4.485738e-03]],\n",
      "\n",
      "         [[-8.039326e-03, -1.898265e-03, -1.039996e-02,  1.701175e-02,\n",
      "            5.657267e-03],\n",
      "          [-9.130441e-03,  7.230062e-03, -7.659552e-03,  1.424771e-02,\n",
      "           -1.441198e-02],\n",
      "          [-1.594122e-02, -3.006236e-03,  1.659538e-02,  1.228984e-03,\n",
      "            1.398545e-02],\n",
      "          [-3.894666e-03,  3.523827e-04, -1.336797e-02,  5.663292e-03,\n",
      "            1.553704e-02],\n",
      "          [-2.394537e-03, -1.715048e-02, -7.882862e-03,  2.113391e-03,\n",
      "           -1.048181e-02]],\n",
      "\n",
      "         [[ 1.483364e-03,  1.295984e-02,  1.091458e-02, -1.474313e-02,\n",
      "            1.579538e-02],\n",
      "          [-1.203896e-02,  1.166357e-03,  1.785345e-03, -1.097112e-02,\n",
      "           -1.508626e-02],\n",
      "          [ 1.031151e-02,  5.724320e-03, -1.800368e-03, -3.071502e-03,\n",
      "           -1.758236e-02],\n",
      "          [-5.604277e-03, -4.839396e-03, -3.570721e-03, -1.231622e-03,\n",
      "            1.423016e-02],\n",
      "          [ 1.174854e-03,  1.336881e-02, -1.699762e-02,  2.284996e-03,\n",
      "           -5.376010e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.565309e-03,  6.447809e-03, -1.558156e-02,  6.932274e-03,\n",
      "            8.853447e-03],\n",
      "          [-8.312164e-03,  3.350848e-03, -4.085859e-03,  9.944612e-03,\n",
      "           -1.366880e-03],\n",
      "          [-6.424530e-03, -3.654956e-03,  4.156083e-04, -9.249552e-03,\n",
      "            5.267460e-03],\n",
      "          [ 2.871107e-03, -4.983507e-04, -1.581815e-02,  1.433942e-02,\n",
      "            5.419591e-03],\n",
      "          [ 4.900862e-03,  1.691271e-02, -1.629821e-02,  5.465832e-03,\n",
      "            7.353587e-03]],\n",
      "\n",
      "         [[ 1.517869e-02,  1.252048e-02, -1.212139e-02, -1.563882e-02,\n",
      "           -1.272800e-02],\n",
      "          [ 1.626942e-02, -8.319432e-03,  1.093195e-02,  2.312753e-04,\n",
      "           -1.402958e-02],\n",
      "          [-1.515986e-02, -1.444579e-02, -1.110271e-03, -4.794387e-03,\n",
      "           -1.448735e-02],\n",
      "          [ 1.149257e-02, -1.580790e-03, -1.763348e-03, -4.809894e-03,\n",
      "           -1.462249e-02],\n",
      "          [ 1.545404e-02, -5.379138e-03,  1.154425e-02, -2.441401e-03,\n",
      "            8.969229e-03]],\n",
      "\n",
      "         [[ 2.802361e-03, -3.497088e-03, -4.111153e-03, -6.394280e-03,\n",
      "            1.216439e-02],\n",
      "          [-1.711925e-02, -1.489373e-02, -1.008981e-02,  6.459029e-03,\n",
      "            3.986105e-03],\n",
      "          [-3.028108e-03, -7.560939e-03,  5.524144e-03, -1.489233e-02,\n",
      "           -5.195448e-03],\n",
      "          [-7.007192e-03, -1.692452e-02, -8.251531e-03, -3.954303e-04,\n",
      "            1.299476e-02],\n",
      "          [ 1.512841e-02,  3.282597e-03,  1.724794e-02,  1.445002e-02,\n",
      "           -1.538530e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.499430e-03, -6.198132e-03,  6.158978e-03,  2.344983e-03,\n",
      "            6.673027e-03],\n",
      "          [ 7.021369e-03, -1.173262e-04,  1.449318e-02, -4.569815e-03,\n",
      "           -1.131587e-02],\n",
      "          [-2.326922e-03,  1.390921e-02,  7.610409e-03,  1.099080e-03,\n",
      "           -1.332259e-02],\n",
      "          [-9.206017e-03, -4.379623e-03,  6.924709e-03, -7.000263e-03,\n",
      "           -1.308687e-02],\n",
      "          [-1.394550e-02, -7.868438e-03,  1.759083e-02, -3.866379e-03,\n",
      "           -8.671774e-03]],\n",
      "\n",
      "         [[ 9.855479e-04,  1.194098e-02, -9.143556e-03,  8.153656e-03,\n",
      "           -1.552880e-02],\n",
      "          [-6.774527e-03,  9.591803e-03, -8.359478e-03, -1.032032e-02,\n",
      "            1.129697e-02],\n",
      "          [-1.248061e-02, -1.730458e-02, -1.470942e-03, -9.012576e-04,\n",
      "           -1.497615e-02],\n",
      "          [-1.539060e-02, -5.559770e-03, -3.328775e-03,  7.083254e-03,\n",
      "           -2.138265e-03],\n",
      "          [-1.315542e-03, -1.720747e-03, -1.560816e-02, -9.792648e-03,\n",
      "            1.576059e-04]],\n",
      "\n",
      "         [[ 1.580646e-02,  1.363499e-02, -9.883877e-03,  7.396992e-04,\n",
      "            1.499629e-02],\n",
      "          [-1.623818e-02, -6.203144e-03,  3.137158e-03,  1.231631e-02,\n",
      "            3.204161e-03],\n",
      "          [ 1.766894e-02,  1.182179e-02,  9.016259e-03, -1.696972e-02,\n",
      "           -4.154091e-03],\n",
      "          [-1.724320e-02, -1.680493e-03, -1.106930e-02,  1.742983e-02,\n",
      "            4.941486e-04],\n",
      "          [ 3.955655e-03,  1.018144e-02,  8.350570e-03, -2.459804e-03,\n",
      "            1.108417e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.012836,  0.014901,  0.008044, -0.013298, -0.016885,  0.002239,\n",
      "        -0.009720,  0.003944, -0.001493,  0.000614,  0.001691,  0.003577,\n",
      "         0.001019, -0.013105,  0.009373,  0.016911, -0.001628, -0.014974,\n",
      "         0.000431,  0.011551, -0.011762,  0.007934, -0.005508,  0.008144,\n",
      "         0.006222, -0.008562, -0.012921, -0.007348, -0.006438,  0.006918,\n",
      "        -0.012423, -0.013232,  0.006638, -0.015927,  0.013592,  0.011776,\n",
      "         0.006674,  0.005732,  0.007201,  0.005100,  0.004496,  0.006382,\n",
      "         0.013143, -0.008036,  0.001101, -0.001407, -0.015930,  0.012967,\n",
      "         0.003807,  0.017128, -0.001877,  0.006107,  0.007934, -0.001193,\n",
      "        -0.007132, -0.007481,  0.000441, -0.009759,  0.005999, -0.007990,\n",
      "        -0.014054, -0.004038, -0.011318,  0.014550, -0.001112, -0.010975,\n",
      "         0.003058, -0.000581,  0.007106, -0.002251, -0.017553,  0.001221,\n",
      "         0.001406, -0.009355, -0.016307,  0.015831,  0.001241,  0.003970,\n",
      "         0.015511,  0.008545, -0.005017,  0.005787,  0.001079,  0.004274,\n",
      "         0.013119, -0.001619, -0.016225,  0.013443, -0.004831,  0.001436,\n",
      "         0.015665, -0.006665, -0.014083, -0.012306, -0.012839, -0.011950],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-1.321797e-02,  2.959137e-02,  1.956338e-02],\n",
      "          [-1.645597e-02,  3.307603e-02, -1.127943e-02],\n",
      "          [-6.358698e-05,  2.730795e-02, -1.651572e-02]],\n",
      "\n",
      "         [[ 2.583842e-02, -6.880462e-03,  3.376221e-02],\n",
      "          [ 3.313370e-03,  1.322056e-02, -1.438415e-02],\n",
      "          [ 2.524704e-02,  2.190186e-02,  7.846043e-03]],\n",
      "\n",
      "         [[ 1.898451e-02,  1.609813e-02, -2.421820e-02],\n",
      "          [ 1.337464e-02,  2.045248e-03, -1.500824e-02],\n",
      "          [ 2.460220e-02,  5.521525e-03,  2.580411e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.541624e-02,  1.464485e-02,  7.403191e-03],\n",
      "          [-1.587079e-02, -1.752240e-02, -1.325466e-02],\n",
      "          [ 2.791962e-02,  2.028164e-02,  2.875097e-02]],\n",
      "\n",
      "         [[ 3.287668e-02, -1.243007e-02, -1.538487e-02],\n",
      "          [ 5.018860e-04, -1.275228e-02,  1.541592e-02],\n",
      "          [-8.704796e-03,  1.688149e-02, -2.323430e-02]],\n",
      "\n",
      "         [[ 1.980972e-02, -2.052417e-02, -2.193828e-02],\n",
      "          [ 2.902682e-02,  5.797096e-03,  1.537152e-02],\n",
      "          [ 3.324417e-02, -1.050650e-02,  3.683545e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.909277e-02, -8.776341e-03,  1.944189e-02],\n",
      "          [ 2.682232e-02,  1.667633e-02, -2.950455e-02],\n",
      "          [-2.807997e-02, -2.340082e-02, -2.857582e-02]],\n",
      "\n",
      "         [[-3.383712e-02,  8.252639e-03,  1.043537e-02],\n",
      "          [-2.710782e-04,  7.674266e-03,  4.325025e-04],\n",
      "          [-1.765045e-02,  1.965425e-02, -3.010263e-02]],\n",
      "\n",
      "         [[ 2.284174e-02,  2.566323e-02,  1.491201e-02],\n",
      "          [-4.382195e-03, -1.480598e-02, -1.544510e-02],\n",
      "          [ 1.853857e-02,  1.694860e-02,  2.441189e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.568327e-02, -1.926683e-02, -2.857978e-03],\n",
      "          [ 1.398889e-02, -2.065019e-02,  9.767398e-03],\n",
      "          [ 1.609664e-02, -8.592190e-03,  7.835552e-04]],\n",
      "\n",
      "         [[-1.968597e-02,  2.685834e-03,  2.914809e-03],\n",
      "          [-1.782087e-02, -1.559450e-02, -2.979603e-02],\n",
      "          [-3.331311e-02,  1.729745e-02,  2.575487e-02]],\n",
      "\n",
      "         [[ 2.104974e-02, -1.420530e-02,  1.817197e-02],\n",
      "          [-7.535966e-03,  2.892763e-02, -2.980167e-02],\n",
      "          [ 1.736902e-02,  1.451472e-02,  2.081400e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.144630e-02,  2.303766e-02,  3.108048e-02],\n",
      "          [ 5.887523e-03, -1.387613e-02, -1.549237e-02],\n",
      "          [ 3.131457e-02,  1.905138e-02,  3.155239e-02]],\n",
      "\n",
      "         [[ 1.863482e-02, -3.161234e-02,  1.990168e-02],\n",
      "          [-2.721359e-02,  3.222281e-02, -2.707656e-03],\n",
      "          [-1.228537e-02, -1.427299e-02, -2.885598e-02]],\n",
      "\n",
      "         [[ 2.357830e-02, -2.675688e-02, -1.445507e-02],\n",
      "          [-2.183624e-02,  2.758087e-02, -2.415090e-02],\n",
      "          [-1.207854e-02,  4.386425e-03, -1.948791e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.751476e-02,  3.265264e-02,  6.292313e-03],\n",
      "          [ 1.673583e-02, -1.824114e-02,  2.497691e-02],\n",
      "          [-3.021827e-03,  2.510026e-04,  1.024206e-02]],\n",
      "\n",
      "         [[ 1.980391e-02,  1.147615e-02,  1.984748e-02],\n",
      "          [-8.768724e-03,  1.557716e-02,  1.162284e-02],\n",
      "          [ 1.035446e-02,  1.976569e-02,  1.880035e-02]],\n",
      "\n",
      "         [[-2.303539e-02, -1.843367e-02,  8.617640e-03],\n",
      "          [ 1.568617e-02,  3.753938e-03,  1.591299e-02],\n",
      "          [ 8.247793e-04, -2.246297e-02,  1.207124e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.188257e-02,  9.238951e-03, -3.296977e-02],\n",
      "          [ 3.185815e-02, -2.940451e-02,  2.621568e-02],\n",
      "          [-8.307207e-03, -7.219087e-03,  1.885817e-02]],\n",
      "\n",
      "         [[-7.261857e-03,  2.890950e-02,  3.211553e-02],\n",
      "          [ 1.637096e-02, -1.907987e-02,  1.462511e-02],\n",
      "          [ 1.528414e-02, -2.017029e-03, -1.359031e-02]],\n",
      "\n",
      "         [[ 2.830758e-02, -2.865081e-02,  2.303438e-02],\n",
      "          [-2.970943e-02, -2.052410e-02, -1.980316e-02],\n",
      "          [ 1.623759e-02, -2.670396e-03, -2.589535e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.428152e-03, -1.468580e-03,  1.317389e-02],\n",
      "          [ 7.503536e-03,  1.489446e-04, -1.397945e-02],\n",
      "          [ 6.496336e-03,  3.292674e-02,  1.744889e-04]],\n",
      "\n",
      "         [[ 2.993267e-02, -2.032257e-02,  2.254970e-02],\n",
      "          [-3.027421e-02,  3.945973e-03,  1.901929e-02],\n",
      "          [-3.320975e-02, -3.282918e-02, -9.225875e-03]],\n",
      "\n",
      "         [[ 2.934007e-02, -3.393144e-02,  3.862731e-03],\n",
      "          [ 5.740382e-03,  2.654876e-02,  3.059890e-02],\n",
      "          [ 2.847516e-02,  2.102433e-02,  1.204247e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.918641e-02,  7.777140e-03, -1.656074e-02],\n",
      "          [ 1.099178e-02,  1.792451e-02,  2.713308e-02],\n",
      "          [-1.362498e-02, -1.859717e-02, -3.262793e-02]],\n",
      "\n",
      "         [[-1.577024e-02,  3.242493e-02, -1.343044e-02],\n",
      "          [ 1.661846e-02, -2.365665e-02,  8.629918e-03],\n",
      "          [ 1.816509e-02, -1.468781e-02, -1.244671e-02]],\n",
      "\n",
      "         [[ 7.270060e-03, -8.732615e-03,  1.239147e-02],\n",
      "          [-1.825427e-02, -2.386747e-02, -2.142758e-02],\n",
      "          [-2.353953e-02, -3.326034e-02, -2.682078e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.253060e-02,  5.632319e-03, -1.532461e-02],\n",
      "          [ 7.109985e-03,  4.430603e-03,  1.325184e-02],\n",
      "          [-3.996164e-03,  1.029554e-02, -3.917227e-03]],\n",
      "\n",
      "         [[-7.208591e-03,  2.138522e-03, -6.296860e-03],\n",
      "          [-1.389826e-02, -1.625327e-02,  1.331807e-02],\n",
      "          [-2.481637e-02,  2.663109e-02, -2.505280e-03]],\n",
      "\n",
      "         [[-3.229728e-03, -2.229382e-02, -2.662179e-02],\n",
      "          [ 3.292692e-02, -2.460538e-02, -8.316264e-04],\n",
      "          [-2.909282e-02, -1.131801e-02, -1.327110e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.904511e-03, -3.278996e-02,  8.094002e-03],\n",
      "          [ 3.029141e-02,  1.784099e-02, -2.245313e-02],\n",
      "          [-3.566975e-03,  5.701676e-03, -8.252028e-03]],\n",
      "\n",
      "         [[-5.920652e-03,  2.079428e-02,  6.928869e-03],\n",
      "          [-3.334088e-02,  3.386305e-02,  6.364405e-03],\n",
      "          [-2.785814e-02,  7.817220e-03,  2.162375e-02]],\n",
      "\n",
      "         [[ 1.545221e-02,  1.010336e-02,  3.025681e-02],\n",
      "          [ 1.590325e-02, -3.173193e-02,  1.247230e-02],\n",
      "          [-1.939466e-02,  2.898414e-02, -3.966993e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.120918e-03,  1.101371e-03, -2.586800e-02],\n",
      "          [ 2.121336e-02, -3.042931e-02,  3.436066e-03],\n",
      "          [ 8.595586e-03,  2.727031e-02, -2.157700e-02]],\n",
      "\n",
      "         [[-3.389503e-02,  6.748252e-03, -1.518526e-02],\n",
      "          [ 9.881496e-03,  2.430523e-02,  2.428319e-03],\n",
      "          [ 3.396221e-02, -2.014807e-02,  1.500483e-02]],\n",
      "\n",
      "         [[ 1.875374e-02,  1.441814e-02, -3.554413e-03],\n",
      "          [-2.088603e-02,  3.484450e-03,  1.282368e-02],\n",
      "          [-4.575528e-03,  1.351030e-02, -5.820515e-03]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.011475,  0.013102, -0.016393, -0.024542,  0.024788, -0.005474,\n",
      "        -0.026948,  0.029361, -0.011314, -0.024274, -0.033131, -0.009360,\n",
      "         0.011039,  0.023975,  0.001494, -0.024057,  0.010860,  0.001330,\n",
      "         0.005587, -0.005342,  0.011737, -0.023926,  0.015127, -0.027295,\n",
      "         0.003210, -0.012144,  0.008363, -0.019169, -0.017229,  0.025031,\n",
      "        -0.008242,  0.001126, -0.009062, -0.018155,  0.017213, -0.033770,\n",
      "        -0.021100, -0.019828, -0.033678, -0.022848,  0.027017, -0.025700,\n",
      "        -0.003117,  0.021573,  0.001161, -0.025363, -0.022086, -0.000884,\n",
      "         0.033250,  0.002264, -0.033584, -0.018994,  0.023223, -0.007901,\n",
      "         0.004029,  0.003921,  0.005211,  0.022137, -0.007669, -0.006318,\n",
      "        -0.032584, -0.029836,  0.015479,  0.022206,  0.004390, -0.025680,\n",
      "         0.004499,  0.007869,  0.008129, -0.031861, -0.004907, -0.004733,\n",
      "        -0.014107,  0.014124,  0.016469,  0.031004,  0.012267, -0.013344,\n",
      "        -0.016214, -0.009191,  0.024056, -0.018730,  0.029397,  0.023907,\n",
      "         0.026118,  0.000939, -0.007519,  0.000976,  0.011062,  0.004901,\n",
      "         0.034017,  0.020507, -0.004439, -0.007350, -0.008786,  0.031378,\n",
      "        -0.012144,  0.013947, -0.010551, -0.000173,  0.000151, -0.028150,\n",
      "        -0.001780,  0.017699, -0.008165, -0.025684, -0.022649, -0.027708,\n",
      "         0.014838,  0.000992, -0.000756,  0.019356,  0.028247,  0.007381,\n",
      "         0.024536, -0.028466,  0.008419,  0.000249, -0.007283, -0.033804,\n",
      "         0.028225,  0.017907, -0.026760, -0.005254, -0.011224, -0.021080,\n",
      "        -0.032412, -0.018055, -0.007801,  0.014213,  0.023957,  0.004541,\n",
      "         0.029640, -0.011437,  0.010570,  0.013323,  0.003189,  0.003664,\n",
      "         0.006382,  0.028919, -0.006306,  0.027282,  0.033834,  0.003794,\n",
      "         0.022571,  0.012841, -0.006571, -0.023044,  0.009488, -0.026764,\n",
      "         0.024077, -0.009862,  0.016649, -0.022850,  0.006614,  0.019354,\n",
      "         0.017541,  0.010619, -0.028026,  0.019866, -0.002745,  0.028815,\n",
      "        -0.023317, -0.032326,  0.001504, -0.012097, -0.018026, -0.017027,\n",
      "         0.020596, -0.001374,  0.022508,  0.007539,  0.004781,  0.008400,\n",
      "         0.023365, -0.029182,  0.026677, -0.033439,  0.014382, -0.032978,\n",
      "         0.021060, -0.009049, -0.029660,  0.027192,  0.022191, -0.000127,\n",
      "         0.023547, -0.000148,  0.015740,  0.021242, -0.032560,  0.025114,\n",
      "         0.018175,  0.027237, -0.015268,  0.028173,  0.017725,  0.031966,\n",
      "        -0.024350, -0.008362,  0.021240, -0.021391,  0.001237, -0.001280,\n",
      "         0.024313,  0.012872,  0.027984, -0.015772,  0.021032,  0.030705,\n",
      "         0.022832,  0.010317, -0.018036,  0.022865, -0.028000,  0.031740,\n",
      "         0.010790, -0.031268, -0.028523, -0.006431, -0.013074, -0.011184,\n",
      "         0.003177, -0.028119,  0.015942, -0.004216,  0.019067, -0.021062,\n",
      "        -0.000222, -0.004106,  0.015947,  0.027720, -0.002466,  0.007754,\n",
      "        -0.003672,  0.000576,  0.014354, -0.013769, -0.028903, -0.010025,\n",
      "         0.021859,  0.008850,  0.028652, -0.033044, -0.001895, -0.032607,\n",
      "         0.016324, -0.031138,  0.029361, -0.033296, -0.034015, -0.009018,\n",
      "         0.033501, -0.031813, -0.015445,  0.023427, -0.016542,  0.031762,\n",
      "        -0.019465,  0.020730,  0.018076, -0.029477, -0.022871,  0.025739,\n",
      "         0.016648, -0.031784, -0.030112, -0.012029, -0.032605,  0.014718,\n",
      "         0.017653,  0.019977,  0.009646, -0.009642, -0.027300, -0.027761,\n",
      "        -0.032576, -0.007612, -0.003901,  0.031575,  0.019991, -0.031488,\n",
      "         0.028457,  0.023488, -0.029420,  0.027435,  0.028522,  0.027942,\n",
      "         0.000774, -0.003183,  0.019621, -0.030073, -0.021206, -0.024886,\n",
      "        -0.028728, -0.031533, -0.008550, -0.007793,  0.030571, -0.025813,\n",
      "        -0.016561,  0.031709,  0.024357,  0.001121, -0.017882,  0.018835,\n",
      "        -0.022281,  0.033436,  0.013039,  0.024723, -0.009498,  0.023393,\n",
      "        -0.023565,  0.002128, -0.030382, -0.011724,  0.027682, -0.012109,\n",
      "         0.006250,  0.012083, -0.006821, -0.010810,  0.025647,  0.013057,\n",
      "         0.014024, -0.002825, -0.029406, -0.033527, -0.012011,  0.014600,\n",
      "         0.014008, -0.033938, -0.001505, -0.017797,  0.013504,  0.031137,\n",
      "        -0.025331,  0.004819, -0.029256,  0.012812,  0.026981, -0.033869,\n",
      "        -0.022718,  0.004808, -0.002340,  0.019021, -0.027169,  0.020206,\n",
      "        -0.002503,  0.000141,  0.025332,  0.031621,  0.000517, -0.023738,\n",
      "         0.022583, -0.018910, -0.003149,  0.033829,  0.026846, -0.015715,\n",
      "        -0.003295, -0.026757,  0.011290,  0.027914, -0.002932, -0.006219,\n",
      "        -0.026459,  0.023676, -0.031581, -0.002450, -0.033474, -0.005652,\n",
      "        -0.021440, -0.017262, -0.008785,  0.027902,  0.000791,  0.024865,\n",
      "        -0.027351,  0.028878, -0.024004, -0.032246, -0.010935,  0.015556,\n",
      "        -0.005161,  0.033916,  0.015137,  0.029974, -0.018742, -0.015336,\n",
      "        -0.000804,  0.008124,  0.030426,  0.017430, -0.001335,  0.023754,\n",
      "        -0.022380, -0.010959, -0.015414, -0.031189, -0.016186,  0.001773,\n",
      "         0.016510, -0.015922, -0.028769, -0.030697,  0.023385,  0.024953,\n",
      "        -0.033862, -0.005930,  0.006206, -0.013417,  0.012692, -0.018239,\n",
      "         0.003323, -0.012823,  0.018896,  0.007717,  0.001622,  0.014174,\n",
      "         0.017113,  0.011763,  0.027329, -0.007770,  0.018986, -0.005412,\n",
      "        -0.001265,  0.004044, -0.008237, -0.005912,  0.016467, -0.030665,\n",
      "         0.025367,  0.030635,  0.017021, -0.001923,  0.009841,  0.015237,\n",
      "         0.023598, -0.009980, -0.004621, -0.024796,  0.019448,  0.018924,\n",
      "         0.033709,  0.029120, -0.014977, -0.032886,  0.011835, -0.023267,\n",
      "         0.003188, -0.009830, -0.008318,  0.017327, -0.025955,  0.010699,\n",
      "         0.027743,  0.020614,  0.004895, -0.015952, -0.025436, -0.003305,\n",
      "        -0.023074, -0.028695,  0.003407,  0.013503,  0.025735,  0.013211,\n",
      "        -0.029347, -0.023221,  0.009551,  0.003815,  0.033857, -0.024588,\n",
      "        -0.020537, -0.019351, -0.024784, -0.014652, -0.019064,  0.016050,\n",
      "         0.000294, -0.009988, -0.017788, -0.010366, -0.006774, -0.001037,\n",
      "        -0.005275,  0.005090, -0.006143, -0.024650,  0.006765, -0.004570,\n",
      "         0.016973, -0.031265,  0.033002, -0.002639,  0.009478,  0.023067,\n",
      "        -0.015159,  0.024087,  0.025387,  0.016955, -0.013638, -0.009398,\n",
      "        -0.016858,  0.021204,  0.026476,  0.025663, -0.025605,  0.023280,\n",
      "         0.031264, -0.017534], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-2.020919e-02,  5.684344e-03,  4.658289e-04],\n",
      "          [-2.438442e-02, -1.934935e-02,  1.701389e-02],\n",
      "          [ 2.779236e-02, -5.347406e-03,  6.815715e-03]],\n",
      "\n",
      "         [[-1.587946e-02, -1.031040e-02,  2.711273e-02],\n",
      "          [ 9.649372e-03,  2.001498e-02, -2.645160e-02],\n",
      "          [ 1.768443e-02, -1.778588e-02,  2.304534e-02]],\n",
      "\n",
      "         [[ 1.545065e-02,  2.901174e-02,  2.325306e-02],\n",
      "          [-1.301930e-02, -2.739814e-02,  2.159009e-03],\n",
      "          [ 1.488011e-02, -1.351755e-02, -1.264948e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.463147e-02, -4.508948e-03, -2.246210e-02],\n",
      "          [ 7.543024e-04, -2.215745e-02, -1.033140e-02],\n",
      "          [ 2.441339e-02,  2.431034e-02, -2.486888e-02]],\n",
      "\n",
      "         [[ 2.780115e-02, -2.117288e-02, -1.486794e-02],\n",
      "          [-1.595185e-02, -1.666301e-02,  1.402892e-02],\n",
      "          [-1.030490e-04, -5.129313e-03,  2.898402e-02]],\n",
      "\n",
      "         [[-7.906724e-03, -2.209176e-02,  2.068787e-02],\n",
      "          [-1.455298e-02,  2.346686e-02,  1.298264e-04],\n",
      "          [ 3.731055e-03, -3.618931e-03, -7.753324e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.907291e-03,  4.506217e-03, -2.257713e-02],\n",
      "          [-9.807536e-03,  8.640630e-03,  2.013268e-03],\n",
      "          [ 1.097225e-02, -1.617087e-02,  1.269254e-02]],\n",
      "\n",
      "         [[-1.837799e-02,  1.661783e-02,  6.532954e-03],\n",
      "          [-2.363311e-02, -1.103173e-02, -2.084122e-02],\n",
      "          [-6.160000e-03,  2.476905e-02,  2.519847e-02]],\n",
      "\n",
      "         [[ 2.409734e-02,  7.332010e-03, -5.961001e-03],\n",
      "          [-2.628344e-02, -2.349428e-02,  1.816990e-03],\n",
      "          [-2.644080e-02, -7.204255e-03, -1.339194e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.689546e-02,  1.483216e-02, -2.323956e-02],\n",
      "          [-6.240400e-03, -1.725544e-02, -5.544633e-03],\n",
      "          [-2.033538e-02,  1.869769e-02,  1.959917e-02]],\n",
      "\n",
      "         [[ 2.304276e-02, -1.016010e-02,  7.373152e-03],\n",
      "          [ 1.369953e-02, -4.487442e-03, -2.155146e-02],\n",
      "          [ 1.636525e-02,  1.248951e-02, -1.082243e-02]],\n",
      "\n",
      "         [[-1.438759e-03,  9.947723e-03, -5.906045e-03],\n",
      "          [-1.925256e-02,  2.558306e-02, -2.203606e-03],\n",
      "          [-2.285156e-03,  1.211366e-02, -5.528487e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.780719e-02,  6.869162e-03, -2.487036e-02],\n",
      "          [ 2.526130e-02,  1.884797e-02,  2.451258e-03],\n",
      "          [-3.518019e-03,  2.461829e-02, -1.208405e-02]],\n",
      "\n",
      "         [[-1.734569e-02,  2.484795e-02, -1.573612e-02],\n",
      "          [ 1.167895e-02,  2.818975e-02,  9.610938e-03],\n",
      "          [ 1.839449e-02,  5.187746e-04, -8.140035e-03]],\n",
      "\n",
      "         [[-1.055143e-02,  2.863003e-02,  6.680166e-03],\n",
      "          [-6.328754e-03,  3.761018e-03,  1.601465e-03],\n",
      "          [ 2.691138e-02,  2.847871e-03, -2.422832e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.238261e-02, -1.901103e-03,  1.735757e-02],\n",
      "          [ 2.007465e-02, -2.344273e-02,  1.497586e-02],\n",
      "          [ 1.904702e-02,  3.733037e-03, -1.974268e-02]],\n",
      "\n",
      "         [[-1.116996e-02,  2.053153e-02,  1.393536e-02],\n",
      "          [-2.805974e-02, -1.446823e-02,  1.021007e-02],\n",
      "          [ 5.847527e-03, -1.860234e-02,  1.455402e-02]],\n",
      "\n",
      "         [[ 1.673649e-02,  1.621147e-02, -3.147980e-03],\n",
      "          [ 7.211516e-03,  3.905253e-03,  2.780939e-02],\n",
      "          [-1.174918e-02, -4.180932e-03, -2.046218e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.935559e-05, -1.636562e-02, -4.139302e-03],\n",
      "          [-5.445661e-03, -1.086915e-02, -7.309619e-03],\n",
      "          [-1.281081e-02, -2.066573e-02, -1.089870e-02]],\n",
      "\n",
      "         [[ 2.297958e-02,  2.063280e-03, -7.787140e-03],\n",
      "          [ 2.858738e-02, -1.762453e-02, -1.258615e-02],\n",
      "          [-2.042624e-02,  1.595047e-02,  2.624949e-02]],\n",
      "\n",
      "         [[-2.190240e-02, -1.702234e-02,  1.188330e-02],\n",
      "          [ 2.656786e-02,  7.830216e-03,  2.814058e-02],\n",
      "          [ 1.985160e-02,  2.589790e-02,  1.838799e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.678094e-03,  6.365703e-03, -2.599572e-02],\n",
      "          [-2.131075e-02,  3.715469e-03, -2.653659e-02],\n",
      "          [-1.625880e-02,  1.369743e-02,  1.749481e-02]],\n",
      "\n",
      "         [[-2.639612e-02, -1.443345e-04,  2.348117e-02],\n",
      "          [ 2.928245e-02, -1.567043e-02, -1.593400e-02],\n",
      "          [ 5.732700e-04,  2.045511e-02, -2.661768e-02]],\n",
      "\n",
      "         [[-2.273552e-02,  2.473927e-02,  2.579795e-03],\n",
      "          [-1.756100e-02, -1.882577e-02, -1.313609e-02],\n",
      "          [ 2.258357e-02,  2.262084e-03,  1.807780e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.880481e-03, -1.371398e-02, -1.739007e-02],\n",
      "          [-1.278619e-02,  2.853942e-02, -1.229878e-02],\n",
      "          [-2.919816e-02,  1.779720e-02,  1.795547e-02]],\n",
      "\n",
      "         [[ 5.194673e-03, -6.545236e-03,  1.345482e-03],\n",
      "          [ 7.861154e-03, -1.114781e-02,  4.130080e-04],\n",
      "          [ 5.551720e-03,  1.229979e-02, -1.015488e-02]],\n",
      "\n",
      "         [[ 1.632010e-02,  1.935653e-02,  2.259707e-02],\n",
      "          [ 6.178064e-03,  1.885464e-02, -1.927651e-02],\n",
      "          [ 6.630948e-03, -1.830750e-02,  2.056204e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.062018e-02,  2.480222e-02, -9.771325e-04],\n",
      "          [ 2.281670e-02,  7.476354e-03, -2.820317e-02],\n",
      "          [-2.342533e-02,  2.483654e-02,  1.980327e-02]],\n",
      "\n",
      "         [[ 1.236175e-02, -2.586823e-02,  1.494763e-02],\n",
      "          [-1.436424e-03, -2.585809e-02,  6.511578e-03],\n",
      "          [-1.874203e-03,  1.274803e-02,  1.541800e-02]],\n",
      "\n",
      "         [[-2.440586e-02, -2.301420e-02, -2.032827e-02],\n",
      "          [ 2.779945e-02,  1.026559e-02,  1.015433e-02],\n",
      "          [ 1.773762e-02,  2.316280e-02, -2.893726e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.223052e-03, -2.264278e-02,  1.922134e-02],\n",
      "          [-1.249872e-03, -2.644722e-02,  7.639201e-03],\n",
      "          [ 7.192904e-03,  1.924132e-02,  2.521932e-02]],\n",
      "\n",
      "         [[ 1.291725e-02, -2.183015e-02,  7.468013e-03],\n",
      "          [ 1.164070e-02, -4.928751e-03, -2.427748e-02],\n",
      "          [-1.947319e-02, -2.498631e-02,  2.540244e-03]],\n",
      "\n",
      "         [[ 7.587807e-03, -6.847084e-05,  1.065520e-02],\n",
      "          [ 1.003173e-02,  2.902040e-03, -2.313035e-02],\n",
      "          [-8.033745e-03, -2.129603e-02,  8.797700e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.913260e-03,  1.130274e-03,  1.435280e-04],\n",
      "          [ 5.905112e-03,  1.634565e-02, -8.439707e-03],\n",
      "          [-4.706837e-03,  1.529138e-02,  2.499514e-02]],\n",
      "\n",
      "         [[ 9.824578e-04,  5.923005e-03, -2.932491e-02],\n",
      "          [-2.845183e-03,  1.679038e-02, -2.855157e-03],\n",
      "          [ 4.734097e-03, -2.351015e-02,  4.883064e-03]],\n",
      "\n",
      "         [[ 1.109556e-02,  1.052181e-02,  5.849307e-03],\n",
      "          [-2.807880e-02,  1.938134e-02,  4.090467e-03],\n",
      "          [-2.828710e-02, -1.813653e-02,  4.103346e-03]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.028359,  0.000103,  0.003965, -0.013379,  0.000143,  0.020456,\n",
      "        -0.007315,  0.028409, -0.021535, -0.024786,  0.005459,  0.025731,\n",
      "         0.025402,  0.019867, -0.025185,  0.013591, -0.003054, -0.010615,\n",
      "         0.029006, -0.019974,  0.003366,  0.001919,  0.013980,  0.023215,\n",
      "         0.025115,  0.007054,  0.012831,  0.014101,  0.021643, -0.020145,\n",
      "         0.017089,  0.020358,  0.017536,  0.017225, -0.022228,  0.016215,\n",
      "        -0.026420,  0.021098,  0.027147,  0.004277, -0.013627, -0.017266,\n",
      "        -0.019153,  0.028182, -0.023440, -0.004026,  0.002365, -0.021862,\n",
      "        -0.004429,  0.016894,  0.015091, -0.023923, -0.023199, -0.017617,\n",
      "        -0.013259,  0.021738,  0.003912, -0.002509,  0.007206,  0.013900,\n",
      "         0.014731, -0.016449, -0.019524, -0.004459,  0.006652,  0.014158,\n",
      "         0.022618, -0.007645,  0.028790,  0.028331, -0.011729,  0.003516,\n",
      "        -0.025001,  0.008102, -0.012474, -0.021839, -0.006340, -0.008834,\n",
      "        -0.007299, -0.004683, -0.007893,  0.023902, -0.010742,  0.027826,\n",
      "        -0.022870,  0.007386,  0.019918,  0.017939, -0.004648,  0.027951,\n",
      "        -0.017994,  0.012718,  0.004832, -0.009798, -0.002818,  0.025463,\n",
      "         0.002798, -0.018321, -0.022997,  0.014034,  0.024396,  0.017588,\n",
      "         0.000980, -0.022802, -0.001273,  0.028662,  0.009033,  0.023544,\n",
      "        -0.000132,  0.002161,  0.011414,  0.020974,  0.014165,  0.009237,\n",
      "         0.003902,  0.006782,  0.027533, -0.010038,  0.028625,  0.011733,\n",
      "         0.004413, -0.007206, -0.028553, -0.019256,  0.004124, -0.028391,\n",
      "        -0.022312, -0.010262, -0.011529, -0.028139, -0.006288,  0.016075,\n",
      "         0.008928,  0.022832,  0.014051,  0.019476, -0.002656,  0.002133,\n",
      "         0.012803,  0.023695,  0.004741,  0.004196,  0.029120,  0.013199,\n",
      "         0.017335,  0.004920,  0.007368, -0.021083,  0.021330,  0.001029,\n",
      "        -0.028335, -0.023685, -0.000246,  0.016700, -0.015553,  0.018414,\n",
      "         0.004258, -0.027745,  0.005388, -0.007286, -0.028429,  0.022480,\n",
      "        -0.009652,  0.000457,  0.014249,  0.006420,  0.003245, -0.015474,\n",
      "        -0.020512, -0.019507, -0.023061, -0.010018,  0.004624, -0.017954,\n",
      "        -0.017889, -0.016535, -0.009417, -0.025107,  0.010052, -0.001361,\n",
      "        -0.008798, -0.002524,  0.003584,  0.006946, -0.019944, -0.001254,\n",
      "        -0.013115,  0.002542,  0.012992, -0.012502,  0.001101, -0.014902,\n",
      "         0.004509, -0.001195, -0.011795,  0.003540, -0.015400,  0.028012,\n",
      "        -0.010243, -0.027825,  0.017848, -0.012090, -0.027326,  0.023926,\n",
      "        -0.020694,  0.017245,  0.024162, -0.029141, -0.026704, -0.015671,\n",
      "        -0.012623,  0.007706, -0.001623, -0.014394,  0.026845,  0.010960,\n",
      "        -0.025879,  0.027793, -0.007581,  0.025193,  0.005800, -0.009621,\n",
      "         0.022788,  0.007954,  0.003221, -0.001825, -0.000393,  0.021640,\n",
      "         0.013503,  0.001564, -0.003105,  0.003930,  0.021136, -0.015261,\n",
      "         0.000456,  0.006356,  0.009347,  0.026714,  0.016106,  0.029308,\n",
      "         0.029078, -0.021578, -0.011687, -0.028614,  0.008037,  0.005747,\n",
      "         0.028857,  0.024947, -0.025463, -0.021125,  0.010348, -0.017204,\n",
      "        -0.004765, -0.000247,  0.024493, -0.010196], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-4.016127e-02, -3.489139e-02,  3.905312e-02],\n",
      "          [-3.412321e-02, -3.514570e-02,  3.785563e-02],\n",
      "          [ 2.330542e-02, -3.726806e-03,  2.766394e-02]],\n",
      "\n",
      "         [[-1.823886e-02, -2.069112e-02,  1.693573e-03],\n",
      "          [-2.720325e-02, -2.211338e-02,  1.987194e-02],\n",
      "          [-2.296869e-02,  6.166380e-03, -2.568211e-03]],\n",
      "\n",
      "         [[-3.541652e-02, -2.773575e-02,  1.822826e-02],\n",
      "          [ 3.344078e-03,  3.099195e-02, -3.418233e-02],\n",
      "          [ 1.009901e-02, -2.976920e-03, -2.508400e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.049979e-02, -1.801730e-02, -2.762155e-02],\n",
      "          [ 1.953809e-02, -2.891485e-02, -2.650779e-02],\n",
      "          [ 1.665381e-02,  8.182723e-03, -1.091269e-02]],\n",
      "\n",
      "         [[-3.594288e-02,  3.269915e-03, -1.530148e-02],\n",
      "          [ 3.935665e-03,  2.915728e-02,  2.357700e-02],\n",
      "          [ 1.940109e-02, -1.002018e-02,  1.928370e-02]],\n",
      "\n",
      "         [[-2.245209e-02,  3.430732e-04, -3.731571e-02],\n",
      "          [ 2.909121e-02, -1.956373e-04,  9.052072e-03],\n",
      "          [ 3.667172e-02,  3.748024e-02,  3.370509e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.051054e-02, -3.943333e-02,  5.862456e-03],\n",
      "          [-3.234752e-02,  4.066592e-02,  2.236955e-02],\n",
      "          [-1.960762e-02, -8.507621e-03,  2.655226e-02]],\n",
      "\n",
      "         [[-2.433775e-02, -2.311200e-03,  1.309368e-02],\n",
      "          [ 2.103255e-02, -1.982197e-03, -5.378421e-03],\n",
      "          [ 2.428091e-02,  2.619606e-02, -1.546969e-02]],\n",
      "\n",
      "         [[-3.010204e-02,  3.546333e-02,  6.160975e-03],\n",
      "          [ 2.273933e-02,  3.594876e-02, -1.352536e-02],\n",
      "          [-3.836186e-02,  2.139791e-02,  1.898905e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.521647e-02, -7.168464e-04, -2.433090e-02],\n",
      "          [-3.995314e-02, -2.041787e-02,  2.334391e-02],\n",
      "          [-1.225265e-02, -4.079775e-02, -1.261795e-02]],\n",
      "\n",
      "         [[ 1.105093e-02, -2.908051e-03, -1.969981e-02],\n",
      "          [-6.655235e-03, -3.747626e-02, -3.989557e-02],\n",
      "          [-2.491791e-02, -3.658260e-02, -3.536954e-02]],\n",
      "\n",
      "         [[ 4.136282e-02,  1.295041e-02,  1.323669e-02],\n",
      "          [ 3.998392e-02,  3.178354e-03,  2.830281e-02],\n",
      "          [-1.302103e-02, -2.813631e-02, -2.624381e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.856326e-02,  6.647184e-03,  3.392545e-02],\n",
      "          [-2.068831e-02,  1.170738e-02, -4.101348e-02],\n",
      "          [-6.878804e-03, -3.720102e-02,  1.235069e-02]],\n",
      "\n",
      "         [[ 1.568426e-02,  6.503984e-05,  1.145333e-02],\n",
      "          [-2.261072e-02,  3.892373e-03,  2.115260e-02],\n",
      "          [ 3.643555e-02,  1.522285e-02,  1.956684e-02]],\n",
      "\n",
      "         [[-2.928313e-02, -2.270710e-03, -7.008538e-03],\n",
      "          [ 3.333269e-02, -8.266751e-03,  7.991850e-03],\n",
      "          [ 1.220888e-02,  7.105708e-03,  1.099933e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.527946e-02, -2.455675e-02,  3.848365e-02],\n",
      "          [-2.387801e-02,  4.138865e-02,  2.109124e-02],\n",
      "          [ 1.581578e-02,  2.047040e-02, -1.096186e-02]],\n",
      "\n",
      "         [[-9.563778e-03,  1.210488e-02, -1.105561e-02],\n",
      "          [-3.452709e-02, -2.541724e-02,  9.407688e-03],\n",
      "          [ 4.950706e-03,  2.047718e-03,  9.743720e-04]],\n",
      "\n",
      "         [[-7.837251e-03, -3.211191e-02, -2.862931e-02],\n",
      "          [-1.430302e-02,  1.494827e-02,  2.727589e-02],\n",
      "          [ 3.553427e-02, -3.487331e-02,  1.305338e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.704103e-02, -1.300768e-02,  2.525080e-02],\n",
      "          [ 3.924840e-02,  1.835946e-03,  3.915423e-02],\n",
      "          [ 3.345678e-02, -8.805245e-03, -3.180793e-02]],\n",
      "\n",
      "         [[ 2.909269e-03, -1.534522e-03, -2.294004e-02],\n",
      "          [-2.234479e-02, -3.995917e-02, -2.864702e-02],\n",
      "          [ 3.140142e-02, -1.720297e-02,  2.037099e-02]],\n",
      "\n",
      "         [[ 1.756963e-02,  1.854018e-02,  1.860973e-02],\n",
      "          [ 3.513957e-02, -2.387959e-02,  3.634687e-02],\n",
      "          [-3.975812e-03,  2.593327e-03,  4.024890e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.921338e-02,  1.371496e-02,  2.816666e-02],\n",
      "          [ 6.496646e-04,  1.028341e-02,  1.543192e-02],\n",
      "          [-3.385550e-02, -3.575111e-02,  8.642554e-03]],\n",
      "\n",
      "         [[-3.653110e-02, -2.598713e-02, -2.545329e-02],\n",
      "          [-3.724817e-03, -3.466953e-02, -2.031798e-02],\n",
      "          [ 1.528023e-02, -2.356100e-02, -6.118137e-03]],\n",
      "\n",
      "         [[-8.096695e-04, -2.615610e-02, -1.900428e-02],\n",
      "          [-1.455056e-02, -4.125219e-03,  1.094094e-02],\n",
      "          [ 1.690931e-02,  2.704550e-02,  1.788829e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.037617e-02,  3.154945e-03, -1.700640e-03],\n",
      "          [ 3.058331e-02, -1.079178e-02,  8.863632e-03],\n",
      "          [-2.161911e-02, -1.650326e-02, -2.741238e-02]],\n",
      "\n",
      "         [[-1.990068e-02, -2.730672e-02,  1.373289e-02],\n",
      "          [-2.861506e-02, -1.457937e-02, -3.228342e-02],\n",
      "          [-1.265611e-03, -1.055118e-02,  3.696040e-02]],\n",
      "\n",
      "         [[ 1.131438e-02,  3.752218e-02,  2.032403e-02],\n",
      "          [-3.506385e-02,  6.609533e-03, -1.560117e-02],\n",
      "          [ 7.489860e-03,  4.257660e-03, -1.310453e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.121167e-02, -1.873666e-02, -3.440319e-02],\n",
      "          [ 3.578799e-02, -4.735038e-03, -4.708562e-03],\n",
      "          [-3.310829e-02, -2.898086e-03,  2.214975e-02]],\n",
      "\n",
      "         [[-3.034288e-02, -2.581582e-02, -3.279220e-02],\n",
      "          [-2.700455e-02, -3.798712e-02, -7.912505e-03],\n",
      "          [ 3.680507e-02, -4.088250e-02, -1.795874e-02]],\n",
      "\n",
      "         [[ 9.434640e-03,  2.276626e-02, -2.713420e-02],\n",
      "          [ 3.461256e-02, -6.297544e-03,  3.281060e-02],\n",
      "          [ 2.195253e-02, -2.486086e-02,  3.452124e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.728106e-02,  3.054446e-02, -2.324916e-04],\n",
      "          [ 1.225724e-02,  4.567206e-03, -3.462061e-03],\n",
      "          [ 2.955702e-02,  4.076179e-02,  4.108997e-02]],\n",
      "\n",
      "         [[ 1.026526e-03,  2.532307e-02,  3.896091e-03],\n",
      "          [ 4.061318e-02, -2.706510e-02,  3.903691e-03],\n",
      "          [ 1.367395e-02,  2.878295e-02,  2.498906e-02]],\n",
      "\n",
      "         [[-3.086982e-02, -2.047801e-02,  1.864510e-02],\n",
      "          [-2.460532e-02, -3.805107e-02, -1.055323e-02],\n",
      "          [-2.643134e-02, -2.827625e-02,  1.376086e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.737214e-02,  3.964584e-03,  1.322372e-02],\n",
      "          [-2.334024e-02,  1.335071e-02, -3.275251e-02],\n",
      "          [ 7.977132e-03, -3.367911e-02, -5.348399e-03]],\n",
      "\n",
      "         [[-1.086881e-02,  2.500123e-02,  1.738879e-02],\n",
      "          [-3.016657e-02,  2.935757e-02,  3.449390e-02],\n",
      "          [ 2.260727e-02,  2.246421e-03, -1.404437e-02]],\n",
      "\n",
      "         [[-1.663351e-02, -3.821542e-02, -2.238812e-02],\n",
      "          [ 3.192824e-02,  1.132484e-02,  2.729112e-02],\n",
      "          [-3.497344e-02,  3.939678e-02, -1.870900e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.002740,  0.006341,  0.024773,  0.018644,  0.027092, -0.018623,\n",
      "        -0.006190, -0.002410,  0.007885,  0.020968,  0.028816,  0.005733],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.019634, -0.010951,  0.027188],\n",
      "          [ 0.023147, -0.028421, -0.023113],\n",
      "          [ 0.025724,  0.001991,  0.002747]],\n",
      "\n",
      "         [[ 0.002495,  0.006287, -0.002778],\n",
      "          [-0.001842, -0.022081, -0.001203],\n",
      "          [-0.018506,  0.028519, -0.004125]],\n",
      "\n",
      "         [[ 0.025964, -0.010812,  0.002593],\n",
      "          [-0.019722, -0.009024,  0.002292],\n",
      "          [-0.014350,  0.011848,  0.021751]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.027596,  0.021674, -0.010744],\n",
      "          [ 0.008038,  0.011827, -0.026541],\n",
      "          [ 0.015590,  0.008235,  0.024353]],\n",
      "\n",
      "         [[-0.003052,  0.004597, -0.018355],\n",
      "          [-0.010272,  0.014214,  0.025284],\n",
      "          [ 0.023353,  0.011211, -0.015612]],\n",
      "\n",
      "         [[-0.021918,  0.013620, -0.011971],\n",
      "          [-0.020799,  0.015083,  0.029156],\n",
      "          [ 0.028802,  0.024970,  0.005319]]],\n",
      "\n",
      "\n",
      "        [[[ 0.021803,  0.026933,  0.000468],\n",
      "          [-0.011084, -0.019804, -0.012416],\n",
      "          [ 0.016906, -0.007182,  0.019674]],\n",
      "\n",
      "         [[ 0.004892,  0.007014,  0.010816],\n",
      "          [ 0.005461, -0.003817,  0.010557],\n",
      "          [-0.006072,  0.025935, -0.028489]],\n",
      "\n",
      "         [[ 0.004591,  0.027358,  0.000484],\n",
      "          [-0.024464,  0.021935,  0.017114],\n",
      "          [ 0.000450, -0.016168,  0.016299]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.009059, -0.013089, -0.019781],\n",
      "          [ 0.008259, -0.022021,  0.007201],\n",
      "          [ 0.001787,  0.024863,  0.012822]],\n",
      "\n",
      "         [[-0.008619, -0.020767, -0.014246],\n",
      "          [-0.015075, -0.009803,  0.023622],\n",
      "          [ 0.008145,  0.005803,  0.027282]],\n",
      "\n",
      "         [[-0.014318, -0.004958,  0.024633],\n",
      "          [ 0.020965,  0.016481, -0.014317],\n",
      "          [ 0.016021, -0.002780,  0.015738]]],\n",
      "\n",
      "\n",
      "        [[[ 0.028616,  0.009945, -0.028776],\n",
      "          [ 0.007296, -0.011480,  0.005659],\n",
      "          [-0.028786, -0.007627,  0.000685]],\n",
      "\n",
      "         [[-0.002143,  0.017271,  0.014912],\n",
      "          [ 0.024592, -0.009135,  0.018503],\n",
      "          [ 0.012024, -0.020741, -0.026572]],\n",
      "\n",
      "         [[-0.016938, -0.012356, -0.027565],\n",
      "          [-0.003606,  0.022512, -0.016898],\n",
      "          [ 0.007999,  0.021153, -0.013366]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.015595,  0.017612,  0.024882],\n",
      "          [-0.023820,  0.004230,  0.020031],\n",
      "          [ 0.020102,  0.007384,  0.000259]],\n",
      "\n",
      "         [[ 0.011650, -0.011733, -0.017094],\n",
      "          [ 0.019325,  0.018126, -0.008054],\n",
      "          [-0.008335, -0.026161,  0.023063]],\n",
      "\n",
      "         [[ 0.007266,  0.019997, -0.016889],\n",
      "          [ 0.023156, -0.003375, -0.007975],\n",
      "          [ 0.015270, -0.005727,  0.005034]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.013298,  0.016911, -0.005939],\n",
      "          [ 0.004466,  0.022630, -0.022234],\n",
      "          [-0.010564,  0.024750, -0.028640]],\n",
      "\n",
      "         [[ 0.022302, -0.019846,  0.001918],\n",
      "          [ 0.026817,  0.026656, -0.009233],\n",
      "          [ 0.023220, -0.023634, -0.008616]],\n",
      "\n",
      "         [[-0.024744, -0.014152,  0.019318],\n",
      "          [ 0.022571,  0.024466,  0.028013],\n",
      "          [ 0.005310,  0.024834,  0.013804]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.017223, -0.009147, -0.019955],\n",
      "          [ 0.010900,  0.002317,  0.007189],\n",
      "          [ 0.011759, -0.005831,  0.025169]],\n",
      "\n",
      "         [[-0.002233, -0.023686,  0.008755],\n",
      "          [ 0.028735, -0.016681,  0.020438],\n",
      "          [ 0.022473, -0.024605, -0.015119]],\n",
      "\n",
      "         [[-0.007046, -0.001019,  0.024843],\n",
      "          [-0.020783,  0.024995, -0.003157],\n",
      "          [ 0.017866, -0.021379, -0.013296]]],\n",
      "\n",
      "\n",
      "        [[[ 0.018499,  0.023727, -0.025894],\n",
      "          [ 0.002791, -0.029124,  0.008940],\n",
      "          [-0.008276,  0.001650,  0.010850]],\n",
      "\n",
      "         [[ 0.018801, -0.018303, -0.027618],\n",
      "          [-0.019161,  0.002863,  0.023705],\n",
      "          [ 0.011588, -0.028214,  0.006866]],\n",
      "\n",
      "         [[ 0.022328, -0.015344, -0.007507],\n",
      "          [ 0.026957,  0.001773,  0.024218],\n",
      "          [ 0.021724,  0.025277,  0.012104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.005775,  0.020565,  0.029067],\n",
      "          [-0.005148,  0.014295, -0.011283],\n",
      "          [-0.013309,  0.007406, -0.009648]],\n",
      "\n",
      "         [[-0.008933, -0.016313,  0.028357],\n",
      "          [ 0.011899,  0.025657, -0.012717],\n",
      "          [ 0.002238, -0.024494, -0.025691]],\n",
      "\n",
      "         [[-0.015670, -0.011389,  0.017761],\n",
      "          [ 0.028452,  0.005766, -0.024753],\n",
      "          [ 0.027255, -0.013790, -0.017469]]],\n",
      "\n",
      "\n",
      "        [[[ 0.020127, -0.011086, -0.005005],\n",
      "          [-0.027436,  0.010052, -0.003803],\n",
      "          [ 0.028564, -0.011967, -0.006172]],\n",
      "\n",
      "         [[-0.008231,  0.019023,  0.011352],\n",
      "          [-0.015891, -0.005809, -0.003168],\n",
      "          [-0.028938, -0.022796,  0.012068]],\n",
      "\n",
      "         [[ 0.020676, -0.023202,  0.011172],\n",
      "          [ 0.028000, -0.012445,  0.009782],\n",
      "          [-0.028750,  0.027931, -0.021098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.021266, -0.001408,  0.010190],\n",
      "          [ 0.005312, -0.010997, -0.007996],\n",
      "          [ 0.012298, -0.022534, -0.019900]],\n",
      "\n",
      "         [[ 0.026471,  0.027336, -0.026518],\n",
      "          [-0.001088,  0.014579, -0.004427],\n",
      "          [-0.022479, -0.009733,  0.020127]],\n",
      "\n",
      "         [[-0.011803, -0.007851, -0.007055],\n",
      "          [ 0.028211, -0.010759,  0.024857],\n",
      "          [-0.028507,  0.014991, -0.002511]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.004786,  0.008047,  0.022209,  0.022859, -0.005455, -0.010277,\n",
      "        -0.024599, -0.007344,  0.001183,  0.008928,  0.017071,  0.015848,\n",
      "        -0.010327, -0.009834, -0.009571, -0.013133,  0.016487, -0.014039,\n",
      "         0.020107,  0.006102, -0.020403, -0.008304, -0.028263,  0.005537,\n",
      "        -0.007916, -0.025099, -0.014392,  0.022132,  0.028605, -0.025568,\n",
      "        -0.009907, -0.003736,  0.022499, -0.027539,  0.001237,  0.008090,\n",
      "         0.020438,  0.008120,  0.027975, -0.023706,  0.015817, -0.013997,\n",
      "        -0.002645,  0.003467,  0.005158,  0.019761, -0.007727,  0.009682,\n",
      "         0.018968, -0.028380, -0.014569, -0.028617,  0.026971, -0.019484,\n",
      "        -0.017911, -0.023807, -0.021869, -0.017981, -0.013055, -0.014088,\n",
      "         0.018478,  0.014643, -0.001158,  0.006237,  0.027025,  0.021237,\n",
      "         0.006603,  0.014856,  0.028370,  0.017218,  0.023436,  0.026448,\n",
      "        -0.005911,  0.017455,  0.017505,  0.010001, -0.020308,  0.016735,\n",
      "        -0.007331, -0.000444,  0.009507, -0.015541, -0.027856, -0.004547,\n",
      "         0.017163,  0.002306, -0.014252, -0.021200,  0.000545,  0.007889,\n",
      "        -0.011624, -0.024687,  0.029244, -0.009346, -0.010668, -0.009962,\n",
      "         0.025553,  0.025285, -0.005722,  0.018377, -0.026303, -0.025447,\n",
      "         0.021127,  0.016659, -0.007321,  0.010856, -0.024541,  0.013041,\n",
      "        -0.014069, -0.007879,  0.027306,  0.023543,  0.002567,  0.002403,\n",
      "        -0.021344, -0.011172, -0.024716,  0.006424, -0.002973, -0.003823,\n",
      "         0.008668,  0.011594, -0.016735,  0.023928,  0.027077,  0.003573,\n",
      "         0.003936, -0.024517], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.028337,  0.025270, -0.022842],\n",
      "          [-0.010897, -0.015078,  0.006860],\n",
      "          [ 0.021214, -0.005470,  0.006183]],\n",
      "\n",
      "         [[-0.028488, -0.022141,  0.004553],\n",
      "          [ 0.027919, -0.009083, -0.021544],\n",
      "          [-0.018587, -0.023869,  0.011617]],\n",
      "\n",
      "         [[ 0.027805,  0.010829, -0.012376],\n",
      "          [ 0.016487, -0.025555, -0.015685],\n",
      "          [-0.001218,  0.009022, -0.007631]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.025835, -0.005521,  0.006105],\n",
      "          [-0.002156, -0.002339, -0.027546],\n",
      "          [ 0.020054, -0.027908, -0.028618]],\n",
      "\n",
      "         [[-0.016830, -0.028192,  0.020365],\n",
      "          [-0.022210, -0.014613,  0.010099],\n",
      "          [ 0.002362, -0.009821,  0.028439]],\n",
      "\n",
      "         [[-0.026956, -0.008352, -0.013665],\n",
      "          [-0.020542,  0.012338,  0.021295],\n",
      "          [-0.018529,  0.002166, -0.004262]]],\n",
      "\n",
      "\n",
      "        [[[-0.015563, -0.002206, -0.015297],\n",
      "          [ 0.003199,  0.005084, -0.022567],\n",
      "          [-0.013043, -0.024094,  0.015032]],\n",
      "\n",
      "         [[ 0.012421, -0.028458, -0.005038],\n",
      "          [-0.004603, -0.002313,  0.024933],\n",
      "          [ 0.000102, -0.017304,  0.001933]],\n",
      "\n",
      "         [[ 0.027869, -0.024891,  0.015780],\n",
      "          [ 0.028423,  0.020830,  0.023161],\n",
      "          [ 0.008488, -0.018963,  0.010103]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.007006,  0.028049,  0.017450],\n",
      "          [ 0.011482, -0.022804,  0.015167],\n",
      "          [-0.018623, -0.011924, -0.000724]],\n",
      "\n",
      "         [[ 0.018600,  0.027144, -0.001792],\n",
      "          [-0.007301, -0.014919, -0.014584],\n",
      "          [ 0.006305,  0.016060,  0.006773]],\n",
      "\n",
      "         [[-0.026162, -0.008842, -0.026657],\n",
      "          [-0.001667, -0.023921,  0.019028],\n",
      "          [-0.007647, -0.002174, -0.029150]]],\n",
      "\n",
      "\n",
      "        [[[ 0.027650,  0.017448,  0.024953],\n",
      "          [ 0.003864, -0.027639,  0.006670],\n",
      "          [ 0.012372,  0.026011,  0.017669]],\n",
      "\n",
      "         [[ 0.012833,  0.028245, -0.027905],\n",
      "          [ 0.007946,  0.021081,  0.021717],\n",
      "          [ 0.015805,  0.019717, -0.010548]],\n",
      "\n",
      "         [[ 0.025388,  0.023426,  0.006094],\n",
      "          [-0.002931,  0.018989,  0.002668],\n",
      "          [ 0.022737,  0.026986,  0.009873]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.024220, -0.011758, -0.027684],\n",
      "          [-0.029164, -0.009185, -0.022411],\n",
      "          [-0.003959,  0.027177, -0.016168]],\n",
      "\n",
      "         [[-0.010929,  0.006886, -0.018676],\n",
      "          [ 0.021062, -0.014562, -0.022352],\n",
      "          [ 0.004229,  0.013935, -0.005888]],\n",
      "\n",
      "         [[-0.028408, -0.015074,  0.013763],\n",
      "          [-0.012366,  0.011430, -0.007429],\n",
      "          [ 0.028974, -0.008810,  0.027617]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.024452,  0.015499,  0.009396],\n",
      "          [ 0.011125,  0.028438, -0.023195],\n",
      "          [ 0.028486, -0.022756, -0.023403]],\n",
      "\n",
      "         [[-0.018781, -0.021403, -0.023986],\n",
      "          [-0.010810, -0.013431, -0.024030],\n",
      "          [-0.012271,  0.013397,  0.021947]],\n",
      "\n",
      "         [[-0.026436,  0.001755, -0.017551],\n",
      "          [-0.020093, -0.005075,  0.005564],\n",
      "          [ 0.001861, -0.014608, -0.011043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.002105, -0.025991,  0.015432],\n",
      "          [ 0.012213, -0.028779,  0.014233],\n",
      "          [-0.018556, -0.008121, -0.024506]],\n",
      "\n",
      "         [[-0.027489, -0.019183, -0.008936],\n",
      "          [-0.002959, -0.010742, -0.008210],\n",
      "          [-0.022763, -0.001503,  0.016799]],\n",
      "\n",
      "         [[ 0.008300,  0.026322, -0.011212],\n",
      "          [-0.005002, -0.011801, -0.012631],\n",
      "          [-0.019804, -0.028272,  0.026115]]],\n",
      "\n",
      "\n",
      "        [[[ 0.020051, -0.001371,  0.019007],\n",
      "          [ 0.018999, -0.013398,  0.015865],\n",
      "          [-0.015085,  0.027528,  0.023734]],\n",
      "\n",
      "         [[-0.000564, -0.011241,  0.024898],\n",
      "          [-0.014215, -0.007992, -0.018802],\n",
      "          [-0.025333, -0.029351,  0.005536]],\n",
      "\n",
      "         [[ 0.005493,  0.022811, -0.028680],\n",
      "          [ 0.019834,  0.011993,  0.010830],\n",
      "          [-0.016253,  0.020860, -0.000810]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.014519,  0.028823,  0.020030],\n",
      "          [ 0.029127, -0.007615, -0.008410],\n",
      "          [ 0.010984,  0.010508,  0.027259]],\n",
      "\n",
      "         [[ 0.006536,  0.026537,  0.011275],\n",
      "          [-0.005871, -0.001542, -0.005156],\n",
      "          [-0.005350, -0.025966, -0.028070]],\n",
      "\n",
      "         [[-0.028340,  0.008274, -0.008860],\n",
      "          [ 0.026783, -0.015071,  0.025622],\n",
      "          [-0.013336,  0.028965,  0.005909]]],\n",
      "\n",
      "\n",
      "        [[[ 0.019475, -0.019163, -0.015030],\n",
      "          [ 0.016845, -0.025228,  0.025910],\n",
      "          [-0.006425, -0.018412, -0.004626]],\n",
      "\n",
      "         [[ 0.024467, -0.005759,  0.006145],\n",
      "          [ 0.009064, -0.016733,  0.011256],\n",
      "          [-0.009094, -0.024283,  0.021901]],\n",
      "\n",
      "         [[-0.028122, -0.017500,  0.012813],\n",
      "          [-0.020852,  0.006551, -0.006654],\n",
      "          [-0.011316,  0.009281,  0.012293]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.024026,  0.008920,  0.029162],\n",
      "          [-0.013879,  0.028022,  0.011445],\n",
      "          [ 0.003395, -0.016142, -0.024676]],\n",
      "\n",
      "         [[ 0.023770, -0.009116, -0.028391],\n",
      "          [ 0.007084, -0.025438,  0.011179],\n",
      "          [-0.017094, -0.015182,  0.001617]],\n",
      "\n",
      "         [[-0.022318,  0.003507, -0.009343],\n",
      "          [-0.006539,  0.026186,  0.026857],\n",
      "          [ 0.021439, -0.015617,  0.008663]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-2.732761e-02, -1.610402e-02, -2.023002e-02,  1.396985e-02,\n",
      "        -2.008278e-02, -1.169756e-02, -1.180733e-02, -1.555671e-02,\n",
      "         7.577715e-03,  2.020058e-02, -1.120662e-02,  2.287417e-02,\n",
      "         2.501876e-02, -8.033326e-03, -3.645010e-05, -1.176825e-02,\n",
      "        -2.174710e-02,  5.280571e-03, -1.375060e-02, -5.280849e-03,\n",
      "         1.045652e-02, -2.188861e-03,  2.716979e-02, -1.752048e-02,\n",
      "         2.876977e-02, -1.852830e-02,  6.320272e-04,  1.533159e-02,\n",
      "        -2.173843e-02,  2.669447e-02,  7.291039e-03, -2.187211e-02,\n",
      "         1.593651e-02, -4.863357e-03, -1.853628e-02,  1.013331e-02,\n",
      "         1.081575e-02, -1.957300e-02, -1.615177e-02,  1.085808e-02,\n",
      "         1.753763e-02, -1.141854e-02,  3.986796e-03,  1.705648e-02,\n",
      "         9.643717e-03,  2.562236e-02,  2.574008e-02,  1.154179e-02,\n",
      "         1.645818e-02,  1.929994e-02,  5.325263e-03, -2.216264e-02,\n",
      "         1.787490e-02, -2.513611e-02,  2.507051e-02,  1.880543e-02,\n",
      "        -1.747771e-02,  2.785922e-02,  5.855156e-03,  5.500911e-03,\n",
      "        -1.497910e-02,  1.094898e-02,  1.172788e-02,  2.109965e-02,\n",
      "        -9.563906e-03,  2.586438e-02, -2.475230e-02, -1.140854e-02,\n",
      "         9.764368e-03,  4.835166e-04,  2.103162e-02, -2.080277e-02,\n",
      "        -1.992711e-02,  1.209921e-02, -6.929440e-03,  2.505702e-02,\n",
      "         7.794021e-03, -2.561599e-02, -1.774310e-02, -3.667045e-03,\n",
      "        -3.345758e-03,  4.349289e-03,  2.103644e-02, -1.017032e-02,\n",
      "        -2.464129e-02,  2.187507e-02, -2.223851e-02, -4.271148e-03,\n",
      "         1.648784e-02,  2.052237e-02,  1.791440e-02, -2.459238e-02,\n",
      "         9.597057e-03, -1.141088e-02,  2.518840e-02, -7.553905e-03,\n",
      "        -2.546377e-02,  9.097511e-03,  1.089388e-02, -1.468440e-02,\n",
      "         1.649197e-02, -2.149614e-02,  6.127967e-03, -2.290548e-02,\n",
      "        -1.522313e-02,  7.412439e-03,  1.925919e-02, -2.001622e-02,\n",
      "        -1.329051e-02, -8.671306e-03,  6.090691e-03,  1.528328e-03,\n",
      "         1.302151e-02,  1.201927e-02,  2.865242e-02,  5.906908e-03,\n",
      "         1.603088e-02,  1.246863e-02,  1.681959e-02,  2.078635e-02,\n",
      "        -1.764327e-02,  2.352864e-02,  1.772658e-02,  8.999074e-03,\n",
      "        -1.558950e-02,  2.610748e-02, -1.731168e-02,  9.912161e-03],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# instanciate the model\n",
    "model = LossyCompAutoencoder()\n",
    "print(model)\n",
    "params = list(model.parameters())\n",
    "print(len(params))\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 44.923530\n",
      "running loss : 43.422592\n",
      "running loss : 42.746727\n",
      "running loss : 43.178691\n",
      "running loss : 43.178471\n",
      "running loss : 43.217670\n",
      "running loss : 42.766190\n",
      "running loss : 42.827812\n",
      "running loss : 43.265769\n",
      "running loss : 43.079006\n",
      "running loss : 43.148810\n",
      "running loss : 42.972984\n",
      "running loss : 42.695945\n",
      "running loss : 42.861766\n",
      "running loss : 42.832451\n",
      "running loss : 42.702663\n",
      "running loss : 42.645923\n",
      "running loss : 42.731988\n",
      "running loss : 42.829333\n",
      "running loss : 42.763890\n",
      "running loss : 42.861785\n",
      "running loss : 42.740514\n",
      "running loss : 42.990489\n",
      "running loss : 42.994992\n",
      "running loss : 43.038153\n",
      "running loss : 42.563785\n",
      "running loss : 42.935054\n",
      "running loss : 42.557880\n",
      "running loss : 42.854448\n",
      "running loss : 43.641883\n",
      "running loss : 42.778502\n",
      "running loss : 42.866602\n",
      "running loss : 42.902910\n",
      "running loss : 42.535625\n",
      "running loss : 42.315875\n",
      "running loss : 43.049296\n",
      "running loss : 43.260003\n",
      "running loss : 42.387189\n",
      "running loss : 42.784305\n",
      "running loss : 42.365922\n",
      "running loss : 42.511634\n",
      "running loss : 42.460831\n",
      "running loss : 42.492768\n",
      "running loss : 42.471322\n",
      "running loss : 42.943743\n",
      "running loss : 43.335035\n",
      "running loss : 42.713686\n",
      "running loss : 42.624963\n",
      "running loss : 42.161405\n",
      "running loss : 42.498004\n",
      "running loss : 42.319931\n",
      "running loss : 42.359559\n",
      "running loss : 42.374625\n",
      "running loss : 42.109003\n",
      "running loss : 42.179943\n",
      "running loss : 42.647691\n",
      "running loss : 42.302937\n",
      "running loss : 42.319128\n",
      "running loss : 42.262248\n",
      "running loss : 42.127206\n",
      "running loss : 42.653981\n",
      "running loss : 42.339595\n",
      "running loss : 42.542327\n",
      "running loss : 42.394363\n",
      "running loss : 42.253410\n",
      "running loss : 42.159700\n",
      "running loss : 42.223188\n",
      "running loss : 42.614771\n",
      "running loss : 42.583104\n",
      "running loss : 42.440596\n",
      "running loss : 42.414242\n",
      "running loss : 42.291857\n",
      "running loss : 42.278415\n",
      "running loss : 42.218198\n",
      "running loss : 42.553085\n",
      "running loss : 42.066193\n",
      "running loss : 42.264576\n",
      "running loss : 42.157740\n",
      "running loss : 42.160053\n",
      "running loss : 42.500378\n",
      "running loss : 42.576058\n",
      "running loss : 42.850151\n",
      "running loss : 42.535431\n",
      "running loss : 42.365121\n",
      "running loss : 42.059874\n",
      "running loss : 42.137930\n",
      "running loss : 41.704384\n",
      "running loss : 42.009096\n",
      "running loss : 42.114253\n",
      "running loss : 42.134407\n",
      "running loss : 42.017349\n",
      "running loss : 42.386073\n",
      "running loss : 41.845161\n",
      "running loss : 42.304321\n",
      "running loss : 41.855989\n",
      "running loss : 42.052804\n",
      "running loss : 42.226635\n",
      "running loss : 42.248075\n",
      "running loss : 42.124556\n",
      "running loss : 42.045099\n",
      "running loss : 42.086433\n",
      "running loss : 41.882611\n",
      "running loss : 41.624568\n",
      "running loss : 41.823497\n",
      "running loss : 42.146130\n",
      "running loss : 41.955842\n",
      "running loss : 42.150049\n",
      "running loss : 41.940780\n",
      "running loss : 41.904305\n",
      "running loss : 41.955680\n",
      "running loss : 41.866815\n",
      "running loss : 41.909500\n",
      "running loss : 41.736864\n",
      "running loss : 42.397150\n",
      "running loss : 41.807684\n",
      "running loss : 42.078180\n",
      "running loss : 41.823628\n",
      "running loss : 42.403819\n",
      "running loss : 42.298137\n",
      "running loss : 42.001175\n",
      "running loss : 41.961497\n",
      "running loss : 42.596310\n",
      "running loss : 42.372831\n",
      "running loss : 42.224506\n",
      "running loss : 41.622138\n",
      "running loss : 42.011167\n",
      "running loss : 41.916893\n",
      "running loss : 42.205901\n",
      "running loss : 41.807566\n",
      "running loss : 41.970901\n",
      "running loss : 41.654188\n",
      "running loss : 42.300280\n",
      "running loss : 41.759451\n",
      "running loss : 41.906544\n",
      "running loss : 41.737819\n",
      "running loss : 42.018984\n",
      "running loss : 42.044215\n",
      "running loss : 42.117140\n",
      "running loss : 41.892728\n",
      "running loss : 41.569490\n",
      "running loss : 41.689594\n",
      "running loss : 41.732475\n",
      "running loss : 42.037376\n",
      "running loss : 41.850109\n",
      "running loss : 42.288769\n",
      "running loss : 41.906202\n",
      "running loss : 41.367803\n",
      "running loss : 41.835298\n",
      "running loss : 41.637584\n",
      "running loss : 41.817786\n",
      "running loss : 41.661991\n",
      "running loss : 41.821755\n",
      "running loss : 41.547506\n",
      "running loss : 41.774717\n",
      "running loss : 41.807082\n",
      "running loss : 41.577825\n",
      "running loss : 41.507479\n",
      "running loss : 41.466095\n",
      "running loss : 41.791379\n",
      "running loss : 42.036470\n",
      "running loss : 41.758975\n",
      "running loss : 41.507225\n",
      "running loss : 41.871322\n",
      "running loss : 41.454668\n",
      "running loss : 41.656997\n",
      "running loss : 41.708262\n",
      "running loss : 41.817519\n",
      "running loss : 41.656917\n",
      "running loss : 41.603389\n",
      "running loss : 41.600409\n",
      "running loss : 41.688551\n",
      "running loss : 41.446240\n",
      "running loss : 41.396941\n",
      "running loss : 41.416018\n",
      "running loss : 41.793515\n",
      "running loss : 41.815457\n",
      "running loss : 41.893675\n",
      "running loss : 41.450977\n",
      "running loss : 41.227439\n",
      "running loss : 41.519179\n",
      "running loss : 41.607411\n",
      "running loss : 41.716486\n",
      "running loss : 41.232819\n",
      "running loss : 41.871367\n",
      "running loss : 41.456467\n",
      "running loss : 41.947609\n",
      "running loss : 41.668048\n",
      "running loss : 41.922854\n",
      "running loss : 41.473328\n",
      "running loss : 41.172597\n",
      "running loss : 41.741529\n",
      "running loss : 41.542988\n",
      "running loss : 41.281389\n",
      "running loss : 41.632765\n",
      "running loss : 41.454114\n",
      "running loss : 41.547477\n",
      "running loss : 41.652229\n",
      "running loss : 41.121975\n",
      "running loss : 41.619526\n",
      "running loss : 41.643709\n",
      "running loss : 41.570070\n",
      "running loss : 41.506962\n",
      "running loss : 41.278127\n",
      "running loss : 41.525280\n",
      "running loss : 41.167542\n",
      "running loss : 41.338245\n",
      "running loss : 41.030396\n",
      "running loss : 41.128537\n",
      "running loss : 40.996708\n",
      "running loss : 40.868746\n",
      "running loss : 41.392218\n",
      "running loss : 41.485216\n",
      "running loss : 41.254695\n",
      "running loss : 41.266690\n",
      "running loss : 40.951371\n",
      "running loss : 41.259905\n",
      "running loss : 41.034830\n",
      "running loss : 42.090954\n",
      "running loss : 41.326321\n",
      "running loss : 41.049956\n",
      "running loss : 41.319318\n",
      "running loss : 41.762899\n",
      "running loss : 41.436858\n",
      "running loss : 41.390870\n",
      "running loss : 41.316247\n",
      "running loss : 41.025010\n",
      "running loss : 41.118160\n",
      "running loss : 41.321979\n",
      "running loss : 41.171877\n",
      "running loss : 40.991369\n",
      "running loss : 41.317897\n",
      "running loss : 41.031378\n",
      "running loss : 41.227317\n",
      "running loss : 41.088493\n",
      "running loss : 41.060102\n",
      "running loss : 41.056391\n",
      "running loss : 41.117215\n",
      "running loss : 41.119861\n",
      "running loss : 41.238656\n",
      "running loss : 41.069055\n",
      "running loss : 41.191172\n",
      "running loss : 41.232970\n",
      "running loss : 41.101005\n",
      "running loss : 40.996147\n",
      "running loss : 41.335363\n",
      "running loss : 40.947520\n",
      "running loss : 41.273486\n",
      "running loss : 41.042204\n",
      "running loss : 40.913759\n",
      "running loss : 41.212111\n",
      "running loss : 41.320721\n",
      "running loss : 41.263608\n",
      "running loss : 40.945615\n",
      "running loss : 41.281483\n",
      "running loss : 41.110189\n",
      "running loss : 41.299095\n",
      "running loss : 41.146772\n",
      "running loss : 41.287276\n",
      "running loss : 41.183409\n",
      "running loss : 40.733906\n",
      "running loss : 40.965458\n",
      "running loss : 41.144368\n",
      "running loss : 41.221544\n",
      "running loss : 41.097657\n",
      "running loss : 40.882725\n",
      "running loss : 40.572456\n",
      "running loss : 41.471331\n",
      "running loss : 40.843707\n",
      "running loss : 41.040861\n",
      "running loss : 40.874936\n",
      "running loss : 41.305284\n",
      "running loss : 41.049167\n",
      "running loss : 40.616191\n",
      "running loss : 40.797179\n",
      "running loss : 40.696042\n",
      "running loss : 40.869761\n",
      "running loss : 41.055765\n",
      "running loss : 40.779230\n",
      "running loss : 41.313409\n",
      "running loss : 40.741772\n",
      "running loss : 41.246114\n",
      "running loss : 40.823011\n",
      "running loss : 41.275614\n",
      "running loss : 41.123846\n",
      "running loss : 40.810066\n",
      "running loss : 40.721724\n",
      "running loss : 40.703284\n",
      "running loss : 40.855388\n",
      "running loss : 40.539770\n",
      "running loss : 41.318316\n",
      "running loss : 40.831727\n",
      "running loss : 41.123685\n",
      "running loss : 40.887214\n",
      "running loss : 40.790885\n",
      "running loss : 40.621074\n",
      "running loss : 41.317755\n",
      "running loss : 40.983537\n",
      "running loss : 40.682260\n",
      "running loss : 40.624531\n",
      "running loss : 40.920307\n",
      "running loss : 41.120205\n",
      "running loss : 40.739484\n",
      "running loss : 40.630958\n",
      "running loss : 40.696628\n",
      "running loss : 40.707421\n",
      "running loss : 40.564199\n",
      "running loss : 40.776133\n",
      "running loss : 40.713116\n",
      "running loss : 40.420846\n",
      "running loss : 40.573526\n",
      "running loss : 40.771007\n",
      "running loss : 40.779507\n",
      "running loss : 40.627204\n",
      "running loss : 40.718256\n",
      "running loss : 40.847357\n",
      "running loss : 40.811629\n",
      "running loss : 40.470052\n",
      "running loss : 40.441044\n",
      "running loss : 40.905161\n",
      "running loss : 40.554113\n",
      "running loss : 40.475244\n",
      "running loss : 40.251629\n",
      "running loss : 40.854545\n",
      "running loss : 40.642477\n",
      "running loss : 40.444942\n",
      "running loss : 40.609610\n",
      "running loss : 40.698776\n",
      "running loss : 40.476899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 40.439491\n",
      "running loss : 40.623884\n",
      "running loss : 40.595018\n",
      "running loss : 40.669544\n",
      "running loss : 40.574267\n",
      "running loss : 41.244713\n",
      "running loss : 40.084970\n",
      "running loss : 40.847029\n",
      "running loss : 40.543849\n",
      "running loss : 40.626065\n",
      "running loss : 40.911249\n",
      "running loss : 40.423082\n",
      "running loss : 40.306543\n",
      "running loss : 40.161401\n",
      "running loss : 40.338567\n",
      "running loss : 40.531435\n",
      "running loss : 40.050873\n",
      "running loss : 40.343762\n",
      "running loss : 41.390183\n",
      "running loss : 40.194072\n",
      "running loss : 40.755450\n",
      "running loss : 40.617160\n",
      "running loss : 40.430021\n",
      "running loss : 40.473687\n",
      "running loss : 40.603134\n",
      "running loss : 40.286817\n",
      "running loss : 40.487705\n",
      "running loss : 40.450451\n",
      "running loss : 40.563675\n",
      "running loss : 40.728410\n",
      "running loss : 40.623710\n",
      "running loss : 40.434028\n",
      "running loss : 40.554688\n",
      "running loss : 40.326010\n",
      "running loss : 40.222104\n",
      "running loss : 40.076177\n",
      "running loss : 40.170344\n",
      "running loss : 40.438091\n",
      "running loss : 40.417919\n",
      "running loss : 40.462432\n",
      "running loss : 40.102696\n",
      "running loss : 40.570839\n",
      "running loss : 40.233179\n",
      "running loss : 40.231006\n",
      "running loss : 40.698986\n",
      "running loss : 40.315425\n",
      "running loss : 40.532246\n",
      "running loss : 40.475672\n",
      "running loss : 40.382165\n",
      "running loss : 40.432858\n",
      "running loss : 40.523229\n",
      "running loss : 40.284332\n",
      "running loss : 40.224168\n",
      "running loss : 40.813915\n",
      "running loss : 40.157823\n",
      "running loss : 40.371618\n",
      "running loss : 40.660401\n",
      "running loss : 39.941136\n",
      "running loss : 40.074004\n",
      "running loss : 40.453655\n",
      "running loss : 40.216886\n",
      "running loss : 40.647225\n",
      "running loss : 40.330293\n",
      "running loss : 40.221175\n",
      "running loss : 40.459903\n",
      "running loss : 40.370718\n",
      "running loss : 40.030883\n",
      "running loss : 40.375860\n",
      "running loss : 39.841244\n",
      "running loss : 40.492327\n",
      "running loss : 40.102038\n",
      "running loss : 40.357261\n"
     ]
    }
   ],
   "source": [
    "# load incremental model\n",
    "model_incremental = LossyCompAutoencoder()\n",
    "model_incremental.load_state_dict(torch.load('./model_parameters/lossy_comp_params_with_rate_beta2_incremental_2.pth'))\n",
    "model_incremental.eval()\n",
    "model_incremental.to(device)\n",
    "\n",
    "# transfert du model au gpu\n",
    "model_incremental.to(device)\n",
    "\n",
    "#define optimizer\n",
    "optimizer = torch.optim.Adam(model_incremental.parameters(), lr=0.00001)\n",
    "\n",
    "# define loss function\n",
    "distortion = nn.MSELoss().cuda()\n",
    "       \n",
    "\n",
    "# general update of coefficients    \n",
    "    #Epochs\n",
    "n_epochs = 400\n",
    "    # beta\n",
    "beta = 2\n",
    "\n",
    "    # Training the network\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "          \n",
    "    #Training\n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        batch_images = data.to(device).float()\n",
    "        [decoded_images, x_quantized] = model_incremental(batch_images, 1, True)\n",
    "        optimizer.zero_grad()\n",
    "        loss = beta * distortion(decoded_images, batch_images) + entropy_rate(x_quantized, model_incremental.phi, model_incremental.var)\n",
    "        #print(loss)\n",
    "            \n",
    "        loss.backward()\n",
    "        #print(\"conv1.weights grad: \", params[0].grad)\n",
    "        #print(model.conv1.bias.grad)\n",
    "        #print(model.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss = running_loss/len(dataloader)\n",
    "    print('running loss : {:.06f}'.format(running_loss), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 171.428085\n",
      "running loss : 165.298092\n",
      "running loss : 154.525253\n",
      "running loss : 148.412019\n",
      "running loss : 145.604814\n",
      "running loss : 141.472328\n",
      "running loss : 136.315337\n",
      "running loss : 133.525751\n",
      "running loss : 131.219286\n",
      "running loss : 127.938756\n",
      "running loss : 124.749460\n",
      "running loss : 121.745778\n",
      "running loss : 119.717947\n",
      "running loss : 116.994394\n",
      "running loss : 114.156701\n",
      "running loss : 111.938231\n",
      "running loss : 108.247507\n",
      "running loss : 105.600042\n",
      "running loss : 102.519346\n",
      "running loss : 100.100471\n",
      "running loss : 97.127291\n",
      "running loss : 94.781453\n",
      "running loss : 92.433450\n",
      "running loss : 91.325681\n",
      "running loss : 88.480431\n",
      "running loss : 87.561033\n",
      "running loss : 83.754731\n",
      "running loss : 80.643883\n",
      "running loss : 78.374884\n",
      "running loss : 75.321966\n",
      "running loss : 73.812018\n",
      "running loss : 70.394998\n",
      "running loss : 68.147568\n",
      "running loss : 65.566177\n",
      "running loss : 63.818108\n",
      "running loss : 61.006274\n",
      "running loss : 58.680607\n",
      "running loss : 56.813688\n",
      "running loss : 55.564984\n",
      "running loss : 54.475893\n",
      "running loss : 53.318633\n",
      "running loss : 52.016286\n",
      "running loss : 50.848067\n",
      "running loss : 49.862799\n",
      "running loss : 49.370080\n",
      "running loss : 48.101476\n",
      "running loss : 47.066588\n",
      "running loss : 47.126433\n",
      "running loss : 46.668494\n",
      "running loss : 46.419803\n",
      "running loss : 46.368199\n",
      "running loss : 45.708205\n",
      "running loss : 45.853509\n",
      "running loss : 45.678351\n",
      "running loss : 45.030321\n",
      "running loss : 44.544487\n",
      "running loss : 44.171493\n",
      "running loss : 44.091875\n",
      "running loss : 43.932016\n",
      "running loss : 43.607401\n",
      "running loss : 43.230529\n",
      "running loss : 42.952612\n",
      "running loss : 43.133347\n",
      "running loss : 42.619248\n",
      "running loss : 42.282838\n",
      "running loss : 42.318042\n",
      "running loss : 42.149607\n",
      "running loss : 41.698707\n",
      "running loss : 41.181844\n",
      "running loss : 41.141127\n",
      "running loss : 40.670562\n",
      "running loss : 40.623183\n",
      "running loss : 40.087724\n",
      "running loss : 40.072923\n",
      "running loss : 39.856510\n",
      "running loss : 39.473689\n",
      "running loss : 39.247417\n",
      "running loss : 38.703266\n",
      "running loss : 38.452972\n",
      "running loss : 38.418289\n",
      "running loss : 37.942101\n",
      "running loss : 37.961960\n",
      "running loss : 37.785247\n",
      "running loss : 37.482768\n",
      "running loss : 37.091357\n",
      "running loss : 36.954373\n",
      "running loss : 36.802883\n",
      "running loss : 36.488313\n",
      "running loss : 36.037495\n",
      "running loss : 36.077450\n",
      "running loss : 35.820417\n",
      "running loss : 35.535531\n",
      "running loss : 35.103167\n",
      "running loss : 34.803556\n",
      "running loss : 34.696637\n",
      "running loss : 34.153360\n",
      "running loss : 34.298692\n",
      "running loss : 34.032153\n",
      "running loss : 33.785430\n",
      "running loss : 33.473710\n",
      "running loss : 33.529715\n",
      "running loss : 33.399154\n",
      "running loss : 33.299012\n",
      "running loss : 33.199469\n",
      "running loss : 33.010718\n",
      "running loss : 33.032290\n",
      "running loss : 32.749947\n",
      "running loss : 32.527559\n",
      "running loss : 32.548643\n",
      "running loss : 32.341050\n",
      "running loss : 32.396496\n",
      "running loss : 32.590837\n",
      "running loss : 32.567569\n",
      "running loss : 32.147412\n",
      "running loss : 32.216174\n",
      "running loss : 31.981276\n",
      "running loss : 32.069440\n",
      "running loss : 31.831223\n",
      "running loss : 31.707794\n",
      "running loss : 31.607758\n",
      "running loss : 31.750325\n",
      "running loss : 31.688947\n",
      "running loss : 31.218653\n",
      "running loss : 31.347588\n",
      "running loss : 31.251774\n",
      "running loss : 31.078695\n",
      "running loss : 30.851464\n",
      "running loss : 31.195738\n",
      "running loss : 30.490371\n",
      "running loss : 30.420160\n",
      "running loss : 30.188408\n",
      "running loss : 30.237378\n",
      "running loss : 30.293164\n",
      "running loss : 29.960059\n",
      "running loss : 30.008445\n",
      "running loss : 29.616867\n",
      "running loss : 29.607578\n",
      "running loss : 29.429360\n",
      "running loss : 29.381623\n",
      "running loss : 29.485595\n",
      "running loss : 29.386945\n",
      "running loss : 28.975017\n",
      "running loss : 28.838556\n",
      "running loss : 28.803571\n",
      "running loss : 28.680868\n",
      "running loss : 28.831707\n",
      "running loss : 28.475084\n",
      "running loss : 28.305355\n",
      "running loss : 28.289357\n",
      "running loss : 28.082424\n",
      "running loss : 28.170070\n",
      "running loss : 28.031731\n",
      "running loss : 27.971095\n",
      "running loss : 27.784096\n",
      "running loss : 27.768324\n",
      "running loss : 27.629478\n",
      "running loss : 27.715897\n",
      "running loss : 27.601957\n",
      "running loss : 27.692540\n",
      "running loss : 27.562638\n",
      "running loss : 27.384310\n",
      "running loss : 27.437973\n",
      "running loss : 27.285784\n",
      "running loss : 27.295628\n",
      "running loss : 27.211171\n",
      "running loss : 27.060077\n",
      "running loss : 26.985120\n",
      "running loss : 27.018045\n",
      "running loss : 26.884598\n",
      "running loss : 26.786358\n",
      "running loss : 26.602862\n",
      "running loss : 26.568921\n",
      "running loss : 26.410116\n",
      "running loss : 26.379205\n",
      "running loss : 26.342849\n",
      "running loss : 25.953728\n",
      "running loss : 26.041668\n",
      "running loss : 25.861028\n",
      "running loss : 25.756275\n",
      "running loss : 25.644267\n",
      "running loss : 25.773676\n",
      "running loss : 25.571716\n",
      "running loss : 25.517427\n",
      "running loss : 25.305620\n",
      "running loss : 25.314788\n",
      "running loss : 25.420856\n",
      "running loss : 25.248720\n",
      "running loss : 25.037367\n",
      "running loss : 24.969569\n",
      "running loss : 24.945425\n",
      "running loss : 24.929308\n",
      "running loss : 24.700016\n",
      "running loss : 24.717997\n",
      "running loss : 24.544865\n",
      "running loss : 24.538167\n",
      "running loss : 24.566845\n",
      "running loss : 24.204029\n",
      "running loss : 24.220051\n",
      "running loss : 24.243121\n",
      "running loss : 23.880942\n",
      "running loss : 23.995615\n",
      "running loss : 23.976675\n",
      "running loss : 23.803361\n",
      "running loss : 23.773300\n",
      "running loss : 23.565301\n",
      "running loss : 23.486416\n",
      "running loss : 23.667598\n",
      "running loss : 23.553413\n",
      "running loss : 23.660374\n",
      "running loss : 23.477137\n",
      "running loss : 23.535849\n",
      "running loss : 23.410170\n",
      "running loss : 23.307101\n",
      "running loss : 23.307343\n",
      "running loss : 23.233133\n",
      "running loss : 23.187927\n",
      "running loss : 23.043187\n",
      "running loss : 23.052080\n",
      "running loss : 22.999729\n",
      "running loss : 22.829973\n",
      "running loss : 22.880788\n",
      "running loss : 22.932977\n",
      "running loss : 22.787025\n",
      "running loss : 22.833886\n",
      "running loss : 22.524869\n",
      "running loss : 22.396360\n",
      "running loss : 22.452724\n",
      "running loss : 22.407118\n",
      "running loss : 22.405152\n",
      "running loss : 22.360466\n",
      "running loss : 22.167220\n",
      "running loss : 22.218445\n",
      "running loss : 22.142444\n",
      "running loss : 22.192846\n",
      "running loss : 21.844208\n",
      "running loss : 21.929523\n",
      "running loss : 21.834366\n",
      "running loss : 21.783431\n",
      "running loss : 21.724327\n",
      "running loss : 21.756828\n",
      "running loss : 21.676993\n",
      "running loss : 21.598681\n",
      "running loss : 21.446250\n",
      "running loss : 21.621945\n",
      "running loss : 21.460378\n",
      "running loss : 21.154103\n",
      "running loss : 21.109812\n",
      "running loss : 21.121571\n",
      "running loss : 21.056609\n",
      "running loss : 20.935214\n",
      "running loss : 20.897850\n",
      "running loss : 20.982452\n",
      "running loss : 20.880162\n",
      "running loss : 20.786794\n",
      "running loss : 20.841870\n",
      "running loss : 20.726594\n",
      "running loss : 20.695945\n",
      "running loss : 20.732636\n",
      "running loss : 20.740143\n",
      "running loss : 20.605821\n",
      "running loss : 20.582102\n",
      "running loss : 20.594863\n",
      "running loss : 20.548600\n",
      "running loss : 20.415437\n",
      "running loss : 20.421436\n",
      "running loss : 20.377229\n",
      "running loss : 20.328357\n",
      "running loss : 20.247343\n",
      "running loss : 20.331964\n",
      "running loss : 20.208276\n",
      "running loss : 20.174541\n",
      "running loss : 20.158259\n",
      "running loss : 20.111403\n",
      "running loss : 19.934659\n",
      "running loss : 19.820315\n",
      "running loss : 19.814401\n",
      "running loss : 19.808119\n",
      "running loss : 19.906591\n",
      "running loss : 19.723953\n",
      "running loss : 19.654076\n",
      "running loss : 19.722918\n",
      "running loss : 19.649955\n",
      "running loss : 19.633903\n",
      "running loss : 19.457389\n",
      "running loss : 19.482234\n",
      "running loss : 19.381729\n",
      "running loss : 19.338179\n",
      "running loss : 19.326160\n",
      "running loss : 19.400762\n",
      "running loss : 19.177502\n",
      "running loss : 19.175272\n",
      "running loss : 18.974072\n",
      "running loss : 19.132408\n",
      "running loss : 18.935764\n",
      "running loss : 18.853005\n",
      "running loss : 18.877038\n",
      "running loss : 19.028166\n",
      "running loss : 18.865699\n",
      "running loss : 18.775881\n",
      "running loss : 18.675842\n",
      "running loss : 18.677659\n",
      "running loss : 18.526957\n",
      "running loss : 18.681923\n",
      "running loss : 18.572605\n",
      "running loss : 18.501469\n",
      "running loss : 18.649693\n",
      "running loss : 18.483200\n",
      "running loss : 18.479416\n",
      "running loss : 18.571282\n",
      "running loss : 18.603988\n",
      "running loss : 18.316921\n",
      "running loss : 18.348143\n",
      "running loss : 18.246530\n",
      "running loss : 18.160333\n",
      "running loss : 18.170753\n",
      "running loss : 18.156729\n",
      "running loss : 18.234546\n",
      "running loss : 18.106758\n",
      "running loss : 17.995779\n",
      "running loss : 18.041893\n",
      "running loss : 18.009598\n",
      "running loss : 17.873991\n",
      "running loss : 17.893585\n",
      "running loss : 17.833851\n",
      "running loss : 17.880359\n",
      "running loss : 17.902041\n",
      "running loss : 17.789803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 17.684534\n",
      "running loss : 17.678082\n",
      "running loss : 17.572147\n",
      "running loss : 17.421605\n",
      "running loss : 17.430271\n",
      "running loss : 17.470608\n",
      "running loss : 17.332202\n",
      "running loss : 17.398822\n",
      "running loss : 17.261724\n",
      "running loss : 17.274817\n",
      "running loss : 17.225063\n",
      "running loss : 17.174861\n",
      "running loss : 17.130926\n",
      "running loss : 17.081111\n",
      "running loss : 17.086290\n",
      "running loss : 16.989676\n",
      "running loss : 16.861157\n",
      "running loss : 16.943512\n",
      "running loss : 16.795938\n",
      "running loss : 16.833276\n",
      "running loss : 16.779245\n",
      "running loss : 17.164408\n",
      "running loss : 17.019157\n",
      "running loss : 16.835541\n",
      "running loss : 16.726740\n",
      "running loss : 16.712314\n",
      "running loss : 16.733612\n",
      "running loss : 16.688623\n",
      "running loss : 16.628349\n",
      "running loss : 16.616849\n",
      "running loss : 16.598906\n",
      "running loss : 16.611400\n",
      "running loss : 16.499395\n",
      "running loss : 16.584261\n",
      "running loss : 16.524556\n",
      "running loss : 16.440599\n",
      "running loss : 16.523318\n",
      "running loss : 16.450753\n",
      "running loss : 16.429570\n",
      "running loss : 16.479867\n",
      "running loss : 16.396666\n",
      "running loss : 16.347758\n",
      "running loss : 16.250649\n",
      "running loss : 16.105778\n",
      "running loss : 16.101245\n",
      "running loss : 16.118683\n",
      "running loss : 16.240919\n",
      "running loss : 16.009165\n",
      "running loss : 15.995699\n",
      "running loss : 15.871840\n",
      "running loss : 15.927842\n",
      "running loss : 16.023492\n",
      "running loss : 15.883065\n",
      "running loss : 15.725636\n",
      "running loss : 15.702426\n",
      "running loss : 15.668305\n",
      "running loss : 15.725045\n",
      "running loss : 15.655774\n",
      "running loss : 15.624000\n",
      "running loss : 15.603745\n",
      "running loss : 15.453074\n",
      "running loss : 15.399180\n",
      "running loss : 15.510533\n",
      "running loss : 15.362314\n",
      "running loss : 15.402372\n",
      "running loss : 15.379060\n",
      "running loss : 15.245696\n",
      "running loss : 15.203266\n",
      "running loss : 15.261359\n",
      "running loss : 15.108201\n",
      "running loss : 15.173804\n",
      "running loss : 15.129302\n",
      "running loss : 15.071822\n",
      "running loss : 15.103811\n",
      "running loss : 15.243680\n",
      "running loss : 15.152974\n",
      "running loss : 15.099752\n",
      "running loss : 15.169419\n",
      "running loss : 15.081927\n",
      "running loss : 14.936267\n",
      "running loss : 15.105049\n",
      "running loss : 15.074302\n",
      "running loss : 14.933177\n",
      "running loss : 14.873738\n",
      "running loss : 14.975417\n",
      "running loss : 15.031987\n",
      "running loss : 15.059134\n",
      "running loss : 15.013387\n",
      "running loss : 14.954859\n",
      "running loss : 14.924592\n",
      "running loss : 14.978524\n",
      "running loss : 14.931908\n",
      "running loss : 14.937146\n",
      "running loss : 15.002116\n",
      "running loss : 14.875048\n",
      "running loss : 14.900112\n",
      "running loss : 14.730342\n",
      "running loss : 14.885679\n",
      "running loss : 14.764224\n",
      "running loss : 14.721812\n",
      "running loss : 14.688982\n",
      "running loss : 14.899152\n",
      "running loss : 14.811428\n",
      "running loss : 14.701483\n",
      "running loss : 14.672055\n",
      "running loss : 14.636326\n",
      "running loss : 14.562948\n",
      "running loss : 14.709825\n",
      "running loss : 14.388362\n",
      "running loss : 14.460744\n",
      "running loss : 14.539868\n",
      "running loss : 14.528191\n",
      "running loss : 14.371132\n",
      "running loss : 14.386716\n",
      "running loss : 14.383183\n",
      "running loss : 14.323673\n",
      "running loss : 14.223706\n",
      "running loss : 14.198848\n",
      "running loss : 14.272442\n",
      "running loss : 14.261393\n",
      "running loss : 14.076105\n",
      "running loss : 14.169767\n",
      "running loss : 14.098279\n",
      "running loss : 14.213008\n",
      "running loss : 14.100573\n",
      "running loss : 14.065290\n",
      "running loss : 14.086659\n",
      "running loss : 14.053705\n",
      "running loss : 14.054117\n",
      "running loss : 14.011299\n",
      "running loss : 14.107309\n",
      "running loss : 14.015066\n",
      "running loss : 14.004871\n",
      "running loss : 14.005825\n",
      "running loss : 13.923741\n",
      "running loss : 13.984080\n",
      "running loss : 14.012041\n",
      "running loss : 13.843379\n",
      "running loss : 13.854349\n",
      "running loss : 13.978293\n",
      "running loss : 13.906332\n",
      "running loss : 13.807899\n",
      "running loss : 13.909043\n",
      "running loss : 13.851704\n",
      "running loss : 13.674957\n",
      "running loss : 13.797639\n",
      "running loss : 13.678540\n",
      "running loss : 13.642788\n",
      "running loss : 13.718885\n",
      "running loss : 13.745593\n",
      "running loss : 13.604343\n",
      "running loss : 13.593767\n",
      "running loss : 13.514254\n",
      "running loss : 13.587461\n",
      "running loss : 13.459372\n",
      "running loss : 13.384025\n",
      "running loss : 13.469513\n",
      "running loss : 13.377646\n",
      "running loss : 13.442878\n",
      "running loss : 13.414718\n",
      "running loss : 13.345500\n",
      "running loss : 13.303079\n",
      "running loss : 13.326582\n",
      "running loss : 13.244286\n",
      "running loss : 13.310692\n",
      "running loss : 13.357172\n",
      "running loss : 13.182588\n",
      "running loss : 13.147335\n",
      "running loss : 13.107934\n",
      "running loss : 13.062116\n",
      "running loss : 13.133817\n",
      "running loss : 13.140729\n",
      "running loss : 13.165021\n",
      "running loss : 13.037182\n",
      "running loss : 12.986775\n",
      "running loss : 12.971473\n",
      "running loss : 12.985547\n",
      "running loss : 12.938681\n",
      "running loss : 12.856844\n",
      "running loss : 12.952959\n",
      "running loss : 12.973527\n",
      "running loss : 12.832781\n",
      "running loss : 12.963016\n",
      "running loss : 12.914581\n",
      "running loss : 12.814174\n",
      "running loss : 12.797842\n",
      "running loss : 12.838097\n",
      "running loss : 12.820311\n",
      "running loss : 12.728236\n",
      "running loss : 12.768263\n",
      "running loss : 12.701182\n",
      "running loss : 12.741979\n",
      "running loss : 12.595729\n",
      "running loss : 12.616656\n",
      "running loss : 12.552730\n",
      "running loss : 12.598402\n",
      "running loss : 12.534672\n",
      "running loss : 12.593973\n",
      "running loss : 12.490243\n",
      "running loss : 12.728962\n",
      "running loss : 12.485685\n",
      "running loss : 12.550624\n",
      "running loss : 12.475276\n",
      "running loss : 12.347771\n",
      "running loss : 12.424162\n",
      "running loss : 12.509966\n",
      "running loss : 12.389663\n",
      "running loss : 12.333932\n",
      "running loss : 12.325815\n",
      "running loss : 12.404604\n",
      "running loss : 12.302102\n",
      "running loss : 12.246278\n",
      "running loss : 12.323102\n",
      "running loss : 12.282807\n",
      "running loss : 12.176946\n",
      "running loss : 12.159875\n",
      "running loss : 12.086521\n",
      "running loss : 12.170000\n",
      "running loss : 12.213081\n",
      "running loss : 12.037377\n",
      "running loss : 12.212810\n",
      "running loss : 12.129234\n",
      "running loss : 12.063127\n",
      "running loss : 12.096388\n",
      "running loss : 12.095426\n",
      "running loss : 12.178572\n",
      "running loss : 11.995014\n",
      "running loss : 12.096517\n",
      "running loss : 12.074011\n",
      "running loss : 12.037238\n",
      "running loss : 12.003417\n",
      "running loss : 11.932128\n",
      "running loss : 11.998946\n",
      "running loss : 11.924617\n",
      "running loss : 12.058228\n",
      "running loss : 11.882293\n",
      "running loss : 12.000134\n",
      "running loss : 11.877791\n",
      "running loss : 11.844085\n",
      "running loss : 11.918141\n",
      "running loss : 11.808922\n",
      "running loss : 11.732856\n",
      "running loss : 11.887406\n",
      "running loss : 11.919451\n",
      "running loss : 11.945889\n",
      "running loss : 11.747343\n",
      "running loss : 11.692269\n",
      "running loss : 11.711947\n",
      "running loss : 11.677051\n",
      "running loss : 11.639464\n",
      "running loss : 11.659558\n",
      "running loss : 11.597008\n",
      "running loss : 11.654400\n",
      "running loss : 11.581606\n",
      "running loss : 11.518248\n",
      "running loss : 11.582285\n",
      "running loss : 11.462647\n",
      "running loss : 11.391128\n",
      "running loss : 11.351517\n",
      "running loss : 11.403337\n",
      "running loss : 11.333325\n",
      "running loss : 11.434573\n",
      "running loss : 11.410956\n",
      "running loss : 11.408226\n",
      "running loss : 11.381296\n",
      "running loss : 11.288906\n",
      "running loss : 11.312695\n",
      "running loss : 11.299038\n",
      "running loss : 11.303909\n",
      "running loss : 11.196517\n",
      "running loss : 11.248093\n",
      "running loss : 11.250714\n",
      "running loss : 11.262274\n",
      "running loss : 11.157655\n",
      "running loss : 11.154228\n",
      "running loss : 11.118014\n",
      "running loss : 11.210027\n",
      "running loss : 11.140632\n",
      "running loss : 11.180605\n",
      "running loss : 11.164774\n",
      "running loss : 11.093524\n",
      "running loss : 11.061857\n",
      "running loss : 11.089152\n",
      "running loss : 11.047648\n",
      "running loss : 11.111008\n",
      "running loss : 11.083828\n",
      "running loss : 10.997871\n",
      "running loss : 11.034416\n",
      "running loss : 11.047656\n",
      "running loss : 10.979058\n",
      "running loss : 10.980927\n",
      "running loss : 10.983401\n",
      "running loss : 10.925856\n",
      "running loss : 11.021840\n",
      "running loss : 10.968609\n",
      "running loss : 10.907031\n",
      "running loss : 11.065034\n",
      "running loss : 10.861994\n",
      "running loss : 10.828403\n",
      "running loss : 10.909325\n",
      "running loss : 10.800301\n",
      "running loss : 10.739475\n",
      "running loss : 10.796380\n",
      "running loss : 10.789044\n",
      "running loss : 10.734561\n",
      "running loss : 10.806727\n",
      "running loss : 10.766974\n",
      "running loss : 10.722415\n",
      "running loss : 10.699977\n",
      "running loss : 10.747602\n",
      "running loss : 10.720038\n",
      "running loss : 10.750134\n",
      "running loss : 10.661975\n",
      "running loss : 10.519212\n",
      "running loss : 10.621573\n",
      "running loss : 10.637455\n",
      "running loss : 10.575992\n",
      "running loss : 10.706330\n",
      "running loss : 10.557270\n",
      "running loss : 10.578551\n",
      "running loss : 10.423397\n",
      "running loss : 10.540562\n",
      "running loss : 10.532824\n",
      "running loss : 10.424233\n",
      "running loss : 10.448542\n",
      "running loss : 10.463651\n",
      "running loss : 10.453741\n",
      "running loss : 10.442910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 10.451279\n",
      "running loss : 10.394179\n",
      "running loss : 10.468761\n",
      "running loss : 10.388043\n",
      "running loss : 10.362525\n",
      "running loss : 10.423447\n",
      "running loss : 10.310354\n",
      "running loss : 10.389745\n",
      "running loss : 10.352796\n",
      "running loss : 10.371820\n",
      "running loss : 10.295872\n",
      "running loss : 10.395231\n",
      "running loss : 10.355159\n",
      "running loss : 10.248750\n",
      "running loss : 10.324615\n",
      "running loss : 10.325953\n",
      "running loss : 10.242782\n",
      "running loss : 10.162034\n",
      "running loss : 10.212267\n",
      "running loss : 10.221675\n",
      "running loss : 10.157132\n",
      "running loss : 10.118882\n",
      "running loss : 10.164307\n",
      "running loss : 10.198609\n",
      "running loss : 10.087902\n",
      "running loss : 10.042576\n",
      "running loss : 10.053151\n",
      "running loss : 10.060194\n",
      "running loss : 10.038095\n",
      "running loss : 10.051306\n",
      "running loss : 9.995373\n",
      "running loss : 9.965188\n",
      "running loss : 9.964843\n",
      "running loss : 10.011082\n",
      "running loss : 9.944212\n",
      "running loss : 10.026435\n",
      "running loss : 9.919166\n",
      "running loss : 9.896631\n",
      "running loss : 9.822476\n",
      "running loss : 9.880906\n",
      "running loss : 9.859232\n",
      "running loss : 9.856623\n",
      "running loss : 9.838958\n",
      "running loss : 9.914041\n",
      "running loss : 9.832305\n",
      "running loss : 9.802469\n",
      "running loss : 9.848778\n",
      "running loss : 9.781171\n",
      "running loss : 9.845903\n",
      "running loss : 9.805858\n",
      "running loss : 9.698902\n",
      "running loss : 9.750831\n",
      "running loss : 9.764182\n",
      "running loss : 9.785133\n",
      "running loss : 9.769236\n",
      "running loss : 9.740201\n",
      "running loss : 9.705517\n",
      "running loss : 9.738922\n",
      "running loss : 9.716729\n",
      "running loss : 9.648051\n",
      "running loss : 9.685258\n",
      "running loss : 9.666540\n",
      "running loss : 9.586639\n",
      "running loss : 9.567553\n",
      "running loss : 9.639357\n",
      "running loss : 9.582366\n",
      "running loss : 9.649271\n",
      "running loss : 9.505792\n",
      "running loss : 9.584488\n",
      "running loss : 9.536178\n",
      "running loss : 9.575093\n",
      "running loss : 9.622294\n",
      "running loss : 9.492891\n",
      "running loss : 9.459774\n",
      "running loss : 9.477306\n",
      "running loss : 9.405941\n",
      "running loss : 9.416683\n",
      "running loss : 9.469615\n",
      "running loss : 9.400504\n",
      "running loss : 9.411431\n",
      "running loss : 9.381031\n",
      "running loss : 9.368537\n",
      "running loss : 9.358061\n",
      "running loss : 9.363032\n",
      "running loss : 9.257762\n",
      "running loss : 9.418647\n",
      "running loss : 9.361831\n",
      "running loss : 9.280754\n",
      "running loss : 9.311775\n",
      "running loss : 9.217273\n",
      "running loss : 9.257100\n",
      "running loss : 9.240141\n",
      "running loss : 9.232698\n",
      "running loss : 9.276580\n",
      "running loss : 9.275599\n",
      "running loss : 9.265603\n",
      "running loss : 9.224893\n",
      "running loss : 9.216019\n",
      "running loss : 9.205851\n",
      "running loss : 9.229810\n",
      "running loss : 9.262895\n",
      "running loss : 9.207407\n",
      "running loss : 9.326932\n",
      "running loss : 9.228440\n",
      "running loss : 9.159992\n",
      "running loss : 9.160190\n",
      "running loss : 9.083419\n",
      "running loss : 9.219445\n",
      "running loss : 9.172478\n",
      "running loss : 9.102418\n",
      "running loss : 9.078772\n",
      "running loss : 9.118246\n",
      "running loss : 9.094615\n",
      "running loss : 9.112712\n",
      "running loss : 9.075760\n",
      "running loss : 9.042859\n",
      "running loss : 9.018495\n",
      "running loss : 8.995301\n",
      "running loss : 9.047535\n",
      "running loss : 8.994185\n",
      "running loss : 9.039196\n",
      "running loss : 8.989194\n",
      "running loss : 9.066563\n",
      "running loss : 9.006455\n",
      "running loss : 8.958120\n",
      "running loss : 8.947481\n",
      "running loss : 8.981945\n",
      "running loss : 8.952349\n",
      "running loss : 8.851504\n",
      "running loss : 8.908895\n",
      "running loss : 8.900739\n",
      "running loss : 8.787442\n",
      "running loss : 8.851076\n",
      "running loss : 8.743550\n",
      "running loss : 8.787701\n",
      "running loss : 8.766732\n",
      "running loss : 8.809865\n",
      "running loss : 8.764347\n",
      "running loss : 8.738231\n",
      "running loss : 8.725996\n",
      "running loss : 8.744750\n",
      "running loss : 8.754836\n",
      "running loss : 8.769087\n",
      "running loss : 8.693151\n",
      "running loss : 8.646603\n",
      "running loss : 8.651293\n",
      "running loss : 8.735434\n",
      "running loss : 8.683467\n",
      "running loss : 8.713888\n",
      "running loss : 8.630652\n",
      "running loss : 8.703690\n",
      "running loss : 8.632330\n",
      "running loss : 8.737096\n",
      "running loss : 8.730427\n",
      "running loss : 8.647090\n",
      "running loss : 8.582480\n",
      "running loss : 8.607167\n",
      "running loss : 8.591027\n",
      "running loss : 8.622325\n",
      "running loss : 8.586039\n",
      "running loss : 8.581706\n",
      "running loss : 8.654881\n",
      "running loss : 8.673056\n",
      "running loss : 8.571257\n",
      "running loss : 8.541862\n",
      "running loss : 8.542838\n",
      "running loss : 8.582974\n",
      "running loss : 8.535475\n",
      "running loss : 8.527567\n",
      "running loss : 8.555926\n",
      "running loss : 8.453800\n",
      "running loss : 8.580086\n",
      "running loss : 8.510435\n",
      "running loss : 8.513449\n",
      "running loss : 8.404350\n",
      "running loss : 8.375576\n",
      "running loss : 8.431506\n",
      "running loss : 8.455956\n",
      "running loss : 8.407736\n",
      "running loss : 8.391847\n",
      "running loss : 8.363374\n",
      "running loss : 8.393621\n",
      "running loss : 8.318910\n",
      "running loss : 8.338545\n",
      "running loss : 8.281391\n",
      "running loss : 8.373821\n",
      "running loss : 8.294632\n",
      "running loss : 8.357066\n",
      "running loss : 8.239860\n",
      "running loss : 8.283929\n",
      "running loss : 8.355863\n",
      "running loss : 8.296747\n",
      "running loss : 8.187769\n",
      "running loss : 8.249063\n",
      "running loss : 8.248883\n",
      "running loss : 8.207167\n",
      "running loss : 8.217014\n",
      "running loss : 8.312826\n",
      "running loss : 8.194882\n",
      "running loss : 8.205310\n",
      "running loss : 8.220549\n",
      "running loss : 8.277444\n",
      "running loss : 8.196175\n",
      "running loss : 8.214918\n",
      "running loss : 8.202969\n",
      "running loss : 8.190632\n",
      "running loss : 8.204627\n",
      "running loss : 8.124985\n",
      "running loss : 8.182467\n",
      "running loss : 8.138238\n",
      "running loss : 8.126239\n",
      "running loss : 8.182481\n",
      "running loss : 8.058827\n",
      "running loss : 8.132302\n",
      "running loss : 8.071189\n",
      "running loss : 8.078706\n",
      "running loss : 8.106722\n",
      "running loss : 8.037793\n",
      "running loss : 8.117918\n",
      "running loss : 8.102652\n",
      "running loss : 8.016844\n",
      "running loss : 7.996497\n",
      "running loss : 8.019480\n",
      "running loss : 8.000539\n",
      "running loss : 8.049478\n",
      "running loss : 7.945331\n",
      "running loss : 7.949898\n",
      "running loss : 7.973651\n",
      "running loss : 7.940110\n",
      "running loss : 7.923586\n",
      "running loss : 7.912338\n",
      "running loss : 7.930878\n",
      "running loss : 7.875819\n",
      "running loss : 7.923457\n",
      "running loss : 7.850254\n",
      "running loss : 7.840723\n",
      "running loss : 7.883211\n",
      "running loss : 7.834032\n",
      "running loss : 7.849187\n",
      "running loss : 7.815230\n",
      "running loss : 7.796542\n",
      "running loss : 7.767611\n",
      "running loss : 7.833682\n",
      "running loss : 7.762714\n",
      "running loss : 7.829677\n",
      "running loss : 7.796596\n",
      "running loss : 7.794066\n",
      "running loss : 7.843040\n",
      "running loss : 7.734925\n",
      "running loss : 7.724905\n",
      "running loss : 7.826032\n",
      "running loss : 7.792665\n",
      "running loss : 7.767354\n",
      "running loss : 7.765051\n",
      "running loss : 7.671229\n",
      "running loss : 7.719845\n",
      "running loss : 7.689633\n",
      "running loss : 7.708869\n",
      "running loss : 7.679414\n",
      "running loss : 7.780232\n",
      "running loss : 7.760133\n",
      "running loss : 7.731548\n",
      "running loss : 7.684033\n",
      "running loss : 7.678741\n",
      "running loss : 7.649468\n",
      "running loss : 7.698052\n",
      "running loss : 7.604234\n",
      "running loss : 7.624083\n",
      "running loss : 7.630331\n",
      "running loss : 7.615441\n",
      "running loss : 7.639126\n",
      "running loss : 7.548052\n",
      "running loss : 7.573308\n",
      "running loss : 7.614102\n",
      "running loss : 7.561160\n",
      "running loss : 7.553073\n",
      "running loss : 7.562296\n",
      "running loss : 7.513274\n",
      "running loss : 7.471549\n",
      "running loss : 7.461204\n",
      "running loss : 7.462956\n",
      "running loss : 7.511537\n",
      "running loss : 7.486084\n",
      "running loss : 7.506067\n",
      "running loss : 7.397907\n",
      "running loss : 7.423130\n",
      "running loss : 7.403976\n",
      "running loss : 7.465445\n",
      "running loss : 7.421005\n",
      "running loss : 7.419360\n",
      "running loss : 7.406309\n",
      "running loss : 7.360009\n",
      "running loss : 7.400907\n",
      "running loss : 7.392683\n",
      "running loss : 7.302772\n",
      "running loss : 7.333616\n",
      "running loss : 7.410090\n",
      "running loss : 7.320930\n",
      "running loss : 7.360917\n",
      "running loss : 7.309534\n",
      "running loss : 7.330069\n",
      "running loss : 7.378868\n",
      "running loss : 7.370704\n",
      "running loss : 7.297556\n",
      "running loss : 7.306930\n",
      "running loss : 7.331589\n",
      "running loss : 7.353842\n",
      "running loss : 7.307577\n",
      "running loss : 7.339066\n",
      "running loss : 7.270557\n",
      "running loss : 7.291897\n",
      "running loss : 7.282080\n",
      "running loss : 7.168319\n",
      "running loss : 7.233845\n",
      "running loss : 7.286494\n",
      "running loss : 7.263116\n",
      "running loss : 7.272819\n",
      "running loss : 7.236621\n",
      "running loss : 7.203283\n",
      "running loss : 7.183226\n",
      "running loss : 7.239253\n",
      "running loss : 7.172868\n",
      "running loss : 7.159258\n",
      "running loss : 7.208896\n",
      "running loss : 7.223124\n",
      "running loss : 7.161249\n",
      "running loss : 7.076668\n",
      "running loss : 7.137590\n",
      "running loss : 7.153264\n",
      "running loss : 7.139877\n",
      "running loss : 7.061642\n",
      "running loss : 7.061931\n",
      "running loss : 7.105236\n",
      "running loss : 7.076282\n",
      "running loss : 7.062414\n",
      "running loss : 7.052896\n",
      "running loss : 7.103817\n",
      "running loss : 7.021640\n",
      "running loss : 7.110034\n",
      "running loss : 7.082781\n",
      "running loss : 7.027017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 7.013618\n",
      "running loss : 7.036814\n",
      "running loss : 7.013382\n",
      "running loss : 7.003105\n",
      "running loss : 7.021514\n",
      "running loss : 6.985517\n",
      "running loss : 7.017577\n",
      "running loss : 7.008509\n",
      "running loss : 6.997798\n",
      "running loss : 6.959509\n",
      "running loss : 7.011243\n",
      "running loss : 6.999750\n",
      "running loss : 6.947290\n",
      "running loss : 6.952153\n",
      "running loss : 6.930468\n",
      "running loss : 6.943455\n",
      "running loss : 6.964752\n",
      "running loss : 6.967239\n",
      "running loss : 7.185082\n",
      "running loss : 7.127109\n",
      "running loss : 6.979653\n",
      "running loss : 6.933107\n",
      "running loss : 6.900641\n",
      "running loss : 6.935779\n",
      "running loss : 6.921309\n",
      "running loss : 7.006279\n",
      "running loss : 6.895660\n",
      "running loss : 6.915483\n",
      "running loss : 6.888609\n",
      "running loss : 6.957187\n",
      "running loss : 6.883443\n",
      "running loss : 6.895411\n",
      "running loss : 6.876664\n",
      "running loss : 6.885499\n",
      "running loss : 6.957025\n",
      "running loss : 6.916388\n",
      "running loss : 6.920920\n",
      "running loss : 6.929640\n",
      "running loss : 6.912927\n",
      "running loss : 6.817657\n",
      "running loss : 6.868999\n",
      "running loss : 6.819879\n",
      "running loss : 6.818225\n",
      "running loss : 6.885347\n",
      "running loss : 6.805365\n",
      "running loss : 6.783434\n",
      "running loss : 6.716569\n",
      "running loss : 6.791365\n",
      "running loss : 6.766870\n",
      "running loss : 6.745711\n",
      "running loss : 6.693448\n",
      "running loss : 6.724717\n",
      "running loss : 6.719321\n",
      "running loss : 6.746548\n",
      "running loss : 6.781360\n",
      "running loss : 6.788124\n",
      "running loss : 6.681298\n",
      "running loss : 6.687521\n",
      "running loss : 6.680344\n",
      "running loss : 6.670429\n",
      "running loss : 6.715175\n",
      "running loss : 6.693700\n",
      "running loss : 6.672785\n",
      "running loss : 6.704448\n",
      "running loss : 6.688383\n",
      "running loss : 6.663582\n",
      "running loss : 6.637663\n",
      "running loss : 6.640656\n",
      "running loss : 6.656983\n",
      "running loss : 6.631947\n",
      "running loss : 6.705953\n",
      "running loss : 6.644982\n",
      "running loss : 6.561932\n",
      "running loss : 6.617161\n",
      "running loss : 6.548187\n",
      "running loss : 6.582010\n",
      "running loss : 6.586666\n",
      "running loss : 6.540160\n",
      "running loss : 6.560444\n",
      "running loss : 6.561084\n",
      "running loss : 6.525421\n",
      "running loss : 6.602372\n",
      "running loss : 6.516841\n",
      "running loss : 6.508592\n",
      "running loss : 6.489409\n",
      "running loss : 6.465299\n",
      "running loss : 6.440594\n",
      "running loss : 6.485268\n",
      "running loss : 6.544606\n",
      "running loss : 6.478600\n",
      "running loss : 6.434461\n",
      "running loss : 6.440192\n",
      "running loss : 6.420603\n",
      "running loss : 6.422728\n",
      "running loss : 6.417209\n",
      "running loss : 6.363348\n",
      "running loss : 6.396168\n",
      "running loss : 6.359680\n",
      "running loss : 6.386322\n",
      "running loss : 6.381744\n",
      "running loss : 6.402877\n",
      "running loss : 6.392456\n",
      "running loss : 6.384277\n",
      "running loss : 6.409489\n",
      "running loss : 6.376697\n",
      "running loss : 6.363055\n",
      "running loss : 6.350916\n",
      "running loss : 6.291679\n",
      "running loss : 6.367155\n",
      "running loss : 6.353364\n",
      "running loss : 6.346590\n",
      "running loss : 6.348286\n",
      "running loss : 6.317155\n",
      "running loss : 6.370800\n",
      "running loss : 6.309739\n",
      "running loss : 6.309675\n",
      "running loss : 6.337093\n",
      "running loss : 6.348622\n",
      "running loss : 6.330930\n",
      "running loss : 6.283031\n",
      "running loss : 6.285791\n",
      "running loss : 6.252144\n",
      "running loss : 6.301926\n",
      "running loss : 6.320321\n",
      "running loss : 6.284619\n",
      "running loss : 6.233926\n",
      "running loss : 6.244659\n",
      "running loss : 6.305404\n",
      "running loss : 6.270493\n",
      "running loss : 6.222807\n",
      "running loss : 6.176118\n",
      "running loss : 6.167832\n",
      "running loss : 6.162238\n",
      "running loss : 6.157903\n",
      "running loss : 6.152193\n",
      "running loss : 6.113895\n",
      "running loss : 6.156741\n",
      "running loss : 6.780860\n",
      "running loss : 6.430522\n",
      "running loss : 6.225914\n",
      "running loss : 6.115898\n",
      "running loss : 6.103604\n",
      "running loss : 6.126730\n",
      "running loss : 6.061423\n",
      "running loss : 6.095932\n",
      "running loss : 6.118106\n",
      "running loss : 6.072193\n",
      "running loss : 6.071949\n",
      "running loss : 6.060305\n",
      "running loss : 6.078091\n",
      "running loss : 6.051967\n",
      "running loss : 6.062242\n",
      "running loss : 6.042672\n",
      "running loss : 6.012204\n",
      "running loss : 6.006015\n",
      "running loss : 6.074161\n",
      "running loss : 6.017850\n",
      "running loss : 6.095765\n",
      "running loss : 6.060414\n",
      "running loss : 6.032828\n",
      "running loss : 6.017848\n",
      "running loss : 6.063742\n",
      "running loss : 5.993389\n",
      "running loss : 5.970923\n",
      "running loss : 5.960722\n",
      "running loss : 5.996407\n",
      "running loss : 6.047959\n",
      "running loss : 6.001737\n",
      "running loss : 5.981828\n",
      "running loss : 5.970548\n",
      "running loss : 5.924611\n",
      "running loss : 5.950539\n",
      "running loss : 5.942399\n",
      "running loss : 5.918234\n",
      "running loss : 5.958699\n",
      "running loss : 5.930312\n",
      "running loss : 5.946471\n",
      "running loss : 5.946020\n",
      "running loss : 5.955020\n",
      "running loss : 5.922161\n",
      "running loss : 5.874050\n",
      "running loss : 5.905055\n",
      "running loss : 5.937653\n",
      "running loss : 5.915234\n",
      "running loss : 5.898009\n",
      "running loss : 5.890200\n",
      "running loss : 5.855770\n",
      "running loss : 5.875026\n",
      "running loss : 5.881010\n",
      "running loss : 5.803534\n",
      "running loss : 5.902858\n",
      "running loss : 5.858413\n",
      "running loss : 5.842111\n",
      "running loss : 5.834463\n",
      "running loss : 5.789093\n",
      "running loss : 5.796974\n",
      "running loss : 5.839483\n",
      "running loss : 5.807040\n",
      "running loss : 5.777340\n",
      "running loss : 5.802370\n",
      "running loss : 5.811956\n",
      "running loss : 5.803465\n",
      "running loss : 5.797741\n",
      "running loss : 5.763267\n",
      "running loss : 5.779732\n",
      "running loss : 5.802635\n",
      "running loss : 5.782146\n",
      "running loss : 5.776842\n",
      "running loss : 5.699951\n",
      "running loss : 5.755764\n",
      "running loss : 5.754001\n",
      "running loss : 5.766178\n",
      "running loss : 5.779112\n",
      "running loss : 5.758791\n",
      "running loss : 5.766238\n",
      "running loss : 5.790706\n",
      "running loss : 5.715598\n",
      "running loss : 5.709964\n",
      "running loss : 5.707661\n",
      "running loss : 5.787558\n",
      "running loss : 5.756242\n",
      "running loss : 5.754666\n",
      "running loss : 5.740718\n",
      "running loss : 5.727948\n",
      "running loss : 5.704351\n",
      "running loss : 5.711780\n",
      "running loss : 5.687545\n",
      "running loss : 5.690429\n",
      "running loss : 5.713828\n",
      "running loss : 5.703089\n",
      "running loss : 5.736527\n",
      "running loss : 5.734148\n",
      "running loss : 5.713063\n",
      "running loss : 5.694560\n",
      "running loss : 5.658221\n",
      "running loss : 5.734817\n",
      "running loss : 5.646955\n",
      "running loss : 5.749538\n",
      "running loss : 5.681457\n",
      "running loss : 5.634565\n",
      "running loss : 5.650108\n",
      "running loss : 5.630504\n",
      "running loss : 5.597905\n",
      "running loss : 5.696962\n",
      "running loss : 5.669792\n",
      "running loss : 5.654522\n",
      "running loss : 5.580442\n",
      "running loss : 5.634731\n",
      "running loss : 5.595350\n",
      "running loss : 5.594512\n",
      "running loss : 5.612988\n",
      "running loss : 5.636987\n",
      "running loss : 5.629505\n",
      "running loss : 5.591361\n",
      "running loss : 5.625618\n",
      "running loss : 5.578424\n",
      "running loss : 5.593931\n",
      "running loss : 5.579671\n",
      "running loss : 5.537741\n",
      "running loss : 5.624203\n",
      "running loss : 5.572911\n",
      "running loss : 5.547693\n",
      "running loss : 5.540052\n",
      "running loss : 5.523267\n",
      "running loss : 5.484598\n",
      "running loss : 5.581429\n",
      "running loss : 5.542495\n",
      "running loss : 5.536873\n",
      "running loss : 5.515703\n",
      "running loss : 5.518744\n",
      "running loss : 5.521830\n",
      "running loss : 5.578541\n",
      "running loss : 5.530516\n",
      "running loss : 5.521475\n",
      "running loss : 5.479823\n",
      "running loss : 5.469102\n",
      "running loss : 5.496487\n",
      "running loss : 5.475821\n",
      "running loss : 5.475610\n",
      "running loss : 5.465433\n",
      "running loss : 5.455488\n",
      "running loss : 5.419307\n",
      "running loss : 5.410748\n",
      "running loss : 5.415448\n",
      "running loss : 5.447559\n",
      "running loss : 5.415133\n",
      "running loss : 5.396715\n",
      "running loss : 5.385028\n",
      "running loss : 5.401703\n",
      "running loss : 5.401653\n",
      "running loss : 5.394440\n",
      "running loss : 5.400824\n",
      "running loss : 5.396067\n",
      "running loss : 5.401344\n",
      "running loss : 5.372456\n",
      "running loss : 5.356459\n",
      "running loss : 5.416134\n",
      "running loss : 5.330682\n",
      "running loss : 5.338673\n",
      "running loss : 5.363607\n",
      "running loss : 5.330608\n",
      "running loss : 5.332116\n",
      "running loss : 5.365867\n",
      "running loss : 5.372424\n",
      "running loss : 5.301480\n",
      "running loss : 5.367488\n",
      "running loss : 5.304670\n",
      "running loss : 5.369523\n",
      "running loss : 5.322639\n",
      "running loss : 5.343402\n",
      "running loss : 5.325736\n",
      "running loss : 5.301994\n",
      "running loss : 5.308211\n",
      "running loss : 5.315638\n",
      "running loss : 5.302339\n",
      "running loss : 5.366691\n",
      "running loss : 5.318753\n",
      "running loss : 5.352015\n",
      "running loss : 5.302701\n",
      "running loss : 5.267627\n",
      "running loss : 5.331200\n",
      "running loss : 5.328903\n",
      "running loss : 5.319637\n",
      "running loss : 5.268683\n",
      "running loss : 5.266157\n",
      "running loss : 5.290855\n",
      "running loss : 5.275520\n",
      "running loss : 5.240913\n",
      "running loss : 5.258836\n",
      "running loss : 5.189863\n",
      "running loss : 5.232746\n",
      "running loss : 5.208447\n",
      "running loss : 5.221212\n",
      "running loss : 5.246824\n",
      "running loss : 5.247983\n",
      "running loss : 5.188926\n",
      "running loss : 5.213422\n",
      "running loss : 5.175947\n",
      "running loss : 5.164321\n",
      "running loss : 5.176659\n",
      "running loss : 5.211172\n",
      "running loss : 5.131152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 5.194759\n",
      "running loss : 5.174139\n",
      "running loss : 5.140612\n",
      "running loss : 5.160042\n",
      "running loss : 5.127445\n",
      "running loss : 5.113999\n",
      "running loss : 5.174141\n",
      "running loss : 5.148758\n",
      "running loss : 5.124841\n",
      "running loss : 5.093247\n",
      "running loss : 5.143798\n",
      "running loss : 5.113564\n",
      "running loss : 5.100820\n",
      "running loss : 5.136462\n",
      "running loss : 5.133645\n",
      "running loss : 5.150106\n",
      "running loss : 5.158227\n",
      "running loss : 5.117937\n",
      "running loss : 5.097021\n",
      "running loss : 5.079520\n",
      "running loss : 5.131897\n",
      "running loss : 5.118476\n",
      "running loss : 5.104292\n",
      "running loss : 5.102376\n",
      "running loss : 5.063134\n",
      "running loss : 5.063735\n",
      "running loss : 5.059441\n",
      "running loss : 5.056709\n",
      "running loss : 5.028163\n",
      "running loss : 5.038625\n",
      "running loss : 5.026673\n",
      "running loss : 5.065519\n",
      "running loss : 5.002443\n",
      "running loss : 4.996800\n",
      "running loss : 5.026178\n",
      "running loss : 5.046766\n",
      "running loss : 5.007104\n",
      "running loss : 5.005334\n",
      "running loss : 4.977666\n",
      "running loss : 5.003035\n",
      "running loss : 5.031067\n",
      "running loss : 4.972874\n",
      "running loss : 4.983308\n",
      "running loss : 4.948103\n",
      "running loss : 4.938716\n",
      "running loss : 4.946401\n",
      "running loss : 4.941817\n",
      "running loss : 4.940816\n",
      "running loss : 4.942919\n",
      "running loss : 4.985585\n",
      "running loss : 4.913716\n",
      "running loss : 4.938977\n",
      "running loss : 4.939693\n",
      "running loss : 4.923497\n",
      "running loss : 4.928186\n",
      "running loss : 4.907683\n",
      "running loss : 4.927493\n",
      "running loss : 4.885987\n",
      "running loss : 4.880471\n",
      "running loss : 4.912066\n",
      "running loss : 4.916458\n",
      "running loss : 4.914067\n",
      "running loss : 4.916809\n",
      "running loss : 4.902925\n",
      "running loss : 4.925953\n",
      "running loss : 4.916489\n",
      "running loss : 4.895951\n",
      "running loss : 4.878155\n",
      "running loss : 4.915107\n",
      "running loss : 4.884250\n",
      "running loss : 4.839045\n",
      "running loss : 4.849285\n",
      "running loss : 4.844531\n",
      "running loss : 4.884252\n",
      "running loss : 4.861285\n",
      "running loss : 4.837475\n",
      "running loss : 4.857443\n",
      "running loss : 4.860757\n",
      "running loss : 4.841112\n",
      "running loss : 4.871161\n",
      "running loss : 4.884184\n",
      "running loss : 4.867098\n",
      "running loss : 4.843687\n",
      "running loss : 4.836318\n",
      "running loss : 4.849427\n",
      "running loss : 4.810472\n",
      "running loss : 4.850064\n",
      "running loss : 4.827363\n",
      "running loss : 4.881848\n",
      "running loss : 4.866131\n",
      "running loss : 4.794728\n",
      "running loss : 4.816134\n",
      "running loss : 4.809913\n",
      "running loss : 4.822090\n",
      "running loss : 4.804055\n",
      "running loss : 4.812506\n",
      "running loss : 4.826937\n",
      "running loss : 4.823853\n",
      "running loss : 4.782556\n",
      "running loss : 4.802413\n",
      "running loss : 4.788928\n",
      "running loss : 4.770027\n",
      "running loss : 4.777655\n",
      "running loss : 4.751748\n",
      "running loss : 4.715161\n",
      "running loss : 4.725440\n",
      "running loss : 4.742895\n",
      "running loss : 4.743323\n",
      "running loss : 4.751509\n",
      "running loss : 4.800455\n",
      "running loss : 4.732791\n",
      "running loss : 4.776066\n",
      "running loss : 4.773736\n",
      "running loss : 4.741394\n",
      "running loss : 4.724196\n",
      "running loss : 4.706670\n",
      "running loss : 4.717368\n",
      "running loss : 4.751048\n",
      "running loss : 4.718441\n",
      "running loss : 4.695403\n",
      "running loss : 4.733145\n",
      "running loss : 4.718142\n",
      "running loss : 4.703719\n",
      "running loss : 4.685183\n",
      "running loss : 4.680779\n",
      "running loss : 4.681786\n",
      "running loss : 4.678397\n",
      "running loss : 4.769080\n",
      "running loss : 4.681005\n",
      "running loss : 4.664848\n",
      "running loss : 4.673013\n",
      "running loss : 4.686581\n",
      "running loss : 4.682282\n",
      "running loss : 4.668919\n",
      "running loss : 4.632503\n",
      "running loss : 4.622992\n",
      "running loss : 4.627776\n",
      "running loss : 4.647631\n",
      "running loss : 4.649043\n",
      "running loss : 4.675590\n",
      "running loss : 4.607322\n",
      "running loss : 4.637554\n",
      "running loss : 4.620306\n",
      "running loss : 4.579603\n",
      "running loss : 4.589303\n",
      "running loss : 4.576391\n",
      "running loss : 4.563690\n",
      "running loss : 4.597267\n",
      "running loss : 4.619781\n",
      "running loss : 4.549962\n",
      "running loss : 4.600555\n",
      "running loss : 4.594710\n",
      "running loss : 4.573921\n",
      "running loss : 4.558971\n",
      "running loss : 4.595499\n",
      "running loss : 4.547491\n",
      "running loss : 4.524686\n",
      "running loss : 4.527954\n",
      "running loss : 4.569199\n",
      "running loss : 4.489138\n",
      "running loss : 4.510743\n",
      "running loss : 4.545223\n",
      "running loss : 4.549652\n",
      "running loss : 4.571830\n",
      "running loss : 4.550711\n",
      "running loss : 4.523799\n",
      "running loss : 4.528828\n",
      "running loss : 4.541867\n",
      "running loss : 4.495789\n",
      "running loss : 4.498760\n",
      "running loss : 4.479708\n",
      "running loss : 4.505589\n",
      "running loss : 4.512281\n",
      "running loss : 4.501766\n",
      "running loss : 4.531554\n",
      "running loss : 4.483066\n",
      "running loss : 4.468519\n",
      "running loss : 4.482493\n",
      "running loss : 4.480723\n",
      "running loss : 4.473594\n",
      "running loss : 4.465698\n",
      "running loss : 4.469571\n",
      "running loss : 4.436995\n",
      "running loss : 4.475130\n",
      "running loss : 4.425877\n",
      "running loss : 4.444975\n",
      "running loss : 4.440155\n",
      "running loss : 4.443532\n",
      "running loss : 4.420682\n",
      "running loss : 4.480478\n",
      "running loss : 4.478365\n",
      "running loss : 4.439772\n",
      "running loss : 4.408512\n",
      "running loss : 4.388337\n",
      "running loss : 4.408857\n",
      "running loss : 4.376159\n",
      "running loss : 4.397607\n",
      "running loss : 4.375109\n",
      "running loss : 4.391188\n",
      "running loss : 4.381674\n",
      "running loss : 4.407383\n",
      "running loss : 4.373431\n",
      "running loss : 4.378242\n",
      "running loss : 4.353774\n",
      "running loss : 4.368816\n",
      "running loss : 4.403384\n",
      "running loss : 4.361237\n",
      "running loss : 4.392224\n",
      "running loss : 4.375296\n",
      "running loss : 4.363937\n",
      "running loss : 4.338555\n",
      "running loss : 4.341640\n",
      "running loss : 4.362165\n",
      "running loss : 4.351819\n",
      "running loss : 4.328260\n",
      "running loss : 4.301943\n",
      "running loss : 4.322057\n",
      "running loss : 4.356149\n",
      "running loss : 4.331870\n",
      "running loss : 4.365180\n",
      "running loss : 4.342227\n",
      "running loss : 4.387602\n",
      "running loss : 4.314927\n",
      "running loss : 4.342227\n",
      "running loss : 4.341610\n",
      "running loss : 4.339955\n",
      "running loss : 4.322456\n",
      "running loss : 4.328921\n",
      "running loss : 4.329929\n",
      "running loss : 4.330869\n",
      "running loss : 4.340622\n",
      "running loss : 4.365740\n",
      "running loss : 4.290652\n",
      "running loss : 4.303599\n",
      "running loss : 4.311484\n",
      "running loss : 4.308794\n",
      "running loss : 4.264738\n",
      "running loss : 4.275008\n",
      "running loss : 4.279636\n",
      "running loss : 4.279622\n",
      "running loss : 4.280709\n",
      "running loss : 4.282046\n",
      "running loss : 4.286161\n",
      "running loss : 4.237524\n",
      "running loss : 4.251145\n",
      "running loss : 4.273401\n",
      "running loss : 4.251006\n",
      "running loss : 4.219488\n",
      "running loss : 4.232657\n",
      "running loss : 4.231402\n",
      "running loss : 4.192637\n",
      "running loss : 4.210065\n",
      "running loss : 4.219780\n",
      "running loss : 4.207870\n",
      "running loss : 4.209318\n",
      "running loss : 4.207053\n",
      "running loss : 4.210282\n",
      "running loss : 4.193730\n",
      "running loss : 4.218049\n",
      "running loss : 4.208858\n",
      "running loss : 4.193620\n",
      "running loss : 4.170402\n",
      "running loss : 4.224291\n",
      "running loss : 4.187306\n",
      "running loss : 4.182473\n",
      "running loss : 4.189586\n",
      "running loss : 4.175130\n",
      "running loss : 4.153437\n",
      "running loss : 4.175988\n",
      "running loss : 4.175751\n",
      "running loss : 4.148609\n",
      "running loss : 4.176857\n",
      "running loss : 4.163728\n",
      "running loss : 4.180547\n",
      "running loss : 4.221965\n",
      "running loss : 4.154135\n",
      "running loss : 4.153754\n",
      "running loss : 4.189778\n",
      "running loss : 4.181854\n",
      "running loss : 4.120810\n",
      "running loss : 4.169650\n",
      "running loss : 4.175043\n",
      "running loss : 4.174508\n",
      "running loss : 4.168118\n",
      "running loss : 4.159836\n",
      "running loss : 4.182659\n",
      "running loss : 4.139671\n",
      "running loss : 4.149558\n",
      "running loss : 4.163724\n",
      "running loss : 4.141204\n",
      "running loss : 4.177495\n",
      "running loss : 4.147049\n",
      "running loss : 4.132820\n",
      "running loss : 4.130627\n",
      "running loss : 4.136513\n",
      "running loss : 4.132229\n",
      "running loss : 4.130381\n",
      "running loss : 4.132183\n",
      "running loss : 4.105684\n",
      "running loss : 4.094202\n",
      "running loss : 4.115638\n",
      "running loss : 4.126285\n",
      "running loss : 4.112823\n",
      "running loss : 4.062846\n",
      "running loss : 4.102124\n",
      "running loss : 4.128058\n",
      "running loss : 4.122700\n",
      "running loss : 4.105310\n",
      "running loss : 4.051915\n",
      "running loss : 4.066639\n",
      "running loss : 4.059571\n",
      "running loss : 4.108643\n",
      "running loss : 4.066983\n",
      "running loss : 4.071394\n",
      "running loss : 4.066478\n",
      "running loss : 4.080771\n",
      "running loss : 4.053568\n",
      "running loss : 4.066158\n",
      "running loss : 4.047716\n",
      "running loss : 4.089442\n",
      "running loss : 4.075273\n",
      "running loss : 4.074653\n",
      "running loss : 4.045303\n",
      "running loss : 4.014225\n",
      "running loss : 4.020507\n",
      "running loss : 4.004748\n",
      "running loss : 4.049915\n",
      "running loss : 4.060028\n",
      "running loss : 4.024833\n",
      "running loss : 4.057976\n",
      "running loss : 4.041956\n",
      "running loss : 4.017936\n",
      "running loss : 3.998630\n",
      "running loss : 3.985383\n",
      "running loss : 3.996069\n",
      "running loss : 4.039570\n",
      "running loss : 4.017614\n",
      "running loss : 4.018118\n",
      "running loss : 4.023939\n",
      "running loss : 4.015616\n",
      "running loss : 3.974623\n",
      "running loss : 3.978058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 3.969384\n",
      "running loss : 3.958569\n",
      "running loss : 3.967813\n",
      "running loss : 3.951866\n",
      "running loss : 3.993756\n",
      "running loss : 4.003326\n",
      "running loss : 3.996240\n",
      "running loss : 3.972094\n",
      "running loss : 3.962825\n",
      "running loss : 3.971494\n",
      "running loss : 3.942578\n",
      "running loss : 3.955330\n",
      "running loss : 3.960975\n",
      "running loss : 3.925923\n",
      "running loss : 3.936997\n",
      "running loss : 3.950781\n",
      "running loss : 3.928463\n",
      "running loss : 3.927109\n",
      "running loss : 3.924015\n",
      "running loss : 3.919279\n",
      "running loss : 3.920851\n",
      "running loss : 3.932064\n",
      "running loss : 3.902138\n",
      "running loss : 3.915209\n",
      "running loss : 3.917971\n",
      "running loss : 3.953174\n",
      "running loss : 3.928554\n",
      "running loss : 3.897118\n",
      "running loss : 3.923415\n",
      "running loss : 3.888945\n",
      "running loss : 3.905203\n",
      "running loss : 3.897476\n",
      "running loss : 3.920923\n",
      "running loss : 3.915422\n",
      "running loss : 3.889860\n",
      "running loss : 3.875035\n",
      "running loss : 3.901933\n",
      "running loss : 3.907656\n",
      "running loss : 3.898589\n",
      "running loss : 3.903959\n",
      "running loss : 3.913670\n",
      "running loss : 3.881341\n",
      "running loss : 3.877792\n",
      "running loss : 3.889690\n",
      "running loss : 3.887318\n",
      "running loss : 3.869418\n",
      "running loss : 3.835545\n",
      "running loss : 3.847681\n",
      "running loss : 3.849035\n",
      "running loss : 3.838601\n",
      "running loss : 3.841158\n",
      "running loss : 3.832440\n",
      "running loss : 3.851672\n",
      "running loss : 3.852589\n",
      "running loss : 3.840757\n",
      "running loss : 3.971629\n",
      "running loss : 9.015685\n",
      "running loss : 5.451998\n",
      "running loss : 4.519056\n",
      "running loss : 4.220631\n",
      "running loss : 4.112463\n",
      "running loss : 4.040660\n",
      "running loss : 4.024114\n",
      "running loss : 3.992856\n",
      "running loss : 3.932020\n",
      "running loss : 3.916747\n",
      "running loss : 3.917049\n",
      "running loss : 3.892357\n",
      "running loss : 3.875437\n",
      "running loss : 3.876201\n",
      "running loss : 3.853896\n",
      "running loss : 3.872852\n",
      "running loss : 3.859230\n",
      "running loss : 3.850774\n",
      "running loss : 3.836704\n",
      "running loss : 3.836406\n",
      "running loss : 3.831507\n",
      "running loss : 3.839067\n",
      "running loss : 3.837598\n",
      "running loss : 3.835504\n",
      "running loss : 3.820891\n",
      "running loss : 3.825708\n",
      "running loss : 3.803195\n",
      "running loss : 3.810010\n",
      "running loss : 3.821635\n",
      "running loss : 3.791284\n",
      "running loss : 3.792622\n",
      "running loss : 3.801731\n",
      "running loss : 3.804308\n",
      "running loss : 3.776532\n",
      "running loss : 3.811103\n",
      "running loss : 3.820604\n",
      "running loss : 3.786444\n",
      "running loss : 3.800420\n",
      "running loss : 3.767821\n",
      "running loss : 3.765450\n",
      "running loss : 3.753317\n",
      "running loss : 3.763567\n",
      "running loss : 3.766822\n",
      "running loss : 3.759834\n",
      "running loss : 3.750177\n",
      "running loss : 3.755028\n",
      "running loss : 3.743164\n",
      "running loss : 3.741562\n",
      "running loss : 3.746039\n",
      "running loss : 3.787057\n",
      "running loss : 3.742477\n",
      "running loss : 3.749233\n",
      "running loss : 3.737031\n",
      "running loss : 3.735048\n",
      "running loss : 3.763053\n",
      "running loss : 3.760186\n",
      "running loss : 3.708587\n",
      "running loss : 3.731663\n",
      "running loss : 3.724222\n",
      "running loss : 3.736249\n",
      "running loss : 3.719629\n",
      "running loss : 3.718431\n",
      "running loss : 3.733159\n",
      "running loss : 3.722153\n",
      "running loss : 3.728884\n",
      "running loss : 3.705063\n",
      "running loss : 3.753171\n",
      "running loss : 3.718075\n",
      "running loss : 3.707705\n",
      "running loss : 3.693951\n",
      "running loss : 3.716080\n",
      "running loss : 3.694425\n",
      "running loss : 3.714528\n",
      "running loss : 3.698030\n",
      "running loss : 3.711687\n",
      "running loss : 3.666813\n",
      "running loss : 3.695122\n",
      "running loss : 3.691592\n",
      "running loss : 3.698786\n",
      "running loss : 3.671572\n",
      "running loss : 3.692441\n",
      "running loss : 3.691742\n",
      "running loss : 3.686611\n",
      "running loss : 3.673349\n",
      "running loss : 3.698940\n",
      "running loss : 3.688188\n",
      "running loss : 3.688379\n",
      "running loss : 3.667074\n",
      "running loss : 3.666151\n",
      "running loss : 3.639824\n",
      "running loss : 3.653163\n",
      "running loss : 3.669433\n",
      "running loss : 3.669190\n",
      "running loss : 3.674361\n",
      "running loss : 3.670278\n",
      "running loss : 3.633269\n",
      "running loss : 3.680241\n",
      "running loss : 3.692419\n",
      "running loss : 3.655842\n",
      "running loss : 3.645251\n",
      "running loss : 3.649462\n",
      "running loss : 3.608638\n",
      "running loss : 3.623891\n",
      "running loss : 3.636076\n",
      "running loss : 3.626521\n",
      "running loss : 3.644874\n",
      "running loss : 3.632382\n",
      "running loss : 3.619334\n",
      "running loss : 3.623235\n",
      "running loss : 3.607518\n",
      "running loss : 3.621856\n",
      "running loss : 3.591942\n",
      "running loss : 3.633125\n",
      "running loss : 3.631760\n",
      "running loss : 3.611689\n",
      "running loss : 3.620289\n",
      "running loss : 3.626488\n",
      "running loss : 3.583594\n",
      "running loss : 3.622389\n",
      "running loss : 3.645632\n",
      "running loss : 3.669658\n",
      "running loss : 3.621827\n",
      "running loss : 3.606401\n",
      "running loss : 3.622784\n",
      "running loss : 3.589822\n",
      "running loss : 3.599414\n",
      "running loss : 3.578893\n",
      "running loss : 3.607838\n",
      "running loss : 3.572401\n",
      "running loss : 3.614343\n",
      "running loss : 3.613672\n",
      "running loss : 3.609034\n",
      "running loss : 3.587229\n",
      "running loss : 3.569425\n",
      "running loss : 3.566408\n",
      "running loss : 3.556039\n",
      "running loss : 3.546582\n",
      "running loss : 3.555827\n",
      "running loss : 3.548476\n",
      "running loss : 3.554555\n",
      "running loss : 3.585040\n",
      "running loss : 3.543795\n",
      "running loss : 3.540008\n",
      "running loss : 3.550285\n",
      "running loss : 3.542171\n",
      "running loss : 3.537300\n",
      "running loss : 3.516978\n",
      "running loss : 3.529662\n",
      "running loss : 3.516271\n",
      "running loss : 3.534943\n",
      "running loss : 3.562334\n",
      "running loss : 3.526593\n",
      "running loss : 3.512721\n",
      "running loss : 3.500574\n",
      "running loss : 3.515125\n",
      "running loss : 3.505844\n",
      "running loss : 3.495667\n",
      "running loss : 3.497205\n",
      "running loss : 3.503912\n",
      "running loss : 3.500692\n",
      "running loss : 3.523540\n",
      "running loss : 3.509450\n",
      "running loss : 3.503143\n",
      "running loss : 3.477400\n",
      "running loss : 3.493836\n",
      "running loss : 3.464919\n",
      "running loss : 3.458104\n",
      "running loss : 3.467110\n",
      "running loss : 3.470000\n",
      "running loss : 3.467003\n",
      "running loss : 3.491045\n",
      "running loss : 3.505772\n",
      "running loss : 3.473820\n",
      "running loss : 3.478678\n",
      "running loss : 3.463624\n",
      "running loss : 3.483722\n",
      "running loss : 3.454148\n",
      "running loss : 3.465572\n",
      "running loss : 3.468232\n",
      "running loss : 3.459403\n",
      "running loss : 3.475567\n",
      "running loss : 3.456554\n",
      "running loss : 3.469814\n",
      "running loss : 3.463223\n",
      "running loss : 3.436121\n",
      "running loss : 3.459496\n",
      "running loss : 3.482750\n",
      "running loss : 3.465868\n",
      "running loss : 3.494116\n",
      "running loss : 3.487168\n",
      "running loss : 3.447916\n",
      "running loss : 3.462451\n",
      "running loss : 3.424570\n",
      "running loss : 3.408238\n",
      "running loss : 3.452101\n",
      "running loss : 3.448783\n",
      "running loss : 3.425408\n",
      "running loss : 3.399263\n",
      "running loss : 3.421355\n",
      "running loss : 3.420654\n",
      "running loss : 3.427758\n",
      "running loss : 3.416184\n",
      "running loss : 3.403627\n",
      "running loss : 3.421743\n",
      "running loss : 3.388779\n",
      "running loss : 3.372408\n",
      "running loss : 3.377701\n",
      "running loss : 3.411780\n",
      "running loss : 3.421321\n",
      "running loss : 3.373030\n",
      "running loss : 3.379130\n",
      "running loss : 3.379265\n",
      "running loss : 3.358449\n",
      "running loss : 3.398209\n",
      "running loss : 3.391575\n",
      "running loss : 3.364616\n",
      "running loss : 3.376768\n",
      "running loss : 3.386384\n",
      "running loss : 3.370304\n",
      "running loss : 3.377931\n",
      "running loss : 3.354336\n",
      "running loss : 3.382549\n",
      "running loss : 3.372306\n",
      "running loss : 3.371223\n",
      "running loss : 3.388661\n",
      "running loss : 3.383841\n",
      "running loss : 3.416228\n",
      "running loss : 3.346005\n",
      "running loss : 3.351801\n",
      "running loss : 3.352808\n",
      "running loss : 3.340217\n",
      "running loss : 3.359620\n",
      "running loss : 3.324736\n",
      "running loss : 3.332521\n",
      "running loss : 3.336590\n",
      "running loss : 3.327885\n",
      "running loss : 3.338176\n",
      "running loss : 3.352786\n",
      "running loss : 3.344962\n",
      "running loss : 3.334877\n",
      "running loss : 3.335764\n",
      "running loss : 3.326714\n",
      "running loss : 3.313478\n",
      "running loss : 3.317909\n",
      "running loss : 3.334056\n",
      "running loss : 3.343781\n",
      "running loss : 3.325657\n",
      "running loss : 3.345412\n",
      "running loss : 3.342485\n",
      "running loss : 3.287806\n",
      "running loss : 3.295984\n",
      "running loss : 3.263203\n",
      "running loss : 3.310096\n",
      "running loss : 3.275945\n",
      "running loss : 3.295901\n",
      "running loss : 3.284827\n",
      "running loss : 3.292500\n",
      "running loss : 3.277401\n",
      "running loss : 3.297679\n",
      "running loss : 3.310043\n",
      "running loss : 3.248760\n",
      "running loss : 3.275419\n",
      "running loss : 3.292549\n",
      "running loss : 3.277545\n",
      "running loss : 3.299014\n",
      "running loss : 3.311612\n",
      "running loss : 3.275754\n",
      "running loss : 3.275899\n",
      "running loss : 3.254610\n",
      "running loss : 3.252016\n",
      "running loss : 3.245959\n",
      "running loss : 3.244923\n",
      "running loss : 3.248300\n",
      "running loss : 3.259531\n",
      "running loss : 3.251452\n",
      "running loss : 3.238269\n",
      "running loss : 3.266053\n",
      "running loss : 3.236991\n",
      "running loss : 3.256330\n",
      "running loss : 3.250372\n",
      "running loss : 3.251995\n",
      "running loss : 3.244093\n",
      "running loss : 3.244090\n",
      "running loss : 3.237978\n",
      "running loss : 3.227480\n",
      "running loss : 3.223307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 3.253561\n",
      "running loss : 3.247994\n",
      "running loss : 3.255467\n",
      "running loss : 3.227386\n",
      "running loss : 3.237433\n",
      "running loss : 3.245234\n",
      "running loss : 3.221188\n",
      "running loss : 3.225262\n",
      "running loss : 3.242467\n",
      "running loss : 3.239054\n",
      "running loss : 3.233813\n",
      "running loss : 3.226081\n",
      "running loss : 3.215760\n",
      "running loss : 3.219538\n",
      "running loss : 3.228483\n",
      "running loss : 3.196307\n",
      "running loss : 3.216058\n",
      "running loss : 3.213674\n",
      "running loss : 3.193802\n",
      "running loss : 3.209174\n",
      "running loss : 3.202869\n",
      "running loss : 3.202768\n",
      "running loss : 3.205409\n",
      "running loss : 3.191646\n",
      "running loss : 3.204328\n",
      "running loss : 3.212152\n",
      "running loss : 3.221054\n",
      "running loss : 3.198595\n",
      "running loss : 3.172700\n",
      "running loss : 3.175053\n",
      "running loss : 3.223141\n",
      "running loss : 3.175869\n",
      "running loss : 3.173846\n",
      "running loss : 3.182105\n",
      "running loss : 3.161083\n",
      "running loss : 3.194079\n",
      "running loss : 3.179032\n",
      "running loss : 3.178857\n",
      "running loss : 3.158310\n",
      "running loss : 3.207959\n",
      "running loss : 3.223593\n",
      "running loss : 3.189491\n",
      "running loss : 3.161429\n",
      "running loss : 3.153332\n",
      "running loss : 3.157454\n",
      "running loss : 3.176130\n",
      "running loss : 3.171579\n",
      "running loss : 3.161899\n",
      "running loss : 3.179524\n",
      "running loss : 3.176766\n",
      "running loss : 3.173618\n",
      "running loss : 3.186121\n",
      "running loss : 3.142675\n",
      "running loss : 3.160552\n",
      "running loss : 3.160161\n",
      "running loss : 3.147663\n",
      "running loss : 3.145860\n",
      "running loss : 3.131081\n",
      "running loss : 3.152804\n",
      "running loss : 3.149699\n",
      "running loss : 3.159075\n",
      "running loss : 3.144978\n",
      "running loss : 3.139942\n",
      "running loss : 3.138375\n",
      "running loss : 3.123824\n",
      "running loss : 3.142464\n",
      "running loss : 3.126605\n",
      "running loss : 3.123212\n",
      "running loss : 3.142473\n",
      "running loss : 3.116561\n",
      "running loss : 3.115901\n",
      "running loss : 3.111883\n",
      "running loss : 3.126133\n",
      "running loss : 3.143924\n",
      "running loss : 3.100633\n",
      "running loss : 3.107115\n",
      "running loss : 3.094242\n",
      "running loss : 3.106126\n",
      "running loss : 3.102046\n",
      "running loss : 3.087204\n",
      "running loss : 3.099397\n",
      "running loss : 3.115178\n",
      "running loss : 3.116668\n",
      "running loss : 3.089798\n",
      "running loss : 3.093522\n",
      "running loss : 3.130609\n",
      "running loss : 3.098105\n",
      "running loss : 3.095930\n",
      "running loss : 3.056980\n",
      "running loss : 3.062247\n",
      "running loss : 3.069440\n",
      "running loss : 3.072704\n",
      "running loss : 3.088186\n",
      "running loss : 3.099793\n",
      "running loss : 3.108570\n",
      "running loss : 3.094211\n",
      "running loss : 3.089500\n",
      "running loss : 3.078181\n",
      "running loss : 3.066169\n",
      "running loss : 3.078586\n",
      "running loss : 3.075096\n",
      "running loss : 3.079697\n",
      "running loss : 3.068490\n",
      "running loss : 3.133294\n",
      "running loss : 3.079019\n",
      "running loss : 3.060979\n",
      "running loss : 3.045851\n",
      "running loss : 3.056322\n",
      "running loss : 3.052476\n",
      "running loss : 3.056755\n",
      "running loss : 3.069062\n",
      "running loss : 3.084232\n",
      "running loss : 3.041238\n",
      "running loss : 3.051717\n",
      "running loss : 3.029837\n",
      "running loss : 3.019159\n",
      "running loss : 3.023875\n",
      "running loss : 3.022047\n",
      "running loss : 3.038988\n",
      "running loss : 3.037269\n",
      "running loss : 3.020661\n",
      "running loss : 3.013067\n",
      "running loss : 3.013002\n",
      "running loss : 3.025336\n",
      "running loss : 3.007401\n",
      "running loss : 3.014312\n",
      "running loss : 3.019721\n",
      "running loss : 3.007933\n",
      "running loss : 3.004656\n",
      "running loss : 3.036715\n",
      "running loss : 3.035622\n",
      "running loss : 3.039856\n",
      "running loss : 3.024842\n",
      "running loss : 3.005346\n",
      "running loss : 3.012576\n",
      "running loss : 2.996583\n",
      "running loss : 3.010133\n",
      "running loss : 3.009270\n",
      "running loss : 3.005075\n",
      "running loss : 3.008034\n",
      "running loss : 3.012321\n",
      "running loss : 3.009415\n",
      "running loss : 2.994635\n",
      "running loss : 3.002475\n",
      "running loss : 2.985233\n",
      "running loss : 2.985031\n",
      "running loss : 3.025825\n",
      "running loss : 3.059329\n",
      "running loss : 3.068751\n",
      "running loss : 3.005994\n",
      "running loss : 2.983055\n",
      "running loss : 3.001180\n",
      "running loss : 3.000030\n",
      "running loss : 2.985484\n",
      "running loss : 2.984855\n",
      "running loss : 2.998347\n",
      "running loss : 2.975020\n",
      "running loss : 2.988844\n",
      "running loss : 3.010078\n",
      "running loss : 2.978550\n",
      "running loss : 2.981996\n",
      "running loss : 2.970862\n",
      "running loss : 2.973180\n",
      "running loss : 2.985749\n",
      "running loss : 2.968177\n",
      "running loss : 2.950809\n",
      "running loss : 2.951330\n",
      "running loss : 2.947525\n",
      "running loss : 2.947605\n",
      "running loss : 2.941904\n",
      "running loss : 2.945766\n",
      "running loss : 2.933236\n",
      "running loss : 2.963599\n",
      "running loss : 2.947901\n",
      "running loss : 2.971892\n",
      "running loss : 2.941055\n",
      "running loss : 2.931427\n",
      "running loss : 2.939556\n",
      "running loss : 2.936604\n",
      "running loss : 2.938200\n",
      "running loss : 2.942136\n",
      "running loss : 2.938579\n",
      "running loss : 2.941848\n",
      "running loss : 2.956886\n",
      "running loss : 2.982611\n",
      "running loss : 2.948767\n",
      "running loss : 2.942216\n",
      "running loss : 2.929630\n",
      "running loss : 2.944304\n",
      "running loss : 2.951283\n",
      "running loss : 2.928534\n",
      "running loss : 2.929232\n",
      "running loss : 2.935824\n",
      "running loss : 2.924078\n",
      "running loss : 2.915227\n",
      "running loss : 2.930469\n",
      "running loss : 2.943053\n",
      "running loss : 2.920828\n",
      "running loss : 2.904488\n",
      "running loss : 2.909705\n",
      "running loss : 2.916114\n",
      "running loss : 2.912091\n",
      "running loss : 2.917038\n",
      "running loss : 2.915250\n",
      "running loss : 2.898599\n",
      "running loss : 2.893899\n",
      "running loss : 2.920393\n",
      "running loss : 2.894646\n",
      "running loss : 2.888085\n",
      "running loss : 2.898445\n",
      "running loss : 2.898405\n",
      "running loss : 2.897818\n",
      "running loss : 2.909729\n",
      "running loss : 2.881627\n",
      "running loss : 2.886645\n",
      "running loss : 2.894934\n",
      "running loss : 2.920871\n",
      "running loss : 2.949592\n",
      "running loss : 2.925731\n",
      "running loss : 2.913473\n",
      "running loss : 2.893456\n",
      "running loss : 2.886361\n",
      "running loss : 2.880894\n",
      "running loss : 2.879330\n",
      "running loss : 2.891907\n",
      "running loss : 2.879273\n",
      "running loss : 2.885891\n",
      "running loss : 2.868153\n",
      "running loss : 2.910652\n",
      "running loss : 2.882311\n",
      "running loss : 2.854121\n",
      "running loss : 2.863492\n",
      "running loss : 2.862230\n",
      "running loss : 2.878705\n",
      "running loss : 2.868542\n",
      "running loss : 2.859008\n",
      "running loss : 2.855787\n",
      "running loss : 2.848026\n",
      "running loss : 2.857753\n",
      "running loss : 2.885648\n",
      "running loss : 2.889597\n",
      "running loss : 2.885210\n",
      "running loss : 2.853401\n",
      "running loss : 2.853775\n",
      "running loss : 2.861657\n",
      "running loss : 2.845336\n",
      "running loss : 2.843377\n",
      "running loss : 2.845768\n",
      "running loss : 2.844050\n",
      "running loss : 2.872883\n",
      "running loss : 2.850789\n",
      "running loss : 2.850646\n",
      "running loss : 2.832590\n",
      "running loss : 2.860550\n",
      "running loss : 2.856758\n",
      "running loss : 2.832335\n",
      "running loss : 2.839890\n",
      "running loss : 2.854124\n",
      "running loss : 2.851652\n",
      "running loss : 2.867559\n",
      "running loss : 2.889377\n",
      "running loss : 2.847703\n",
      "running loss : 2.833344\n",
      "running loss : 2.850014\n",
      "running loss : 2.855174\n",
      "running loss : 2.831169\n",
      "running loss : 2.824202\n",
      "running loss : 2.836188\n",
      "running loss : 2.863268\n",
      "running loss : 2.837352\n",
      "running loss : 2.811559\n",
      "running loss : 2.811678\n",
      "running loss : 2.801487\n",
      "running loss : 2.805605\n",
      "running loss : 2.801766\n",
      "running loss : 2.811132\n",
      "running loss : 2.794529\n",
      "running loss : 2.801629\n",
      "running loss : 2.804657\n",
      "running loss : 2.811392\n",
      "running loss : 2.797341\n",
      "running loss : 2.867879\n",
      "running loss : 2.848918\n",
      "running loss : 2.800955\n",
      "running loss : 2.806385\n",
      "running loss : 2.805654\n",
      "running loss : 2.809385\n",
      "running loss : 2.810893\n",
      "running loss : 2.789668\n",
      "running loss : 2.790100\n",
      "running loss : 2.798169\n",
      "running loss : 2.788833\n",
      "running loss : 2.786067\n",
      "running loss : 2.793100\n",
      "running loss : 2.781767\n",
      "running loss : 2.794787\n",
      "running loss : 2.802811\n",
      "running loss : 2.806316\n",
      "running loss : 2.796154\n",
      "running loss : 2.797605\n",
      "running loss : 2.802798\n",
      "running loss : 2.816899\n",
      "running loss : 2.812606\n",
      "running loss : 2.790618\n",
      "running loss : 2.787736\n",
      "running loss : 2.793749\n",
      "running loss : 2.786755\n",
      "running loss : 2.790865\n",
      "running loss : 2.798269\n",
      "running loss : 2.816978\n",
      "running loss : 2.845240\n",
      "running loss : 2.811198\n",
      "running loss : 2.780098\n",
      "running loss : 2.772678\n",
      "running loss : 2.780148\n",
      "running loss : 2.776463\n",
      "running loss : 2.769559\n",
      "running loss : 2.797244\n",
      "running loss : 2.762962\n",
      "running loss : 2.777021\n",
      "running loss : 2.766624\n",
      "running loss : 2.752179\n",
      "running loss : 2.755955\n",
      "running loss : 2.760897\n",
      "running loss : 2.768085\n",
      "running loss : 2.782079\n",
      "running loss : 2.757563\n",
      "running loss : 2.760171\n",
      "running loss : 2.761288\n",
      "running loss : 2.761179\n",
      "running loss : 2.763805\n",
      "running loss : 2.751327\n",
      "running loss : 2.758582\n",
      "running loss : 2.732677\n",
      "running loss : 2.782311\n",
      "running loss : 2.763884\n",
      "running loss : 2.780717\n",
      "running loss : 2.765520\n",
      "running loss : 2.745992\n",
      "running loss : 2.726054\n",
      "running loss : 2.740368\n",
      "running loss : 2.781842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.757821\n",
      "running loss : 2.733415\n",
      "running loss : 2.743057\n",
      "running loss : 2.749659\n",
      "running loss : 2.757804\n",
      "running loss : 2.759416\n",
      "running loss : 2.739080\n",
      "running loss : 2.771463\n",
      "running loss : 2.761091\n",
      "running loss : 2.739786\n",
      "running loss : 2.719015\n",
      "running loss : 2.740208\n",
      "running loss : 2.759509\n",
      "running loss : 2.739020\n",
      "running loss : 2.719751\n",
      "running loss : 2.747173\n",
      "running loss : 2.734716\n",
      "running loss : 2.739124\n",
      "running loss : 2.727571\n",
      "running loss : 2.739107\n",
      "running loss : 2.760494\n",
      "running loss : 2.721484\n",
      "running loss : 2.730470\n",
      "running loss : 2.721066\n",
      "running loss : 2.727045\n",
      "running loss : 2.714766\n",
      "running loss : 2.705719\n",
      "running loss : 2.718871\n",
      "running loss : 2.737824\n",
      "running loss : 2.717222\n",
      "running loss : 2.711318\n",
      "running loss : 2.720881\n",
      "running loss : 2.711874\n",
      "running loss : 2.700832\n",
      "running loss : 2.695700\n",
      "running loss : 2.700717\n",
      "running loss : 2.706950\n",
      "running loss : 2.703999\n",
      "running loss : 2.749454\n",
      "running loss : 2.763526\n",
      "running loss : 2.718280\n",
      "running loss : 2.690196\n",
      "running loss : 2.703321\n",
      "running loss : 2.684140\n",
      "running loss : 2.703481\n",
      "running loss : 2.691940\n",
      "running loss : 2.680994\n",
      "running loss : 2.676538\n",
      "running loss : 2.674665\n",
      "running loss : 2.685525\n",
      "running loss : 2.678153\n",
      "running loss : 2.679208\n",
      "running loss : 2.681785\n",
      "running loss : 2.677707\n",
      "running loss : 2.675741\n",
      "running loss : 2.659661\n",
      "running loss : 2.670368\n",
      "running loss : 2.668919\n",
      "running loss : 2.670860\n",
      "running loss : 2.666953\n",
      "running loss : 2.667420\n",
      "running loss : 2.679402\n",
      "running loss : 2.677295\n",
      "running loss : 2.664879\n",
      "running loss : 2.671112\n",
      "running loss : 2.684560\n",
      "running loss : 2.664653\n",
      "running loss : 2.666845\n",
      "running loss : 2.656056\n",
      "running loss : 2.670370\n",
      "running loss : 2.656390\n",
      "running loss : 2.677934\n",
      "running loss : 2.687278\n",
      "running loss : 2.678384\n",
      "running loss : 2.663483\n",
      "running loss : 2.664226\n",
      "running loss : 2.654198\n",
      "running loss : 2.655930\n",
      "running loss : 2.649279\n",
      "running loss : 2.666112\n",
      "running loss : 2.665038\n",
      "running loss : 2.650324\n",
      "running loss : 2.641602\n",
      "running loss : 2.647797\n",
      "running loss : 2.649215\n",
      "running loss : 2.632180\n",
      "running loss : 2.646889\n",
      "running loss : 2.648821\n",
      "running loss : 2.687878\n",
      "running loss : 2.686043\n",
      "running loss : 2.645968\n",
      "running loss : 2.658927\n",
      "running loss : 2.645398\n",
      "running loss : 2.641007\n",
      "running loss : 2.657964\n",
      "running loss : 2.639853\n",
      "running loss : 2.639977\n",
      "running loss : 2.638824\n",
      "running loss : 2.629862\n",
      "running loss : 2.637055\n",
      "running loss : 2.675473\n",
      "running loss : 2.683683\n",
      "running loss : 2.644684\n",
      "running loss : 2.629912\n",
      "running loss : 2.624828\n",
      "running loss : 2.634188\n",
      "running loss : 2.628403\n",
      "running loss : 2.620924\n",
      "running loss : 2.631775\n",
      "running loss : 2.624012\n",
      "running loss : 2.629764\n",
      "running loss : 2.636351\n",
      "running loss : 2.644333\n",
      "running loss : 2.626212\n",
      "running loss : 2.616221\n",
      "running loss : 2.624205\n",
      "running loss : 2.641285\n",
      "running loss : 2.623457\n",
      "running loss : 2.641201\n",
      "running loss : 2.623557\n",
      "running loss : 2.605608\n",
      "running loss : 2.598458\n",
      "running loss : 2.612388\n",
      "running loss : 2.630285\n",
      "running loss : 2.601121\n",
      "running loss : 2.612840\n",
      "running loss : 2.620914\n",
      "running loss : 2.632515\n",
      "running loss : 2.600108\n",
      "running loss : 2.610038\n",
      "running loss : 2.602445\n",
      "running loss : 2.602684\n",
      "running loss : 2.598413\n",
      "running loss : 2.618585\n",
      "running loss : 2.635966\n",
      "running loss : 2.603113\n",
      "running loss : 2.603936\n",
      "running loss : 2.608105\n",
      "running loss : 2.592186\n",
      "running loss : 2.591503\n",
      "running loss : 2.588170\n",
      "running loss : 2.593302\n",
      "running loss : 2.633853\n",
      "running loss : 2.607904\n",
      "running loss : 2.600678\n",
      "running loss : 2.582723\n",
      "running loss : 2.594578\n",
      "running loss : 2.597594\n",
      "running loss : 2.594056\n",
      "running loss : 2.573754\n",
      "running loss : 2.577958\n",
      "running loss : 2.587284\n",
      "running loss : 2.612082\n",
      "running loss : 2.579791\n",
      "running loss : 2.577555\n",
      "running loss : 2.574829\n",
      "running loss : 2.569434\n",
      "running loss : 2.563452\n",
      "running loss : 2.565705\n",
      "running loss : 2.576098\n",
      "running loss : 2.566515\n",
      "running loss : 2.557439\n",
      "running loss : 2.568854\n",
      "running loss : 2.568065\n",
      "running loss : 2.561665\n",
      "running loss : 2.563052\n",
      "running loss : 2.570786\n",
      "running loss : 2.576113\n",
      "running loss : 2.566584\n",
      "running loss : 2.575480\n",
      "running loss : 2.577466\n",
      "running loss : 2.595132\n",
      "running loss : 20.149926\n",
      "running loss : 8.960990\n",
      "running loss : 5.379816\n",
      "running loss : 4.454437\n",
      "running loss : 3.940435\n",
      "running loss : 3.650555\n",
      "running loss : 3.498156\n",
      "running loss : 3.451891\n",
      "running loss : 3.297792\n",
      "running loss : 3.217239\n",
      "running loss : 3.153248\n",
      "running loss : 3.110006\n",
      "running loss : 3.078960\n",
      "running loss : 3.043457\n",
      "running loss : 3.048987\n",
      "running loss : 3.067843\n",
      "running loss : 3.016384\n",
      "running loss : 2.945118\n",
      "running loss : 2.924070\n",
      "running loss : 2.901351\n",
      "running loss : 2.892316\n",
      "running loss : 2.870218\n",
      "running loss : 2.859895\n",
      "running loss : 2.860147\n",
      "running loss : 2.873435\n",
      "running loss : 2.817895\n",
      "running loss : 2.814644\n",
      "running loss : 2.798007\n",
      "running loss : 2.782657\n",
      "running loss : 2.807771\n",
      "running loss : 2.783667\n",
      "running loss : 2.777768\n",
      "running loss : 2.783183\n",
      "running loss : 2.770834\n",
      "running loss : 2.760113\n",
      "running loss : 2.752105\n",
      "running loss : 2.735927\n",
      "running loss : 2.763823\n",
      "running loss : 2.772398\n",
      "running loss : 2.751648\n",
      "running loss : 2.726020\n",
      "running loss : 2.713429\n",
      "running loss : 2.729945\n",
      "running loss : 2.751295\n",
      "running loss : 2.723038\n",
      "running loss : 2.703208\n",
      "running loss : 2.693311\n",
      "running loss : 2.712694\n",
      "running loss : 2.703157\n",
      "running loss : 2.701844\n",
      "running loss : 2.679847\n",
      "running loss : 2.684511\n",
      "running loss : 2.691178\n",
      "running loss : 2.694152\n",
      "running loss : 2.700095\n",
      "running loss : 2.674588\n",
      "running loss : 2.673413\n",
      "running loss : 2.678505\n",
      "running loss : 2.689378\n",
      "running loss : 2.667665\n",
      "running loss : 2.647222\n",
      "running loss : 2.654228\n",
      "running loss : 2.654794\n",
      "running loss : 2.669796\n",
      "running loss : 2.707400\n",
      "running loss : 2.712840\n",
      "running loss : 2.660950\n",
      "running loss : 2.657038\n",
      "running loss : 2.654353\n",
      "running loss : 2.639195\n",
      "running loss : 2.648807\n",
      "running loss : 2.639255\n",
      "running loss : 2.643591\n",
      "running loss : 2.645987\n",
      "running loss : 2.634016\n",
      "running loss : 2.634825\n",
      "running loss : 2.647527\n",
      "running loss : 2.637604\n",
      "running loss : 2.638434\n",
      "running loss : 2.623658\n",
      "running loss : 2.638852\n",
      "running loss : 2.641885\n",
      "running loss : 2.628323\n",
      "running loss : 2.620923\n",
      "running loss : 2.617758\n",
      "running loss : 2.622892\n",
      "running loss : 2.683918\n",
      "running loss : 2.849094\n",
      "running loss : 2.626116\n",
      "running loss : 2.620491\n",
      "running loss : 2.613150\n",
      "running loss : 2.617538\n",
      "running loss : 2.674543\n",
      "running loss : 2.653805\n",
      "running loss : 2.617680\n",
      "running loss : 2.602577\n",
      "running loss : 2.608485\n",
      "running loss : 2.604890\n",
      "running loss : 2.599641\n",
      "running loss : 2.627174\n",
      "running loss : 2.595790\n",
      "running loss : 2.599837\n",
      "running loss : 2.598033\n",
      "running loss : 2.602394\n",
      "running loss : 2.594605\n",
      "running loss : 2.612021\n",
      "running loss : 2.606643\n",
      "running loss : 2.617846\n",
      "running loss : 2.608267\n",
      "running loss : 2.593743\n",
      "running loss : 2.601072\n",
      "running loss : 2.604908\n",
      "running loss : 2.612860\n",
      "running loss : 2.606129\n",
      "running loss : 2.605513\n",
      "running loss : 2.635329\n",
      "running loss : 2.577413\n",
      "running loss : 2.567915\n",
      "running loss : 2.588039\n",
      "running loss : 2.571854\n",
      "running loss : 2.569038\n",
      "running loss : 2.578510\n",
      "running loss : 2.582525\n",
      "running loss : 2.669163\n",
      "running loss : 2.602035\n",
      "running loss : 2.585100\n",
      "running loss : 2.611029\n",
      "running loss : 2.602957\n",
      "running loss : 2.576142\n",
      "running loss : 2.586785\n",
      "running loss : 2.620473\n",
      "running loss : 2.604704\n",
      "running loss : 2.595053\n",
      "running loss : 2.574736\n",
      "running loss : 2.564298\n",
      "running loss : 2.579515\n",
      "running loss : 2.569645\n",
      "running loss : 2.581094\n",
      "running loss : 2.572853\n",
      "running loss : 2.557181\n",
      "running loss : 2.563996\n",
      "running loss : 2.570552\n",
      "running loss : 2.569743\n",
      "running loss : 2.577570\n",
      "running loss : 2.582145\n",
      "running loss : 2.579189\n",
      "running loss : 2.562986\n",
      "running loss : 2.571141\n",
      "running loss : 2.561080\n",
      "running loss : 2.573827\n",
      "running loss : 2.556647\n",
      "running loss : 2.575076\n",
      "running loss : 2.553931\n",
      "running loss : 2.579978\n",
      "running loss : 2.559978\n",
      "running loss : 2.548845\n",
      "running loss : 2.570648\n",
      "running loss : 2.656930\n",
      "running loss : 2.578856\n",
      "running loss : 2.553773\n",
      "running loss : 2.563434\n",
      "running loss : 2.617826\n",
      "running loss : 2.599774\n",
      "running loss : 2.549708\n",
      "running loss : 2.560842\n",
      "running loss : 2.576622\n",
      "running loss : 2.550639\n",
      "running loss : 2.554780\n",
      "running loss : 2.574612\n",
      "running loss : 2.558390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.543928\n",
      "running loss : 2.539132\n",
      "running loss : 2.561815\n",
      "running loss : 2.545238\n",
      "running loss : 2.555706\n",
      "running loss : 2.558050\n",
      "running loss : 2.533462\n",
      "running loss : 2.559385\n",
      "running loss : 2.543359\n",
      "running loss : 2.559428\n",
      "running loss : 2.578363\n",
      "running loss : 2.595845\n",
      "running loss : 2.554711\n",
      "running loss : 2.542628\n",
      "running loss : 2.551057\n",
      "running loss : 2.542679\n",
      "running loss : 2.533953\n",
      "running loss : 2.626980\n",
      "running loss : 2.573437\n",
      "running loss : 2.532222\n",
      "running loss : 2.533260\n",
      "running loss : 2.547035\n",
      "running loss : 2.553667\n",
      "running loss : 2.533373\n",
      "running loss : 2.537171\n",
      "running loss : 2.566290\n",
      "running loss : 2.528995\n",
      "running loss : 2.529407\n",
      "running loss : 2.548534\n",
      "running loss : 2.532156\n",
      "running loss : 2.539916\n",
      "running loss : 2.522170\n",
      "running loss : 2.576740\n",
      "running loss : 2.541346\n",
      "running loss : 2.526871\n",
      "running loss : 2.539196\n",
      "running loss : 2.533532\n",
      "running loss : 2.521926\n",
      "running loss : 2.532676\n",
      "running loss : 2.529228\n",
      "running loss : 2.522913\n",
      "running loss : 2.529515\n",
      "running loss : 2.508786\n",
      "running loss : 2.524568\n",
      "running loss : 2.516957\n",
      "running loss : 2.513410\n",
      "running loss : 2.509114\n",
      "running loss : 2.509575\n",
      "running loss : 2.533967\n",
      "running loss : 2.523843\n",
      "running loss : 2.502499\n",
      "running loss : 2.497618\n",
      "running loss : 2.501315\n",
      "running loss : 2.510654\n",
      "running loss : 2.509238\n",
      "running loss : 2.525312\n",
      "running loss : 2.514543\n",
      "running loss : 2.510008\n",
      "running loss : 2.507912\n",
      "running loss : 2.500433\n",
      "running loss : 2.494965\n",
      "running loss : 2.494347\n",
      "running loss : 2.517249\n",
      "running loss : 2.510097\n",
      "running loss : 2.494584\n",
      "running loss : 2.505149\n",
      "running loss : 2.498784\n",
      "running loss : 2.524908\n",
      "running loss : 2.492379\n",
      "running loss : 2.517036\n",
      "running loss : 2.511106\n",
      "running loss : 2.529042\n",
      "running loss : 2.508515\n",
      "running loss : 2.490337\n",
      "running loss : 2.479779\n",
      "running loss : 2.493555\n",
      "running loss : 2.510534\n",
      "running loss : 2.510957\n",
      "running loss : 2.499329\n",
      "running loss : 2.488897\n",
      "running loss : 2.503217\n",
      "running loss : 2.518657\n",
      "running loss : 2.496364\n",
      "running loss : 2.490670\n",
      "running loss : 2.482689\n",
      "running loss : 2.483367\n",
      "running loss : 2.487241\n",
      "running loss : 2.470391\n",
      "running loss : 2.544035\n",
      "running loss : 2.608343\n",
      "running loss : 2.514535\n",
      "running loss : 2.485341\n",
      "running loss : 2.490921\n",
      "running loss : 2.480234\n",
      "running loss : 2.477486\n",
      "running loss : 2.462464\n",
      "running loss : 2.474594\n",
      "running loss : 2.485890\n",
      "running loss : 2.485944\n",
      "running loss : 2.499396\n",
      "running loss : 2.544172\n",
      "running loss : 2.531583\n",
      "running loss : 2.487929\n",
      "running loss : 2.491680\n",
      "running loss : 2.458292\n",
      "running loss : 2.460922\n",
      "running loss : 2.464807\n",
      "running loss : 2.496414\n",
      "running loss : 2.484119\n",
      "running loss : 2.477446\n",
      "running loss : 2.459163\n",
      "running loss : 2.463774\n",
      "running loss : 2.475010\n",
      "running loss : 2.471193\n",
      "running loss : 2.455787\n",
      "running loss : 2.457196\n",
      "running loss : 2.484465\n",
      "running loss : 2.465376\n",
      "running loss : 2.461324\n",
      "running loss : 2.466453\n",
      "running loss : 2.457727\n",
      "running loss : 2.450171\n",
      "running loss : 2.445221\n",
      "running loss : 2.480006\n",
      "running loss : 2.463631\n",
      "running loss : 2.488831\n",
      "running loss : 2.460430\n",
      "running loss : 2.470712\n",
      "running loss : 2.446621\n",
      "running loss : 2.439210\n",
      "running loss : 2.461602\n",
      "running loss : 2.446167\n",
      "running loss : 2.444361\n",
      "running loss : 2.436526\n",
      "running loss : 2.439868\n",
      "running loss : 2.432939\n",
      "running loss : 2.435072\n",
      "running loss : 2.480420\n",
      "running loss : 2.448003\n",
      "running loss : 2.446818\n",
      "running loss : 2.442567\n",
      "running loss : 2.423686\n",
      "running loss : 2.426220\n",
      "running loss : 2.434976\n",
      "running loss : 2.433352\n",
      "running loss : 2.441179\n",
      "running loss : 2.461748\n",
      "running loss : 2.453751\n",
      "running loss : 2.432478\n",
      "running loss : 2.422020\n",
      "running loss : 2.416483\n",
      "running loss : 2.432495\n",
      "running loss : 2.418888\n",
      "running loss : 2.426103\n",
      "running loss : 2.426014\n",
      "running loss : 2.424646\n",
      "running loss : 2.430775\n",
      "running loss : 2.428602\n",
      "running loss : 2.416364\n",
      "running loss : 2.427446\n",
      "running loss : 2.417014\n",
      "running loss : 2.469799\n",
      "running loss : 2.440987\n",
      "running loss : 2.423173\n",
      "running loss : 2.404810\n",
      "running loss : 2.416834\n",
      "running loss : 2.411021\n",
      "running loss : 2.429736\n",
      "running loss : 2.444035\n",
      "running loss : 2.428767\n",
      "running loss : 2.404758\n",
      "running loss : 2.409482\n",
      "running loss : 2.416355\n",
      "running loss : 2.438266\n",
      "running loss : 2.414316\n",
      "running loss : 2.430535\n",
      "running loss : 2.444039\n",
      "running loss : 2.423347\n",
      "running loss : 2.430636\n",
      "running loss : 2.410095\n",
      "running loss : 2.408399\n",
      "running loss : 2.408363\n",
      "running loss : 2.409056\n",
      "running loss : 2.492957\n",
      "running loss : 2.455967\n",
      "running loss : 2.416933\n",
      "running loss : 2.417775\n",
      "running loss : 2.416263\n",
      "running loss : 2.399732\n",
      "running loss : 2.412267\n",
      "running loss : 2.416766\n",
      "running loss : 2.399724\n",
      "running loss : 2.401234\n",
      "running loss : 2.406395\n",
      "running loss : 2.399759\n",
      "running loss : 2.392128\n",
      "running loss : 2.407291\n",
      "running loss : 2.414970\n",
      "running loss : 2.428200\n",
      "running loss : 2.399664\n",
      "running loss : 2.402961\n",
      "running loss : 2.596492\n",
      "running loss : 2.506225\n",
      "running loss : 2.415702\n",
      "running loss : 2.398801\n",
      "running loss : 2.392614\n",
      "running loss : 2.403682\n",
      "running loss : 2.387680\n",
      "running loss : 2.401281\n",
      "running loss : 2.409997\n",
      "running loss : 2.400934\n",
      "running loss : 2.392926\n",
      "running loss : 2.387014\n",
      "running loss : 2.390073\n",
      "running loss : 2.388547\n",
      "running loss : 2.381336\n",
      "running loss : 2.384515\n",
      "running loss : 2.410093\n",
      "running loss : 2.389715\n",
      "running loss : 2.403285\n",
      "running loss : 2.401452\n",
      "running loss : 2.393707\n",
      "running loss : 2.396150\n",
      "running loss : 2.391089\n",
      "running loss : 2.430160\n",
      "running loss : 2.408063\n",
      "running loss : 2.391123\n",
      "running loss : 2.379031\n",
      "running loss : 2.392454\n",
      "running loss : 2.373841\n",
      "running loss : 2.403829\n",
      "running loss : 2.395377\n",
      "running loss : 2.393145\n",
      "running loss : 2.387315\n",
      "running loss : 2.371678\n",
      "running loss : 2.379618\n",
      "running loss : 2.371658\n",
      "running loss : 2.376593\n",
      "running loss : 2.386585\n",
      "running loss : 2.397265\n",
      "running loss : 2.381376\n",
      "running loss : 2.376630\n",
      "running loss : 2.381090\n",
      "running loss : 2.379835\n",
      "running loss : 2.383109\n",
      "running loss : 2.431273\n",
      "running loss : 2.375877\n",
      "running loss : 2.366512\n",
      "running loss : 2.376798\n",
      "running loss : 2.377268\n",
      "running loss : 2.365349\n",
      "running loss : 2.362889\n",
      "running loss : 2.365697\n",
      "running loss : 2.366114\n",
      "running loss : 2.563864\n",
      "running loss : 2.476964\n",
      "running loss : 2.382897\n",
      "running loss : 2.370329\n",
      "running loss : 2.378184\n",
      "running loss : 2.361154\n",
      "running loss : 2.352461\n",
      "running loss : 2.359422\n",
      "running loss : 2.369799\n",
      "running loss : 2.363741\n",
      "running loss : 2.354295\n",
      "running loss : 2.346833\n",
      "running loss : 2.356628\n",
      "running loss : 2.372225\n",
      "running loss : 2.359576\n",
      "running loss : 2.354805\n",
      "running loss : 2.355980\n",
      "running loss : 2.366408\n",
      "running loss : 2.356264\n",
      "running loss : 2.360349\n",
      "running loss : 2.357983\n",
      "running loss : 2.361212\n",
      "running loss : 2.358912\n",
      "running loss : 2.371429\n",
      "running loss : 2.366665\n",
      "running loss : 2.358551\n",
      "running loss : 2.348791\n",
      "running loss : 2.353347\n",
      "running loss : 2.350488\n",
      "running loss : 2.356288\n",
      "running loss : 2.356274\n",
      "running loss : 2.359063\n",
      "running loss : 2.353007\n",
      "running loss : 2.350959\n",
      "running loss : 2.350809\n",
      "running loss : 2.345755\n",
      "running loss : 2.363442\n",
      "running loss : 2.353330\n",
      "running loss : 2.340923\n",
      "running loss : 2.343057\n",
      "running loss : 2.340213\n",
      "running loss : 2.357357\n",
      "running loss : 2.339269\n",
      "running loss : 2.336287\n",
      "running loss : 2.331042\n",
      "running loss : 2.341684\n",
      "running loss : 2.347655\n",
      "running loss : 2.349853\n",
      "running loss : 2.337815\n",
      "running loss : 2.328048\n",
      "running loss : 2.329927\n",
      "running loss : 2.360504\n",
      "running loss : 2.346330\n",
      "running loss : 2.362704\n",
      "running loss : 2.351721\n",
      "running loss : 2.336037\n",
      "running loss : 2.340186\n",
      "running loss : 2.333091\n",
      "running loss : 2.336855\n",
      "running loss : 2.375071\n",
      "running loss : 2.391244\n",
      "running loss : 2.348816\n",
      "running loss : 2.326065\n",
      "running loss : 2.319493\n",
      "running loss : 2.323071\n",
      "running loss : 2.323131\n",
      "running loss : 2.348551\n",
      "running loss : 2.326773\n",
      "running loss : 2.355785\n",
      "running loss : 2.329655\n",
      "running loss : 2.319111\n",
      "running loss : 2.336910\n",
      "running loss : 2.327788\n",
      "running loss : 2.326922\n",
      "running loss : 2.309453\n",
      "running loss : 2.336503\n",
      "running loss : 2.334263\n",
      "running loss : 2.326205\n",
      "running loss : 2.327245\n",
      "running loss : 2.319532\n",
      "running loss : 2.311176\n",
      "running loss : 2.313374\n",
      "running loss : 2.316296\n",
      "running loss : 2.356324\n",
      "running loss : 2.321478\n",
      "running loss : 2.310271\n",
      "running loss : 2.321024\n",
      "running loss : 2.327993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.319969\n",
      "running loss : 2.345640\n",
      "running loss : 2.329285\n",
      "running loss : 2.309163\n",
      "running loss : 2.315744\n",
      "running loss : 2.311075\n",
      "running loss : 2.320858\n",
      "running loss : 2.303471\n",
      "running loss : 2.322175\n",
      "running loss : 2.339242\n",
      "running loss : 2.314318\n",
      "running loss : 2.315181\n",
      "running loss : 2.310317\n",
      "running loss : 2.302963\n",
      "running loss : 2.315111\n",
      "running loss : 2.306821\n",
      "running loss : 2.311423\n",
      "running loss : 2.310579\n",
      "running loss : 2.321262\n",
      "running loss : 2.314942\n",
      "running loss : 2.306107\n",
      "running loss : 2.303085\n",
      "running loss : 2.311331\n",
      "running loss : 2.317235\n",
      "running loss : 2.299084\n",
      "running loss : 2.304760\n",
      "running loss : 2.302897\n",
      "running loss : 2.306352\n",
      "running loss : 2.342703\n",
      "running loss : 2.322532\n",
      "running loss : 2.337794\n",
      "running loss : 2.315639\n",
      "running loss : 2.301572\n",
      "running loss : 2.305126\n",
      "running loss : 2.327630\n",
      "running loss : 2.301939\n",
      "running loss : 2.297963\n",
      "running loss : 2.286712\n",
      "running loss : 2.306098\n",
      "running loss : 2.296008\n",
      "running loss : 2.296415\n",
      "running loss : 2.293388\n",
      "running loss : 2.283878\n",
      "running loss : 2.314243\n",
      "running loss : 2.299019\n",
      "running loss : 2.288941\n",
      "running loss : 2.288934\n",
      "running loss : 2.291222\n",
      "running loss : 2.284738\n",
      "running loss : 2.279727\n",
      "running loss : 2.285214\n",
      "running loss : 2.277561\n",
      "running loss : 2.291568\n",
      "running loss : 2.295938\n",
      "running loss : 2.332130\n",
      "running loss : 2.417638\n",
      "running loss : 2.498757\n",
      "running loss : 2.326147\n",
      "running loss : 2.294384\n",
      "running loss : 2.296496\n",
      "running loss : 2.285826\n",
      "running loss : 2.282344\n",
      "running loss : 2.281424\n",
      "running loss : 2.282466\n",
      "running loss : 2.280141\n",
      "running loss : 2.274142\n",
      "running loss : 2.272358\n",
      "running loss : 2.278600\n",
      "running loss : 2.276215\n",
      "running loss : 2.269905\n",
      "running loss : 2.283327\n",
      "running loss : 2.283996\n",
      "running loss : 2.277434\n",
      "running loss : 2.266414\n",
      "running loss : 2.272704\n",
      "running loss : 2.267826\n",
      "running loss : 2.273315\n",
      "running loss : 2.274027\n",
      "running loss : 2.267419\n",
      "running loss : 2.271702\n",
      "running loss : 2.270223\n",
      "running loss : 2.298660\n",
      "running loss : 2.292174\n",
      "running loss : 2.266196\n",
      "running loss : 2.267885\n",
      "running loss : 2.264981\n",
      "running loss : 2.276146\n",
      "running loss : 2.272155\n",
      "running loss : 2.275261\n",
      "running loss : 2.277772\n",
      "running loss : 2.279539\n",
      "running loss : 2.279198\n",
      "running loss : 2.265195\n",
      "running loss : 2.287658\n",
      "running loss : 2.276832\n",
      "running loss : 2.280000\n",
      "running loss : 2.274935\n",
      "running loss : 2.283295\n",
      "running loss : 2.275513\n",
      "running loss : 2.314528\n",
      "running loss : 2.322781\n",
      "running loss : 2.277667\n",
      "running loss : 2.265537\n",
      "running loss : 2.267905\n",
      "running loss : 2.271586\n",
      "running loss : 2.272612\n",
      "running loss : 2.265903\n",
      "running loss : 2.263712\n",
      "running loss : 2.262036\n",
      "running loss : 2.269785\n",
      "running loss : 2.273181\n",
      "running loss : 2.278035\n",
      "running loss : 2.277361\n",
      "running loss : 2.271294\n",
      "running loss : 2.277734\n",
      "running loss : 2.268478\n",
      "running loss : 2.254842\n",
      "running loss : 2.285316\n",
      "running loss : 2.265489\n",
      "running loss : 2.259368\n",
      "running loss : 2.265741\n",
      "running loss : 2.273197\n",
      "running loss : 2.280693\n",
      "running loss : 2.267000\n",
      "running loss : 2.273909\n",
      "running loss : 2.271659\n",
      "running loss : 2.270802\n",
      "running loss : 2.275018\n",
      "running loss : 2.272875\n",
      "running loss : 2.258970\n",
      "running loss : 2.257013\n",
      "running loss : 2.263843\n",
      "running loss : 2.296382\n",
      "running loss : 2.277366\n",
      "running loss : 2.262846\n",
      "running loss : 2.254342\n",
      "running loss : 2.252882\n",
      "running loss : 2.254369\n",
      "running loss : 2.253057\n",
      "running loss : 2.256326\n",
      "running loss : 2.250412\n",
      "running loss : 2.246221\n",
      "running loss : 2.249032\n",
      "running loss : 2.249308\n",
      "running loss : 2.245317\n",
      "running loss : 2.270368\n",
      "running loss : 2.253731\n",
      "running loss : 2.271411\n",
      "running loss : 2.240397\n",
      "running loss : 2.244605\n",
      "running loss : 2.241827\n",
      "running loss : 2.250572\n",
      "running loss : 2.250743\n",
      "running loss : 2.245961\n",
      "running loss : 2.239213\n",
      "running loss : 2.251868\n",
      "running loss : 2.242929\n",
      "running loss : 2.252691\n",
      "running loss : 2.255689\n",
      "running loss : 2.250330\n",
      "running loss : 2.234977\n",
      "running loss : 2.285912\n",
      "running loss : 2.286505\n",
      "running loss : 2.259107\n",
      "running loss : 2.240897\n",
      "running loss : 2.233694\n",
      "running loss : 2.241226\n",
      "running loss : 2.247763\n",
      "running loss : 2.236087\n",
      "running loss : 2.229146\n",
      "running loss : 2.228553\n",
      "running loss : 2.236198\n",
      "running loss : 2.233280\n",
      "running loss : 2.228809\n",
      "running loss : 2.238217\n",
      "running loss : 2.238227\n",
      "running loss : 2.254217\n",
      "running loss : 2.254431\n",
      "running loss : 2.237115\n",
      "running loss : 2.231913\n",
      "running loss : 2.227548\n",
      "running loss : 2.224082\n",
      "running loss : 2.228375\n",
      "running loss : 2.242726\n",
      "running loss : 2.231102\n",
      "running loss : 2.240645\n",
      "running loss : 2.241917\n",
      "running loss : 2.246805\n",
      "running loss : 2.227792\n",
      "running loss : 2.221134\n",
      "running loss : 2.216940\n",
      "running loss : 2.218288\n",
      "running loss : 2.222040\n",
      "running loss : 2.225833\n",
      "running loss : 2.225194\n",
      "running loss : 2.224531\n",
      "running loss : 2.231119\n",
      "running loss : 2.215467\n",
      "running loss : 2.217383\n",
      "running loss : 2.227912\n",
      "running loss : 2.227746\n",
      "running loss : 2.261000\n",
      "running loss : 2.250187\n",
      "running loss : 2.227410\n",
      "running loss : 2.221791\n",
      "running loss : 2.221419\n",
      "running loss : 2.233406\n",
      "running loss : 2.222906\n",
      "running loss : 2.218765\n",
      "running loss : 2.211429\n",
      "running loss : 2.222322\n",
      "running loss : 2.229297\n",
      "running loss : 2.215060\n",
      "running loss : 2.212815\n",
      "running loss : 2.214459\n",
      "running loss : 2.219826\n",
      "running loss : 2.254713\n",
      "running loss : 2.272211\n",
      "running loss : 2.232289\n",
      "running loss : 2.212519\n",
      "running loss : 2.211729\n",
      "running loss : 2.202152\n",
      "running loss : 2.217337\n",
      "running loss : 2.204649\n",
      "running loss : 2.209620\n",
      "running loss : 2.218703\n",
      "running loss : 2.211304\n",
      "running loss : 2.206192\n",
      "running loss : 2.209976\n",
      "running loss : 2.205170\n",
      "running loss : 2.201593\n",
      "running loss : 2.210032\n",
      "running loss : 2.219980\n",
      "running loss : 2.216870\n",
      "running loss : 2.211471\n",
      "running loss : 2.218334\n",
      "running loss : 2.213124\n",
      "running loss : 2.243932\n",
      "running loss : 2.222026\n",
      "running loss : 2.198291\n",
      "running loss : 2.221848\n",
      "running loss : 2.243418\n",
      "running loss : 2.221555\n",
      "running loss : 2.215085\n",
      "running loss : 2.209314\n",
      "running loss : 2.206768\n",
      "running loss : 2.213975\n",
      "running loss : 2.204396\n",
      "running loss : 2.217264\n",
      "running loss : 2.215867\n",
      "running loss : 2.218782\n",
      "running loss : 2.222083\n",
      "running loss : 2.222291\n",
      "running loss : 2.219624\n",
      "running loss : 2.212510\n",
      "running loss : 2.243254\n",
      "running loss : 2.261753\n",
      "running loss : 2.218412\n",
      "running loss : 2.206678\n",
      "running loss : 2.199126\n",
      "running loss : 2.211081\n",
      "running loss : 2.201545\n",
      "running loss : 2.218017\n",
      "running loss : 2.223189\n",
      "running loss : 2.215771\n",
      "running loss : 2.214346\n",
      "running loss : 2.212339\n",
      "running loss : 2.216974\n",
      "running loss : 2.215979\n",
      "running loss : 2.227519\n",
      "running loss : 2.215843\n",
      "running loss : 2.206018\n",
      "running loss : 2.221757\n",
      "running loss : 2.222149\n",
      "running loss : 2.206423\n",
      "running loss : 2.212653\n",
      "running loss : 2.204713\n",
      "running loss : 2.201537\n",
      "running loss : 2.204113\n",
      "running loss : 2.216621\n",
      "running loss : 2.206620\n",
      "running loss : 2.201996\n",
      "running loss : 2.189311\n",
      "running loss : 2.227172\n",
      "running loss : 2.204857\n",
      "running loss : 2.208157\n",
      "running loss : 2.196727\n",
      "running loss : 2.197850\n",
      "running loss : 2.192133\n",
      "running loss : 2.193008\n",
      "running loss : 2.193871\n",
      "running loss : 2.199913\n",
      "running loss : 2.208867\n",
      "running loss : 2.185654\n",
      "running loss : 2.186160\n",
      "running loss : 2.184184\n",
      "running loss : 2.206726\n",
      "running loss : 2.220895\n",
      "running loss : 2.204258\n",
      "running loss : 2.204476\n",
      "running loss : 2.191880\n",
      "running loss : 2.203862\n",
      "running loss : 2.211810\n",
      "running loss : 2.196328\n",
      "running loss : 2.196336\n",
      "running loss : 2.192417\n",
      "running loss : 2.195755\n",
      "running loss : 2.191947\n",
      "running loss : 2.197810\n",
      "running loss : 2.199089\n",
      "running loss : 2.195194\n",
      "running loss : 2.193793\n",
      "running loss : 2.189562\n",
      "running loss : 2.194634\n",
      "running loss : 2.182781\n",
      "running loss : 2.186590\n",
      "running loss : 2.190612\n",
      "running loss : 2.199545\n",
      "running loss : 2.205128\n",
      "running loss : 2.207601\n",
      "running loss : 2.194837\n",
      "running loss : 2.185382\n",
      "running loss : 2.181004\n",
      "running loss : 2.181826\n",
      "running loss : 2.183086\n",
      "running loss : 2.188437\n",
      "running loss : 2.183831\n",
      "running loss : 2.183085\n",
      "running loss : 2.186643\n",
      "running loss : 2.183852\n",
      "running loss : 2.185392\n",
      "running loss : 2.218360\n",
      "running loss : 2.232647\n",
      "running loss : 2.191600\n",
      "running loss : 2.191789\n",
      "running loss : 2.190552\n",
      "running loss : 2.194818\n",
      "running loss : 2.191984\n",
      "running loss : 2.203956\n",
      "running loss : 2.218432\n",
      "running loss : 2.200099\n",
      "running loss : 2.200788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.192168\n",
      "running loss : 2.191025\n",
      "running loss : 2.188348\n",
      "running loss : 2.191412\n",
      "running loss : 2.188999\n",
      "running loss : 2.200008\n",
      "running loss : 2.190852\n",
      "running loss : 2.195835\n",
      "running loss : 2.193395\n",
      "running loss : 2.184737\n",
      "running loss : 2.189273\n",
      "running loss : 2.195546\n",
      "running loss : 2.195080\n",
      "running loss : 2.204154\n",
      "running loss : 2.190584\n",
      "running loss : 2.189992\n",
      "running loss : 2.200891\n",
      "running loss : 2.198411\n",
      "running loss : 2.201328\n",
      "running loss : 2.199273\n",
      "running loss : 2.239336\n",
      "running loss : 2.231798\n",
      "running loss : 2.206828\n",
      "running loss : 2.195583\n",
      "running loss : 2.187642\n",
      "running loss : 2.183057\n",
      "running loss : 2.181447\n",
      "running loss : 2.177953\n",
      "running loss : 2.186828\n",
      "running loss : 2.183569\n",
      "running loss : 2.190087\n",
      "running loss : 2.190806\n",
      "running loss : 2.178211\n",
      "running loss : 2.180149\n",
      "running loss : 2.176606\n",
      "running loss : 2.187596\n",
      "running loss : 2.206304\n",
      "running loss : 2.180526\n",
      "running loss : 2.171589\n",
      "running loss : 2.185772\n",
      "running loss : 2.178036\n",
      "running loss : 2.171287\n",
      "running loss : 2.184820\n",
      "running loss : 2.239696\n",
      "running loss : 2.198090\n",
      "running loss : 2.176380\n",
      "running loss : 2.173185\n",
      "running loss : 2.180594\n",
      "running loss : 2.179594\n",
      "running loss : 2.196678\n",
      "running loss : 2.180241\n",
      "running loss : 2.169356\n",
      "running loss : 2.173542\n",
      "running loss : 2.176530\n",
      "running loss : 2.185734\n",
      "running loss : 2.178560\n",
      "running loss : 2.180259\n",
      "running loss : 2.180783\n",
      "running loss : 2.178460\n",
      "running loss : 2.192304\n",
      "running loss : 2.171327\n",
      "running loss : 2.163021\n",
      "running loss : 2.173103\n",
      "running loss : 2.181297\n",
      "running loss : 2.179664\n",
      "running loss : 2.171613\n",
      "running loss : 2.162780\n",
      "running loss : 2.161844\n",
      "running loss : 2.166208\n",
      "running loss : 2.156082\n",
      "running loss : 2.167773\n",
      "running loss : 2.163919\n",
      "running loss : 2.168464\n",
      "running loss : 2.177195\n",
      "running loss : 2.179535\n",
      "running loss : 2.179460\n",
      "running loss : 2.174689\n",
      "running loss : 2.159268\n",
      "running loss : 2.166964\n",
      "running loss : 2.168959\n",
      "running loss : 2.179325\n",
      "running loss : 2.174299\n",
      "running loss : 2.166773\n",
      "running loss : 2.161262\n",
      "running loss : 2.172312\n",
      "running loss : 2.161394\n",
      "running loss : 2.181184\n",
      "running loss : 2.184405\n",
      "running loss : 2.171227\n",
      "running loss : 2.165649\n",
      "running loss : 2.159055\n",
      "running loss : 2.163835\n",
      "running loss : 2.167732\n",
      "running loss : 2.170885\n",
      "running loss : 2.198399\n",
      "running loss : 2.171326\n",
      "running loss : 2.175891\n",
      "running loss : 2.160470\n",
      "running loss : 2.174936\n",
      "running loss : 2.165478\n",
      "running loss : 2.154609\n",
      "running loss : 2.155489\n",
      "running loss : 2.174664\n",
      "running loss : 2.178536\n",
      "running loss : 2.169651\n",
      "running loss : 2.164061\n",
      "running loss : 2.166540\n",
      "running loss : 2.202530\n",
      "running loss : 2.183425\n",
      "running loss : 2.162070\n",
      "running loss : 2.162045\n",
      "running loss : 2.162076\n",
      "running loss : 2.155240\n",
      "running loss : 2.160307\n",
      "running loss : 2.166095\n",
      "running loss : 2.181743\n",
      "running loss : 2.165961\n",
      "running loss : 2.163452\n",
      "running loss : 2.161596\n",
      "running loss : 2.157537\n",
      "running loss : 2.155637\n",
      "running loss : 2.171047\n",
      "running loss : 2.164684\n",
      "running loss : 2.154621\n",
      "running loss : 2.154927\n",
      "running loss : 2.157888\n",
      "running loss : 2.172097\n",
      "running loss : 2.159088\n",
      "running loss : 2.153681\n",
      "running loss : 2.157333\n",
      "running loss : 2.153361\n",
      "running loss : 2.148470\n",
      "running loss : 2.170532\n",
      "running loss : 2.180416\n",
      "running loss : 2.173161\n",
      "running loss : 2.166217\n",
      "running loss : 2.169656\n",
      "running loss : 2.162958\n",
      "running loss : 2.167342\n",
      "running loss : 2.189119\n",
      "running loss : 2.164853\n",
      "running loss : 2.157992\n",
      "running loss : 2.147978\n",
      "running loss : 2.156857\n",
      "running loss : 2.161588\n",
      "running loss : 2.175486\n",
      "running loss : 2.165598\n",
      "running loss : 2.158922\n",
      "running loss : 2.156489\n",
      "running loss : 2.151673\n",
      "running loss : 2.159639\n",
      "running loss : 2.175991\n",
      "running loss : 2.158317\n",
      "running loss : 2.145156\n",
      "running loss : 2.152921\n",
      "running loss : 2.160481\n",
      "running loss : 2.165101\n",
      "running loss : 2.167459\n",
      "running loss : 2.155244\n",
      "running loss : 2.147052\n",
      "running loss : 2.150583\n",
      "running loss : 2.163136\n",
      "running loss : 2.143769\n",
      "running loss : 2.146738\n",
      "running loss : 2.173251\n",
      "running loss : 2.168431\n",
      "running loss : 2.155285\n",
      "running loss : 2.147713\n",
      "running loss : 2.181038\n",
      "running loss : 2.172220\n",
      "running loss : 2.167070\n",
      "running loss : 2.152581\n",
      "running loss : 2.150769\n",
      "running loss : 2.156518\n",
      "running loss : 2.161225\n",
      "running loss : 2.147663\n",
      "running loss : 2.145162\n",
      "running loss : 2.148240\n",
      "running loss : 2.164114\n",
      "running loss : 2.149454\n",
      "running loss : 2.162008\n",
      "running loss : 2.155359\n",
      "running loss : 2.150895\n",
      "running loss : 2.169354\n",
      "running loss : 2.173490\n",
      "running loss : 2.157661\n",
      "running loss : 2.151625\n",
      "running loss : 2.143918\n",
      "running loss : 2.142458\n",
      "running loss : 2.181104\n",
      "running loss : 2.150536\n",
      "running loss : 2.140906\n",
      "running loss : 2.141349\n",
      "running loss : 2.147037\n",
      "running loss : 2.148430\n",
      "running loss : 2.138580\n",
      "running loss : 2.167881\n",
      "running loss : 2.145101\n",
      "running loss : 2.139669\n",
      "running loss : 2.144904\n",
      "running loss : 2.139105\n",
      "running loss : 2.169603\n",
      "running loss : 2.169887\n",
      "running loss : 2.139493\n",
      "running loss : 2.150581\n",
      "running loss : 2.138607\n",
      "running loss : 2.139348\n",
      "running loss : 2.135328\n",
      "running loss : 2.131207\n",
      "running loss : 2.131803\n",
      "running loss : 2.128283\n",
      "running loss : 2.133478\n",
      "running loss : 2.136955\n",
      "running loss : 2.134936\n",
      "running loss : 2.128370\n",
      "running loss : 2.136406\n",
      "running loss : 2.145504\n",
      "running loss : 2.165383\n",
      "running loss : 2.137350\n",
      "running loss : 2.125074\n",
      "running loss : 2.125714\n",
      "running loss : 2.129504\n",
      "running loss : 2.125774\n",
      "running loss : 2.125182\n",
      "running loss : 2.125540\n",
      "running loss : 2.130961\n",
      "running loss : 2.129249\n",
      "running loss : 2.129864\n",
      "running loss : 2.124334\n",
      "running loss : 2.114983\n",
      "running loss : 2.136168\n",
      "running loss : 2.131312\n",
      "running loss : 2.123960\n",
      "running loss : 2.120890\n",
      "running loss : 2.120048\n",
      "running loss : 2.122599\n",
      "running loss : 2.121553\n",
      "running loss : 2.123289\n",
      "running loss : 2.133532\n",
      "running loss : 2.138070\n",
      "running loss : 2.140210\n",
      "running loss : 2.126513\n",
      "running loss : 2.137702\n",
      "running loss : 2.125520\n",
      "running loss : 2.130660\n",
      "running loss : 2.132287\n",
      "running loss : 2.117428\n",
      "running loss : 2.119520\n",
      "running loss : 2.120957\n",
      "running loss : 2.120707\n",
      "running loss : 2.125255\n",
      "running loss : 2.151377\n",
      "running loss : 2.119699\n",
      "running loss : 2.123112\n",
      "running loss : 2.127969\n",
      "running loss : 2.121583\n",
      "running loss : 2.122995\n",
      "running loss : 2.125501\n",
      "running loss : 2.108540\n",
      "running loss : 2.122764\n",
      "running loss : 2.127598\n",
      "running loss : 2.116230\n",
      "running loss : 2.122759\n",
      "running loss : 2.125613\n",
      "running loss : 2.116527\n",
      "running loss : 2.111548\n",
      "running loss : 2.110712\n",
      "running loss : 2.122907\n",
      "running loss : 2.112593\n",
      "running loss : 2.125658\n",
      "running loss : 2.114161\n",
      "running loss : 2.120311\n",
      "running loss : 2.139841\n",
      "running loss : 2.137169\n",
      "running loss : 2.130383\n",
      "running loss : 2.116201\n",
      "running loss : 2.124490\n",
      "running loss : 2.132254\n",
      "running loss : 2.117373\n",
      "running loss : 2.121103\n",
      "running loss : 2.130506\n",
      "running loss : 2.135122\n",
      "running loss : 2.160129\n",
      "running loss : 2.131714\n",
      "running loss : 2.119009\n",
      "running loss : 2.128430\n",
      "running loss : 2.115670\n",
      "running loss : 2.116644\n",
      "running loss : 2.116745\n",
      "running loss : 2.119482\n",
      "running loss : 2.143106\n",
      "running loss : 2.113082\n",
      "running loss : 2.117396\n",
      "running loss : 2.105818\n",
      "running loss : 2.104607\n",
      "running loss : 2.111031\n",
      "running loss : 2.109927\n",
      "running loss : 2.113697\n",
      "running loss : 2.112464\n",
      "running loss : 2.131065\n",
      "running loss : 2.114457\n",
      "running loss : 2.126018\n",
      "running loss : 2.119221\n",
      "running loss : 2.124023\n",
      "running loss : 2.123685\n",
      "running loss : 2.121044\n",
      "running loss : 2.124562\n",
      "running loss : 2.128237\n",
      "running loss : 2.136704\n",
      "running loss : 2.118369\n",
      "running loss : 2.111002\n",
      "running loss : 2.101950\n",
      "running loss : 2.114368\n",
      "running loss : 2.108986\n",
      "running loss : 2.117901\n",
      "running loss : 2.113179\n",
      "running loss : 2.111862\n",
      "running loss : 2.111185\n",
      "running loss : 2.118424\n",
      "running loss : 2.117268\n",
      "running loss : 2.111234\n",
      "running loss : 2.103000\n",
      "running loss : 2.098030\n",
      "running loss : 2.107964\n",
      "running loss : 2.108921\n",
      "running loss : 2.120742\n",
      "running loss : 2.113205\n",
      "running loss : 2.102164\n",
      "running loss : 2.113552\n",
      "running loss : 2.124395\n",
      "running loss : 2.113732\n",
      "running loss : 2.123772\n",
      "running loss : 2.148819\n",
      "running loss : 2.116740\n",
      "running loss : 2.119907\n",
      "running loss : 2.120986\n",
      "running loss : 2.131021\n",
      "running loss : 2.114991\n",
      "running loss : 2.112012\n",
      "running loss : 2.120572\n",
      "running loss : 2.112935\n",
      "running loss : 2.108042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.105216\n",
      "running loss : 2.105687\n",
      "running loss : 2.105250\n",
      "running loss : 2.102948\n",
      "running loss : 2.105638\n",
      "running loss : 2.107604\n",
      "running loss : 2.112581\n",
      "running loss : 2.120172\n",
      "running loss : 2.102704\n",
      "running loss : 2.111365\n",
      "running loss : 2.112464\n",
      "running loss : 2.106388\n",
      "running loss : 2.102760\n",
      "running loss : 2.097196\n",
      "running loss : 2.106284\n",
      "running loss : 2.112799\n",
      "running loss : 2.116607\n",
      "running loss : 2.104416\n",
      "running loss : 2.113477\n",
      "running loss : 2.105511\n",
      "running loss : 2.114200\n",
      "running loss : 2.108830\n",
      "running loss : 2.114892\n",
      "running loss : 2.119273\n",
      "running loss : 2.119316\n",
      "running loss : 2.116331\n",
      "running loss : 2.138683\n",
      "running loss : 2.137289\n",
      "running loss : 2.126756\n",
      "running loss : 2.134489\n",
      "running loss : 2.127002\n",
      "running loss : 2.109034\n",
      "running loss : 2.100407\n",
      "running loss : 2.124686\n",
      "running loss : 2.152143\n",
      "running loss : 2.147471\n",
      "running loss : 2.118043\n",
      "running loss : 2.114712\n",
      "running loss : 2.101926\n",
      "running loss : 2.111129\n",
      "running loss : 2.109444\n",
      "running loss : 2.106652\n",
      "running loss : 2.107642\n",
      "running loss : 2.114200\n",
      "running loss : 2.118634\n",
      "running loss : 2.109893\n",
      "running loss : 2.107912\n",
      "running loss : 2.117976\n",
      "running loss : 2.112449\n",
      "running loss : 2.103644\n",
      "running loss : 2.129993\n",
      "running loss : 2.128663\n",
      "running loss : 2.113405\n",
      "running loss : 2.103411\n",
      "running loss : 2.099489\n",
      "running loss : 2.100321\n",
      "running loss : 2.099486\n",
      "running loss : 2.109349\n",
      "running loss : 2.097881\n",
      "running loss : 2.095488\n",
      "running loss : 2.113832\n",
      "running loss : 2.107075\n",
      "running loss : 2.104299\n",
      "running loss : 2.093331\n",
      "running loss : 2.096750\n",
      "running loss : 2.090775\n",
      "running loss : 2.095701\n",
      "running loss : 2.102360\n",
      "running loss : 2.096775\n",
      "running loss : 2.088869\n",
      "running loss : 2.093467\n",
      "running loss : 2.089047\n",
      "running loss : 2.094274\n",
      "running loss : 2.093623\n",
      "running loss : 2.105612\n",
      "running loss : 2.112466\n",
      "running loss : 2.104201\n",
      "running loss : 2.094478\n",
      "running loss : 2.100760\n",
      "running loss : 2.111777\n",
      "running loss : 2.109592\n",
      "running loss : 2.106451\n",
      "running loss : 2.102244\n",
      "running loss : 2.120188\n",
      "running loss : 2.124634\n",
      "running loss : 2.114165\n",
      "running loss : 2.114538\n",
      "running loss : 2.124869\n",
      "running loss : 2.118817\n",
      "running loss : 2.114636\n",
      "running loss : 2.132745\n",
      "running loss : 2.125555\n",
      "running loss : 2.113134\n",
      "running loss : 2.116648\n",
      "running loss : 2.107350\n",
      "running loss : 2.113506\n",
      "running loss : 2.121925\n",
      "running loss : 2.134730\n",
      "running loss : 2.116712\n",
      "running loss : 2.106795\n",
      "running loss : 2.107141\n",
      "running loss : 2.105597\n",
      "running loss : 2.110261\n",
      "running loss : 2.115311\n",
      "running loss : 2.111784\n",
      "running loss : 2.114238\n",
      "running loss : 2.106660\n",
      "running loss : 2.117469\n",
      "running loss : 2.126381\n",
      "running loss : 2.119558\n",
      "running loss : 2.107665\n",
      "running loss : 2.098793\n",
      "running loss : 2.109141\n",
      "running loss : 2.116853\n",
      "running loss : 2.105853\n",
      "running loss : 2.098501\n",
      "running loss : 2.098279\n",
      "running loss : 2.104504\n",
      "running loss : 2.105649\n",
      "running loss : 2.110949\n",
      "running loss : 2.109720\n",
      "running loss : 2.102661\n",
      "running loss : 2.107912\n",
      "running loss : 2.109831\n",
      "running loss : 2.121586\n",
      "running loss : 2.122189\n",
      "running loss : 2.106894\n",
      "running loss : 2.097264\n",
      "running loss : 2.108691\n",
      "running loss : 2.095568\n",
      "running loss : 2.104553\n",
      "running loss : 2.132531\n",
      "running loss : 2.112542\n",
      "running loss : 2.111864\n",
      "running loss : 2.110716\n",
      "running loss : 2.096755\n",
      "running loss : 2.100320\n",
      "running loss : 2.096192\n",
      "running loss : 2.098076\n",
      "running loss : 2.095566\n",
      "running loss : 2.101417\n",
      "running loss : 2.099064\n",
      "running loss : 2.116931\n",
      "running loss : 2.095261\n",
      "running loss : 2.089507\n",
      "running loss : 2.108638\n",
      "running loss : 2.109682\n",
      "running loss : 2.121582\n",
      "running loss : 2.103008\n",
      "running loss : 2.086656\n",
      "running loss : 2.094249\n",
      "running loss : 2.091609\n",
      "running loss : 2.092715\n",
      "running loss : 2.093868\n",
      "running loss : 2.098179\n",
      "running loss : 2.107352\n",
      "running loss : 2.089995\n",
      "running loss : 2.093656\n",
      "running loss : 2.092280\n",
      "running loss : 2.116187\n",
      "running loss : 2.097259\n",
      "running loss : 2.096743\n",
      "running loss : 2.098058\n",
      "running loss : 2.112622\n",
      "running loss : 2.115780\n",
      "running loss : 2.109599\n",
      "running loss : 2.113334\n",
      "running loss : 2.105187\n",
      "running loss : 2.092472\n",
      "running loss : 2.097404\n",
      "running loss : 2.114631\n",
      "running loss : 2.102620\n",
      "running loss : 2.085057\n",
      "running loss : 2.094169\n",
      "running loss : 2.102422\n",
      "running loss : 2.095488\n",
      "running loss : 2.099192\n",
      "running loss : 2.088056\n",
      "running loss : 2.096601\n",
      "running loss : 2.089262\n",
      "running loss : 2.087401\n",
      "running loss : 2.097042\n",
      "running loss : 2.092380\n",
      "running loss : 2.101498\n",
      "running loss : 2.092418\n",
      "running loss : 2.100479\n",
      "running loss : 2.094121\n",
      "running loss : 2.093934\n",
      "running loss : 2.091007\n",
      "running loss : 2.102368\n",
      "running loss : 2.104370\n",
      "running loss : 2.094036\n",
      "running loss : 2.095216\n",
      "running loss : 2.087260\n",
      "running loss : 2.095015\n",
      "running loss : 2.098283\n",
      "running loss : 2.091357\n",
      "running loss : 2.099829\n",
      "running loss : 2.107024\n",
      "running loss : 2.095087\n",
      "running loss : 2.089758\n",
      "running loss : 2.094082\n",
      "running loss : 2.108396\n",
      "running loss : 2.120379\n",
      "running loss : 2.109486\n",
      "running loss : 2.098112\n",
      "running loss : 2.101621\n",
      "running loss : 2.096275\n",
      "running loss : 2.107719\n",
      "running loss : 2.094910\n",
      "running loss : 2.107009\n",
      "running loss : 2.106524\n",
      "running loss : 2.130367\n",
      "running loss : 2.112055\n",
      "running loss : 2.101195\n",
      "running loss : 2.104494\n",
      "running loss : 2.096693\n",
      "running loss : 2.099983\n",
      "running loss : 2.098569\n",
      "running loss : 2.097984\n",
      "running loss : 2.105220\n",
      "running loss : 2.079826\n",
      "running loss : 2.095332\n",
      "running loss : 2.103456\n",
      "running loss : 2.108888\n",
      "running loss : 2.120680\n",
      "running loss : 2.101142\n",
      "running loss : 2.086692\n",
      "running loss : 2.100614\n",
      "running loss : 2.111537\n",
      "running loss : 2.108631\n",
      "running loss : 2.102510\n",
      "running loss : 2.091849\n",
      "running loss : 2.085952\n",
      "running loss : 2.082653\n",
      "running loss : 2.080384\n",
      "running loss : 2.085721\n",
      "running loss : 2.082424\n",
      "running loss : 2.081587\n",
      "running loss : 2.072791\n",
      "running loss : 2.078056\n",
      "running loss : 2.079152\n",
      "running loss : 2.082087\n",
      "running loss : 2.081201\n",
      "running loss : 2.072239\n",
      "running loss : 2.095259\n",
      "running loss : 2.089578\n",
      "running loss : 2.078777\n",
      "running loss : 2.072439\n",
      "running loss : 2.074970\n",
      "running loss : 2.075548\n",
      "running loss : 2.077360\n",
      "running loss : 2.085312\n",
      "running loss : 2.095346\n",
      "running loss : 2.105731\n",
      "running loss : 2.108700\n",
      "running loss : 2.092888\n",
      "running loss : 2.080491\n",
      "running loss : 2.079042\n",
      "running loss : 2.073232\n",
      "running loss : 2.080797\n",
      "running loss : 2.117286\n",
      "running loss : 2.092758\n",
      "running loss : 2.083114\n",
      "running loss : 2.077344\n",
      "running loss : 2.070109\n",
      "running loss : 2.066544\n",
      "running loss : 2.068381\n",
      "running loss : 2.078675\n",
      "running loss : 2.080633\n",
      "running loss : 2.080381\n",
      "running loss : 2.083115\n",
      "running loss : 2.082716\n",
      "running loss : 2.082138\n",
      "running loss : 2.084398\n",
      "running loss : 2.084744\n",
      "running loss : 2.088437\n",
      "running loss : 2.079586\n",
      "running loss : 2.092892\n",
      "running loss : 2.082383\n",
      "running loss : 2.086534\n",
      "running loss : 2.093701\n",
      "running loss : 2.098596\n",
      "running loss : 2.101415\n",
      "running loss : 2.123742\n",
      "running loss : 2.097646\n",
      "running loss : 2.089854\n",
      "running loss : 2.091120\n",
      "running loss : 2.102904\n",
      "running loss : 2.099039\n",
      "running loss : 2.088834\n",
      "running loss : 2.086739\n",
      "running loss : 2.099315\n",
      "running loss : 2.094152\n",
      "running loss : 2.090948\n",
      "running loss : 2.088997\n",
      "running loss : 2.090980\n",
      "running loss : 2.089742\n",
      "running loss : 2.093737\n",
      "running loss : 2.091931\n",
      "running loss : 2.092945\n",
      "running loss : 2.084013\n",
      "running loss : 2.082094\n",
      "running loss : 2.090824\n",
      "running loss : 2.082911\n",
      "running loss : 2.081222\n",
      "running loss : 2.075466\n",
      "running loss : 2.085349\n",
      "running loss : 2.097763\n",
      "running loss : 2.081668\n",
      "running loss : 2.084918\n",
      "running loss : 2.084240\n",
      "running loss : 2.082528\n",
      "running loss : 2.085799\n",
      "running loss : 2.077884\n",
      "running loss : 2.076079\n",
      "running loss : 2.076501\n",
      "running loss : 2.073031\n",
      "running loss : 2.107497\n",
      "running loss : 2.098974\n",
      "running loss : 2.093563\n",
      "running loss : 2.079059\n",
      "running loss : 2.097707\n",
      "running loss : 2.091371\n",
      "running loss : 2.095582\n",
      "running loss : 2.094583\n",
      "running loss : 2.088212\n",
      "running loss : 2.100736\n",
      "running loss : 2.087300\n",
      "running loss : 2.081905\n",
      "running loss : 2.084542\n",
      "running loss : 2.080470\n",
      "running loss : 2.084236\n",
      "running loss : 2.080827\n",
      "running loss : 2.082243\n",
      "running loss : 2.080968\n",
      "running loss : 2.083931\n",
      "running loss : 2.084192\n",
      "running loss : 2.083451\n",
      "running loss : 2.082177\n",
      "running loss : 2.083924\n",
      "running loss : 2.080276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.080637\n",
      "running loss : 2.087468\n",
      "running loss : 2.096773\n",
      "running loss : 2.083600\n",
      "running loss : 2.082555\n",
      "running loss : 2.078928\n",
      "running loss : 2.077729\n",
      "running loss : 2.087580\n",
      "running loss : 2.094172\n",
      "running loss : 2.083935\n",
      "running loss : 2.078988\n",
      "running loss : 2.073743\n",
      "running loss : 2.073597\n",
      "running loss : 2.073105\n",
      "running loss : 2.083179\n",
      "running loss : 2.086574\n",
      "running loss : 2.086126\n",
      "running loss : 2.084980\n",
      "running loss : 2.099693\n",
      "running loss : 2.081425\n",
      "running loss : 2.074390\n",
      "running loss : 2.071428\n",
      "running loss : 2.067595\n",
      "running loss : 2.080782\n",
      "running loss : 2.073604\n",
      "running loss : 2.079400\n",
      "running loss : 2.079827\n",
      "running loss : 2.082163\n",
      "running loss : 2.083671\n",
      "running loss : 2.074566\n",
      "running loss : 2.078576\n",
      "running loss : 2.068554\n",
      "running loss : 2.069616\n",
      "running loss : 2.062562\n",
      "running loss : 2.062530\n",
      "running loss : 2.065435\n",
      "running loss : 2.062335\n",
      "running loss : 2.062199\n",
      "running loss : 2.061988\n",
      "running loss : 2.065856\n",
      "running loss : 2.077555\n",
      "running loss : 2.072536\n",
      "running loss : 2.060569\n",
      "running loss : 2.069867\n",
      "running loss : 2.064194\n",
      "running loss : 2.062899\n",
      "running loss : 2.064157\n",
      "running loss : 2.068590\n",
      "running loss : 2.066637\n",
      "running loss : 2.068512\n",
      "running loss : 2.066111\n",
      "running loss : 2.076724\n",
      "running loss : 2.107050\n",
      "running loss : 2.099695\n",
      "running loss : 2.069886\n",
      "running loss : 2.065568\n",
      "running loss : 2.059057\n",
      "running loss : 2.054173\n",
      "running loss : 2.057036\n",
      "running loss : 2.054604\n",
      "running loss : 2.073785\n",
      "running loss : 2.069165\n",
      "running loss : 2.064939\n",
      "running loss : 2.059647\n",
      "running loss : 2.072933\n",
      "running loss : 2.057713\n",
      "running loss : 2.056586\n",
      "running loss : 2.071725\n",
      "running loss : 2.070811\n",
      "running loss : 2.086187\n",
      "running loss : 2.079599\n",
      "running loss : 2.069416\n",
      "running loss : 2.070674\n",
      "running loss : 2.075269\n",
      "running loss : 2.065495\n",
      "running loss : 2.070352\n",
      "running loss : 2.068130\n",
      "running loss : 2.069345\n",
      "running loss : 2.071629\n",
      "running loss : 2.069052\n",
      "running loss : 2.075728\n",
      "running loss : 2.068359\n",
      "running loss : 2.073285\n",
      "running loss : 2.113994\n",
      "running loss : 2.078712\n",
      "running loss : 2.071099\n",
      "running loss : 2.073782\n",
      "running loss : 2.063222\n",
      "running loss : 2.070246\n",
      "running loss : 2.078142\n",
      "running loss : 2.066581\n",
      "running loss : 2.069212\n",
      "running loss : 2.066405\n",
      "running loss : 2.064095\n",
      "running loss : 2.073521\n",
      "running loss : 2.077820\n",
      "running loss : 2.090000\n",
      "running loss : 2.082079\n",
      "running loss : 2.091298\n",
      "running loss : 2.086652\n",
      "running loss : 2.074964\n",
      "running loss : 2.075266\n",
      "running loss : 2.069083\n",
      "running loss : 2.091373\n",
      "running loss : 2.099129\n",
      "running loss : 2.082036\n",
      "running loss : 2.078767\n",
      "running loss : 2.080765\n",
      "running loss : 2.108433\n",
      "running loss : 2.100993\n",
      "running loss : 2.081669\n",
      "running loss : 2.092342\n",
      "running loss : 2.072946\n",
      "running loss : 2.081947\n",
      "running loss : 2.075270\n",
      "running loss : 2.082524\n",
      "running loss : 2.071979\n",
      "running loss : 2.064788\n",
      "running loss : 2.063341\n",
      "running loss : 2.073254\n",
      "running loss : 2.073133\n",
      "running loss : 2.071907\n",
      "running loss : 2.074295\n",
      "running loss : 2.074580\n",
      "running loss : 2.074987\n",
      "running loss : 2.085683\n",
      "running loss : 2.077744\n",
      "running loss : 2.070124\n",
      "running loss : 2.070404\n",
      "running loss : 2.082868\n",
      "running loss : 2.089428\n",
      "running loss : 2.094509\n",
      "running loss : 2.088704\n",
      "running loss : 2.084166\n",
      "running loss : 2.081028\n",
      "running loss : 2.073552\n",
      "running loss : 2.070939\n",
      "running loss : 2.067625\n",
      "running loss : 2.066787\n",
      "running loss : 2.066168\n",
      "running loss : 2.061172\n",
      "running loss : 2.076268\n",
      "running loss : 2.076844\n",
      "running loss : 2.068170\n",
      "running loss : 2.059927\n",
      "running loss : 2.061137\n",
      "running loss : 2.094914\n",
      "running loss : 2.068207\n",
      "running loss : 2.059071\n",
      "running loss : 2.058482\n",
      "running loss : 2.062815\n",
      "running loss : 2.063628\n",
      "running loss : 2.059625\n",
      "running loss : 2.062758\n",
      "running loss : 2.063884\n",
      "running loss : 2.061745\n",
      "running loss : 2.067333\n",
      "running loss : 2.056891\n",
      "running loss : 2.059316\n",
      "running loss : 2.060751\n",
      "running loss : 2.063986\n",
      "running loss : 2.074913\n",
      "running loss : 2.073198\n",
      "running loss : 2.078057\n",
      "running loss : 2.076267\n",
      "running loss : 2.051798\n",
      "running loss : 2.057383\n",
      "running loss : 2.062091\n",
      "running loss : 2.064594\n",
      "running loss : 2.066160\n",
      "running loss : 2.067566\n",
      "running loss : 2.059675\n",
      "running loss : 2.079998\n",
      "running loss : 2.069207\n",
      "running loss : 2.061655\n",
      "running loss : 2.059243\n",
      "running loss : 2.054767\n",
      "running loss : 2.051494\n",
      "running loss : 2.053609\n",
      "running loss : 2.055886\n",
      "running loss : 2.057627\n",
      "running loss : 2.066568\n",
      "running loss : 2.076112\n",
      "running loss : 2.070397\n",
      "running loss : 2.061075\n",
      "running loss : 2.064509\n",
      "running loss : 2.071836\n",
      "running loss : 2.090058\n",
      "running loss : 2.065342\n",
      "running loss : 2.063643\n",
      "running loss : 2.072693\n",
      "running loss : 2.072828\n",
      "running loss : 2.060118\n",
      "running loss : 2.060569\n",
      "running loss : 2.058657\n",
      "running loss : 2.053989\n",
      "running loss : 2.056010\n",
      "running loss : 2.056844\n",
      "running loss : 2.066006\n",
      "running loss : 2.068462\n",
      "running loss : 2.054951\n",
      "running loss : 2.065032\n",
      "running loss : 2.064953\n",
      "running loss : 2.067002\n",
      "running loss : 2.060843\n",
      "running loss : 2.067140\n",
      "running loss : 2.111956\n",
      "running loss : 2.071670\n",
      "running loss : 2.065967\n",
      "running loss : 2.062253\n",
      "running loss : 2.059268\n",
      "running loss : 2.052772\n",
      "running loss : 2.058744\n",
      "running loss : 2.063932\n",
      "running loss : 2.056202\n",
      "running loss : 2.054938\n",
      "running loss : 2.065276\n",
      "running loss : 2.057633\n",
      "running loss : 2.059931\n",
      "running loss : 2.050967\n",
      "running loss : 2.054332\n",
      "running loss : 2.071541\n",
      "running loss : 2.065885\n",
      "running loss : 2.049727\n",
      "running loss : 2.045834\n",
      "running loss : 2.051727\n",
      "running loss : 2.053907\n",
      "running loss : 2.056364\n",
      "running loss : 2.051580\n",
      "running loss : 2.055909\n",
      "running loss : 2.063260\n",
      "running loss : 2.083371\n",
      "running loss : 2.076857\n",
      "running loss : 2.064855\n",
      "running loss : 2.060222\n",
      "running loss : 2.057149\n",
      "running loss : 2.061053\n",
      "running loss : 2.072743\n",
      "running loss : 2.052104\n",
      "running loss : 2.044239\n",
      "running loss : 2.052248\n",
      "running loss : 2.043278\n",
      "running loss : 2.052867\n",
      "running loss : 2.053778\n",
      "running loss : 2.066338\n",
      "running loss : 2.060633\n",
      "running loss : 2.043079\n",
      "running loss : 2.052806\n",
      "running loss : 2.065435\n",
      "running loss : 2.062272\n",
      "running loss : 2.052475\n",
      "running loss : 2.047048\n",
      "running loss : 2.047656\n",
      "running loss : 2.046826\n",
      "running loss : 2.050044\n",
      "running loss : 2.061524\n",
      "running loss : 2.053384\n",
      "running loss : 2.059321\n",
      "running loss : 2.082675\n",
      "running loss : 2.061841\n",
      "running loss : 2.051205\n",
      "running loss : 2.046454\n",
      "running loss : 2.050887\n",
      "running loss : 2.048558\n",
      "running loss : 2.048528\n",
      "running loss : 2.078642\n",
      "running loss : 2.060905\n",
      "running loss : 2.056891\n",
      "running loss : 2.048772\n",
      "running loss : 2.047309\n",
      "running loss : 2.035573\n",
      "running loss : 2.039947\n",
      "running loss : 2.047147\n",
      "running loss : 2.038250\n",
      "running loss : 2.046419\n",
      "running loss : 2.060498\n",
      "running loss : 2.071258\n",
      "running loss : 2.053845\n",
      "running loss : 2.053126\n",
      "running loss : 2.056111\n",
      "running loss : 2.053139\n",
      "running loss : 2.045417\n",
      "running loss : 2.045278\n",
      "running loss : 2.044311\n",
      "running loss : 2.052552\n",
      "running loss : 2.055289\n",
      "running loss : 2.073738\n",
      "running loss : 2.063193\n",
      "running loss : 2.051229\n",
      "running loss : 2.047564\n",
      "running loss : 2.055136\n",
      "running loss : 2.048783\n",
      "running loss : 2.053790\n",
      "running loss : 2.052145\n",
      "running loss : 2.067360\n",
      "running loss : 2.049238\n",
      "running loss : 2.050411\n",
      "running loss : 2.058476\n",
      "running loss : 2.054011\n",
      "running loss : 2.059401\n",
      "running loss : 2.051915\n",
      "running loss : 2.059919\n",
      "running loss : 2.053149\n",
      "running loss : 2.047850\n",
      "running loss : 2.052322\n",
      "running loss : 2.054646\n",
      "running loss : 2.047653\n",
      "running loss : 2.058737\n",
      "running loss : 2.056540\n",
      "running loss : 2.055189\n",
      "running loss : 2.044255\n",
      "running loss : 2.049920\n",
      "running loss : 2.070136\n",
      "running loss : 2.064792\n",
      "running loss : 2.062412\n",
      "running loss : 2.054918\n",
      "running loss : 2.055244\n",
      "running loss : 2.049394\n",
      "running loss : 2.045881\n",
      "running loss : 2.053785\n",
      "running loss : 2.056776\n",
      "running loss : 2.053049\n",
      "running loss : 2.060146\n",
      "running loss : 2.049572\n",
      "running loss : 2.054407\n",
      "running loss : 2.065093\n",
      "running loss : 2.068764\n",
      "running loss : 2.059011\n",
      "running loss : 2.048094\n",
      "running loss : 2.047321\n",
      "running loss : 2.053616\n",
      "running loss : 2.061061\n",
      "running loss : 2.046962\n",
      "running loss : 2.049429\n",
      "running loss : 2.061849\n",
      "running loss : 2.054535\n",
      "running loss : 2.054116\n",
      "running loss : 2.062856\n",
      "running loss : 2.064711\n",
      "running loss : 2.052882\n",
      "running loss : 2.048894\n",
      "running loss : 2.042820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.052683\n",
      "running loss : 2.046492\n",
      "running loss : 2.047774\n",
      "running loss : 2.051840\n",
      "running loss : 2.047361\n",
      "running loss : 2.055770\n",
      "running loss : 2.052612\n",
      "running loss : 2.041903\n",
      "running loss : 2.046880\n",
      "running loss : 2.048799\n",
      "running loss : 2.049728\n",
      "running loss : 2.048754\n",
      "running loss : 2.055285\n",
      "running loss : 2.052132\n",
      "running loss : 2.048650\n",
      "running loss : 2.047984\n",
      "running loss : 2.050923\n",
      "running loss : 2.035796\n",
      "running loss : 2.043984\n",
      "running loss : 2.051648\n",
      "running loss : 2.049629\n",
      "running loss : 2.052338\n",
      "running loss : 2.045819\n",
      "running loss : 2.064058\n",
      "running loss : 2.066694\n",
      "running loss : 2.050905\n",
      "running loss : 2.048445\n",
      "running loss : 2.049463\n",
      "running loss : 2.049978\n",
      "running loss : 2.046516\n",
      "running loss : 2.051588\n",
      "running loss : 2.055265\n",
      "running loss : 2.047072\n",
      "running loss : 2.047782\n",
      "running loss : 2.040296\n",
      "running loss : 2.053933\n",
      "running loss : 2.054792\n",
      "running loss : 2.036265\n",
      "running loss : 2.046520\n",
      "running loss : 2.047063\n",
      "running loss : 2.053519\n",
      "running loss : 2.055113\n",
      "running loss : 2.042108\n",
      "running loss : 2.042919\n",
      "running loss : 2.043161\n",
      "running loss : 2.048314\n",
      "running loss : 2.057090\n",
      "running loss : 2.054798\n",
      "running loss : 2.064794\n",
      "running loss : 2.064098\n",
      "running loss : 2.053113\n",
      "running loss : 2.056457\n",
      "running loss : 2.069651\n",
      "running loss : 2.057012\n",
      "running loss : 2.057784\n",
      "running loss : 2.059423\n",
      "running loss : 2.054035\n",
      "running loss : 2.057680\n",
      "running loss : 2.080718\n",
      "running loss : 2.072212\n",
      "running loss : 2.066181\n",
      "running loss : 2.065728\n",
      "running loss : 2.062868\n",
      "running loss : 2.070129\n",
      "running loss : 2.080886\n",
      "running loss : 2.067892\n",
      "running loss : 2.067834\n",
      "running loss : 2.061639\n",
      "running loss : 2.067852\n",
      "running loss : 2.064556\n",
      "running loss : 2.066609\n",
      "running loss : 2.067625\n",
      "running loss : 2.065002\n",
      "running loss : 2.067812\n",
      "running loss : 2.057808\n",
      "running loss : 2.052619\n",
      "running loss : 2.054865\n",
      "running loss : 2.062045\n",
      "running loss : 2.073829\n",
      "running loss : 2.056122\n",
      "running loss : 2.060675\n",
      "running loss : 2.050519\n",
      "running loss : 2.050265\n",
      "running loss : 2.055875\n",
      "running loss : 2.051384\n",
      "running loss : 2.051890\n",
      "running loss : 2.040791\n",
      "running loss : 2.058489\n",
      "running loss : 2.084119\n",
      "running loss : 2.053800\n",
      "running loss : 2.052470\n",
      "running loss : 2.042551\n",
      "running loss : 2.047559\n",
      "running loss : 2.049923\n",
      "running loss : 2.043964\n",
      "running loss : 2.049191\n",
      "running loss : 2.038645\n",
      "running loss : 2.040809\n",
      "running loss : 2.051164\n",
      "running loss : 2.046197\n",
      "running loss : 2.042309\n",
      "running loss : 2.043573\n",
      "running loss : 2.037388\n",
      "running loss : 2.038098\n",
      "running loss : 2.037319\n",
      "running loss : 2.040006\n",
      "running loss : 2.048033\n",
      "running loss : 2.058278\n",
      "running loss : 2.047568\n",
      "running loss : 2.040655\n",
      "running loss : 2.036736\n",
      "running loss : 2.039778\n",
      "running loss : 2.038110\n",
      "running loss : 2.051654\n",
      "running loss : 2.043916\n",
      "running loss : 2.045003\n",
      "running loss : 2.049672\n",
      "running loss : 2.079350\n",
      "running loss : 2.083852\n",
      "running loss : 18.860381\n",
      "running loss : 8.630465\n",
      "running loss : 4.598994\n",
      "running loss : 3.605154\n",
      "running loss : 3.238873\n",
      "running loss : 3.037348\n",
      "running loss : 2.905355\n",
      "running loss : 2.802364\n",
      "running loss : 2.721075\n",
      "running loss : 2.663307\n",
      "running loss : 2.612609\n",
      "running loss : 2.565837\n",
      "running loss : 2.530619\n",
      "running loss : 2.501674\n",
      "running loss : 2.469838\n",
      "running loss : 2.445726\n",
      "running loss : 2.421503\n",
      "running loss : 2.398168\n",
      "running loss : 2.382948\n",
      "running loss : 2.377575\n",
      "running loss : 2.346414\n",
      "running loss : 2.340735\n",
      "running loss : 2.318797\n",
      "running loss : 2.305825\n",
      "running loss : 2.300241\n",
      "running loss : 2.298040\n",
      "running loss : 2.275541\n",
      "running loss : 2.273552\n",
      "running loss : 2.255263\n",
      "running loss : 2.253398\n",
      "running loss : 2.250427\n",
      "running loss : 2.243279\n",
      "running loss : 2.237013\n",
      "running loss : 2.219672\n",
      "running loss : 2.230604\n",
      "running loss : 2.234866\n",
      "running loss : 2.220105\n",
      "running loss : 2.217274\n",
      "running loss : 2.202804\n",
      "running loss : 2.198438\n",
      "running loss : 2.205826\n",
      "running loss : 2.194623\n",
      "running loss : 2.190383\n",
      "running loss : 2.188885\n",
      "running loss : 2.202691\n",
      "running loss : 2.184757\n",
      "running loss : 2.174785\n",
      "running loss : 2.168107\n",
      "running loss : 2.155288\n",
      "running loss : 2.166816\n",
      "running loss : 2.159282\n",
      "running loss : 2.149708\n",
      "running loss : 2.152406\n",
      "running loss : 2.143907\n",
      "running loss : 2.166137\n",
      "running loss : 2.153085\n",
      "running loss : 2.135122\n",
      "running loss : 2.137538\n",
      "running loss : 2.139160\n",
      "running loss : 2.145967\n",
      "running loss : 2.134795\n",
      "running loss : 2.131226\n",
      "running loss : 2.149604\n",
      "running loss : 2.144244\n",
      "running loss : 2.132445\n",
      "running loss : 2.148368\n",
      "running loss : 2.123036\n",
      "running loss : 2.123743\n",
      "running loss : 2.126622\n",
      "running loss : 2.117253\n",
      "running loss : 2.123678\n",
      "running loss : 2.148904\n",
      "running loss : 2.135780\n",
      "running loss : 2.114668\n",
      "running loss : 2.109615\n",
      "running loss : 2.109532\n",
      "running loss : 2.111076\n",
      "running loss : 2.104929\n",
      "running loss : 2.105425\n",
      "running loss : 2.103665\n",
      "running loss : 2.126891\n",
      "running loss : 2.111203\n",
      "running loss : 2.134520\n",
      "running loss : 2.132028\n",
      "running loss : 2.118908\n",
      "running loss : 2.096045\n",
      "running loss : 2.093027\n",
      "running loss : 2.095217\n",
      "running loss : 2.094112\n",
      "running loss : 2.094545\n",
      "running loss : 2.096182\n",
      "running loss : 2.106691\n",
      "running loss : 2.097332\n",
      "running loss : 2.121666\n",
      "running loss : 2.117767\n",
      "running loss : 2.108100\n",
      "running loss : 2.096621\n",
      "running loss : 2.103743\n",
      "running loss : 2.092100\n",
      "running loss : 2.094353\n",
      "running loss : 2.091204\n",
      "running loss : 2.096564\n",
      "running loss : 2.090363\n",
      "running loss : 2.130239\n",
      "running loss : 2.144429\n",
      "running loss : 2.105342\n",
      "running loss : 2.088833\n",
      "running loss : 2.079826\n",
      "running loss : 2.082571\n",
      "running loss : 2.097270\n",
      "running loss : 2.081428\n",
      "running loss : 2.082825\n",
      "running loss : 2.085660\n",
      "running loss : 2.147047\n",
      "running loss : 2.114933\n",
      "running loss : 2.086963\n",
      "running loss : 2.087498\n",
      "running loss : 2.092952\n",
      "running loss : 2.084678\n",
      "running loss : 2.084880\n",
      "running loss : 2.081081\n",
      "running loss : 2.079699\n",
      "running loss : 2.085172\n",
      "running loss : 2.084079\n",
      "running loss : 2.071174\n",
      "running loss : 2.091268\n",
      "running loss : 2.100435\n",
      "running loss : 2.088533\n",
      "running loss : 2.148986\n",
      "running loss : 2.115520\n",
      "running loss : 2.086876\n",
      "running loss : 2.068987\n",
      "running loss : 2.068475\n",
      "running loss : 2.082547\n",
      "running loss : 2.088858\n",
      "running loss : 2.076420\n",
      "running loss : 2.071625\n",
      "running loss : 2.070524\n",
      "running loss : 2.070509\n",
      "running loss : 2.061835\n",
      "running loss : 2.070228\n",
      "running loss : 2.083752\n",
      "running loss : 2.068820\n",
      "running loss : 2.068282\n",
      "running loss : 2.075828\n",
      "running loss : 2.070577\n",
      "running loss : 2.063222\n",
      "running loss : 2.067004\n",
      "running loss : 2.072322\n",
      "running loss : 2.070689\n",
      "running loss : 2.067653\n",
      "running loss : 2.076506\n",
      "running loss : 2.138215\n",
      "running loss : 2.093244\n",
      "running loss : 2.073802\n",
      "running loss : 2.072416\n",
      "running loss : 2.066746\n",
      "running loss : 2.065583\n",
      "running loss : 2.066667\n",
      "running loss : 2.070510\n",
      "running loss : 2.070008\n",
      "running loss : 2.064936\n",
      "running loss : 2.061873\n",
      "running loss : 2.110192\n",
      "running loss : 2.069119\n",
      "running loss : 2.066674\n",
      "running loss : 2.065561\n",
      "running loss : 2.088270\n",
      "running loss : 2.085287\n",
      "running loss : 2.081546\n",
      "running loss : 2.060702\n",
      "running loss : 2.076631\n",
      "running loss : 2.094578\n",
      "running loss : 2.061551\n",
      "running loss : 2.052951\n",
      "running loss : 2.049821\n",
      "running loss : 2.064408\n",
      "running loss : 2.052627\n",
      "running loss : 2.049168\n",
      "running loss : 2.050830\n",
      "running loss : 2.068961\n",
      "running loss : 2.072801\n",
      "running loss : 2.057130\n",
      "running loss : 2.049075\n",
      "running loss : 2.046917\n",
      "running loss : 2.044552\n",
      "running loss : 2.054603\n",
      "running loss : 2.107740\n",
      "running loss : 2.089737\n",
      "running loss : 2.067944\n",
      "running loss : 2.065226\n",
      "running loss : 2.070201\n",
      "running loss : 2.054542\n",
      "running loss : 2.049925\n",
      "running loss : 2.056315\n",
      "running loss : 2.052183\n",
      "running loss : 2.059965\n",
      "running loss : 2.089692\n",
      "running loss : 2.105525\n",
      "running loss : 2.073420\n",
      "running loss : 2.063997\n",
      "running loss : 2.059010\n",
      "running loss : 2.066378\n",
      "running loss : 2.066456\n",
      "running loss : 2.056357\n",
      "running loss : 2.072684\n",
      "running loss : 2.057043\n",
      "running loss : 2.056370\n",
      "running loss : 2.057081\n",
      "running loss : 2.093889\n",
      "running loss : 2.086953\n",
      "running loss : 2.061890\n",
      "running loss : 2.057392\n",
      "running loss : 2.059955\n",
      "running loss : 2.073438\n",
      "running loss : 2.048971\n",
      "running loss : 2.050211\n",
      "running loss : 2.066698\n",
      "running loss : 2.056428\n",
      "running loss : 2.071645\n",
      "running loss : 2.047437\n",
      "running loss : 2.053650\n",
      "running loss : 2.040849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.045450\n",
      "running loss : 2.114562\n",
      "running loss : 2.079354\n",
      "running loss : 2.053223\n",
      "running loss : 2.059687\n",
      "running loss : 2.061810\n",
      "running loss : 2.046087\n",
      "running loss : 2.042959\n",
      "running loss : 2.051310\n",
      "running loss : 2.063242\n",
      "running loss : 2.057192\n",
      "running loss : 2.046193\n",
      "running loss : 2.052895\n",
      "running loss : 2.064046\n",
      "running loss : 2.059979\n",
      "running loss : 2.052717\n",
      "running loss : 2.052167\n",
      "running loss : 2.065650\n",
      "running loss : 2.072508\n",
      "running loss : 2.050841\n",
      "running loss : 2.056587\n",
      "running loss : 2.068489\n",
      "running loss : 2.058452\n",
      "running loss : 2.053341\n",
      "running loss : 2.053598\n",
      "running loss : 2.056067\n",
      "running loss : 2.071935\n",
      "running loss : 2.052061\n",
      "running loss : 2.051916\n",
      "running loss : 2.059922\n",
      "running loss : 2.056544\n",
      "running loss : 2.066711\n",
      "running loss : 2.051108\n",
      "running loss : 2.070378\n",
      "running loss : 2.122940\n",
      "running loss : 2.080008\n",
      "running loss : 2.058358\n",
      "running loss : 2.055254\n",
      "running loss : 2.061040\n",
      "running loss : 2.052691\n",
      "running loss : 2.055911\n",
      "running loss : 2.075753\n",
      "running loss : 2.061807\n",
      "running loss : 2.054022\n",
      "running loss : 2.070881\n",
      "running loss : 2.057534\n",
      "running loss : 2.053338\n",
      "running loss : 2.079401\n",
      "running loss : 2.110239\n",
      "running loss : 2.052690\n",
      "running loss : 2.041954\n",
      "running loss : 2.048099\n",
      "running loss : 2.051431\n",
      "running loss : 2.049153\n",
      "running loss : 2.040732\n",
      "running loss : 2.035723\n",
      "running loss : 2.047587\n",
      "running loss : 2.062961\n",
      "running loss : 2.056414\n",
      "running loss : 2.035361\n",
      "running loss : 2.040766\n",
      "running loss : 2.045065\n",
      "running loss : 2.046278\n",
      "running loss : 2.046446\n",
      "running loss : 2.053363\n",
      "running loss : 2.042012\n",
      "running loss : 2.043850\n",
      "running loss : 2.041955\n",
      "running loss : 2.039044\n",
      "running loss : 2.040700\n",
      "running loss : 2.037978\n",
      "running loss : 2.071026\n",
      "running loss : 2.048533\n",
      "running loss : 2.051533\n",
      "running loss : 2.082358\n",
      "running loss : 2.077894\n",
      "running loss : 2.052504\n",
      "running loss : 2.042225\n",
      "running loss : 2.038358\n",
      "running loss : 2.035442\n",
      "running loss : 2.037682\n",
      "running loss : 2.036400\n",
      "running loss : 2.049155\n",
      "running loss : 2.041467\n",
      "running loss : 2.039584\n",
      "running loss : 2.033637\n",
      "running loss : 2.055362\n",
      "running loss : 2.031143\n",
      "running loss : 2.059714\n",
      "running loss : 2.054851\n",
      "running loss : 2.035158\n",
      "running loss : 2.041026\n",
      "running loss : 2.032547\n",
      "running loss : 2.042945\n",
      "running loss : 2.048409\n",
      "running loss : 2.033093\n",
      "running loss : 2.033328\n",
      "running loss : 2.033140\n",
      "running loss : 2.040179\n",
      "running loss : 2.031907\n",
      "running loss : 2.032552\n",
      "running loss : 2.030181\n",
      "running loss : 2.040930\n",
      "running loss : 2.034745\n",
      "running loss : 2.028494\n",
      "running loss : 2.042363\n",
      "running loss : 2.041873\n",
      "running loss : 2.047631\n",
      "running loss : 2.035145\n",
      "running loss : 2.032332\n",
      "running loss : 2.030963\n",
      "running loss : 2.062131\n",
      "running loss : 2.041275\n",
      "running loss : 2.024083\n",
      "running loss : 2.025884\n",
      "running loss : 2.033028\n",
      "running loss : 2.045420\n",
      "running loss : 2.044286\n",
      "running loss : 2.042948\n",
      "running loss : 2.047943\n",
      "running loss : 2.034739\n",
      "running loss : 2.035317\n",
      "running loss : 2.032744\n",
      "running loss : 2.032869\n",
      "running loss : 2.032418\n",
      "running loss : 2.061008\n",
      "running loss : 2.050535\n",
      "running loss : 2.049611\n",
      "running loss : 2.042865\n",
      "running loss : 2.042178\n",
      "running loss : 2.052014\n",
      "running loss : 2.040843\n",
      "running loss : 2.043183\n",
      "running loss : 2.045600\n",
      "running loss : 2.050740\n",
      "running loss : 2.041031\n",
      "running loss : 2.055256\n",
      "running loss : 2.054606\n",
      "running loss : 2.041474\n",
      "running loss : 2.036868\n",
      "running loss : 2.035489\n",
      "running loss : 2.038959\n",
      "running loss : 2.032301\n",
      "running loss : 2.037447\n",
      "running loss : 2.041552\n",
      "running loss : 2.036559\n",
      "running loss : 2.035100\n",
      "running loss : 2.034095\n",
      "running loss : 2.026464\n",
      "running loss : 2.037927\n",
      "running loss : 2.032462\n",
      "running loss : 2.042334\n",
      "running loss : 2.039524\n",
      "running loss : 2.049814\n",
      "running loss : 2.043032\n",
      "running loss : 2.047073\n",
      "running loss : 2.037639\n",
      "running loss : 2.033763\n",
      "running loss : 2.030091\n",
      "running loss : 2.037534\n",
      "running loss : 2.042325\n",
      "running loss : 2.042337\n",
      "running loss : 2.049955\n",
      "running loss : 2.052371\n",
      "running loss : 2.053854\n",
      "running loss : 2.041990\n",
      "running loss : 2.037420\n",
      "running loss : 2.037975\n",
      "running loss : 2.050171\n",
      "running loss : 2.058714\n",
      "running loss : 2.028623\n",
      "running loss : 2.046903\n",
      "running loss : 2.032868\n",
      "running loss : 2.031606\n",
      "running loss : 2.029989\n",
      "running loss : 2.030135\n",
      "running loss : 2.033512\n",
      "running loss : 2.036442\n",
      "running loss : 2.026115\n",
      "running loss : 2.027276\n",
      "running loss : 2.030673\n",
      "running loss : 2.032272\n",
      "running loss : 2.028573\n",
      "running loss : 2.032263\n",
      "running loss : 2.034059\n",
      "running loss : 2.021933\n",
      "running loss : 2.026873\n",
      "running loss : 2.024387\n",
      "running loss : 2.033436\n",
      "running loss : 2.028150\n",
      "running loss : 2.024769\n",
      "running loss : 2.057923\n",
      "running loss : 2.031248\n",
      "running loss : 2.025454\n",
      "running loss : 2.060231\n",
      "running loss : 2.052368\n",
      "running loss : 2.037012\n",
      "running loss : 2.025586\n",
      "running loss : 2.033402\n",
      "running loss : 2.039318\n",
      "running loss : 2.032590\n",
      "running loss : 2.021345\n",
      "running loss : 2.022228\n",
      "running loss : 2.026171\n",
      "running loss : 2.025888\n",
      "running loss : 2.028004\n",
      "running loss : 2.033620\n",
      "running loss : 2.021808\n",
      "running loss : 2.027447\n",
      "running loss : 2.022453\n",
      "running loss : 2.030258\n",
      "running loss : 2.025695\n",
      "running loss : 2.041337\n",
      "running loss : 2.054816\n",
      "running loss : 2.024375\n",
      "running loss : 2.019187\n",
      "running loss : 2.020037\n",
      "running loss : 2.020685\n",
      "running loss : 2.027361\n",
      "running loss : 2.026820\n",
      "running loss : 2.024415\n",
      "running loss : 2.035515\n",
      "running loss : 2.021647\n",
      "running loss : 2.020163\n",
      "running loss : 2.036018\n",
      "running loss : 2.034026\n",
      "running loss : 2.037360\n",
      "running loss : 2.039416\n",
      "running loss : 2.036905\n",
      "running loss : 2.044727\n",
      "running loss : 2.049125\n",
      "running loss : 2.056278\n",
      "running loss : 2.047385\n",
      "running loss : 2.042869\n",
      "running loss : 2.039253\n",
      "running loss : 2.038979\n",
      "running loss : 2.040121\n",
      "running loss : 2.043484\n",
      "running loss : 2.037008\n",
      "running loss : 2.038799\n",
      "running loss : 2.046799\n",
      "running loss : 2.058705\n",
      "running loss : 2.037020\n",
      "running loss : 2.044067\n",
      "running loss : 2.035686\n",
      "running loss : 2.035532\n",
      "running loss : 2.039178\n",
      "running loss : 2.041743\n",
      "running loss : 2.047819\n",
      "running loss : 2.064070\n",
      "running loss : 2.057149\n",
      "running loss : 2.049099\n",
      "running loss : 2.055681\n",
      "running loss : 2.055333\n",
      "running loss : 2.044793\n",
      "running loss : 2.059785\n",
      "running loss : 2.053507\n",
      "running loss : 2.065309\n",
      "running loss : 2.056944\n",
      "running loss : 2.051191\n",
      "running loss : 2.057542\n",
      "running loss : 2.062025\n",
      "running loss : 2.056348\n",
      "running loss : 2.052319\n",
      "running loss : 2.049186\n",
      "running loss : 2.047029\n",
      "running loss : 2.044899\n",
      "running loss : 2.045665\n",
      "running loss : 2.053861\n",
      "running loss : 2.060851\n",
      "running loss : 2.059973\n",
      "running loss : 2.049666\n",
      "running loss : 2.052657\n",
      "running loss : 2.058727\n",
      "running loss : 2.054324\n",
      "running loss : 2.055076\n",
      "running loss : 2.059137\n",
      "running loss : 2.067535\n",
      "running loss : 2.064092\n",
      "running loss : 2.062941\n",
      "running loss : 2.056586\n",
      "running loss : 2.064021\n",
      "running loss : 2.060014\n",
      "running loss : 2.070922\n",
      "running loss : 2.058135\n",
      "running loss : 2.055243\n",
      "running loss : 2.054544\n",
      "running loss : 2.058570\n",
      "running loss : 2.075894\n",
      "running loss : 2.056664\n",
      "running loss : 2.071556\n",
      "running loss : 2.064787\n",
      "running loss : 2.059744\n",
      "running loss : 2.071336\n",
      "running loss : 2.083253\n",
      "running loss : 2.067875\n",
      "running loss : 2.062407\n",
      "running loss : 2.067887\n",
      "running loss : 2.060148\n",
      "running loss : 2.067053\n",
      "running loss : 2.061805\n",
      "running loss : 2.067444\n",
      "running loss : 2.062800\n",
      "running loss : 2.058454\n",
      "running loss : 2.067160\n",
      "running loss : 2.062105\n",
      "running loss : 2.062721\n",
      "running loss : 2.067133\n",
      "running loss : 2.057104\n",
      "running loss : 2.059441\n",
      "running loss : 2.059260\n",
      "running loss : 2.065699\n",
      "running loss : 2.053312\n",
      "running loss : 2.050597\n",
      "running loss : 2.052395\n",
      "running loss : 2.061710\n",
      "running loss : 2.054401\n",
      "running loss : 2.056955\n",
      "running loss : 2.060114\n",
      "running loss : 2.056541\n",
      "running loss : 2.070421\n",
      "running loss : 2.053219\n",
      "running loss : 2.057500\n",
      "running loss : 2.058476\n",
      "running loss : 2.079855\n"
     ]
    }
   ],
   "source": [
    "# transfert du model au gpu\n",
    "model.to(device)\n",
    "\n",
    "#define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# define loss function\n",
    "distortion = nn.MSELoss().cuda()\n",
    "        \n",
    "# incremental update of coefficients        \n",
    "\n",
    "# define beta\n",
    "beta = 0.05\n",
    "# define threshold and loss_init\n",
    "threshold = 0.95\n",
    "loss_init = float(\"Inf\")\n",
    "nb_ones = 1\n",
    "iteration = 0\n",
    "mask=(compute_mask(1, (96, 16, 16)).unsqueeze(0)).cuda()\n",
    "dim_latent = 16*16*96\n",
    "output_flag = False\n",
    "\n",
    "#Epochs\n",
    "n_epochs = 6150\n",
    "\n",
    "\n",
    "# Training the network\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \"\"\"\n",
    "    if epoch==100:\n",
    "        # define a new learning rate and so a new optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    \"\"\"\n",
    "        \n",
    "    #Training\n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        batch_images = data.to(device).float()\n",
    "        [decoded_images, x_quantized] = model(batch_images, mask, True)\n",
    "        optimizer.zero_grad()\n",
    "        loss_dist = distortion(decoded_images, batch_images)\n",
    "        loss_bit = mean_bit_per_px(x_quantized, model.phi, model.var)\n",
    "        #print(\" loss distortion : \", loss_dist)\n",
    "        #print(\"loss bit : \", loss_bit)\n",
    "        loss = beta * loss_dist + loss_bit\n",
    "        #print(loss)\n",
    "        \n",
    "        # check the value of the loss to see if another coefficient can be enabled\n",
    "        if (loss.item() < loss_init*threshold or iteration > 5):\n",
    "            if (nb_ones<dim_latent):\n",
    "                nb_ones +=1\n",
    "                loss_init = loss.item()\n",
    "                iteration = 0\n",
    "                mask = (compute_mask(nb_ones, tuple(x_quantized.size()[1:])).unsqueeze(0)).cuda()\n",
    "            else:\n",
    "                output_flag = True\n",
    "                break\n",
    "            \n",
    "        loss.backward()\n",
    "        #print(\"conv1.weights grad: \", params[0].grad)\n",
    "        #print(model.conv1.bias.grad)\n",
    "        #print(model.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        iteration += 1\n",
    "\n",
    "    if output_flag:\n",
    "        break\n",
    "    running_loss = running_loss/len(dataloader)\n",
    "    print('running loss : {:.06f}'.format(running_loss), )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "torch.save(model.state_dict(), './model_parameters/lossy_comp_params_with_rate_beta005_incremental_ng.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 3.608064\n",
      "running loss : 3.595169\n",
      "running loss : 3.577811\n",
      "running loss : 3.565715\n",
      "running loss : 3.556746\n",
      "running loss : 3.551123\n",
      "running loss : 3.508999\n",
      "running loss : 3.493525\n",
      "running loss : 3.477084\n",
      "running loss : 3.480756\n",
      "running loss : 3.484556\n",
      "running loss : 3.470062\n",
      "running loss : 3.494472\n",
      "running loss : 3.480626\n",
      "running loss : 3.473711\n",
      "running loss : 3.469631\n",
      "running loss : 3.474533\n",
      "running loss : 3.457910\n",
      "running loss : 3.457608\n",
      "running loss : 3.463701\n",
      "running loss : 3.462066\n",
      "running loss : 3.455566\n",
      "running loss : 3.454701\n",
      "running loss : 3.452302\n",
      "running loss : 3.461875\n",
      "running loss : 3.440914\n",
      "running loss : 3.449169\n",
      "running loss : 3.461837\n",
      "running loss : 3.453840\n",
      "running loss : 3.431719\n",
      "running loss : 3.450540\n",
      "running loss : 3.444341\n",
      "running loss : 3.436081\n",
      "running loss : 3.438335\n",
      "running loss : 3.434041\n",
      "running loss : 3.437564\n",
      "running loss : 3.452365\n",
      "running loss : 3.440963\n",
      "running loss : 3.444202\n",
      "running loss : 3.428230\n",
      "running loss : 3.436434\n",
      "running loss : 3.443303\n",
      "running loss : 3.439506\n",
      "running loss : 3.427543\n",
      "running loss : 3.431219\n",
      "running loss : 3.448644\n",
      "running loss : 3.422745\n",
      "running loss : 3.433221\n",
      "running loss : 3.450936\n",
      "running loss : 3.433569\n",
      "running loss : 3.442692\n",
      "running loss : 3.429689\n",
      "running loss : 3.430512\n",
      "running loss : 3.426101\n",
      "running loss : 3.430047\n",
      "running loss : 3.432502\n",
      "running loss : 3.439135\n",
      "running loss : 3.429702\n",
      "running loss : 3.420823\n",
      "running loss : 3.431744\n",
      "running loss : 3.428611\n",
      "running loss : 3.433411\n",
      "running loss : 3.418620\n",
      "running loss : 3.420307\n",
      "running loss : 3.428004\n",
      "running loss : 3.420471\n",
      "running loss : 3.434505\n",
      "running loss : 3.439297\n",
      "running loss : 3.418552\n",
      "running loss : 3.423885\n",
      "running loss : 3.438213\n",
      "running loss : 3.421547\n",
      "running loss : 3.447951\n",
      "running loss : 3.426076\n",
      "running loss : 3.431946\n",
      "running loss : 3.421086\n",
      "running loss : 3.422254\n",
      "running loss : 3.434877\n",
      "running loss : 3.446865\n",
      "running loss : 3.416438\n",
      "running loss : 3.411806\n",
      "running loss : 3.418630\n",
      "running loss : 3.406292\n",
      "running loss : 3.428759\n",
      "running loss : 3.416834\n",
      "running loss : 3.421250\n",
      "running loss : 3.428968\n",
      "running loss : 3.419444\n",
      "running loss : 3.411746\n",
      "running loss : 3.431971\n",
      "running loss : 3.417159\n",
      "running loss : 3.417692\n",
      "running loss : 3.423909\n",
      "running loss : 3.426233\n",
      "running loss : 3.416708\n",
      "running loss : 3.409153\n",
      "running loss : 3.410394\n",
      "running loss : 3.412747\n",
      "running loss : 3.416086\n",
      "running loss : 3.417805\n",
      "running loss : 3.416933\n",
      "running loss : 3.418952\n",
      "running loss : 3.411268\n",
      "running loss : 3.418695\n",
      "running loss : 3.415554\n",
      "running loss : 3.407512\n",
      "running loss : 3.418305\n",
      "running loss : 3.417855\n",
      "running loss : 3.415935\n",
      "running loss : 3.404594\n",
      "running loss : 3.407119\n",
      "running loss : 3.408349\n",
      "running loss : 3.416635\n",
      "running loss : 3.411231\n",
      "running loss : 3.417814\n",
      "running loss : 3.407900\n",
      "running loss : 3.417695\n",
      "running loss : 3.410966\n",
      "running loss : 3.411711\n",
      "running loss : 3.405085\n",
      "running loss : 3.405621\n",
      "running loss : 3.403342\n",
      "running loss : 3.418212\n",
      "running loss : 3.418930\n",
      "running loss : 3.400970\n",
      "running loss : 3.425234\n",
      "running loss : 3.405430\n",
      "running loss : 3.414903\n",
      "running loss : 3.397287\n",
      "running loss : 3.409523\n",
      "running loss : 3.405635\n",
      "running loss : 3.404655\n",
      "running loss : 3.423258\n",
      "running loss : 3.418636\n",
      "running loss : 3.403312\n",
      "running loss : 3.402433\n",
      "running loss : 3.408503\n",
      "running loss : 3.411906\n",
      "running loss : 3.396481\n",
      "running loss : 3.413033\n",
      "running loss : 3.401829\n",
      "running loss : 3.399232\n",
      "running loss : 3.408765\n",
      "running loss : 3.413618\n",
      "running loss : 3.401739\n",
      "running loss : 3.393259\n",
      "running loss : 3.409699\n",
      "running loss : 3.405459\n",
      "running loss : 3.402204\n",
      "running loss : 3.401693\n",
      "running loss : 3.415576\n",
      "running loss : 3.393906\n",
      "running loss : 3.410737\n",
      "running loss : 3.409878\n",
      "running loss : 3.406994\n",
      "running loss : 3.402496\n",
      "running loss : 3.398531\n",
      "running loss : 3.406441\n",
      "running loss : 3.405680\n",
      "running loss : 3.404914\n",
      "running loss : 3.403816\n",
      "running loss : 3.415388\n",
      "running loss : 3.404948\n",
      "running loss : 3.404524\n",
      "running loss : 3.408215\n",
      "running loss : 3.397031\n",
      "running loss : 3.391528\n",
      "running loss : 3.394352\n",
      "running loss : 3.388567\n",
      "running loss : 3.402069\n",
      "running loss : 3.407573\n",
      "running loss : 3.401749\n",
      "running loss : 3.397013\n",
      "running loss : 3.380713\n",
      "running loss : 3.416723\n",
      "running loss : 3.395859\n",
      "running loss : 3.401124\n",
      "running loss : 3.395975\n",
      "running loss : 3.401524\n",
      "running loss : 3.397739\n",
      "running loss : 3.398284\n",
      "running loss : 3.397540\n",
      "running loss : 3.390580\n",
      "running loss : 3.395998\n",
      "running loss : 3.406830\n",
      "running loss : 3.400811\n",
      "running loss : 3.399028\n",
      "running loss : 3.391226\n",
      "running loss : 3.391155\n",
      "running loss : 3.403034\n",
      "running loss : 3.386472\n",
      "running loss : 3.391889\n",
      "running loss : 3.410040\n",
      "running loss : 3.396352\n",
      "running loss : 3.393411\n",
      "running loss : 3.392596\n",
      "running loss : 3.398096\n",
      "running loss : 3.419137\n",
      "running loss : 3.386801\n",
      "running loss : 3.393241\n",
      "running loss : 3.405118\n",
      "running loss : 3.401632\n",
      "running loss : 3.391891\n",
      "running loss : 3.387445\n",
      "running loss : 3.391386\n",
      "running loss : 3.387829\n",
      "running loss : 3.392365\n",
      "running loss : 3.400446\n",
      "running loss : 3.372927\n",
      "running loss : 3.404625\n",
      "running loss : 3.388007\n",
      "running loss : 3.395960\n",
      "running loss : 3.412260\n",
      "running loss : 3.404648\n",
      "running loss : 3.398713\n",
      "running loss : 3.397545\n",
      "running loss : 3.384526\n",
      "running loss : 3.385824\n",
      "running loss : 3.383352\n",
      "running loss : 3.393349\n",
      "running loss : 3.387968\n",
      "running loss : 3.382640\n",
      "running loss : 3.380239\n",
      "running loss : 3.384858\n",
      "running loss : 3.374717\n",
      "running loss : 3.409348\n",
      "running loss : 3.401197\n",
      "running loss : 3.389739\n",
      "running loss : 3.388080\n",
      "running loss : 3.392952\n",
      "running loss : 3.398019\n",
      "running loss : 3.404827\n",
      "running loss : 3.382396\n",
      "running loss : 3.380256\n",
      "running loss : 3.378441\n",
      "running loss : 3.373515\n",
      "running loss : 3.379723\n",
      "running loss : 3.386646\n",
      "running loss : 3.381797\n",
      "running loss : 3.386999\n",
      "running loss : 3.384829\n",
      "running loss : 3.369290\n",
      "running loss : 3.385859\n",
      "running loss : 3.388848\n",
      "running loss : 3.379311\n",
      "running loss : 3.373440\n",
      "running loss : 3.392347\n",
      "running loss : 3.382227\n",
      "running loss : 3.367000\n",
      "running loss : 3.378753\n",
      "running loss : 3.377418\n",
      "running loss : 3.396743\n",
      "running loss : 3.378321\n",
      "running loss : 3.384744\n",
      "running loss : 3.383695\n",
      "running loss : 3.388330\n",
      "running loss : 3.387338\n",
      "running loss : 3.391584\n",
      "running loss : 3.387342\n",
      "running loss : 3.375059\n",
      "running loss : 3.383311\n",
      "running loss : 3.387176\n",
      "running loss : 3.387320\n",
      "running loss : 3.379785\n",
      "running loss : 3.388733\n",
      "running loss : 3.375195\n",
      "running loss : 3.377278\n",
      "running loss : 3.381037\n",
      "running loss : 3.378940\n",
      "running loss : 3.377081\n",
      "running loss : 3.379055\n",
      "running loss : 3.384051\n",
      "running loss : 3.372547\n",
      "running loss : 3.359944\n",
      "running loss : 3.389396\n",
      "running loss : 3.377261\n",
      "running loss : 3.375371\n",
      "running loss : 3.374853\n",
      "running loss : 3.375038\n",
      "running loss : 3.371395\n",
      "running loss : 3.380230\n",
      "running loss : 3.374034\n",
      "running loss : 3.381019\n",
      "running loss : 3.379792\n",
      "running loss : 3.379630\n",
      "running loss : 3.375633\n",
      "running loss : 3.380527\n",
      "running loss : 3.374819\n",
      "running loss : 3.374065\n",
      "running loss : 3.376456\n",
      "running loss : 3.372698\n",
      "running loss : 3.376132\n",
      "running loss : 3.382859\n",
      "running loss : 3.361300\n",
      "running loss : 3.369921\n",
      "running loss : 3.382626\n",
      "running loss : 3.365912\n",
      "running loss : 3.374336\n",
      "running loss : 3.370419\n",
      "running loss : 3.375273\n",
      "running loss : 3.381060\n",
      "running loss : 3.368045\n",
      "running loss : 3.384040\n",
      "running loss : 3.379451\n",
      "running loss : 3.377281\n",
      "running loss : 3.376848\n",
      "running loss : 3.379195\n",
      "running loss : 3.377004\n",
      "running loss : 3.366520\n",
      "running loss : 3.369531\n",
      "running loss : 3.359590\n",
      "running loss : 3.379268\n",
      "running loss : 3.370147\n",
      "running loss : 3.380034\n",
      "running loss : 3.371945\n",
      "running loss : 3.378165\n",
      "running loss : 3.371639\n",
      "running loss : 3.365722\n",
      "running loss : 3.378202\n",
      "running loss : 3.383245\n",
      "running loss : 3.372720\n",
      "running loss : 3.357288\n",
      "running loss : 3.363374\n",
      "running loss : 3.380017\n",
      "running loss : 3.369098\n",
      "running loss : 3.370510\n",
      "running loss : 3.373468\n",
      "running loss : 3.365971\n",
      "running loss : 3.371524\n",
      "running loss : 3.371745\n",
      "running loss : 3.368102\n",
      "running loss : 3.368026\n",
      "running loss : 3.382858\n",
      "running loss : 3.381158\n",
      "running loss : 3.372145\n",
      "running loss : 3.366211\n",
      "running loss : 3.379800\n",
      "running loss : 3.365970\n",
      "running loss : 3.388563\n",
      "running loss : 3.364501\n",
      "running loss : 3.361850\n",
      "running loss : 3.367398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 3.370314\n",
      "running loss : 3.377068\n",
      "running loss : 3.380413\n",
      "running loss : 3.369731\n",
      "running loss : 3.372108\n",
      "running loss : 3.373563\n",
      "running loss : 3.365202\n",
      "running loss : 3.375456\n",
      "running loss : 3.366879\n",
      "running loss : 3.364543\n",
      "running loss : 3.367663\n",
      "running loss : 3.371529\n",
      "running loss : 3.359032\n",
      "running loss : 3.364099\n",
      "running loss : 3.354579\n",
      "running loss : 3.367204\n",
      "running loss : 3.370713\n",
      "running loss : 3.366639\n",
      "running loss : 3.360884\n",
      "running loss : 3.353266\n",
      "running loss : 3.368702\n",
      "running loss : 3.359209\n",
      "running loss : 3.361315\n",
      "running loss : 3.372081\n",
      "running loss : 3.363859\n",
      "running loss : 3.356524\n",
      "running loss : 3.360332\n",
      "running loss : 3.353770\n",
      "running loss : 3.355852\n",
      "running loss : 3.365560\n",
      "running loss : 3.375980\n",
      "running loss : 3.351310\n",
      "running loss : 3.372552\n",
      "running loss : 3.356415\n",
      "running loss : 3.355415\n",
      "running loss : 3.359442\n",
      "running loss : 3.354993\n",
      "running loss : 3.353920\n",
      "running loss : 3.357007\n",
      "running loss : 3.347224\n",
      "running loss : 3.360047\n",
      "running loss : 3.356805\n",
      "running loss : 3.377442\n",
      "running loss : 3.360175\n",
      "running loss : 3.349696\n",
      "running loss : 3.370999\n",
      "running loss : 3.359068\n",
      "running loss : 3.362040\n",
      "running loss : 3.358622\n",
      "running loss : 3.352350\n",
      "running loss : 3.358476\n",
      "running loss : 3.346589\n",
      "running loss : 3.363932\n",
      "running loss : 3.356358\n",
      "running loss : 3.360231\n",
      "running loss : 3.361587\n",
      "running loss : 3.361075\n",
      "running loss : 3.363794\n",
      "running loss : 3.346298\n",
      "running loss : 3.363001\n",
      "running loss : 3.358429\n",
      "running loss : 3.357310\n",
      "running loss : 3.356154\n",
      "running loss : 3.360374\n",
      "running loss : 3.370111\n",
      "running loss : 3.365619\n",
      "running loss : 3.345095\n",
      "running loss : 3.357239\n",
      "running loss : 3.355625\n",
      "running loss : 3.357598\n",
      "running loss : 3.357125\n",
      "running loss : 3.355613\n",
      "running loss : 3.355986\n",
      "running loss : 3.368297\n",
      "running loss : 3.357122\n",
      "running loss : 3.355062\n",
      "running loss : 3.353528\n",
      "running loss : 3.369331\n",
      "running loss : 3.354843\n",
      "running loss : 3.371120\n",
      "running loss : 3.358374\n",
      "running loss : 3.369029\n",
      "running loss : 3.351763\n",
      "running loss : 3.356055\n",
      "running loss : 3.356574\n",
      "running loss : 3.353526\n",
      "running loss : 3.346547\n",
      "running loss : 3.355653\n",
      "running loss : 3.344817\n",
      "running loss : 3.366189\n",
      "running loss : 3.357121\n",
      "running loss : 3.355565\n",
      "running loss : 3.360159\n",
      "running loss : 3.346670\n",
      "running loss : 3.349266\n",
      "running loss : 3.361551\n",
      "running loss : 3.345708\n",
      "running loss : 3.346406\n",
      "running loss : 3.364660\n",
      "running loss : 3.348421\n",
      "running loss : 3.366565\n",
      "running loss : 3.357172\n",
      "running loss : 3.360273\n",
      "running loss : 3.361555\n",
      "running loss : 3.360843\n",
      "running loss : 3.364662\n",
      "running loss : 3.356550\n",
      "running loss : 3.346063\n",
      "running loss : 3.359142\n",
      "running loss : 3.352849\n",
      "running loss : 3.369623\n",
      "running loss : 3.360721\n",
      "running loss : 3.351882\n",
      "running loss : 3.359600\n",
      "running loss : 3.355730\n",
      "running loss : 3.353931\n",
      "running loss : 3.343998\n",
      "running loss : 3.359867\n",
      "running loss : 3.354931\n",
      "running loss : 3.346388\n",
      "running loss : 3.347316\n",
      "running loss : 3.372011\n",
      "running loss : 3.353952\n",
      "running loss : 3.336895\n",
      "running loss : 3.341002\n",
      "running loss : 3.344184\n",
      "running loss : 3.348712\n",
      "running loss : 3.357724\n",
      "running loss : 3.342228\n",
      "running loss : 3.339523\n",
      "running loss : 3.336710\n",
      "running loss : 3.359275\n",
      "running loss : 3.352273\n",
      "running loss : 3.355335\n",
      "running loss : 3.346686\n",
      "running loss : 3.351825\n",
      "running loss : 3.343329\n",
      "running loss : 3.353132\n",
      "running loss : 3.348568\n",
      "running loss : 3.349761\n",
      "running loss : 3.346203\n",
      "running loss : 3.345687\n",
      "running loss : 3.346822\n",
      "running loss : 3.359846\n",
      "running loss : 3.344461\n",
      "running loss : 3.347605\n",
      "running loss : 3.360306\n",
      "running loss : 3.349484\n",
      "running loss : 3.361984\n",
      "running loss : 3.345488\n",
      "running loss : 3.352357\n",
      "running loss : 3.350787\n",
      "running loss : 3.363186\n",
      "running loss : 3.358625\n",
      "running loss : 3.349598\n",
      "running loss : 3.350769\n",
      "running loss : 3.356160\n",
      "running loss : 3.355965\n",
      "running loss : 3.347878\n",
      "running loss : 3.362272\n",
      "running loss : 3.334891\n",
      "running loss : 3.350863\n",
      "running loss : 3.352918\n",
      "running loss : 3.351285\n",
      "running loss : 3.340953\n",
      "running loss : 3.351766\n",
      "running loss : 3.346930\n",
      "running loss : 3.345097\n",
      "running loss : 3.359069\n",
      "running loss : 3.344168\n",
      "running loss : 3.351817\n",
      "running loss : 3.335797\n",
      "running loss : 3.336338\n",
      "running loss : 3.369614\n",
      "running loss : 3.348467\n",
      "running loss : 3.338204\n",
      "running loss : 3.348724\n",
      "running loss : 3.343201\n",
      "running loss : 3.337590\n",
      "running loss : 3.345075\n",
      "running loss : 3.343137\n",
      "running loss : 3.342944\n",
      "running loss : 3.333315\n",
      "running loss : 3.359916\n",
      "running loss : 3.343439\n",
      "running loss : 3.348096\n",
      "running loss : 3.348777\n",
      "running loss : 3.342959\n",
      "running loss : 3.355742\n",
      "running loss : 3.344180\n",
      "running loss : 3.339853\n",
      "running loss : 3.346722\n",
      "running loss : 3.344836\n",
      "running loss : 3.338519\n",
      "running loss : 3.354768\n",
      "running loss : 3.354207\n",
      "running loss : 3.354161\n",
      "running loss : 3.350398\n",
      "running loss : 3.335574\n",
      "running loss : 3.339052\n",
      "running loss : 3.325654\n",
      "running loss : 3.346711\n",
      "running loss : 3.345718\n",
      "running loss : 3.342996\n",
      "running loss : 3.345942\n",
      "running loss : 3.340115\n",
      "running loss : 3.351426\n",
      "running loss : 3.335214\n",
      "running loss : 3.348179\n",
      "running loss : 3.339886\n",
      "running loss : 3.341955\n",
      "running loss : 3.343468\n",
      "running loss : 3.342511\n",
      "running loss : 3.339258\n",
      "running loss : 3.352079\n",
      "running loss : 3.351474\n",
      "running loss : 3.349672\n",
      "running loss : 3.326735\n",
      "running loss : 3.331779\n",
      "running loss : 3.332662\n",
      "running loss : 3.344620\n",
      "running loss : 3.342527\n",
      "running loss : 3.338769\n",
      "running loss : 3.329740\n",
      "running loss : 3.334696\n",
      "running loss : 3.349396\n",
      "running loss : 3.331655\n",
      "running loss : 3.343893\n",
      "running loss : 3.334330\n",
      "running loss : 3.341412\n",
      "running loss : 3.341261\n",
      "running loss : 3.342445\n",
      "running loss : 3.355054\n",
      "running loss : 3.342108\n",
      "running loss : 3.342142\n",
      "running loss : 3.333979\n",
      "running loss : 3.329740\n",
      "running loss : 3.330187\n",
      "running loss : 3.320707\n",
      "running loss : 3.337103\n",
      "running loss : 3.341556\n",
      "running loss : 3.334582\n",
      "running loss : 3.343184\n",
      "running loss : 3.342706\n",
      "running loss : 3.340070\n",
      "running loss : 3.344993\n",
      "running loss : 3.349691\n",
      "running loss : 3.340178\n",
      "running loss : 3.336386\n",
      "running loss : 3.342811\n",
      "running loss : 3.344449\n",
      "running loss : 3.357886\n",
      "running loss : 3.348683\n",
      "running loss : 3.346992\n",
      "running loss : 3.331960\n",
      "running loss : 3.348751\n",
      "running loss : 3.343655\n",
      "running loss : 3.350069\n"
     ]
    }
   ],
   "source": [
    "model = LossyCompAutoencoder()\n",
    "model.load_state_dict(torch.load('./model_parameters/mean_bit_ppx/lossy_comp_params_with_rate_beta005_incremental.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# transfert du model au gpu\n",
    "model.to(device)\n",
    "\n",
    "# general update of coefficients    \n",
    "    #define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    # define loss function\n",
    "distortion = nn.MSELoss().cuda()\n",
    "    #Epochs\n",
    "n_epochs = 600\n",
    "beta = 0.05\n",
    "\n",
    "    # Training the network\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "          \n",
    "    #Training\n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        batch_images = data.to(device).float()\n",
    "        [decoded_images, x_quantized] = model(batch_images, 1, True)\n",
    "        optimizer.zero_grad()\n",
    "        loss_dist = distortion(decoded_images, batch_images)\n",
    "        loss_bit = mean_bit_per_px(x_quantized, model.phi, model.var)\n",
    "        loss = beta * loss_dist + loss_bit\n",
    "        #print(loss)\n",
    "            \n",
    "        loss.backward()\n",
    "        #print(\"conv1.weights grad: \", params[0].grad)\n",
    "        #print(model.conv1.bias.grad)\n",
    "        #print(model.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss = running_loss/len(dataloader)\n",
    "    print('running loss : {:.06f}'.format(running_loss), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "torch.save(model.state_dict(), './model_parameters/lossy_comp_params_with_rate_beta2_incremental_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-2faacbdd681e>:32: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1, 1, sharey=True, tight_layout=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min vec latent :  tensor(-4., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-4., device='cuda:0')\n",
      "max vec latent :  tensor(6., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-6., device='cuda:0')\n",
      "max vec latent :  tensor(9., device='cuda:0')\n",
      "min vec latent :  tensor(-6., device='cuda:0')\n",
      "max vec latent :  tensor(6., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-6., device='cuda:0')\n",
      "max vec latent :  tensor(9., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(8., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-6., device='cuda:0')\n",
      "max vec latent :  tensor(5., device='cuda:0')\n",
      "min vec latent :  tensor(-6., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(8., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(8., device='cuda:0')\n",
      "min vec latent :  tensor(-4., device='cuda:0')\n",
      "max vec latent :  tensor(6., device='cuda:0')\n",
      "min vec latent :  tensor(-4., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-4., device='cuda:0')\n",
      "max vec latent :  tensor(9., device='cuda:0')\n",
      "min vec latent :  tensor(-6., device='cuda:0')\n",
      "max vec latent :  tensor(6., device='cuda:0')\n",
      "min vec latent :  tensor(-8., device='cuda:0')\n",
      "max vec latent :  tensor(5., device='cuda:0')\n",
      "min vec latent :  tensor(-6., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n",
      "min vec latent :  tensor(-5., device='cuda:0')\n",
      "max vec latent :  tensor(7., device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATb0lEQVR4nO3da4xd13ne8f8T0pYVp4QliFQJDlHKAHOR1PiiCctUaOCEbsTGhqkvAhjAEZEKICqorlOkSEkHRdAPBNQL0lhoJYCwFVGwYoFV7IpwKtcsEzcooEge2XJoilZFWC45ISNOHLhRWkAG5bcfzpJzyDkzcyiTc9aM/j/gYO/9nrX2vEca8pl9mc1UFZIk9eZHJt2AJEmjGFCSpC4ZUJKkLhlQkqQuGVCSpC6tnXQDS7nhhhtqy5Ytk25DknSVPPfcc39RVesvrXcfUFu2bGFmZmbSbUiSrpIk/3tU3VN8kqQuGVCSpC4ZUJKkLhlQkqQuGVCSpC4ZUJKkLhlQkqQuGVCSpC4ZUJKkLhlQkqQudf+oI+lK2LLvD674Pr99/4eu+D4l/Y2xjqCSvCvJE0m+meRkkp9Ncn2So0leasvrhsbvT3IqyYtJ7hiq35bkeHvvgSS5Gh9KkrTyjXuK75PAF6vqJ4H3ACeBfcCxqtoKHGvbJLkZ2A3cAuwEHkyypu3nIWAvsLW9dl6hzyFJWmWWDKgk64CfAz4NUFXfq6rvAruAQ23YIeDOtr4LeLyqXquql4FTwLYkG4F1VfV0VRXw6NAcSZIuMs4R1LuBOeB3k3wtyaeSvBO4sarOAbTlhjZ+E3BmaP5sq21q65fW50myN8lMkpm5ubnL+kCSpNVhnIBaC7wfeKiq3gf8X9rpvAWMuq5Ui9TnF6sOVtV0VU2vXz/v37CSJL0FjBNQs8BsVT3Ttp9gEFivtNN2tOX5ofGbh+ZPAWdbfWpEXZKkeZYMqKr6c+BMkp9opR3AC8ARYE+r7QGebOtHgN1JrklyE4ObIZ5tpwFfTbK93b1399AcSZIuMu7vQX0MeCzJ24FvAb/KINwOJ7kHOA3cBVBVJ5IcZhBiF4D7qur1tp97gUeAa4Gn2kuSpHnGCqiqeh6YHvHWjgXGHwAOjKjPALdeToOSpLcmH3UkSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnq0lgBleTbSY4neT7JTKtdn+Rokpfa8rqh8fuTnEryYpI7huq3tf2cSvJAklz5jyRJWg0u5wjq56vqvVU13bb3AceqaitwrG2T5GZgN3ALsBN4MMmaNuchYC+wtb12/vAfQZK0Gv0wp/h2AYfa+iHgzqH641X1WlW9DJwCtiXZCKyrqqerqoBHh+ZIknSRcQOqgC8leS7J3la7sarOAbTlhlbfBJwZmjvbapva+qX1eZLsTTKTZGZubm7MFiVJq8naMcfdXlVnk2wAjib55iJjR11XqkXq84tVB4GDANPT0yPHSJJWt7GOoKrqbFueBz4PbANeaaftaMvzbfgssHlo+hRwttWnRtQlSZpnyYBK8s4kf+uNdeAXgW8AR4A9bdge4Mm2fgTYneSaJDcxuBni2XYa8NUk29vde3cPzZEk6SLjnOK7Efh8uyN8LfB7VfXFJF8BDie5BzgN3AVQVSeSHAZeAC4A91XV621f9wKPANcCT7WXJEnzLBlQVfUt4D0j6t8Bdiww5wBwYER9Brj18tuUJL3V+CQJSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSl8YOqCRrknwtyRfa9vVJjiZ5qS2vGxq7P8mpJC8muWOofluS4+29B5Lkyn4cSdJqcTlHUB8HTg5t7wOOVdVW4FjbJsnNwG7gFmAn8GCSNW3OQ8BeYGt77fyhupckrVpjBVSSKeBDwKeGyruAQ239EHDnUP3xqnqtql4GTgHbkmwE1lXV01VVwKNDcyRJusi4R1C/A/wG8P2h2o1VdQ6gLTe0+ibgzNC42Vbb1NYvrc+TZG+SmSQzc3NzY7YoSVpNlgyoJB8GzlfVc2Puc9R1pVqkPr9YdbCqpqtqev369WN+WUnSarJ2jDG3Ax9J8kvAO4B1ST4DvJJkY1Wda6fvzrfxs8DmoflTwNlWnxpRlyRpniWPoKpqf1VNVdUWBjc//GFVfRQ4Auxpw/YAT7b1I8DuJNckuYnBzRDPttOArybZ3u7eu3tojiRJFxnnCGoh9wOHk9wDnAbuAqiqE0kOAy8AF4D7qur1Nude4BHgWuCp9pIkaZ7LCqiq+jLw5bb+HWDHAuMOAAdG1GeAWy+3SUnSW49PkpAkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHXJgJIkdcmAkiR1yYCSJHVpyYBK8o4kzyb5epITSf51q1+f5GiSl9ryuqE5+5OcSvJikjuG6rclOd7eeyBJrs7HkiStdOMcQb0G/EJVvQd4L7AzyXZgH3CsqrYCx9o2SW4GdgO3ADuBB5Osaft6CNgLbG2vnVfws0iSVpElA6oG/rptvq29CtgFHGr1Q8CdbX0X8HhVvVZVLwOngG1JNgLrqurpqirg0aE5kiRdZKxrUEnWJHkeOA8crapngBur6hxAW25owzcBZ4amz7baprZ+aX3U19ubZCbJzNzc3OV8HknSKjFWQFXV61X1XmCKwdHQrYsMH3VdqRapj/p6B6tquqqm169fP06LkqRV5rLu4quq7wJfZnDt6JV22o62PN+GzQKbh6ZNAWdbfWpEXZKkeca5i299kne19WuBDwLfBI4Ae9qwPcCTbf0IsDvJNUluYnAzxLPtNOCrSba3u/fuHpojSdJF1o4xZiNwqN2J9yPA4ar6QpKngcNJ7gFOA3cBVNWJJIeBF4ALwH1V9Xrb173AI8C1wFPtJUnSPEsGVFX9KfC+EfXvADsWmHMAODCiPgMsdv1KkiTAJ0lIkjplQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6ZEBJkrpkQEmSumRASZK6tGRAJdmc5I+SnExyIsnHW/36JEeTvNSW1w3N2Z/kVJIXk9wxVL8tyfH23gNJcnU+liRppRvnCOoC8OtV9VPAduC+JDcD+4BjVbUVONa2ae/tBm4BdgIPJlnT9vUQsBfY2l47r+BnkSStIksGVFWdq6qvtvVXgZPAJmAXcKgNOwTc2dZ3AY9X1WtV9TJwCtiWZCOwrqqerqoCHh2aI0nSRS7rGlSSLcD7gGeAG6vqHAxCDNjQhm0CzgxNm221TW390vqor7M3yUySmbm5uctpUZK0SowdUEl+DPh94Neq6q8WGzqiVovU5xerDlbVdFVNr1+/ftwWJUmryFgBleRtDMLpsar6XCu/0k7b0ZbnW30W2Dw0fQo42+pTI+qSJM0zzl18AT4NnKyq3x566wiwp63vAZ4cqu9Ock2SmxjcDPFsOw34apLtbZ93D82RJOkia8cYczvwK8DxJM+32ieA+4HDSe4BTgN3AVTViSSHgRcY3AF4X1W93ubdCzwCXAs81V6SJM2zZEBV1f9k9PUjgB0LzDkAHBhRnwFuvZwGJUlvTT5JQpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1CUDSpLUJQNKktQlA0qS1KUlAyrJw0nOJ/nGUO36JEeTvNSW1w29tz/JqSQvJrljqH5bkuPtvQeS5Mp/HEnSajHOEdQjwM5LavuAY1W1FTjWtklyM7AbuKXNeTDJmjbnIWAvsLW9Lt2nJEk/sGRAVdUfA395SXkXcKitHwLuHKo/XlWvVdXLwClgW5KNwLqqerqqCnh0aI4kSfO82WtQN1bVOYC23NDqm4AzQ+NmW21TW7+0PlKSvUlmkszMzc29yRYlSSvZlb5JYtR1pVqkPlJVHayq6aqaXr9+/RVrTpK0crzZgHqlnbajLc+3+iyweWjcFHC21adG1CVJGunNBtQRYE9b3wM8OVTfneSaJDcxuBni2XYa8NUk29vde3cPzZEkaZ61Sw1I8lngA8ANSWaB3wLuBw4nuQc4DdwFUFUnkhwGXgAuAPdV1ettV/cyuCPwWuCp9pIkaaQlA6qqfnmBt3YsMP4AcGBEfQa49bK6kyS9ZfkkCUlSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpcMKElSlwwoSVKXDChJUpeWPaCS7EzyYpJTSfYt99eXJK0Ma5fziyVZA/wn4B8Cs8BXkhypqheWsw/1a8u+P5h0C5I6sawBBWwDTlXVtwCSPA7sAgworThXK0y/ff+Hrsp+pZVmuQNqE3BmaHsW+HuXDkqyF9jbNv86yYvL0NsbbgD+Yhm/3g9jpfS6UvqEDnrNvxl76MR7vQz2enWsll7/zqjicgdURtRqXqHqIHDw6rczX5KZqpqexNe+XCul15XSJ9jr1WKvV8dq73W5b5KYBTYPbU8BZ5e5B0nSCrDcAfUVYGuSm5K8HdgNHFnmHiRJK8CynuKrqgtJ/inw34A1wMNVdWI5exjDRE4tvkkrpdeV0ifY69Vir1fHqu41VfMuAUmSNHE+SUKS1CUDSpLUJQNqhCQfa49jOpHk3066n6Uk+RdJKskNk+5lIUn+XZJvJvnTJJ9P8q5J93SplfIYriSbk/xRkpPte/Tjk+5pKUnWJPlaki9MupfFJHlXkifa9+rJJD876Z4WkuSft///30jy2STvmHRPb0jycJLzSb4xVLs+ydEkL7XldUvtx4C6RJKfZ/B0i5+uqluAfz/hlhaVZDODR0ednnQvSzgK3FpVPw38L2D/hPu5yNBjuP4RcDPwy0lunmxXC7oA/HpV/RSwHbiv417f8HHg5KSbGMMngS9W1U8C76HTnpNsAv4ZMF1VtzK46Wz3ZLu6yCPAzktq+4BjVbUVONa2F2VAzXcvcH9VvQZQVecn3M9S/gPwG4z4heeeVNWXqupC2/wTBr8D15MfPIarqr4HvPEYru5U1bmq+mpbf5XBX6KbJtvVwpJMAR8CPjXpXhaTZB3wc8CnAarqe1X13cl2tai1wLVJ1gI/Ske/U1pVfwz85SXlXcChtn4IuHOp/RhQ8/048A+SPJPkfyT5mUk3tJAkHwH+rKq+PuleLtM/Bp6adBOXGPUYrm7/0n9Dki3A+4BnJtvJon6HwQ9R3590I0t4NzAH/G47HfmpJO+cdFOjVNWfMTi7cxo4B/yfqvrSZLta0o1VdQ4GP2QBG5aasNyPOupCkv8O/O0Rb/0mg/8m1zE4dfIzwOEk764J3Y+/RK+fAH5xeTta2GK9VtWTbcxvMjhF9dhy9jaGsR7D1ZMkPwb8PvBrVfVXk+5nlCQfBs5X1XNJPjDpfpawFng/8LGqeibJJxmchvpXk21rvnb9ZhdwE/Bd4D8n+WhVfWaynV1Zb8mAqqoPLvReknuBz7VAejbJ9xk85HBuufobtlCvSf4ug2/OryeBwSmzrybZVlV/vowt/sBi/10BkuwBPgzsmFTgL2JFPYYrydsYhNNjVfW5SfeziNuBjyT5JeAdwLokn6mqj064r1FmgdmqeuNo9AnGuE4yIR8EXq6qOYAknwP+PtBzQL2SZGNVnUuyEVjy8omn+Ob7L8AvACT5ceDtdPi04Ko6XlUbqmpLVW1h8Ifr/ZMKp6Uk2Qn8S+AjVfX/Jt3PCCvmMVwZ/ETyaeBkVf32pPtZTFXtr6qp9j26G/jDTsOJ9mfnTJKfaKUd9PtPAZ0Gtif50fb9sINOb+gYcgTY09b3AE8uNeEteQS1hIeBh9vtkd8D9nT40/5K9B+Ba4Cj7YjvT6rqn0y2pb+xQh7D9YbbgV8Bjid5vtU+UVX/dYI9rRYfAx5rP6R8C/jVCfczUjsF+QTwVQanzL9GR489SvJZ4APADUlmgd8C7mdwyeQeBgF715L78e9eSVKPPMUnSeqSASVJ6pIBJUnqkgElSeqSASVJ6pIBJUnqkgElSerS/wdDf0AgF7kWwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x0000029EAD960670> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             display(\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2119\u001b[1;33m                 result = print_method(\n\u001b[0m\u001b[0;32m   2120\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2121\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m         }\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpil_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[0;32m    392\u001b[0m               else nullcontext()):\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   1736\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[0;32m   1737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2630\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1228\u001b[1;33m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0m\u001b[0;32m   1229\u001b[0m                                                                 renderer)\n\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m         \u001b[1;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[0;32m   1174\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    903\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m         \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;31m# get the rotation matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate_deg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;31m# now offset the individual text lines within the box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, matrix, **kwargs)\u001b[0m\n\u001b[0;32m   1842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m             \u001b[1;31m# A bit faster than np.identity(3).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIdentityTransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test set \n",
    "\n",
    "model = LossyCompAutoencoder()\n",
    "model.load_state_dict(torch.load('./model_parameters/mean_bit_ppx/lossy_comp_params_with_rate_beta00005_incremental.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "#test_dataset = ImageDataset(root_dir='./data/kodac/', transform=transforms.Compose([RandomCrop(128), ToTensor()]))\n",
    "test_dataset = ImageDataset(root_dir='./data/kodac/', transform=ToTensor())\n",
    "#fig, axes = plt.subplots(nrows=4, ncols=6, sharex=True, sharey=True, figsize=(8,8))\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        if test_image.size(2)<test_image.size(3):\n",
    "            test_image = test_image.permute(0, 1, 3, 2)\n",
    "        \n",
    "        [reconstructed_image, vec_latent ]= model(test_image, 1, True)\n",
    "        print(\"min vec latent : \", torch.min(vec_latent))\n",
    "        print(\"max vec latent : \", torch.max(vec_latent)) \n",
    "        \"\"\"\n",
    "        ax = fig.add_subplot(4, 6, i+1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.squeeze(reconstructed_image.int().cpu()).permute(1, 2, 0))\n",
    "        \"\"\"\n",
    "\n",
    "        # We can set the number of bins with the `bins` kwarg\n",
    "        bins_list = [-6.5, -5.5, -4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "        for k in range(96):\n",
    "            # plot histograms\n",
    "            fig, ax = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "            ax.hist((vec_latent[:, k, :, :]).view(-1).cpu(), bins=bins_list)\n",
    "            plt.savefig(\"D:\\\\autoencoder_data\\\\histograms\\\\rgb\\\\\" + \"img\" + str(i)+ \"hist\" + str(k) + \".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# save results\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        reconstructed_image = np.squeeze(model(test_image).cpu())\n",
    "        print(reconstructed_image.type())\n",
    "        save_image(reconstructed_image, \".\\\\reconstructed_data\\\\kodac\\\\loss_distortion_and_mean_bit_ppx\\\\beta_01_incremental\\\\\" + \"img\" + str(i)+\".png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy :  tensor(0.336470, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.504704, device='cuda:0')\n",
      "psnr :  tensor(25.554382)\n",
      "entropy :  tensor(0.238760, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.358140, device='cuda:0')\n",
      "psnr :  tensor(29.492023)\n",
      "entropy :  tensor(0.465061, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.697591, device='cuda:0')\n",
      "psnr :  tensor(28.188541)\n",
      "entropy :  tensor(0.274725, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.412088, device='cuda:0')\n",
      "psnr :  tensor(28.214451)\n",
      "entropy :  tensor(0.383294, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.574942, device='cuda:0')\n",
      "psnr :  tensor(25.345343)\n",
      "entropy :  tensor(0.322674, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.484011, device='cuda:0')\n",
      "psnr :  tensor(26.271297)\n",
      "entropy :  tensor(0.272499, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.408748, device='cuda:0')\n",
      "psnr :  tensor(28.703783)\n",
      "entropy :  tensor(0.411846, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.617769, device='cuda:0')\n",
      "psnr :  tensor(24.610319)\n",
      "entropy :  tensor(0.256009, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.384014, device='cuda:0')\n",
      "psnr :  tensor(29.017010)\n",
      "entropy :  tensor(0.271361, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.407042, device='cuda:0')\n",
      "psnr :  tensor(29.554737)\n",
      "entropy :  tensor(0.269653, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.404480, device='cuda:0')\n",
      "psnr :  tensor(27.420452)\n",
      "entropy :  tensor(0.271458, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.407188, device='cuda:0')\n",
      "psnr :  tensor(29.574333)\n",
      "entropy :  tensor(0.393803, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.590705, device='cuda:0')\n",
      "psnr :  tensor(23.470707)\n",
      "entropy :  tensor(0.315640, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.473460, device='cuda:0')\n",
      "psnr :  tensor(26.455442)\n",
      "entropy :  tensor(0.312634, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.468951, device='cuda:0')\n",
      "psnr :  tensor(27.353783)\n",
      "entropy :  tensor(0.339333, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.509000, device='cuda:0')\n",
      "psnr :  tensor(28.963634)\n",
      "entropy :  tensor(0.252564, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.378846, device='cuda:0')\n",
      "psnr :  tensor(29.120052)\n",
      "entropy :  tensor(0.323111, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.484667, device='cuda:0')\n",
      "psnr :  tensor(25.985968)\n",
      "entropy :  tensor(0.416473, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.624710, device='cuda:0')\n",
      "psnr :  tensor(27.968447)\n",
      "entropy :  tensor(0.307162, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.460743, device='cuda:0')\n",
      "psnr :  tensor(27.823193)\n",
      "entropy :  tensor(0.605184, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.907777, device='cuda:0')\n",
      "psnr :  tensor(26.128046)\n",
      "entropy :  tensor(0.328278, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.492417, device='cuda:0')\n",
      "psnr :  tensor(27.464525)\n",
      "entropy :  tensor(0.276063, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.414094, device='cuda:0')\n",
      "psnr :  tensor(27.933672)\n",
      "entropy :  tensor(0.311144, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.466717, device='cuda:0')\n",
      "psnr :  tensor(25.808447)\n",
      "mean nb bits per pixel :  tensor(0.497200, device='cuda:0')\n",
      "psnr mean :  tensor(27.350943)\n"
     ]
    }
   ],
   "source": [
    "# compute PSNR for each image of the test set and its reconstruction\n",
    "# and write the latent vector in a file\n",
    "\n",
    "def write_data(filepath , tensor_data):\n",
    "    batch, channel, h, w = tensor_data.size()\n",
    "    matrix = tensor_data.cpu().numpy()\n",
    "    file = open(filepath, \"w\")\n",
    "    for image in range(batch):\n",
    "        np.savetxt(file, matrix[image, :, :, :].reshape(channel*h, w), fmt ='%.0f')\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "def compute_entropy(tensor_data):\n",
    "    min_val = tensor_data.min()\n",
    "    max_val = tensor_data.max()\n",
    "    nb_bins = max_val - min_val + 1\n",
    "    hist = torch.histc(tensor_data, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "    hist_prob = hist/hist.sum()\n",
    "    hist_prob[hist_prob == 0] = 1\n",
    "    entropy = -(hist_prob*torch.log2(hist_prob)).sum()\n",
    "    return entropy\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "def psnr(original, compressed, max_pixel): \n",
    "    mse = torch.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse)) \n",
    "    return psnr \n",
    "\n",
    "\n",
    "test_dataset = ImageDataset(root_dir='./data/kodac/', transform=ToTensor())\n",
    "psnr_sum = 0.0\n",
    "bit_rate_sum = 0.0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        [reconstructed_image, im_quantized] = model(test_image, 1, True)\n",
    "        #write_data('.\\\\reconstructed_data\\\\kodac\\\\loss_distortion_and_bitrate\\\\beta_2\\\\latent_vect\\\\' + 'vec' + str(i) +'.txt', im_quantized)\n",
    "        nb_symbols = im_quantized.size(0)*im_quantized.size(1)*im_quantized.size(2)*im_quantized.size(3)\n",
    "        entropy = compute_entropy(im_quantized)\n",
    "        nbpp = nb_symbols*entropy/float(test_image.size(0)*test_image.size(2)*test_image.size(3))\n",
    "        psnr_sum+= psnr(test_image.cpu(), reconstructed_image.cpu(), 255.0)\n",
    "        bit_rate_sum += nbpp\n",
    "        print(\"entropy : \", entropy)\n",
    "        print( \"nb bits per pixel : \", nbpp)\n",
    "        print(\"psnr : \" , psnr(test_image.cpu(), reconstructed_image.cpu(), 255.0))\n",
    "print( \"mean nb bits per pixel : \", bit_rate_sum/len(test_dataset))\n",
    "print(\"psnr mean : \", psnr_sum/len(test_dataset) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.586427, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.293213, device='cuda:0')\n",
      "psnr :  tensor(123.688316)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.815805, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.407903, device='cuda:0')\n",
      "psnr :  tensor(117.780769)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.538711, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.269355, device='cuda:0')\n",
      "psnr :  tensor(129.589996)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.647012, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.323506, device='cuda:0')\n",
      "psnr :  tensor(120.536690)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.679401, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.339700, device='cuda:0')\n",
      "psnr :  tensor(118.219521)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.610384, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.305192, device='cuda:0')\n",
      "psnr :  tensor(134.769150)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.785823, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.392911, device='cuda:0')\n",
      "psnr :  tensor(118.351860)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.864688, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.432344, device='cuda:0')\n",
      "psnr :  tensor(117.496704)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.630359, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.315180, device='cuda:0')\n",
      "psnr :  tensor(133.008240)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.745101, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.372550, device='cuda:0')\n",
      "psnr :  tensor(128.950592)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.670370, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.335185, device='cuda:0')\n",
      "psnr :  tensor(121.260513)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.835310, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.417655, device='cuda:0')\n",
      "psnr :  tensor(117.740143)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.673313, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.336656, device='cuda:0')\n",
      "psnr :  tensor(129.965164)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.826417, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.413209, device='cuda:0')\n",
      "psnr :  tensor(139.162476)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.660114, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.330057, device='cuda:0')\n",
      "psnr :  tensor(135.405853)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.690275, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.345137, device='cuda:0')\n",
      "psnr :  tensor(127.586403)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.826136, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.413068, device='cuda:0')\n",
      "psnr :  tensor(123.554451)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.819209, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.409605, device='cuda:0')\n",
      "psnr :  tensor(110.427216)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.564250, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.282125, device='cuda:0')\n",
      "psnr :  tensor(108.895103)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.622593, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.311296, device='cuda:0')\n",
      "psnr :  tensor(109.556084)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.641507, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.320754, device='cuda:0')\n",
      "psnr :  tensor(108.493637)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(1.069692, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.534846, device='cuda:0')\n",
      "psnr :  tensor(123.058990)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.772198, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.386099, device='cuda:0')\n",
      "psnr :  tensor(120.885551)\n",
      "nb_symbols :  460800\n",
      "entropy :  tensor(0.832820, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.416410, device='cuda:0')\n",
      "psnr :  tensor(110.522926)\n",
      "mean entropy :  tensor(0.725330, device='cuda:0')\n",
      "mean nbpp :  tensor(0.362665, device='cuda:0')\n",
      "mean psnr :  tensor(122.037773)\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 48 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_entropy(tensor_data):\n",
    "    min_val = tensor_data.min()\n",
    "    max_val = tensor_data.max()\n",
    "    nb_bins = max_val - min_val + 1\n",
    "    hist = torch.histc(tensor_data, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "    hist_prob = hist/hist.sum()\n",
    "    hist_prob[hist_prob == 0] = 1\n",
    "    entropy = -(hist_prob*torch.log2(hist_prob)).sum()\n",
    "    return entropy\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "def psnr(original, compressed, max_pixel): \n",
    "    mse = torch.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse)) \n",
    "    return psnr \n",
    "\n",
    "\n",
    "# Load previous model\n",
    "model_prev = LossyCompAutoencoder()\n",
    "#model_prev.load_state_dict(torch.load('./model_parameters/lossy_comp_params_with_rate_beta2_incremental_2.pth'))\n",
    "model_prev.load_state_dict(torch.load('./model_parameters/lossy_comp_params_with_rate_beta005_incremental_ng.pth'))\n",
    "model_prev.eval()\n",
    "model_prev.to(device)\n",
    "\n",
    "\n",
    "# And run test \n",
    "#test_dataset = ImageDataset(root_dir='./data/kodac_intensity/', transform=ToTensor())\n",
    "test_dataset = ImageDataset(root_dir='D:/autoencoder_data/depthmaps/test/test_ng_stacked/', transform=ToTensor())\n",
    "mean_entropy = 0.0\n",
    "mean_nbpp = 0.0\n",
    "mean_psnr = 0.0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        [reconstructed_image, im_quantized] = model_prev(test_image,1, True)\n",
    "        nb_symbols = im_quantized.size(0)*im_quantized.size(1)*im_quantized.size(2)*im_quantized.size(3)\n",
    "        entropy = compute_entropy(im_quantized)\n",
    "        nbpp = nb_symbols*entropy/float(test_image.size(0)*test_image.size(1)*test_image.size(2)*test_image.size(3))\n",
    "        print(\"nb_symbols : \", nb_symbols)\n",
    "        print(\"entropy : \", entropy)\n",
    "        print( \"nb bits per pixel : \", nbpp)\n",
    "        print(\"psnr : \" , psnr(test_image.cpu(), reconstructed_image.cpu(), 255.0))\n",
    "        \n",
    "        mean_entropy = mean_entropy + entropy\n",
    "        mean_nbpp = mean_nbpp + nbpp\n",
    "        mean_psnr = mean_psnr + psnr(test_image.cpu(), reconstructed_image.cpu(), 255.0)\n",
    "        \n",
    "    mean_entropy = mean_entropy / len(test_dataset)\n",
    "    mean_nbpp = mean_nbpp / len(test_dataset)\n",
    "    mean_psnr = mean_psnr / len(test_dataset)\n",
    "    print(\"mean entropy : \", mean_entropy)\n",
    "    print(\"mean nbpp : \", mean_nbpp)\n",
    "    print(\"mean psnr : \", mean_psnr)\n",
    "    \n",
    "    \n",
    "# And print figures\n",
    "fig, axes = plt.subplots(nrows=6, ncols=4, sharex=True, sharey=True, figsize=(8,8))\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        if test_image.size(2)<test_image.size(3):\n",
    "            test_image = test_image.permute(0, 1, 3, 2)\n",
    "        \n",
    "        reconstructed_image = model_prev(test_image, 1,  False)\n",
    "        ax = fig.add_subplot(6, 4, i+1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.squeeze(reconstructed_image.int().cpu()).permute(1, 2, 0))\n",
    "        \n",
    "# And save figures\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        reconstructed_image = np.squeeze(model_prev(test_image).cpu())\n",
    "        print(reconstructed_image.type())\n",
    "        #save_image(reconstructed_image, \".\\\\reconstructed_data\\\\kodac\\\\loss_distortion_and_bitrate\\\\beta_2_incremental_bis\\\\\" + \"img\" + str(i)+\".png\", normalize=True)\n",
    "        save_image(reconstructed_image, \"D:\\\\autoencoder_data\\\\depthmaps\\\\test\\\\test_ng_stacked\\\\reconstructed\\\\beta005\\\\\" + \"img\" + str(i)+\".png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy :  tensor(4.992423, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3783.756348, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(35.316048, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3331.412354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(33.194473, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3280.784668, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(16.982132, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3833.349854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(6.236253, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(2998.021240, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(13.942085, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4020.668213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(11.401224, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4049.084229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.091653, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3914.844238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(7.532864, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3699.531006, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(11.252965, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3502.669678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(10.172251, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3233.638916, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(7.888332, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3444.639160, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.890505, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3758.968750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(6.177967, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4241.679688, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(9.358366, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3220.504639, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(9.724493, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4545.562988, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(9.402671, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4369.997559, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(6.538430, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3352.075195, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.289365, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3834.843750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(8.297033, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4144.026855, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(9.374476, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3154.157715, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(8.841386, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4223.809570, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(7.746368, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3535.041992, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(7.335207, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3648.764893, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.753038, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3968.517578, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.264740, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3936.420410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(6.236658, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3609.426758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(6.787442, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3621.904053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.986058, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3584.592773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.134099, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3085.294434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.148417, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3078.743896, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "running loss : 7364.701818\n",
      "entropy :  tensor(4.213949, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3561.325195, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.420860, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4118.843750, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.712553, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3637.174072, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.181670, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3776.993408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.715181, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3658.700684, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.026452, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3791.611328, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.472366, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4050.481445, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.867154, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3336.663330, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.950971, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3322.977051, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.643092, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4383.884766, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.033780, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3470.098389, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.374466, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3601.259033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.418680, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3595.695068, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.429362, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3701.815430, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.102546, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3141.937500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.463200, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3970.664551, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.480068, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3244.265625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.471892, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(2789.662354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.854553, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3421.625000, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.668358, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3847.244141, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.893020, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3640.884033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.753895, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3621.660889, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.477390, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3783.617676, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.891545, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3746.264893, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.493074, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3678.192139, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy :  tensor(5.630400, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3549.524658, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.559849, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4365.400879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.162018, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3316.888916, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.600066, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4416.073242, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.738790, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3471.339355, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.830067, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3463.139160, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "running loss : 7325.527312\n",
      "entropy :  tensor(4.101906, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3192.148926, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.396014, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3742.691406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.590349, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3849.504639, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.895749, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3491.651123, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.641007, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4195.920410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.343550, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3944.066650, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.613401, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4216.042480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.502293, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3049.093506, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.733954, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3798.904053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.907295, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3719.422607, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.409454, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4018.825928, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.734862, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3615.893311, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.000767, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3642.697998, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.202386, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3506.140625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.790451, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3232.975098, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.380569, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3508.238281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.895568, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3694.142822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.072883, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4317.682617, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.832406, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4027.855713, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.920688, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3767.455078, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.862641, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3264.986572, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.719895, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4004.869873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.916548, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4323.069336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.967666, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3907.452393, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.934248, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(2999.002930, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.289047, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(2505.118652, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.870194, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4147.109375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.423337, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3512.333496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.135796, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3871.651367, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.967262, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3634.952393, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.092330, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3359.604248, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "running loss : 7363.004930\n",
      "entropy :  tensor(4.633295, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3139.896729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.070031, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3575.467285, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.227845, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3609.120117, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.996907, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3616.994873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.381008, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3829.067871, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.837486, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3339.719971, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.817800, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4347.520020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.860142, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3464.789062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.896253, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4551.415039, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.827601, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3452.354248, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.569146, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3794.308105, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.554885, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3845.634033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.403165, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3455.653320, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.059866, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3478.770264, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.289261, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3852.079590, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.021917, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3600.819336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.051328, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3497.921875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.201411, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3255.215820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.554189, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4136.752930, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy :  tensor(4.246066, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3295.793945, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.635244, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3478.754639, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.102264, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3763.461426, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.196034, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4100.532227, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.446591, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3757.830322, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.754829, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3774.031982, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.520656, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3873.743408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.275048, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3438.102783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.607435, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3460.519043, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.637674, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3826.956543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.591435, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3878.642822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.162878, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3433.025391, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "running loss : 7354.103846\n",
      "entropy :  tensor(4.620280, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3298.912598, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.318409, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3800.219482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.816199, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3631.963867, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.382011, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3240.898193, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.510946, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3849.567139, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.464328, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3702.857178, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.930068, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4211.910156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.386963, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3327.402100, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.831267, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3852.551025, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.988003, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3921.562500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.036786, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4011.409180, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.082215, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3708.434326, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.569836, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3154.246338, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.478528, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3101.435059, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.168176, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3542.913818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.105164, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3626.312256, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.071478, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4125.389160, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.526067, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3433.823242, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.772271, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3028.429443, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.746798, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3720.492920, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.604512, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3789.600586, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.793251, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4585.376465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.316394, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3291.835938, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.916682, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3814.273193, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.233948, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3621.671631, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.867783, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3551.011963, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.909818, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3597.802979, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.171260, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4248.392090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.454364, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3356.989014, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.357918, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4464.163086, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.439377, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3682.323730, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "running loss : 7378.103547\n",
      "entropy :  tensor(4.464605, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4247.145020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.041227, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3718.154785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.016944, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3908.405273, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.325893, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3082.682861, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.636497, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3973.458740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.057147, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3696.356445, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.079339, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3260.221680, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.469907, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3645.316406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.778839, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4300.535156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.180281, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3801.203125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.553485, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3260.219482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.214372, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4241.640625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.027046, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3628.932617, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy :  tensor(3.884955, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3497.729980, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.003486, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3901.556641, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.076899, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3660.745605, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.157312, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3802.956543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.281355, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3690.774658, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.307217, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3914.927246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.948053, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3237.705078, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(2.646946, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3699.364990, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.319393, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3790.334229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.034118, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4250.434082, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.208065, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3926.363525, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.747485, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3669.388184, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.253601, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3282.483643, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.040407, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(2838.232910, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.175869, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3185.782471, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.151800, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4109.848145, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.158847, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3655.943604, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.653343, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3582.857666, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "running loss : 7388.880544\n",
      "entropy :  tensor(4.078692, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4331.937500, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.303016, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3650.385498, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.910847, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3701.556152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.063138, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3586.044678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.186852, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3436.955322, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.935975, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3857.169678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.243153, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4031.090088, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.233263, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3312.595947, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.272809, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3685.513916, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.544210, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3571.533936, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.963799, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3686.460693, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.587257, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3620.589844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.902643, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3835.430908, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.706846, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3853.415283, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(5.016892, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3530.089355, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.708622, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3393.946533, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.012492, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3616.270264, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.857601, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3201.696533, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.309969, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3394.364746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.094294, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4268.666504, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.429111, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3004.241211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.262102, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3367.807373, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.463998, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3204.622803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.628301, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3945.990479, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.638970, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4537.041016, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(3.390480, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4347.650391, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.352649, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(4050.649658, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.300420, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3470.998291, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "entropy :  tensor(4.867441, device='cuda:0', grad_fn=<DivBackward1>)\n",
      "distortion :  tensor(3542.787354, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-17527ea6f60d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distortion : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;31m#print(\"conv1.weights grad: \", params[0].grad)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m#print(model.conv1.bias.grad)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def entropy_rate(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.01, 0.01).cuda()        \n",
    "    gsm_sum = torch.zeros(len(u)).cuda()\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm_sum_i = sum_gsm(x, var, phi, 6)\n",
    "        gsm_sum[i] = gsm_sum_i\n",
    "\n",
    "    entropy = torch.trapz(gsm_sum, u)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "# Load incremental model\n",
    "incremental_model = LossyCompAutoencoder()\n",
    "incremental_model.load_state_dict(torch.load('./model_parameters/lossy_comp_params_with_rate_beta2_incremental.pth'))\n",
    "incremental_model.eval()\n",
    "incremental_model.to(device)\n",
    "\n",
    "# train again the model starting form incremental-learned weights\n",
    "    #define optimizer\n",
    "optimizer = torch.optim.Adam(incremental_model.parameters(), lr=0.0001)\n",
    "\n",
    "# define loss function\n",
    "distortion = nn.MSELoss().cuda()\n",
    "\n",
    "\n",
    "# define beta\n",
    "beta = 2.0\n",
    "\n",
    "#Epochs\n",
    "n_epochs = 600\n",
    "\n",
    "\n",
    "# Training the network\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "           \n",
    "    #Training\n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        batch_images = data.to(device).float()\n",
    "        [decoded_images, x_quantized] = incremental_model(batch_images, False, True)\n",
    "        optimizer.zero_grad()\n",
    "        entropy = entropy_rate(x_quantized, incremental_model.phi, incremental_model.var)\n",
    "        print(\"entropy : \", entropy)\n",
    "        dist = distortion(decoded_images, batch_images)\n",
    "        print(\"distortion : \", dist)\n",
    "        loss = beta * dist + entropy\n",
    "        loss.backward()\n",
    "        #print(\"conv1.weights grad: \", params[0].grad)\n",
    "        #print(model.conv1.bias.grad)\n",
    "        #print(model.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss = running_loss/len(dataloader)\n",
    "    print('running loss : {:.06f}'.format(running_loss), )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619240\n",
      "417832\n",
      "381184\n",
      "485040\n",
      "681856\n",
      "566208\n",
      "438336\n",
      "716840\n",
      "393552\n",
      "406752\n",
      "519136\n",
      "394736\n",
      "786376\n",
      "594720\n",
      "470824\n",
      "428256\n",
      "399592\n",
      "613760\n",
      "510416\n",
      "464416\n",
      "540400\n",
      "507440\n",
      "400992\n",
      "585792\n",
      "513487.3333333333\n",
      "1.3058658175998263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    test_image = test_dataset[1].unsqueeze(0).to(device).float()\\n    [reconstructed_image, data_comp] = model(test_image, 1, True)\\n        # compute symbol probabilities\\n    min_val = data_comp.min()\\n    print(min_val)\\n    print(data_comp.max())\\n    if min_val <0:\\n        data_comp -= min_val\\n        min_val = 0\\n    max_val = data_comp.max()\\n    \\n    print(max_val)\\n    nb_bins = max_val - min_val + 1\\n    print(nb_bins)\\n    hist = torch.histc(data_comp, bins=nb_bins.int(), min=min_val, max=max_val)\\n    prob = hist/hist.sum()\\n    print(prob)\\n         # convert probabilities to cumulative integer frequency table\\n    cumFreq = prob_to_cum_freq(prob.cpu(), resolution=128)\\n    #print(cumFreq)\\n\\n    print(torch.flatten(data_comp).cpu().tolist())\\n    \\n    \\n        # encode data\\n    filepath_to_write = \"D:\\\\lossy_autoencoder\\\\latent_vect_encoded\\\\\" + \"img\" + str(1) + \".bin\"\\n    encoder = RangeEncoder(filepath_to_write)\\n    print(torch.flatten(data_comp).cpu().tolist())\\n    encoder.encode(torch.flatten(data_comp.int()).cpu().tolist(), cumFreq)\\n    encoder.close()   \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from range_coder import RangeEncoder, RangeDecoder, prob_to_cum_freq\n",
    "import os\n",
    "\n",
    "# Load previous model\n",
    "model = LossyCompAutoencoder()\n",
    "model.load_state_dict(torch.load('./model_parameters/mean_bit_ppx/lossy_comp_params_with_rate_beta0005_incremental.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "nb_bits = 0.0\n",
    "test_dataset = ImageDataset(root_dir='./data/kodac/', transform=ToTensor())\n",
    "with torch.no_grad():  \n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        [reconstructed_image, data_comp] = model(test_image, 1, True)\n",
    "            # compute symbol probabilities\n",
    "        min_val = data_comp.min()\n",
    "        if min_val <0:\n",
    "            data_comp -= min_val\n",
    "            min_val = 0\n",
    "        max_val = data_comp.max()\n",
    "        nb_bins = max_val - min_val + 1\n",
    "        hist = torch.histc(data_comp, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "        prob = hist/hist.sum()\n",
    "        #print(\"data comp : \", data_comp)\n",
    "        #print(prob)\n",
    "        \n",
    "        \"\"\"\n",
    "        if len(torch.nonzero(prob)) != len(prob):\n",
    "            zero_indices = ((prob == 0).nonzero())\n",
    "            for j in reversed(range(0, len(zero_indices), 1)):\n",
    "                data_comp[data_comp > int(zero_indices[j])+min_val] -=1\n",
    "            min_val = data_comp.min()\n",
    "            max_val = data_comp.max()\n",
    "            nb_bins = max_val - min_val + 1\n",
    "            hist = torch.histc(data_comp, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "            prob = hist/hist.sum()\n",
    "            print(min_val)\n",
    "            print(max_val)\n",
    "            print(\"data comp : \", data_comp)\n",
    "            print(prob)\n",
    "         \"\"\" \n",
    "            \n",
    "            # convert probabilities to cumulative integer frequency table\n",
    "        #cumFreq = prob_to_cum_freq(torch.clamp(prob, min=np.finfo(np.float32).eps).cpu(), resolution=128)\n",
    "        cumFreq = prob_to_cum_freq(prob.cpu(), resolution=128)\n",
    "        #print(cumFreq)\n",
    "        \n",
    "        # encode data\n",
    "        filepath_to_write = \"D:\\\\lossy_autoencoder\\\\latent_vect_encoded\\\\\" + \"img\" + str(i) + \".bin\"\n",
    "        encoder = RangeEncoder(filepath_to_write)\n",
    "        #print(torch.flatten(data_comp).cpu().tolist())\n",
    "        encoder.encode(torch.flatten(data_comp.int()).cpu().tolist(), cumFreq)\n",
    "        encoder.close()\n",
    "        \n",
    "        \n",
    "        file_size = os.path.getsize(filepath_to_write)*8 #number of bits in the file\n",
    "        print(file_size)\n",
    "        nb_bits += file_size\n",
    "        \n",
    "    nb_bits_per_image = nb_bits/len(test_dataset)\n",
    "    print(nb_bits_per_image)\n",
    "    nb_bits_per_pixel = nb_bits_per_image/(512*768)\n",
    "    print(nb_bits_per_pixel)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "    test_image = test_dataset[1].unsqueeze(0).to(device).float()\n",
    "    [reconstructed_image, data_comp] = model(test_image, 1, True)\n",
    "        # compute symbol probabilities\n",
    "    min_val = data_comp.min()\n",
    "    print(min_val)\n",
    "    print(data_comp.max())\n",
    "    if min_val <0:\n",
    "        data_comp -= min_val\n",
    "        min_val = 0\n",
    "    max_val = data_comp.max()\n",
    "    \n",
    "    print(max_val)\n",
    "    nb_bins = max_val - min_val + 1\n",
    "    print(nb_bins)\n",
    "    hist = torch.histc(data_comp, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "    prob = hist/hist.sum()\n",
    "    print(prob)\n",
    "         # convert probabilities to cumulative integer frequency table\n",
    "    cumFreq = prob_to_cum_freq(prob.cpu(), resolution=128)\n",
    "    #print(cumFreq)\n",
    "\n",
    "    print(torch.flatten(data_comp).cpu().tolist())\n",
    "    \n",
    "    \n",
    "        # encode data\n",
    "    filepath_to_write = \"D:\\\\lossy_autoencoder\\\\latent_vect_encoded\\\\\" + \"img\" + str(1) + \".bin\"\n",
    "    encoder = RangeEncoder(filepath_to_write)\n",
    "    print(torch.flatten(data_comp).cpu().tolist())\n",
    "    encoder.encode(torch.flatten(data_comp.int()).cpu().tolist(), cumFreq)\n",
    "    encoder.close()   \n",
    "\"\"\" \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
