{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch.autograd as ag\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "torch.set_printoptions(precision=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([20, 1, 128, 128])\n",
      "1 torch.Size([20, 1, 128, 128])\n",
      "2 torch.Size([20, 1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntransform = transforms.Compose([\\n    transforms.Pad(12, padding_mode='reflect'),\\n    transforms.ToTensor()])\\n\\ntrainset = torchvision.datasets.Flickr8k(root='./data/flickr', ann_file = './data/flickr/file.csv', transform=transform)\\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        path, dirs, files = next(os.walk(self.root_dir))\n",
    "        file_count = len(files)\n",
    "        return file_count\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        path, dirs, files = next(os.walk(self.root_dir))\n",
    "        img_name = os.path.join(self.root_dir, files[idx])\n",
    "        image = io.imread(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        if h!= new_h:\n",
    "            top = np.random.randint(0, h - new_h)\n",
    "        else:\n",
    "            top = 0\n",
    "        if w!= new_w:\n",
    "            left = np.random.randint(0, w - new_w)\n",
    "        else:\n",
    "            left = 0\n",
    "     \n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "        \n",
    "        image = np.expand_dims(image, axis=2)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class Downsample(object):\n",
    "    \"\"\"Downsample the image\n",
    "\n",
    "    Args:\n",
    "        downsampling_factor (int or tuple): Desired downsampling factor for rows and columns.\n",
    "        If the downsampling factor is an int, then both rows and columns are sampled by the same factor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, downsampling_factor):\n",
    "        assert isinstance(downsampling_factor, (int, tuple))\n",
    "        if isinstance(downsampling_factor, int):\n",
    "            self.downsampling_factor = (downsampling_factor, downsampling_factor)\n",
    "        else:\n",
    "            assert len(downsampling_factor) == 2\n",
    "            self.downsampling_factor = downsampling_factor\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        down_fact_h, down_fact_w = self.downsampling_factor\n",
    "        image = image[::down_fact_h,\n",
    "                      ::down_fact_w]\n",
    "\n",
    "        return image\n",
    "    \n",
    "    \n",
    "class ConvertDepthToColor(object):\n",
    "    \"\"\" convert a 1xmxn 16-bits depthmap to a 2xmxn 8-bits colormap\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if len(image.shape[:]) <3:\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "            \n",
    "        h, w = image.shape[:2]\n",
    "        image_r_color= np.zeros((h,w,1), dtype=int)\n",
    "        image_g_color= np.zeros((h,w,1), dtype=int)\n",
    "        image_g_color[(image > 2**8 - 1)] = image[(image > 2**8 - 1)] >> 8\n",
    "        image_r_color = image - (image_g_color <<8)\n",
    "\n",
    "        return np.concatenate((image_r_color, image_g_color), axis=2)\n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in images to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, images):\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        images = images.transpose((2, 0, 1))\n",
    "        images = images.astype(float)\n",
    "        return torch.from_numpy(images)\n",
    "    \n",
    "\n",
    "    \n",
    "class ConvertColorToDepth(object):\n",
    "    \"\"\" convert a 2xmxn 8-bits colormap to a 1xmxn 16-bits depthmap\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, color_image):\n",
    "            \n",
    "        depth_image = color_image[:, 0, :, :]\n",
    "        depth_image += color_image[:, 1, :, :] << 8\n",
    "\n",
    "        return depth_image\n",
    "\n",
    "    \n",
    "def show_image_batch(images_batch):\n",
    "    \"\"\"Show image for a batch of samples.\"\"\"\n",
    "    if images_batch.size(1) == 1:\n",
    "        images_batch_normed = images_batch/torch.max(images_batch)\n",
    "        grid = utils.make_grid(images_batch_normed)\n",
    "        plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "        plt.title('Batch from dataloader')\n",
    "    else:\n",
    "        print(images_batch.size())\n",
    "        images_b_batch = torch.zeros(images_batch.size(0), 1, images_batch.size(2) , images_batch.size(3))\n",
    "        images_color_batch = torch.cat((images_batch, images_b_batch), 1) \n",
    "        print(images_color_batch.size())\n",
    "        grid = utils.make_grid(images_color_batch)\n",
    "        plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "        plt.title('Batch from dataloader')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Load training dataset\n",
    "\n",
    "#mirror_padding_transform = transforms.Compose([transforms.ToPILImage(), transforms.Pad(padding=12, padding_mode='reflect'), transforms.ToTensor()])\n",
    "transformed_dataset = ImageDataset(root_dir='D:/autoencoder_data/depthmaps/training', \n",
    "                                           transform=transforms.Compose([\n",
    "                                            RandomCrop((384, 640)), Downsample(( 3, 5)), ToTensor()])\n",
    "                                  )\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "for i_batch, batch_images in enumerate(dataloader):\n",
    "    print(i_batch, batch_images.size())\n",
    "\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 2:\n",
    "        plt.figure()\n",
    "        show_image_batch(batch_images)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(12, padding_mode='reflect'),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.Flickr8k(root='./data/flickr', ann_file = './data/flickr/file.csv', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass GaussianDistribution(torch.autograd.Function):\\n    @staticmethod\\n    def forward(ctx, input, var, phi, nScale, nChannel):\\n        batch_size = input.size(0)\\n        h = input.size(-1)\\n        w = input.size(-2)\\n        ctx.save_for_backward(input, var, phi)\\n        #print(\"input : \", input)\\n        coeff = torch.sqrt(1.0 / (2 * np.pi * var))\\n        #print(\"coeff : \", coeff)\\n        input_resized = input.repeat((nScale, 1, 1, 1, 1))\\n        #print(\"input : \", input_resized)\\n        exponent = (-0.5*(input_resized ** 2)/var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w))\\n        #print(\"exponent : \", exponent)\\n        coeffs_resized = coeff.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        #print(\"coeffs : \", coeffs_resized)\\n        gaussian = coeffs_resized * torch.exp(exponent)\\n        #print(\"gaussian : \", gaussian)\\n        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        phi_gaussian = phi_resized*gaussian\\n        sum_phi_gaussian = phi_gaussian.sum(dim=0)\\n        #print(\"sum over scales : \", sum_phi_gaussian)\\n        result = -torch.log2(sum_phi_gaussian).sum()\\n\\n        return result\\n\\n    @staticmethod\\n    def backward(ctx, grad_output):\\n        input, var, phi = ctx.saved_tensors\\n        batch_size = input.size(0)\\n        h = input.size(-1)\\n        w = input.size(-2)\\n        nChannel = var.size(1)\\n        nScale = var.size(0)\\n        \\n        \\n        var_resized = var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\\n        input_resized = input.repeat((nScale, 1, 1, 1, 1))\\n        \\n        d_phi = -torch.log2(1.0/torch.sqrt(2.0*np.pi*var_resized)*(torch.exp(-0.5*input_resized**2/var_resized))).sum(dim = [3, 4])\\n        d_var = -torch.log2(phi_resized*(1.0/(np.sqrt(2.0*np.pi)*var_resized)*torch.exp(-0.5*input_resized**2/var_resized))*(1.0 + input_resized**2/var_resized)).sum(dim = [3, 4])\\n        d_xq = -torch.log2((phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\\n        print(\"d_xq : \", (phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\\n        \\n        return grad_output*d_phi, grad_output*d_var, grad_output*d_xq\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define additionnnal functions\n",
    "def periodic_shuffling(T, C):\n",
    "    T_copy = T.clone()\n",
    "    batch_size = T.size()[0]\n",
    "    H = T.size()[2]\n",
    "    W = T.size()[3]\n",
    "    T = T.view(batch_size, C, H*2, W*2)\n",
    "    \"\"\"\n",
    "    for k in range(C):\n",
    "        for i in range(2*H):\n",
    "            for j in range(2*W):\n",
    "                T[:, k, i, j] = T_copy[:, C*((j&1)<<1)+C*(i&1)+k, i>>1, j>>1]\n",
    "    \"\"\"\n",
    "                \n",
    "    T[:, :, ::2, ::2] = T_copy[:, 0:C, :, :]\n",
    "    T[:, :, 1::2, ::2] = T_copy[:, C:2*C, :, :]\n",
    "    T[:, :, ::2, 1::2] = T_copy[:, 2*C:3*C, :, :]\n",
    "    T[:, :, 1::2, 1::2] = T_copy[:, 3*C:4*C, :, :]\n",
    "\n",
    "    return T\n",
    "    \n",
    "    \n",
    "def mirror_padding(x, padding_size):\n",
    "    up_line = x[:, :, 0:padding_size, :].flip(2)\n",
    "    left_col = x[:, :, :, 0:padding_size].flip(3)\n",
    "    right_col = x[:, :, :, -padding_size:].flip(3)\n",
    "    bottom_line = x[:, :, -padding_size:, :].flip(2)\n",
    "    left_up_corner = left_col[:, :, 0:padding_size, :].flip(2)\n",
    "    right_up_corner = right_col[:, :, 0:padding_size, :].flip(2)\n",
    "    left_bottom_corner = left_col[:, :, -padding_size:, :].flip(2)\n",
    "    right_bottom_corner = right_col[:, :, -padding_size:, :].flip(2)\n",
    "\n",
    "    x_mirror_pad = torch.cat((torch.cat((left_up_corner, up_line, right_up_corner), 3), torch.cat((left_col, x, right_col), 3), torch.cat((left_bottom_corner, bottom_line, right_bottom_corner), 3)), 2)\n",
    "    return x_mirror_pad\n",
    "    \n",
    "\n",
    "def normalize_input(x):\n",
    "    mean_channels = torch.mean(1.0*x, [2,3])\n",
    "    mean_channels_images = (mean_channels.repeat_interleave(x.size()[2]*x.size()[3])).view(x.size()[0], x.size()[1], x.size()[2], x.size()[3])\n",
    "    x_centered = x - mean_channels_images\n",
    "    max_value = torch.max(x)\n",
    "    min_value = torch.min(x)\n",
    "    radius = max(max_value, abs(min_value))\n",
    "    x_centered_normalized = x_centered/radius\n",
    "    return x_centered_normalized, radius, mean_channels\n",
    "\n",
    "def standardize_input(x):\n",
    "    mean_channels = torch.mean(1.0*x, [2,3])\n",
    "    mean_channels_images = (mean_channels.repeat_interleave(x.size()[2]*x.size()[3])).view(x.size()[0], x.size()[1], x.size()[2], x.size()[3])\n",
    "    x_centered = x - mean_channels_images\n",
    "    var = torch.sum(x_centered**2, (0, 1))/(x.size()[0]*x.size()[1])\n",
    "    return x_centered/torch.sqrt(var), mean_channels, var\n",
    "    \n",
    "def denormalize_output(x, radius, mean_channels):\n",
    "    x_denormalized = x*radius\n",
    "    mean_channels_images = (mean_channels.repeat_interleave(x.size()[2]*x.size()[3])).view(x.size()[0], x.size()[1], x.size()[2], x.size()[3])\n",
    "    x_denormalized_centered = x_denormalized + mean_channels_images\n",
    "    return x_denormalized_centered\n",
    "\n",
    "def destandardize_output(x, mean_channels, var):\n",
    "    x_rescaled = x*torch.sqrt(var)\n",
    "    mean_channels_images = (mean_channels.repeat_interleave(x.size()[2]*x.size()[3])).view(x.size()[0], x.size()[1], x.size()[2], x.size()[3])\n",
    "    x_destandardized = x_rescaled + mean_channels_images\n",
    "    return x_destandardized\n",
    "\n",
    "\n",
    "\n",
    "def compute_gsm(x, var, phi, nScale):\n",
    "    gsm = 0.0\n",
    "    \n",
    "    phi = torch.abs(phi)\n",
    "    var = torch.abs(var)\n",
    "    phi_s_sum = torch.sum(phi, 0).unsqueeze(0)\n",
    "    phi_norm = phi/phi_s_sum\n",
    "    \n",
    "    for s in range(nScale):\n",
    "        var_s = var[s, :].view(1, -1, 1, 1)\n",
    "        phi_s = phi_norm[s, :].view(1, -1, 1, 1)\n",
    "        gaussian = phi_s*(1.0/(torch.sqrt(2*np.pi*var_s)))*torch.exp(-0.5*(x**2/var_s))\n",
    "        gsm += gaussian\n",
    "    return gsm\n",
    "\n",
    "\n",
    "def sum_gsm(x, var, phi, nScale):\n",
    "    gsm = 0.0\n",
    "    \n",
    "    phi = torch.abs(phi)\n",
    "    var = torch.abs(var)\n",
    "    phi_s_sum = torch.sum(phi, 0).unsqueeze(0)\n",
    "    phi_norm = phi/phi_s_sum\n",
    "    \n",
    "    for s in range(nScale):\n",
    "        var_s = var[s, :].view(1, -1, 1, 1)\n",
    "        phi_s = phi_norm[s, :].view(1, -1, 1, 1)\n",
    "        gaussian = phi_s*(1.0/(torch.sqrt(2*np.pi*var_s)))*torch.exp(-0.5*(x**2/var_s))\n",
    "        gsm += gaussian\n",
    "    #gsm_sum = (torch.log2(gsm)).sum()\n",
    "    gsm_sum = gsm.sum()\n",
    "    return gsm_sum\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    h = x.size(-1)\n",
    "    w = x.size(-2)\n",
    "    #print(\"input : \", input)\n",
    "    coeff = torch.sqrt(1.0 / (2 * np.pi * var))\n",
    "    #print(\"coeff : \", coeff)\n",
    "    x_resized = x.repeat((nScale, 1, 1, 1, 1))\n",
    "    #print(\"input : \", input_resized)\n",
    "    exponent = (-0.5*(x_resized ** 2)/var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w))\n",
    "    #print(\"exponent : \", exponent)\n",
    "    coeffs_resized = coeff.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "    #print(\"coeffs : \", coeffs_resized)\n",
    "    gaussian = coeffs_resized * torch.exp(exponent)\n",
    "    #print(\"gaussian : \", gaussian)\n",
    "    phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "    phi_gaussian = phi_resized*gaussian\n",
    "    sum_phi_gaussian = phi_gaussian.sum(dim=0)\n",
    "    #print(\"sum over scales : \", sum_phi_gaussian)\n",
    "    result = -torch.log2(sum_phi_gaussian).sum()\n",
    "\n",
    "    return result\n",
    "    \"\"\"\n",
    "    \n",
    "def compute_mask(nb_ones, dims):\n",
    "    mask = torch.zeros(dims)\n",
    "    indices = np.arange(nb_ones)\n",
    "    mask_flatten = mask.view(-1, 1, 1, 1)\n",
    "    mask_flatten[indices] = 1\n",
    "    mask_reshaped = mask_flatten.view(dims)\n",
    "    return mask_reshaped\n",
    "\n",
    "\n",
    "def entropy_rate(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.1, 0.1).cuda()        \n",
    "    gsm_sum = torch.zeros(len(u)).cuda()\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm_sum_i = sum_gsm(x, var, phi, 6)\n",
    "        gsm_sum[i] = gsm_sum_i\n",
    "\n",
    "    integral_u = torch.trapz(gsm_sum, u)\n",
    "    #print(\"gsm sum : \", gsm_sum)\n",
    "    #print(\"integral over u : \", integral_u)\n",
    "    entropy = -torch.log2(integral_u)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n",
    "def mean_bit_per_px(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.1, 0.1).cuda()   \n",
    "    gsm_stacked = []\n",
    "    #u_stacked = []\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm = compute_gsm(x, var, phi, 6)\n",
    "        gsm_stacked.append(gsm)\n",
    "        #u_stacked.append(torch.ones(gsm.size()).cuda()*u[i])\n",
    "    \n",
    "    gsms = torch.stack(gsm_stacked, dim=0)\n",
    "    #us = torch.stack(u_stacked, dim=0)\n",
    "    integral_u = torch.trapz(gsms, dx=0.1, dim=0)\n",
    "    if torch.any(integral_u.isnan()):\n",
    "        print(\"integral u is nan\", integral_u)\n",
    "        integral_u[integral_u.isnan()] = 1\n",
    "    nb_bits = (-torch.log2(torch.clamp(integral_u, min=np.exp(-10**2), max=1))).sum()\n",
    "    if nb_bits < 0:\n",
    "        #print(\"integral u : \", integral_u)\n",
    "        print(\"nb_bits negative : \", nb_bits)\n",
    "    return nb_bits/reduce(lambda x, y: x*y, list(x_quantized.size()))\n",
    "\n",
    "\"\"\"\n",
    "def entropy_rate(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.05, 0.05).cuda()   \n",
    "    sum_log_gsm = torch.zeros(len(u)).cuda()\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm = compute_gsm(x, var, phi, 6)\n",
    "        sum_log_gsm[i] = (-torch.log2(gsm)).sum()\n",
    "    \n",
    "    entropy = torch.trapz(sum_log_gsm, u)\n",
    "    if entropy < 0:\n",
    "        print(\"negative entropy\")\n",
    "    return entropy\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def clip(x):\n",
    "    x_n = (x - torch.min(x))/(torch.max(x) - torch.min(x))\n",
    "    x_clipped = torch.round(255*x_n).float()\n",
    "    return x_clipped\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MyQuantization(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.round(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output\n",
    "\n",
    "        \n",
    "        \n",
    "class MyClipping(torch.autograd.Function):\n",
    "  \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.round(input).clamp(min=0, max=2**16-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input = ctx.saved_tensors\n",
    "        return grad_output\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "class GaussianDistribution(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, var, phi, nScale, nChannel):\n",
    "        batch_size = input.size(0)\n",
    "        h = input.size(-1)\n",
    "        w = input.size(-2)\n",
    "        ctx.save_for_backward(input, var, phi)\n",
    "        #print(\"input : \", input)\n",
    "        coeff = torch.sqrt(1.0 / (2 * np.pi * var))\n",
    "        #print(\"coeff : \", coeff)\n",
    "        input_resized = input.repeat((nScale, 1, 1, 1, 1))\n",
    "        #print(\"input : \", input_resized)\n",
    "        exponent = (-0.5*(input_resized ** 2)/var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w))\n",
    "        #print(\"exponent : \", exponent)\n",
    "        coeffs_resized = coeff.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        #print(\"coeffs : \", coeffs_resized)\n",
    "        gaussian = coeffs_resized * torch.exp(exponent)\n",
    "        #print(\"gaussian : \", gaussian)\n",
    "        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        phi_gaussian = phi_resized*gaussian\n",
    "        sum_phi_gaussian = phi_gaussian.sum(dim=0)\n",
    "        #print(\"sum over scales : \", sum_phi_gaussian)\n",
    "        result = -torch.log2(sum_phi_gaussian).sum()\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, var, phi = ctx.saved_tensors\n",
    "        batch_size = input.size(0)\n",
    "        h = input.size(-1)\n",
    "        w = input.size(-2)\n",
    "        nChannel = var.size(1)\n",
    "        nScale = var.size(0)\n",
    "        \n",
    "        \n",
    "        var_resized = var.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        phi_resized = phi.repeat_interleave(batch_size*h*w, 1).view(nScale, batch_size, nChannel, h, w)\n",
    "        input_resized = input.repeat((nScale, 1, 1, 1, 1))\n",
    "        \n",
    "        d_phi = -torch.log2(1.0/torch.sqrt(2.0*np.pi*var_resized)*(torch.exp(-0.5*input_resized**2/var_resized))).sum(dim = [3, 4])\n",
    "        d_var = -torch.log2(phi_resized*(1.0/(np.sqrt(2.0*np.pi)*var_resized)*torch.exp(-0.5*input_resized**2/var_resized))*(1.0 + input_resized**2/var_resized)).sum(dim = [3, 4])\n",
    "        d_xq = -torch.log2((phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\n",
    "        print(\"d_xq : \", (phi_resized*(-input_resized/torch.sqrt(2.0*np.pi*var_resized**3))*torch.exp(-0.5*input_resized**2/var_resized)).sum(dim=[0]))\n",
    "        \n",
    "        return grad_output*d_phi, grad_output*d_var, grad_output*d_xq\n",
    "\"\"\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Convolutional Autoencoder with integrated classifer\n",
    "    #taille de l'image d'entrée : 128*128\n",
    "class LossyCompAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossyCompAutoencoder, self).__init__()\n",
    "       \n",
    "        #Encoder\n",
    "            # input block\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5, stride=2, padding=0)  \n",
    "        self.conv2 = nn.Conv2d(64, 128, 5, stride=2, padding=0)\n",
    "            # residual block \n",
    "        self.resConv = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "            # output block\n",
    "        self.conv3 = nn.Conv2d(128, 96, 5, stride=2, padding=0)\n",
    "        self.quantization = MyQuantization.apply\n",
    "        #self.gaussian_distribution = GaussianDistribution.apply\n",
    "        \n",
    "\n",
    "       \n",
    "        #Decoder\n",
    "            # subpixel 1\n",
    "        self.subpix1 = nn.Conv2d(96, 512, 3, stride=1, padding=1)\n",
    "            # subpixel 2\n",
    "        self.subpix2 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "            # subpixel 3\n",
    "        self.subpix3 = nn.Conv2d(256//4, 4, 3, stride=1, padding=1)\n",
    "            #residual block\n",
    "        self.deconv1 = nn.Conv2d(512//4, 128, 3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.clip = MyClipping.apply\n",
    "        \n",
    "        #Bit-rate      \n",
    "        self.var = nn.Parameter(torch.Tensor(6, 96))\n",
    "        self.phi = nn.Parameter(torch.Tensor(6, 96))\n",
    "        self.var.data.uniform_(0, 1)\n",
    "        self.phi.data.uniform_(0, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.gsm_pi = torch.nn.Parameter(torch.randn(6, 96))\n",
    "        self.gsm_sigma = torch.nn.Parameter(torch.randn(6, 96))\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x, mask= 1, return_xq=False):\n",
    "        #encoder\n",
    "            # normalization\n",
    "        x, mean_channels, var = standardize_input(x)\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after normalization is nan\", x)\n",
    "            # mirror padding\n",
    "        x = mirror_padding(x, 14)\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after mirror padding is nan\", x)\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            x_copy = x.cpu()\n",
    "            show_image_batch(x_copy)\n",
    "        \"\"\"\n",
    "            # input blocks\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x_c1 = x.clone()\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after input block is nan\", x)\n",
    "            # residual block 1\n",
    "        x = F.relu(self.resConv(x))\n",
    "        x = self.resConv(x)\n",
    "        x += x_c1\n",
    "        x_c2 = x.clone()\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after residual block 1 is nan\", x)\n",
    "            # residual block 2\n",
    "        x = F.relu(self.resConv(x))\n",
    "        x = self.resConv(x)\n",
    "        x += x_c2\n",
    "        x_c3 = x.clone()\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after residual block 2 is nan\", x)\n",
    "            # residual block 3\n",
    "        x = F.relu(self.resConv(x))\n",
    "        x = self.resConv(x)\n",
    "        x += x_c3\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after residual block 3 is nan\", x)\n",
    "            # output block\n",
    "        x = self.conv3(x)\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after output block is nan\", x)\n",
    "            # quantization\n",
    "        x = self.quantization(x)\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after quantization block is nan\", x)\n",
    "            # add mask for incremental training\n",
    "        x = x*mask\n",
    "        x_quantized = x\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after mask is nan\", x)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        w = x_quantized.size()[2]\n",
    "        h = x_quantized.size()[3]\n",
    "        gsm = 0.0\n",
    "        for i in range(6)\n",
    "            mi = torch.flatten(x_quantized),torch.diagonal(self.gsm_sigma[s, :].repeat(w*h, 1).squeeze(0))\n",
    "            gsm += \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        #decoder\n",
    "            # subpixel 1\n",
    "        x = self.subpix1(x)\n",
    "        x = periodic_shuffling(x, 512//4)\n",
    "        x_c4 = x.clone()\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after subpix 1 is nan\", x)\n",
    "            # residual block 1\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = self.deconv2(x)\n",
    "        x += x_c4\n",
    "        x_c5 = x.clone()\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after residual block 1 is nan\", x)\n",
    "               # residual block 2\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = self.deconv2(x)\n",
    "        x += x_c5\n",
    "        x_c6 = x.clone()\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after residual block 2 is nan\", x)\n",
    "               # residual block 3\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = self.deconv2(x)\n",
    "        x += x_c6\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after residual block 3 is nan\", x)\n",
    "                # subpixel 2\n",
    "        x = self.subpix2(x)\n",
    "        x = F.relu(periodic_shuffling(x, 256//4))\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after subpix 2 is nan\", x)\n",
    "                # subpixel 3\n",
    "        x = self.subpix3(x)\n",
    "        x = periodic_shuffling(x, 4//4)\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after subpix 3 is nan\", x)\n",
    "                # denormalization\n",
    "        x = destandardize_output(x, mean_channels, var)\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after denormalization is nan\", x)\n",
    "                # clipping\n",
    "        x = self.clip(x)\n",
    "        if torch.any(x.isnan()):\n",
    "            print(\"x after clipping is nan\", x)\n",
    "\n",
    "        \n",
    "        if return_xq:\n",
    "            return x, x_quantized\n",
    "        else:\n",
    "            return x\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossyCompAutoencoder(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (resConv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 96, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (subpix1): Conv2d(96, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (subpix2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (subpix3): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (deconv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (deconv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "20\n",
      "[Parameter containing:\n",
      "tensor([[6.400760e-01, 8.857015e-01, 4.499664e-01, 4.643448e-01, 6.452761e-01,\n",
      "         5.135911e-01, 1.509400e-01, 8.417791e-01, 7.908556e-01, 5.748329e-01,\n",
      "         1.661864e-01, 1.761546e-01, 6.150917e-01, 4.156637e-01, 1.619503e-01,\n",
      "         3.864181e-01, 7.027156e-01, 3.875849e-01, 6.845230e-01, 6.072849e-02,\n",
      "         4.693353e-01, 7.139146e-01, 8.590559e-01, 2.421373e-01, 1.048446e-01,\n",
      "         6.167632e-01, 8.904637e-01, 9.373696e-01, 2.587593e-01, 1.585371e-01,\n",
      "         2.140026e-01, 8.565799e-01, 2.959833e-01, 5.569817e-01, 3.263109e-01,\n",
      "         4.076631e-01, 3.506221e-01, 4.703618e-01, 2.773420e-01, 9.138827e-01,\n",
      "         7.242306e-01, 6.300953e-01, 9.808991e-01, 4.257481e-01, 2.532519e-01,\n",
      "         6.996983e-01, 2.390678e-01, 1.968181e-02, 8.869034e-01, 5.659599e-01,\n",
      "         4.279037e-01, 9.041889e-01, 9.562625e-01, 8.995575e-01, 4.202743e-01,\n",
      "         5.185084e-01, 9.916509e-01, 6.585503e-02, 2.029119e-01, 8.926052e-01,\n",
      "         6.762784e-01, 1.366248e-01, 5.526385e-01, 5.260657e-01, 4.098833e-01,\n",
      "         8.715630e-01, 9.719250e-01, 3.383613e-02, 4.756440e-01, 2.182863e-01,\n",
      "         7.480292e-01, 5.626927e-01, 7.177160e-01, 2.924407e-02, 3.344043e-01,\n",
      "         3.066704e-01, 3.325897e-01, 6.805002e-01, 6.717485e-01, 1.490301e-01,\n",
      "         7.099630e-01, 7.477253e-01, 8.284680e-01, 5.091710e-01, 6.565905e-01,\n",
      "         2.066393e-01, 8.256784e-01, 9.167315e-01, 7.845608e-01, 3.264493e-01,\n",
      "         5.608797e-05, 8.132457e-01, 6.502876e-01, 9.225129e-01, 9.404048e-01,\n",
      "         4.294347e-01],\n",
      "        [3.694420e-01, 4.376613e-01, 4.620519e-01, 6.655511e-01, 5.764742e-01,\n",
      "         5.316384e-01, 5.584721e-01, 9.466092e-01, 3.439724e-02, 1.752776e-01,\n",
      "         1.067661e-01, 2.525715e-01, 4.718972e-01, 7.047266e-01, 6.858122e-01,\n",
      "         3.552979e-01, 3.346847e-01, 4.949794e-01, 9.606248e-01, 2.522056e-01,\n",
      "         7.208146e-01, 1.642984e-01, 7.919822e-01, 9.848452e-01, 4.248392e-01,\n",
      "         7.572859e-01, 7.720214e-01, 1.139985e-01, 2.867302e-01, 2.267048e-01,\n",
      "         9.686546e-01, 8.648738e-01, 2.881521e-01, 1.355695e-01, 4.358813e-01,\n",
      "         4.082313e-01, 9.268825e-01, 5.633304e-01, 3.470219e-01, 3.045382e-01,\n",
      "         9.227319e-01, 4.198414e-02, 3.079585e-01, 3.761140e-01, 3.953236e-02,\n",
      "         1.054376e-02, 3.143386e-01, 2.049419e-01, 4.415826e-01, 8.427016e-01,\n",
      "         2.489879e-01, 7.092954e-01, 8.930922e-01, 7.734506e-01, 6.944932e-01,\n",
      "         6.199254e-01, 2.801965e-01, 1.169564e-01, 8.420931e-01, 8.941783e-01,\n",
      "         1.872059e-01, 2.432100e-01, 8.587070e-01, 1.333698e-01, 7.371897e-01,\n",
      "         2.379081e-01, 4.581861e-01, 7.397565e-01, 1.094736e-01, 1.928478e-01,\n",
      "         6.574587e-01, 5.308981e-01, 1.313630e-01, 1.383200e-01, 9.187631e-01,\n",
      "         7.826859e-02, 2.779971e-01, 5.523887e-01, 1.337513e-01, 3.584920e-01,\n",
      "         4.291656e-01, 2.072312e-01, 1.694281e-01, 8.911638e-01, 6.284228e-01,\n",
      "         3.350191e-01, 2.873344e-01, 8.056104e-02, 4.299440e-01, 3.241657e-01,\n",
      "         7.601877e-01, 3.465969e-01, 8.768666e-01, 1.302385e-02, 1.966393e-02,\n",
      "         2.694117e-01],\n",
      "        [3.328382e-01, 9.919387e-01, 9.101384e-01, 7.485966e-01, 6.262476e-01,\n",
      "         1.593395e-01, 9.088211e-01, 1.378471e-02, 9.513834e-01, 9.010360e-01,\n",
      "         4.910334e-01, 8.824450e-01, 8.042645e-01, 6.858555e-01, 2.178836e-01,\n",
      "         5.219157e-01, 7.256690e-01, 7.337056e-01, 6.130928e-01, 8.664390e-01,\n",
      "         2.179314e-01, 3.837113e-01, 8.404153e-01, 2.223877e-01, 6.079745e-01,\n",
      "         9.019254e-01, 7.634829e-01, 9.010840e-01, 9.273319e-01, 9.450525e-01,\n",
      "         2.580041e-01, 9.519025e-01, 6.851879e-01, 1.335228e-01, 9.698285e-01,\n",
      "         3.202570e-01, 4.286475e-01, 9.357961e-01, 5.893179e-01, 2.653981e-01,\n",
      "         1.169467e-01, 9.403408e-02, 9.056189e-01, 2.735031e-02, 5.467640e-01,\n",
      "         1.037216e-01, 7.800178e-01, 3.882537e-01, 2.865006e-01, 6.907710e-01,\n",
      "         8.856564e-01, 2.471456e-01, 6.094471e-01, 8.671907e-01, 1.614810e-01,\n",
      "         7.548354e-01, 9.103746e-01, 2.764722e-01, 5.277756e-01, 5.614775e-01,\n",
      "         4.070531e-01, 7.224212e-01, 3.744510e-01, 7.751332e-01, 7.610362e-01,\n",
      "         6.620592e-02, 1.535683e-01, 8.432608e-01, 5.444037e-01, 6.466076e-01,\n",
      "         4.850243e-01, 7.589474e-01, 7.878624e-01, 5.439541e-01, 1.975307e-01,\n",
      "         1.942274e-01, 6.790428e-01, 1.684956e-01, 9.310138e-01, 6.579989e-01,\n",
      "         9.283046e-01, 5.866237e-01, 6.487265e-01, 2.749867e-01, 9.121299e-01,\n",
      "         8.387663e-01, 5.714541e-01, 7.291800e-01, 9.921339e-01, 1.070171e-01,\n",
      "         9.927265e-01, 1.911290e-01, 3.611907e-01, 2.885802e-01, 2.926521e-01,\n",
      "         7.402830e-01],\n",
      "        [6.251063e-01, 6.179094e-01, 2.875746e-01, 8.929428e-01, 8.324902e-01,\n",
      "         5.873633e-01, 6.632781e-02, 5.360636e-01, 7.109772e-01, 9.538664e-01,\n",
      "         3.523059e-01, 4.503499e-01, 5.391459e-01, 3.134927e-01, 7.801645e-01,\n",
      "         3.954843e-01, 8.626689e-01, 6.478837e-01, 5.838459e-01, 4.462108e-01,\n",
      "         1.002172e-01, 9.850878e-01, 7.253968e-01, 8.274682e-01, 1.014886e-01,\n",
      "         8.839924e-01, 8.084343e-01, 2.654322e-01, 7.118100e-02, 1.257744e-01,\n",
      "         2.758157e-02, 4.591954e-01, 8.208472e-01, 4.263623e-01, 3.027670e-01,\n",
      "         7.816756e-01, 5.528134e-01, 7.690537e-02, 6.510428e-01, 6.386286e-02,\n",
      "         6.871712e-01, 6.011110e-01, 8.521795e-02, 6.269758e-01, 8.012182e-01,\n",
      "         7.240098e-01, 8.154681e-01, 6.174212e-01, 6.699440e-01, 8.404379e-01,\n",
      "         9.717570e-01, 2.546846e-01, 9.493728e-01, 2.215409e-01, 5.087957e-01,\n",
      "         4.561486e-01, 7.295775e-01, 7.644063e-01, 5.133846e-01, 7.590451e-01,\n",
      "         7.176670e-01, 5.677274e-01, 9.490010e-01, 5.435084e-01, 1.310700e-02,\n",
      "         6.554963e-01, 4.034703e-01, 8.477847e-01, 2.597215e-01, 4.079455e-02,\n",
      "         5.315509e-01, 2.208084e-02, 2.449727e-02, 7.668501e-01, 5.825550e-01,\n",
      "         7.778742e-01, 1.589882e-02, 3.042137e-01, 8.512836e-01, 8.570721e-01,\n",
      "         6.477814e-01, 5.406219e-01, 7.647135e-01, 7.921704e-01, 9.395491e-01,\n",
      "         2.759026e-01, 7.016543e-01, 9.729949e-01, 9.370691e-01, 9.345917e-01,\n",
      "         4.259622e-02, 7.720065e-01, 9.045464e-02, 3.437992e-01, 3.655207e-01,\n",
      "         8.969520e-01],\n",
      "        [2.172610e-01, 5.474965e-01, 5.683184e-01, 3.423268e-01, 3.842458e-01,\n",
      "         3.760456e-01, 1.772090e-01, 9.585029e-02, 5.094390e-01, 6.596693e-01,\n",
      "         9.074045e-01, 9.473808e-01, 3.413082e-01, 9.148301e-01, 2.049106e-01,\n",
      "         4.681407e-01, 3.512174e-01, 2.447293e-01, 4.954917e-01, 1.000840e-01,\n",
      "         7.614044e-01, 1.523904e-01, 9.953968e-01, 5.216752e-01, 2.379082e-01,\n",
      "         4.091393e-01, 1.446317e-01, 1.110183e-01, 2.562678e-01, 9.577119e-01,\n",
      "         3.953834e-01, 3.952641e-01, 4.826609e-01, 8.815283e-01, 6.282817e-01,\n",
      "         1.088765e-01, 8.277719e-01, 7.319794e-01, 7.587875e-01, 5.518270e-01,\n",
      "         1.309966e-01, 2.174557e-01, 9.064299e-02, 7.646860e-01, 9.681172e-01,\n",
      "         9.125630e-01, 3.394246e-01, 8.129863e-01, 1.305414e-01, 2.522731e-01,\n",
      "         4.029292e-01, 8.697033e-03, 8.105431e-01, 1.758224e-01, 1.239502e-02,\n",
      "         1.018559e-01, 4.487623e-01, 6.627739e-01, 7.049554e-01, 6.185469e-01,\n",
      "         2.025251e-01, 2.169690e-01, 4.415509e-01, 3.810868e-01, 9.776714e-01,\n",
      "         8.783124e-01, 1.271878e-01, 8.031889e-01, 2.262293e-01, 5.997349e-01,\n",
      "         3.716879e-01, 6.749232e-01, 7.655196e-01, 8.924901e-01, 7.778941e-01,\n",
      "         2.934048e-01, 3.327243e-01, 8.975550e-01, 8.147243e-01, 7.689210e-01,\n",
      "         5.748400e-01, 1.628145e-01, 8.722082e-01, 9.070650e-01, 8.571429e-01,\n",
      "         4.356878e-01, 3.670929e-01, 4.654701e-01, 7.015563e-01, 2.991624e-01,\n",
      "         4.106666e-01, 8.125674e-01, 8.620416e-01, 6.686243e-01, 6.741466e-01,\n",
      "         9.614105e-01],\n",
      "        [7.665737e-01, 8.105757e-01, 4.392336e-01, 3.834653e-01, 4.007890e-01,\n",
      "         6.564198e-01, 9.288210e-01, 3.827585e-01, 9.499147e-01, 4.912386e-01,\n",
      "         4.043952e-01, 8.753392e-01, 3.603667e-02, 8.631825e-01, 7.628730e-01,\n",
      "         8.977073e-01, 5.810283e-01, 4.030741e-01, 8.633574e-01, 2.834897e-01,\n",
      "         2.306677e-01, 2.860867e-01, 5.614724e-01, 7.497452e-01, 7.783940e-01,\n",
      "         1.287053e-01, 1.664277e-01, 3.142346e-01, 4.246200e-01, 7.526048e-01,\n",
      "         7.171330e-01, 3.125733e-01, 1.323844e-01, 2.277489e-01, 6.643307e-01,\n",
      "         8.627611e-02, 5.720451e-01, 9.679846e-01, 4.616823e-01, 8.869541e-01,\n",
      "         4.618949e-01, 5.571414e-01, 4.678491e-01, 2.978828e-01, 2.989042e-02,\n",
      "         7.455391e-01, 5.465959e-01, 5.175979e-01, 4.962947e-01, 1.916443e-01,\n",
      "         9.247506e-02, 9.950063e-01, 6.217400e-01, 1.508494e-01, 4.330356e-01,\n",
      "         1.562893e-01, 7.313068e-01, 8.965563e-01, 3.513292e-01, 9.266031e-02,\n",
      "         9.364563e-01, 2.907673e-01, 3.628694e-01, 9.146144e-01, 5.450088e-01,\n",
      "         4.720068e-01, 2.882320e-01, 2.467288e-01, 2.919137e-02, 4.311212e-01,\n",
      "         7.109064e-01, 1.563979e-01, 3.805940e-01, 8.397288e-01, 3.112406e-02,\n",
      "         2.136086e-01, 8.795769e-01, 5.022390e-01, 9.693130e-01, 3.438109e-01,\n",
      "         1.154382e-01, 3.673576e-01, 8.888259e-01, 2.370519e-01, 9.008300e-01,\n",
      "         4.462926e-01, 9.008899e-01, 9.005731e-01, 7.048302e-01, 1.849740e-01,\n",
      "         1.245210e-01, 5.854188e-01, 8.743539e-01, 9.834659e-01, 5.679342e-01,\n",
      "         4.999740e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([[5.480242e-01, 5.295128e-01, 7.058067e-01, 9.850986e-01, 4.664010e-01,\n",
      "         9.768296e-01, 3.095003e-01, 1.769054e-01, 7.215685e-02, 7.998097e-02,\n",
      "         7.605242e-01, 7.175048e-01, 2.590652e-01, 9.949289e-01, 6.035369e-01,\n",
      "         5.132247e-01, 1.700026e-01, 5.287055e-01, 3.297381e-01, 4.159366e-01,\n",
      "         7.072923e-01, 4.614941e-01, 5.400789e-02, 1.595056e-01, 5.797989e-01,\n",
      "         5.504827e-01, 9.879816e-01, 3.198124e-01, 9.095150e-01, 9.812201e-01,\n",
      "         6.738416e-01, 3.596550e-02, 3.292577e-01, 4.471250e-01, 1.871648e-01,\n",
      "         1.847017e-01, 4.119597e-01, 9.955426e-01, 5.634006e-01, 5.930048e-01,\n",
      "         3.250663e-01, 2.589518e-01, 7.040769e-02, 7.081510e-01, 5.351767e-01,\n",
      "         2.625194e-01, 3.562922e-01, 3.971779e-02, 2.169709e-01, 1.450771e-01,\n",
      "         9.039338e-01, 3.328913e-02, 9.153048e-01, 8.142096e-01, 1.159612e-01,\n",
      "         9.400149e-01, 2.509983e-01, 1.873394e-01, 8.851781e-01, 8.046872e-01,\n",
      "         8.457764e-01, 2.175235e-01, 2.094514e-01, 5.298097e-01, 5.200254e-01,\n",
      "         5.381511e-01, 4.438677e-01, 2.947071e-01, 6.998951e-01, 8.859918e-01,\n",
      "         8.709173e-01, 7.432938e-01, 1.151721e-01, 7.239814e-01, 3.783888e-02,\n",
      "         6.016306e-01, 1.747507e-02, 5.348259e-01, 2.388836e-01, 3.158804e-01,\n",
      "         7.212593e-01, 3.325908e-01, 9.759754e-02, 1.479806e-01, 8.633196e-02,\n",
      "         2.278757e-01, 7.588009e-01, 3.507197e-01, 9.179978e-01, 1.308187e-01,\n",
      "         8.145546e-01, 2.035242e-01, 3.833942e-01, 7.921473e-01, 4.439260e-01,\n",
      "         1.158979e-01],\n",
      "        [4.116709e-01, 6.886178e-01, 5.658965e-01, 9.467314e-01, 3.397650e-01,\n",
      "         3.405359e-01, 6.731732e-01, 7.534472e-01, 7.235014e-02, 2.592276e-01,\n",
      "         2.124836e-01, 8.129699e-01, 6.576214e-01, 4.594509e-01, 8.026274e-01,\n",
      "         1.258004e-01, 8.960677e-01, 7.618636e-01, 1.480773e-01, 1.405613e-01,\n",
      "         7.812077e-02, 3.211095e-01, 6.132335e-01, 1.434212e-01, 7.761657e-03,\n",
      "         8.169941e-01, 9.052497e-01, 4.046903e-01, 5.611068e-02, 9.849348e-01,\n",
      "         6.637623e-01, 2.918115e-01, 4.345071e-02, 7.493513e-01, 1.538906e-01,\n",
      "         3.819457e-01, 3.229836e-01, 1.997687e-01, 1.442562e-01, 5.913321e-01,\n",
      "         3.204333e-01, 8.481639e-01, 3.194742e-01, 9.412873e-02, 1.208373e-01,\n",
      "         9.783886e-01, 3.825226e-01, 3.243779e-01, 5.331451e-01, 9.354250e-01,\n",
      "         7.890522e-02, 4.143373e-01, 3.998483e-01, 5.989207e-01, 9.411739e-01,\n",
      "         2.088991e-01, 4.280224e-01, 6.581612e-01, 8.721726e-01, 2.253578e-01,\n",
      "         6.831852e-01, 9.342854e-01, 9.838021e-02, 5.312846e-01, 5.257029e-01,\n",
      "         8.668349e-01, 4.807401e-02, 4.457738e-01, 5.635197e-01, 1.759266e-01,\n",
      "         6.685567e-01, 6.255138e-01, 6.868750e-02, 9.737151e-01, 9.181292e-01,\n",
      "         9.668677e-01, 8.967937e-01, 7.062960e-01, 1.218341e-01, 6.337097e-01,\n",
      "         7.553999e-01, 6.861962e-01, 4.891451e-01, 3.173373e-01, 9.414891e-01,\n",
      "         2.898017e-01, 5.092650e-01, 5.033529e-01, 3.354464e-01, 9.100367e-01,\n",
      "         9.133286e-01, 7.255059e-01, 5.552994e-01, 4.556793e-02, 3.716069e-01,\n",
      "         1.432025e-01],\n",
      "        [8.315488e-01, 1.203353e-01, 2.957461e-01, 7.562277e-01, 4.930275e-01,\n",
      "         8.630342e-01, 3.432641e-01, 8.654148e-01, 9.784157e-01, 1.386374e-01,\n",
      "         6.298332e-01, 1.906653e-01, 8.722833e-01, 1.204638e-01, 7.866495e-01,\n",
      "         5.368922e-01, 3.569375e-01, 1.998715e-01, 9.909463e-02, 5.393381e-01,\n",
      "         9.307094e-01, 6.771076e-01, 7.680788e-01, 6.420189e-01, 2.580835e-01,\n",
      "         5.583715e-02, 8.429496e-01, 1.561854e-01, 7.404220e-01, 9.902937e-01,\n",
      "         2.764124e-02, 6.855726e-02, 7.431444e-01, 1.056555e-01, 6.261468e-04,\n",
      "         9.772978e-01, 2.114339e-01, 7.487291e-02, 6.705170e-01, 9.570621e-01,\n",
      "         1.012969e-02, 7.161051e-02, 8.993447e-03, 2.678769e-01, 5.232621e-01,\n",
      "         4.554105e-02, 4.762599e-01, 7.403715e-01, 4.334261e-01, 5.319251e-01,\n",
      "         4.552550e-01, 2.248914e-01, 4.082749e-01, 8.822404e-01, 7.703001e-01,\n",
      "         3.245618e-01, 5.402488e-01, 8.879783e-01, 7.362432e-01, 5.131208e-01,\n",
      "         2.616652e-01, 2.511697e-01, 1.170378e-01, 7.768435e-01, 3.451686e-01,\n",
      "         3.772002e-01, 3.558935e-01, 6.041357e-01, 1.421624e-01, 3.066188e-01,\n",
      "         5.443707e-01, 6.037982e-01, 2.140391e-01, 1.661985e-01, 3.801742e-01,\n",
      "         1.371906e-01, 8.650875e-01, 9.308365e-01, 1.402535e-01, 9.843588e-03,\n",
      "         4.020459e-01, 5.895392e-01, 1.451828e-01, 1.336939e-01, 8.198593e-01,\n",
      "         3.446102e-02, 2.150738e-01, 6.425561e-01, 3.133091e-01, 2.632234e-01,\n",
      "         1.030290e-01, 4.209791e-01, 5.366977e-01, 3.828420e-01, 7.882645e-01,\n",
      "         4.133670e-01],\n",
      "        [5.798191e-01, 7.706052e-01, 6.560581e-01, 4.315485e-01, 9.632946e-01,\n",
      "         5.504004e-01, 4.411691e-02, 3.770216e-01, 1.884651e-01, 7.352352e-03,\n",
      "         6.124843e-01, 8.223770e-01, 5.953986e-01, 3.036937e-01, 9.040032e-01,\n",
      "         8.762395e-01, 2.556009e-01, 5.670869e-01, 1.163397e-01, 3.724650e-01,\n",
      "         4.941264e-01, 6.991103e-01, 8.335410e-01, 5.117174e-01, 4.762797e-01,\n",
      "         9.768161e-01, 6.857647e-01, 6.980698e-01, 1.885474e-03, 9.658325e-01,\n",
      "         7.791395e-01, 5.938469e-01, 6.196814e-01, 6.507870e-01, 8.826604e-01,\n",
      "         8.739467e-01, 9.336832e-01, 3.697795e-01, 6.809060e-01, 3.119789e-01,\n",
      "         1.971885e-01, 4.682425e-01, 4.949461e-01, 2.062487e-01, 6.390322e-01,\n",
      "         8.444995e-02, 4.753996e-01, 2.739307e-01, 5.821069e-01, 1.667339e-01,\n",
      "         6.989588e-01, 6.243629e-01, 5.839253e-01, 2.127936e-01, 9.381703e-01,\n",
      "         2.191830e-01, 3.434566e-01, 3.237225e-01, 4.392267e-01, 3.825603e-01,\n",
      "         2.879131e-02, 5.292091e-01, 1.404537e-01, 7.821865e-01, 7.667381e-02,\n",
      "         3.075909e-01, 4.778767e-02, 3.908966e-01, 7.975510e-01, 4.947040e-01,\n",
      "         5.617792e-01, 7.361048e-02, 8.843601e-03, 5.577171e-01, 8.180618e-03,\n",
      "         6.970084e-01, 4.325565e-01, 5.526459e-01, 5.035620e-01, 1.360551e-01,\n",
      "         2.269985e-01, 8.245214e-01, 3.456196e-01, 2.794327e-01, 1.735128e-01,\n",
      "         9.273338e-02, 9.267373e-01, 9.251210e-01, 1.693742e-01, 4.490854e-01,\n",
      "         9.769526e-01, 5.970170e-01, 6.282014e-01, 1.617041e-01, 1.798627e-01,\n",
      "         1.425661e-01],\n",
      "        [7.069588e-02, 4.707146e-02, 3.617759e-01, 8.818086e-01, 7.397484e-01,\n",
      "         1.314421e-01, 6.968021e-02, 2.992796e-01, 2.462198e-01, 7.561448e-01,\n",
      "         2.600976e-01, 9.397829e-02, 8.732140e-01, 9.005287e-01, 5.651404e-01,\n",
      "         7.184433e-01, 1.605100e-01, 6.336463e-01, 9.852617e-01, 7.190812e-02,\n",
      "         2.078744e-01, 3.223258e-01, 1.698223e-01, 9.097611e-01, 8.912281e-01,\n",
      "         7.487643e-01, 2.970842e-01, 6.797961e-01, 8.061000e-01, 9.211813e-01,\n",
      "         4.804045e-01, 9.196204e-01, 3.329125e-01, 7.785466e-01, 8.007564e-01,\n",
      "         4.206517e-01, 9.038326e-01, 6.723464e-01, 9.226937e-01, 1.785129e-01,\n",
      "         7.674378e-02, 7.829006e-01, 2.575606e-01, 3.957441e-01, 6.712303e-01,\n",
      "         4.834785e-01, 4.263215e-01, 5.087562e-01, 2.864804e-01, 8.032137e-02,\n",
      "         8.598603e-01, 5.350211e-01, 7.743543e-01, 8.271500e-01, 9.129247e-01,\n",
      "         3.677535e-02, 4.761246e-01, 3.976822e-03, 8.789511e-01, 1.037905e-01,\n",
      "         9.310852e-01, 2.821678e-01, 5.834340e-01, 5.076036e-01, 5.264525e-01,\n",
      "         2.878749e-01, 5.539680e-01, 2.421315e-01, 7.884032e-01, 4.218242e-01,\n",
      "         2.159554e-01, 5.401233e-01, 6.458198e-01, 4.527960e-01, 9.533405e-01,\n",
      "         6.361708e-01, 4.688525e-02, 1.044580e-01, 6.435687e-01, 7.478937e-01,\n",
      "         7.487416e-01, 8.349302e-01, 7.953835e-01, 7.071801e-01, 6.685587e-01,\n",
      "         1.975519e-01, 1.530710e-01, 7.382829e-01, 6.554341e-01, 9.905547e-01,\n",
      "         9.535045e-01, 5.615770e-01, 7.278168e-01, 1.864769e-01, 7.323013e-01,\n",
      "         6.468828e-01],\n",
      "        [4.984853e-01, 4.654717e-01, 3.691103e-01, 8.990254e-01, 4.075536e-01,\n",
      "         4.313481e-02, 6.583644e-01, 3.637806e-01, 8.819624e-01, 4.965411e-01,\n",
      "         2.872148e-01, 8.858533e-01, 6.782354e-01, 6.594195e-01, 6.569061e-01,\n",
      "         9.234203e-01, 1.670973e-01, 6.804079e-01, 1.234292e-01, 6.697017e-02,\n",
      "         3.020030e-01, 8.295566e-01, 7.216089e-01, 8.172568e-01, 3.607491e-01,\n",
      "         1.373029e-01, 2.126962e-01, 5.716248e-01, 7.815738e-01, 7.023510e-01,\n",
      "         4.380720e-01, 5.126917e-01, 2.741938e-01, 1.911491e-02, 7.563867e-01,\n",
      "         8.367671e-01, 6.950767e-01, 8.148835e-01, 2.570317e-01, 8.433182e-01,\n",
      "         7.948998e-01, 3.301060e-02, 4.054500e-01, 2.677642e-01, 8.488960e-01,\n",
      "         4.462327e-01, 7.365976e-01, 9.476846e-01, 4.405968e-01, 8.729219e-01,\n",
      "         4.965202e-01, 1.333536e-01, 7.155542e-01, 8.128989e-01, 7.001054e-01,\n",
      "         5.531882e-01, 2.923158e-01, 1.443097e-01, 9.619027e-02, 4.198630e-01,\n",
      "         7.931869e-01, 8.704352e-01, 8.463064e-01, 1.239480e-01, 2.802736e-01,\n",
      "         9.931820e-01, 8.755403e-01, 8.130372e-03, 2.272840e-01, 3.995311e-01,\n",
      "         5.626981e-01, 6.778621e-01, 3.603454e-01, 4.335598e-01, 4.612371e-01,\n",
      "         4.637826e-01, 6.123336e-01, 7.249948e-01, 8.535958e-01, 3.513342e-02,\n",
      "         3.505644e-01, 6.537597e-01, 8.351595e-01, 8.887743e-01, 7.139001e-01,\n",
      "         7.806341e-01, 3.623970e-01, 7.652919e-01, 1.977590e-01, 4.756248e-02,\n",
      "         7.755599e-01, 1.844298e-01, 6.157577e-01, 6.151801e-01, 9.761969e-01,\n",
      "         3.940811e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.059644,  0.122385,  0.054880,  0.034898, -0.047445],\n",
      "          [-0.081196,  0.093398,  0.033774, -0.009533,  0.183814],\n",
      "          [ 0.147908, -0.011292, -0.043454,  0.046849,  0.188372],\n",
      "          [-0.026934,  0.106487,  0.057912, -0.108951, -0.091091],\n",
      "          [-0.005009, -0.178705, -0.116888, -0.123599,  0.074031]]],\n",
      "\n",
      "\n",
      "        [[[-0.054648, -0.172300,  0.170368,  0.000774, -0.005976],\n",
      "          [ 0.040016,  0.026377,  0.067789,  0.186313,  0.181453],\n",
      "          [-0.092066, -0.048551,  0.095915,  0.038220,  0.146470],\n",
      "          [-0.004170, -0.167477,  0.087647,  0.065888,  0.056299],\n",
      "          [ 0.006913,  0.030495, -0.047353, -0.034590, -0.133458]]],\n",
      "\n",
      "\n",
      "        [[[-0.015036,  0.087201,  0.190553, -0.184634, -0.158324],\n",
      "          [ 0.112413,  0.169747,  0.168770,  0.137192, -0.025465],\n",
      "          [ 0.190635, -0.129703,  0.058890,  0.009556,  0.052048],\n",
      "          [-0.030724,  0.175588,  0.117806, -0.087697,  0.136340],\n",
      "          [ 0.059493, -0.009909,  0.061570, -0.102250,  0.088304]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.010978, -0.028321,  0.012218,  0.003010,  0.157992],\n",
      "          [-0.191109, -0.113886,  0.061198, -0.007757,  0.045648],\n",
      "          [ 0.160257,  0.178703, -0.034128,  0.137813, -0.130118],\n",
      "          [-0.027603,  0.171828, -0.096782,  0.151673, -0.179141],\n",
      "          [-0.133752,  0.073266, -0.049850,  0.137855,  0.110286]]],\n",
      "\n",
      "\n",
      "        [[[-0.063342,  0.179706, -0.182352,  0.134164, -0.044162],\n",
      "          [ 0.052543, -0.007675,  0.093289,  0.001898,  0.049550],\n",
      "          [ 0.166009, -0.019580, -0.086163, -0.106541,  0.166378],\n",
      "          [-0.134013,  0.012271,  0.034601,  0.012561,  0.051148],\n",
      "          [-0.015744, -0.066473,  0.011128,  0.059416, -0.198348]]],\n",
      "\n",
      "\n",
      "        [[[ 0.029246,  0.024592, -0.030050,  0.173568,  0.061543],\n",
      "          [-0.184751,  0.009492,  0.125525, -0.105853, -0.157867],\n",
      "          [-0.121707, -0.182111,  0.098856, -0.045333,  0.157907],\n",
      "          [ 0.023734,  0.137037, -0.176866,  0.116411, -0.116189],\n",
      "          [-0.190899, -0.084227,  0.113674, -0.141780, -0.003204]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.134085, -0.181830, -0.134169,  0.156080, -0.114018,  0.006116,\n",
      "        -0.005054,  0.110974, -0.017811,  0.078291,  0.062769, -0.099896,\n",
      "        -0.125767,  0.173757,  0.177266,  0.085861,  0.067351,  0.051246,\n",
      "         0.171340,  0.045016,  0.144497,  0.191839,  0.144227, -0.063029,\n",
      "        -0.042944,  0.031359, -0.128584, -0.028449, -0.085710, -0.094952,\n",
      "        -0.004197,  0.043744,  0.022418, -0.126849, -0.160125, -0.055974,\n",
      "         0.094572,  0.168951, -0.190616, -0.100043,  0.037248, -0.161823,\n",
      "         0.188211,  0.152683, -0.118918,  0.133713, -0.097256, -0.002078,\n",
      "         0.198313,  0.010065,  0.095967,  0.035482,  0.036748, -0.187011,\n",
      "         0.040829,  0.175866, -0.027064,  0.162181,  0.104434,  0.002442,\n",
      "        -0.163096, -0.033682,  0.106355, -0.146866], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-1.753271e-03, -1.866622e-02, -1.012556e-02, -1.044820e-02,\n",
      "            1.910850e-03],\n",
      "          [-1.646343e-02, -1.943393e-02,  1.218692e-02, -1.438251e-02,\n",
      "            1.741940e-02],\n",
      "          [-2.322438e-02, -1.622215e-03, -7.236455e-03,  1.401136e-02,\n",
      "            2.324468e-03],\n",
      "          [-2.112757e-03, -1.490897e-02, -1.651351e-02, -2.144308e-02,\n",
      "           -3.181437e-03],\n",
      "          [ 5.421311e-03, -5.540058e-03,  1.492860e-02, -1.893090e-02,\n",
      "            2.080406e-02]],\n",
      "\n",
      "         [[ 3.806522e-03,  1.179820e-02, -1.321140e-02,  6.004712e-03,\n",
      "            1.870261e-02],\n",
      "          [ 1.905649e-02,  2.090995e-02, -3.286228e-03, -2.087569e-02,\n",
      "            2.436032e-02],\n",
      "          [ 1.024647e-02, -1.289275e-02,  1.352219e-02,  1.079943e-02,\n",
      "           -5.924707e-03],\n",
      "          [ 2.088674e-02, -9.618399e-03,  1.272638e-02, -2.279739e-02,\n",
      "           -7.740304e-03],\n",
      "          [ 1.021329e-02, -8.241311e-03,  1.550968e-02, -1.191756e-02,\n",
      "           -1.032650e-02]],\n",
      "\n",
      "         [[-7.365953e-03, -5.258009e-03,  9.171324e-03, -1.220730e-02,\n",
      "            3.145883e-03],\n",
      "          [-1.455469e-02,  1.620653e-02, -2.024377e-02,  4.234221e-04,\n",
      "            1.722063e-02],\n",
      "          [ 1.566272e-02,  2.410620e-03, -3.013726e-03, -3.357697e-03,\n",
      "            2.414448e-02],\n",
      "          [-6.995643e-03, -4.999865e-03,  7.950487e-03, -5.287867e-03,\n",
      "            1.746708e-02],\n",
      "          [ 4.358763e-03,  1.642072e-02,  1.258119e-02,  6.915743e-03,\n",
      "            8.027790e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.757905e-03,  1.726638e-02,  1.925730e-02, -1.792168e-02,\n",
      "            6.511142e-03],\n",
      "          [-1.785794e-03,  6.567536e-03, -4.952082e-03, -3.079688e-03,\n",
      "            8.311542e-03],\n",
      "          [-2.038304e-02,  1.677860e-03,  3.353924e-03,  8.476729e-03,\n",
      "           -1.101883e-02],\n",
      "          [-1.467361e-02,  2.663622e-03,  4.626956e-03,  5.273644e-03,\n",
      "           -2.401123e-02],\n",
      "          [ 2.437655e-03,  1.590577e-02, -2.486727e-02,  9.355860e-03,\n",
      "            3.833035e-03]],\n",
      "\n",
      "         [[-1.741584e-02,  2.078982e-02,  6.979676e-03,  1.326305e-02,\n",
      "            2.087332e-02],\n",
      "          [ 1.051621e-02, -1.933491e-02,  1.794331e-02,  9.755082e-04,\n",
      "           -3.386889e-03],\n",
      "          [ 2.135980e-02, -4.894694e-03, -1.481080e-03, -5.878344e-03,\n",
      "           -7.616827e-03],\n",
      "          [ 1.312190e-02, -2.495231e-02, -1.102208e-02,  1.987466e-02,\n",
      "           -1.565007e-02],\n",
      "          [ 2.427796e-02,  1.598975e-03,  9.721590e-03, -1.466897e-02,\n",
      "           -3.404101e-03]],\n",
      "\n",
      "         [[-2.142073e-02,  1.541829e-02, -1.407684e-02,  9.061638e-04,\n",
      "           -1.387570e-02],\n",
      "          [ 1.506932e-02,  2.468100e-02,  6.760450e-03, -2.037466e-03,\n",
      "           -1.571306e-02],\n",
      "          [ 2.494051e-02, -1.807117e-02,  2.246811e-02,  1.844710e-02,\n",
      "           -9.220341e-03],\n",
      "          [ 9.404520e-03,  1.303561e-02,  2.368242e-02,  1.650382e-02,\n",
      "           -2.422875e-02],\n",
      "          [ 2.207811e-02,  1.240206e-02, -1.894653e-03,  2.297698e-02,\n",
      "           -5.070880e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.526145e-03, -8.332241e-03,  1.847376e-02,  1.733790e-02,\n",
      "           -1.226192e-02],\n",
      "          [ 1.272231e-03,  1.962605e-02, -4.300740e-03, -8.152183e-03,\n",
      "            2.162278e-02],\n",
      "          [-8.539489e-03,  2.011034e-02,  2.906600e-03, -5.957324e-03,\n",
      "           -1.364699e-02],\n",
      "          [-3.421400e-04, -1.364192e-02,  7.858312e-03,  1.630345e-02,\n",
      "            2.788156e-03],\n",
      "          [-5.425476e-04, -6.995335e-03, -1.699373e-02, -1.120008e-02,\n",
      "           -1.965528e-02]],\n",
      "\n",
      "         [[ 1.860772e-02,  1.720423e-02, -1.513947e-02,  2.402532e-02,\n",
      "            1.491232e-02],\n",
      "          [-1.338490e-02, -9.816840e-03,  2.085694e-02,  2.272878e-02,\n",
      "            1.602595e-02],\n",
      "          [-2.082951e-02, -2.463832e-02,  5.911142e-03, -1.952518e-03,\n",
      "           -2.228852e-03],\n",
      "          [ 1.393113e-02,  1.577178e-02, -8.591766e-03, -1.629997e-02,\n",
      "           -1.571501e-02],\n",
      "          [-2.371715e-02, -1.585611e-02,  5.675454e-03,  1.401619e-02,\n",
      "           -2.391530e-02]],\n",
      "\n",
      "         [[ 4.639810e-03, -1.894553e-02, -1.953998e-02,  1.609643e-02,\n",
      "           -2.087028e-02],\n",
      "          [ 2.958491e-03, -4.060244e-03,  2.312190e-02, -1.241253e-02,\n",
      "           -6.768757e-03],\n",
      "          [ 1.147732e-02, -2.134457e-03, -2.400728e-02, -1.612889e-02,\n",
      "           -2.470224e-02],\n",
      "          [-1.374404e-02,  2.593622e-03,  1.812948e-02,  8.681269e-03,\n",
      "           -9.899122e-03],\n",
      "          [ 3.510678e-03,  1.175296e-02, -4.369836e-03,  5.511157e-04,\n",
      "           -2.196323e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.467925e-02,  1.886127e-02,  1.438022e-02,  6.507961e-03,\n",
      "            1.517974e-02],\n",
      "          [-5.594324e-03, -3.570314e-03,  2.018679e-02, -1.615662e-02,\n",
      "            1.683884e-02],\n",
      "          [-1.219282e-02,  2.419522e-03, -1.399414e-02,  1.202145e-02,\n",
      "           -2.371130e-02],\n",
      "          [-4.299421e-03,  2.220982e-02,  1.269181e-02,  3.712270e-03,\n",
      "            2.336353e-02],\n",
      "          [ 2.426403e-02, -1.123643e-02,  7.782577e-03, -3.917133e-03,\n",
      "            2.378412e-02]],\n",
      "\n",
      "         [[-1.259873e-02,  9.139134e-03, -2.138520e-03,  9.071233e-03,\n",
      "           -1.332826e-02],\n",
      "          [ 1.443514e-02, -2.295905e-02,  1.770355e-02,  1.497503e-02,\n",
      "           -8.511905e-03],\n",
      "          [ 5.765092e-03, -1.967484e-02,  1.026005e-03,  2.879489e-03,\n",
      "           -1.336011e-02],\n",
      "          [ 1.038172e-02, -1.992713e-02, -2.294684e-03,  1.944446e-02,\n",
      "           -9.177338e-03],\n",
      "          [ 1.133714e-02,  6.704303e-03, -1.895113e-02,  2.159874e-02,\n",
      "            2.354289e-02]],\n",
      "\n",
      "         [[ 1.388948e-02,  2.102001e-02,  6.117076e-04, -1.536644e-02,\n",
      "           -1.304322e-02],\n",
      "          [ 1.100434e-02, -3.092477e-03,  2.979115e-03, -7.700760e-03,\n",
      "           -2.383637e-02],\n",
      "          [ 2.251401e-02, -1.209539e-02,  1.172704e-02,  4.996654e-03,\n",
      "            1.777221e-02],\n",
      "          [ 7.323703e-03, -1.207570e-02,  1.659498e-02,  1.563387e-02,\n",
      "            6.570721e-03],\n",
      "          [ 2.449836e-02, -2.409406e-04,  2.137973e-02, -4.995933e-03,\n",
      "            1.950081e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.465777e-02, -2.241067e-02,  2.410786e-02,  6.240238e-03,\n",
      "            2.345997e-02],\n",
      "          [ 2.148206e-02,  1.651226e-02,  1.915497e-02, -3.512308e-03,\n",
      "           -2.330383e-02],\n",
      "          [ 1.442352e-02,  2.082796e-02, -6.173814e-03,  2.179876e-02,\n",
      "            1.665269e-02],\n",
      "          [ 2.013350e-02,  1.188276e-02, -1.262619e-02,  1.956497e-02,\n",
      "           -1.002834e-02],\n",
      "          [ 1.620438e-02,  1.542430e-02, -1.596776e-02,  4.025817e-03,\n",
      "            2.137225e-02]],\n",
      "\n",
      "         [[ 6.140485e-03, -3.855789e-03, -9.847172e-04, -9.313706e-03,\n",
      "           -1.261718e-02],\n",
      "          [-1.151092e-02,  2.160806e-02,  2.358218e-02, -1.062721e-02,\n",
      "            4.999600e-04],\n",
      "          [-2.138410e-04,  9.577828e-03,  3.897980e-03,  2.456360e-02,\n",
      "            1.101774e-02],\n",
      "          [ 1.879340e-03, -6.967103e-03,  2.446817e-02, -1.948519e-02,\n",
      "            1.296327e-02],\n",
      "          [ 1.137846e-02,  1.934343e-02, -2.424245e-02, -2.037673e-02,\n",
      "            2.278926e-02]],\n",
      "\n",
      "         [[-1.035008e-02,  1.445416e-02, -1.445850e-02, -6.391222e-03,\n",
      "            2.160983e-02],\n",
      "          [-1.564614e-02, -2.426600e-02, -1.662595e-02, -8.878727e-03,\n",
      "           -1.548347e-02],\n",
      "          [-1.437914e-02,  1.059285e-02,  2.114294e-02, -2.443139e-02,\n",
      "           -1.579032e-02],\n",
      "          [-1.714451e-02, -5.300084e-03, -1.797574e-02, -1.287544e-02,\n",
      "            2.342638e-03],\n",
      "          [ 1.279025e-02,  1.665598e-02, -1.373945e-02, -2.128835e-02,\n",
      "           -4.566945e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.553078e-03, -1.067939e-02,  5.843446e-03,  1.557808e-03,\n",
      "            3.223309e-03],\n",
      "          [ 2.369439e-03, -2.499621e-02, -9.393040e-04,  8.231165e-03,\n",
      "            1.892925e-02],\n",
      "          [ 2.277663e-03, -2.329519e-02,  1.210035e-02,  1.252348e-02,\n",
      "           -1.303539e-02],\n",
      "          [ 4.996415e-04, -1.051687e-04,  2.032625e-02,  6.754508e-03,\n",
      "            8.457361e-03],\n",
      "          [-1.186085e-02, -3.430840e-03,  7.242816e-03, -1.316502e-02,\n",
      "            2.297157e-03]],\n",
      "\n",
      "         [[ 1.572542e-02, -1.393383e-02,  1.332570e-03,  1.793909e-02,\n",
      "            2.499377e-02],\n",
      "          [ 2.417137e-02, -7.296115e-03,  1.593084e-02,  4.827857e-03,\n",
      "           -3.314778e-03],\n",
      "          [-6.738504e-03,  1.593890e-02,  8.243265e-03,  2.067602e-02,\n",
      "           -1.461163e-02],\n",
      "          [ 1.814858e-02,  2.348062e-02,  1.725785e-02,  1.828855e-02,\n",
      "            1.906367e-02],\n",
      "          [-1.623372e-02, -2.157575e-02, -1.512477e-02, -1.617039e-02,\n",
      "           -7.561706e-04]],\n",
      "\n",
      "         [[ 8.965300e-03, -1.922286e-02, -1.560302e-02, -1.356357e-02,\n",
      "            3.545770e-03],\n",
      "          [ 1.948055e-02, -2.199725e-02, -1.087943e-02,  5.665589e-03,\n",
      "            2.255905e-02],\n",
      "          [-1.043315e-02,  5.791489e-03, -1.946247e-02,  1.541725e-02,\n",
      "            2.388781e-02],\n",
      "          [-1.917729e-02,  2.129238e-02, -1.695706e-02,  6.733881e-03,\n",
      "            7.185044e-03],\n",
      "          [-2.246857e-02, -2.446529e-02,  1.637195e-02,  9.504782e-03,\n",
      "            2.651755e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.230729e-02,  1.224900e-02,  1.742261e-02,  1.314475e-02,\n",
      "           -5.833972e-03],\n",
      "          [-1.711262e-02,  1.366328e-02, -1.409512e-02,  2.111584e-03,\n",
      "            2.286494e-03],\n",
      "          [-6.532466e-03, -1.321947e-02,  7.334160e-03, -1.031654e-02,\n",
      "           -5.324095e-03],\n",
      "          [ 2.218563e-02, -9.796739e-03, -7.138530e-03,  1.267136e-02,\n",
      "            9.230860e-04],\n",
      "          [ 2.327335e-02, -2.183747e-02,  1.894272e-02,  2.436426e-03,\n",
      "           -1.240225e-02]],\n",
      "\n",
      "         [[ 8.282270e-04,  1.362333e-02, -8.464897e-03,  1.501229e-02,\n",
      "            2.343925e-02],\n",
      "          [-2.443766e-03, -2.149431e-02,  1.655235e-02,  4.348269e-03,\n",
      "            1.003096e-02],\n",
      "          [ 1.621678e-03, -5.619293e-03, -1.654870e-02, -2.203435e-02,\n",
      "           -1.235199e-02],\n",
      "          [-1.784439e-02, -1.644456e-02,  5.328264e-04, -3.190897e-05,\n",
      "            1.895072e-02],\n",
      "          [-2.030096e-02,  1.755507e-02,  1.089923e-02, -2.120993e-02,\n",
      "           -4.831556e-03]],\n",
      "\n",
      "         [[ 1.944277e-02,  4.670430e-03,  1.971226e-02, -3.387785e-03,\n",
      "           -5.395105e-03],\n",
      "          [ 1.716562e-02, -7.240048e-03, -2.174788e-02, -1.686623e-02,\n",
      "           -1.408098e-02],\n",
      "          [-1.291187e-02,  2.002476e-02,  1.721038e-02, -2.296363e-02,\n",
      "           -9.211246e-03],\n",
      "          [-1.090897e-02, -7.984858e-03,  2.051761e-02, -2.231535e-02,\n",
      "            1.548271e-02],\n",
      "          [-1.608979e-02,  1.070490e-03,  6.117517e-03,  6.960334e-03,\n",
      "            2.107834e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.309377e-02, -3.859363e-04, -1.905374e-02,  1.211408e-02,\n",
      "            2.110366e-02],\n",
      "          [-2.224490e-02, -1.100541e-02, -1.891876e-02,  1.218961e-02,\n",
      "            2.435274e-02],\n",
      "          [-1.019631e-02,  1.265392e-03, -2.389521e-02, -1.927588e-02,\n",
      "            1.915895e-02],\n",
      "          [-1.256744e-02,  1.640115e-02, -1.999577e-02, -1.398985e-02,\n",
      "            2.228668e-02],\n",
      "          [ 9.274110e-06, -1.386585e-02,  2.223440e-02,  8.078964e-03,\n",
      "           -1.581671e-02]],\n",
      "\n",
      "         [[ 2.277513e-02, -1.172746e-02,  1.009273e-02,  2.271322e-02,\n",
      "            3.040832e-03],\n",
      "          [-1.890172e-02, -5.951390e-03,  2.439940e-03, -1.373533e-04,\n",
      "            4.978772e-03],\n",
      "          [ 2.464315e-03, -2.222588e-02,  2.139300e-03, -2.429852e-02,\n",
      "            1.533771e-03],\n",
      "          [-7.183561e-03, -1.228429e-02,  1.576078e-02,  4.181335e-03,\n",
      "            2.398285e-02],\n",
      "          [-2.390718e-02,  1.573209e-04, -1.155982e-02,  1.460697e-02,\n",
      "           -7.790133e-03]],\n",
      "\n",
      "         [[-7.341381e-03, -2.179242e-02,  5.745698e-03,  2.266579e-02,\n",
      "            3.353249e-03],\n",
      "          [ 1.486215e-02, -4.101077e-03, -6.343972e-03, -1.477354e-02,\n",
      "            2.392914e-03],\n",
      "          [-2.450816e-02,  2.336171e-02, -5.655447e-03,  2.053018e-02,\n",
      "           -1.347323e-02],\n",
      "          [ 5.511332e-03,  1.864586e-02, -1.276541e-02,  2.266097e-02,\n",
      "            1.963088e-02],\n",
      "          [-2.065412e-02,  2.343351e-03,  3.931617e-03, -2.353859e-02,\n",
      "           -5.672619e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.023508e-02,  8.060941e-03, -1.582581e-02, -9.210128e-03,\n",
      "           -2.426114e-02],\n",
      "          [ 1.628497e-02,  2.375323e-03, -1.847913e-03, -1.055199e-02,\n",
      "            8.020364e-04],\n",
      "          [ 1.304409e-02,  1.511170e-02,  8.139687e-03,  2.959743e-06,\n",
      "            2.627483e-03],\n",
      "          [ 2.274597e-02,  1.429018e-02,  9.043401e-03, -2.046447e-02,\n",
      "            1.838210e-02],\n",
      "          [ 1.584039e-02, -1.172547e-02, -1.057448e-02, -9.932527e-03,\n",
      "           -6.909421e-03]],\n",
      "\n",
      "         [[-1.797209e-02, -7.248184e-03, -1.722152e-02, -2.080942e-03,\n",
      "           -8.073289e-03],\n",
      "          [ 1.216088e-02,  2.208276e-02, -2.108236e-02,  2.305147e-02,\n",
      "           -1.127850e-02],\n",
      "          [ 2.347935e-02, -2.546497e-04,  2.474608e-02, -1.157696e-02,\n",
      "           -8.430336e-03],\n",
      "          [ 1.722059e-02, -1.918636e-02, -1.330438e-02, -1.094838e-02,\n",
      "           -2.775528e-04],\n",
      "          [ 3.467355e-03, -2.339359e-02,  1.059910e-03, -1.140340e-02,\n",
      "           -1.043241e-02]],\n",
      "\n",
      "         [[ 1.149788e-03,  1.397970e-02,  1.175728e-02,  2.144732e-02,\n",
      "            1.662093e-02],\n",
      "          [-1.099418e-02,  6.509693e-03, -6.537918e-03,  3.155705e-03,\n",
      "           -7.933151e-03],\n",
      "          [ 1.401187e-02,  4.545277e-03,  1.779694e-02, -1.698630e-02,\n",
      "           -5.286291e-03],\n",
      "          [ 2.158900e-02,  1.549664e-02,  3.021752e-03,  1.935090e-02,\n",
      "           -2.149476e-02],\n",
      "          [-2.064038e-02, -1.977264e-02,  1.273550e-02, -1.728291e-02,\n",
      "            1.731428e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.618697e-03,  2.659645e-03, -1.353145e-02, -4.372796e-03,\n",
      "            2.245448e-02],\n",
      "          [-1.459366e-02, -1.128620e-02, -1.746973e-03, -6.733935e-03,\n",
      "           -3.432656e-03],\n",
      "          [ 7.404735e-03, -4.283246e-03,  6.441580e-03, -1.517555e-02,\n",
      "            6.641233e-03],\n",
      "          [-2.289485e-02, -1.791313e-03,  2.492793e-02, -1.441349e-02,\n",
      "           -2.244755e-02],\n",
      "          [ 1.404502e-02,  1.661826e-03, -1.895005e-02, -1.338734e-02,\n",
      "           -2.132512e-02]],\n",
      "\n",
      "         [[ 1.871679e-02,  4.447322e-03,  8.023845e-03,  9.322444e-03,\n",
      "           -9.891599e-03],\n",
      "          [ 6.311761e-03, -1.118946e-02,  1.670578e-02,  9.668993e-03,\n",
      "            1.734332e-02],\n",
      "          [-7.942494e-03, -2.475578e-02, -7.375684e-04,  2.352373e-02,\n",
      "            5.004829e-03],\n",
      "          [-1.675354e-02, -2.238354e-03,  6.721074e-03, -1.000408e-02,\n",
      "           -2.253468e-02],\n",
      "          [ 9.393333e-03,  1.676818e-03, -4.930317e-03,  1.938417e-02,\n",
      "           -1.668642e-02]],\n",
      "\n",
      "         [[ 1.236151e-02,  5.931571e-03, -2.186234e-02, -1.402172e-02,\n",
      "            1.684994e-02],\n",
      "          [ 4.839191e-03, -3.414210e-03,  2.466507e-02, -9.385601e-03,\n",
      "           -8.085137e-03],\n",
      "          [-1.082023e-02,  1.408606e-02, -1.598870e-02, -2.454395e-02,\n",
      "            1.724413e-02],\n",
      "          [-2.977187e-03, -1.469732e-02,  5.494516e-03, -1.621999e-02,\n",
      "           -1.149074e-02],\n",
      "          [-1.950378e-02, -1.279554e-02,  2.286971e-02, -1.428342e-02,\n",
      "            7.045828e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 6.455002e-03, -1.856355e-02, -5.213922e-03, -5.268287e-03,\n",
      "           -1.411747e-02],\n",
      "          [ 1.935225e-02,  2.403578e-02, -2.117640e-02, -1.555152e-02,\n",
      "           -8.987006e-03],\n",
      "          [-1.056516e-02,  1.439731e-02, -1.407009e-02, -1.693948e-02,\n",
      "            1.383677e-02],\n",
      "          [ 1.333138e-02,  7.686926e-03, -1.309941e-02,  1.341402e-02,\n",
      "            1.179436e-02],\n",
      "          [-2.158428e-02,  1.178301e-02, -1.983541e-02, -1.774159e-02,\n",
      "            9.746142e-04]],\n",
      "\n",
      "         [[ 2.451315e-02, -1.652014e-02, -1.743390e-02, -1.092800e-02,\n",
      "            1.296792e-03],\n",
      "          [-8.652937e-03,  1.288483e-02,  1.985841e-02, -1.392848e-02,\n",
      "            1.382880e-02],\n",
      "          [-9.904262e-04,  1.071324e-02, -1.141880e-02,  1.576331e-02,\n",
      "           -6.662194e-03],\n",
      "          [ 1.748179e-02, -2.380422e-02,  1.928314e-02,  2.317030e-02,\n",
      "           -2.862129e-03],\n",
      "          [ 1.355829e-02, -2.170652e-04,  3.535375e-03, -4.127990e-03,\n",
      "           -1.378266e-02]],\n",
      "\n",
      "         [[ 9.081146e-03,  1.229459e-02, -1.491813e-02, -1.778880e-02,\n",
      "           -2.124623e-02],\n",
      "          [ 1.664571e-02,  1.940507e-02, -1.440697e-02,  6.533729e-03,\n",
      "           -2.485527e-02],\n",
      "          [-5.554995e-03, -4.665161e-03,  1.291329e-03, -6.111830e-03,\n",
      "           -1.737287e-02],\n",
      "          [-7.810930e-03, -7.522052e-03,  7.588657e-03,  9.081213e-03,\n",
      "           -5.767234e-04],\n",
      "          [ 1.159420e-02, -2.487658e-02,  2.176953e-02,  1.719995e-02,\n",
      "            1.816524e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.153074e-02,  1.180594e-02,  1.483902e-02, -2.406219e-02,\n",
      "            9.043409e-03],\n",
      "          [ 8.213410e-03,  1.157673e-02,  1.026957e-02,  1.003260e-02,\n",
      "            2.327234e-02],\n",
      "          [ 1.462177e-02,  8.639453e-03,  2.472952e-02, -1.537064e-02,\n",
      "           -2.288814e-02],\n",
      "          [ 1.512406e-02, -1.036097e-02, -1.345042e-03,  1.478847e-03,\n",
      "           -1.285688e-02],\n",
      "          [ 8.702980e-03, -9.504619e-03,  1.029358e-02,  2.428434e-02,\n",
      "           -1.487766e-02]],\n",
      "\n",
      "         [[-1.330743e-02, -2.918810e-03, -5.696397e-03,  1.993631e-02,\n",
      "           -2.370291e-02],\n",
      "          [ 2.273044e-02,  2.156207e-03, -4.551895e-04,  7.181587e-03,\n",
      "            9.461196e-03],\n",
      "          [ 5.792279e-03, -1.558427e-02, -8.163702e-03,  5.579628e-04,\n",
      "           -4.628455e-03],\n",
      "          [-1.878328e-02, -4.098613e-03, -2.226321e-02, -1.890671e-02,\n",
      "           -7.845690e-03],\n",
      "          [ 1.921459e-02, -1.747787e-02, -1.257682e-02, -2.054205e-02,\n",
      "           -1.052898e-02]],\n",
      "\n",
      "         [[ 7.881815e-03, -1.383339e-02,  2.368884e-02,  1.787860e-02,\n",
      "            2.944376e-03],\n",
      "          [ 1.887916e-02,  1.326557e-02, -1.879624e-02, -2.026762e-02,\n",
      "            2.400227e-02],\n",
      "          [ 7.072689e-03, -1.016639e-02,  2.062690e-02, -8.357137e-03,\n",
      "           -1.292797e-02],\n",
      "          [ 4.148725e-03, -7.926067e-03,  6.431838e-03, -8.259024e-04,\n",
      "           -2.327954e-02],\n",
      "          [ 2.220264e-02, -2.264040e-02, -9.215146e-03, -1.020682e-02,\n",
      "            2.176314e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.645564e-02,  6.752014e-04, -1.229495e-03, -1.601602e-02,\n",
      "        -9.925571e-03,  1.406084e-02, -7.149095e-03, -1.526239e-02,\n",
      "         2.335885e-02,  2.134348e-02, -1.708833e-02,  1.557101e-02,\n",
      "         1.585173e-02, -1.916933e-02, -1.171944e-02,  2.814773e-04,\n",
      "         1.734735e-02, -7.951776e-03,  2.237109e-02,  1.066679e-02,\n",
      "         1.071069e-02, -1.135212e-02,  7.559547e-03, -7.597083e-03,\n",
      "         2.094591e-02, -1.190394e-02,  2.221694e-03,  1.070495e-02,\n",
      "         6.101197e-03,  2.042714e-02,  1.221120e-02, -2.119615e-02,\n",
      "         1.465317e-03,  2.212751e-02, -2.415174e-02,  2.325169e-02,\n",
      "         1.993589e-02, -2.571311e-03, -1.499535e-02,  1.012182e-02,\n",
      "        -2.489345e-02, -2.433816e-03, -2.367085e-02, -1.126212e-02,\n",
      "        -1.129270e-03,  5.482202e-03,  2.267578e-02,  2.037187e-02,\n",
      "         1.525539e-02, -3.689587e-03,  2.263104e-02, -1.290226e-02,\n",
      "        -1.564320e-02, -8.828383e-03,  1.714315e-02, -1.117798e-02,\n",
      "        -2.034261e-02, -7.498767e-03, -2.294689e-02,  2.010869e-02,\n",
      "        -1.911747e-02,  1.938408e-02, -1.539261e-02,  1.892486e-02,\n",
      "        -2.447279e-02,  1.626391e-02,  8.034391e-03, -1.264145e-02,\n",
      "        -2.475524e-02,  7.744869e-03,  9.298325e-05,  1.077718e-02,\n",
      "         1.681920e-02, -3.197948e-03,  3.145078e-03,  9.213334e-03,\n",
      "        -1.987183e-02, -1.721259e-02,  8.460321e-04, -2.027915e-02,\n",
      "         3.627460e-03, -2.024858e-02,  1.345061e-02,  2.072970e-02,\n",
      "        -2.051944e-02,  1.999890e-02, -5.755216e-03, -7.696029e-03,\n",
      "         1.741127e-02,  1.953132e-02,  2.309846e-02, -2.353398e-02,\n",
      "         1.812184e-03, -1.705552e-02,  1.513519e-02,  1.371075e-02,\n",
      "        -2.467086e-02, -1.583613e-02, -3.149133e-03,  3.410380e-03,\n",
      "        -1.007555e-02,  1.080941e-02, -2.415015e-02, -1.956847e-02,\n",
      "         8.757571e-03,  7.341510e-03,  7.096393e-03, -2.207473e-02,\n",
      "         4.670942e-03,  1.544883e-02, -6.665230e-03,  2.339934e-02,\n",
      "        -1.413504e-02, -1.129107e-02,  1.250004e-02, -2.430758e-02,\n",
      "         1.989599e-02,  1.620896e-02, -2.269348e-02, -1.330678e-02,\n",
      "        -1.623053e-02, -1.181668e-02,  1.018717e-02, -1.335060e-02,\n",
      "        -2.068541e-02,  1.753739e-02, -1.908780e-02,  2.074036e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.018930, -0.012912, -0.007419],\n",
      "          [ 0.015499, -0.024811,  0.017288],\n",
      "          [-0.001864, -0.020608,  0.025773]],\n",
      "\n",
      "         [[-0.003071, -0.005287, -0.019568],\n",
      "          [-0.025855, -0.009971, -0.022423],\n",
      "          [ 0.023283, -0.000104,  0.026684]],\n",
      "\n",
      "         [[-0.021387, -0.017485,  0.008750],\n",
      "          [ 0.021743, -0.022685, -0.020531],\n",
      "          [-0.015742, -0.006450, -0.006977]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.005176,  0.005640, -0.015690],\n",
      "          [ 0.017340, -0.008510, -0.005735],\n",
      "          [ 0.027818, -0.015654, -0.006637]],\n",
      "\n",
      "         [[-0.020471, -0.017095, -0.012069],\n",
      "          [ 0.000557,  0.023830,  0.006258],\n",
      "          [ 0.010786, -0.001409,  0.025999]],\n",
      "\n",
      "         [[ 0.008776, -0.007543,  0.005613],\n",
      "          [-0.010256,  0.010051,  0.003194],\n",
      "          [ 0.021080, -0.029028,  0.014349]]],\n",
      "\n",
      "\n",
      "        [[[-0.003593, -0.012522, -0.001883],\n",
      "          [-0.016062,  0.006454,  0.028573],\n",
      "          [ 0.002731, -0.026949,  0.027470]],\n",
      "\n",
      "         [[-0.009806,  0.001566,  0.027364],\n",
      "          [-0.019559, -0.005363,  0.021986],\n",
      "          [-0.018754,  0.009381, -0.020527]],\n",
      "\n",
      "         [[-0.004580, -0.015314, -0.015147],\n",
      "          [-0.007787,  0.000312, -0.021277],\n",
      "          [-0.021717,  0.021693,  0.012134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.028479, -0.014568, -0.020822],\n",
      "          [ 0.001251, -0.029448,  0.005386],\n",
      "          [ 0.017775, -0.013422,  0.016315]],\n",
      "\n",
      "         [[-0.027235,  0.012100,  0.014663],\n",
      "          [ 0.019655,  0.008381,  0.028147],\n",
      "          [ 0.029373, -0.027708, -0.014630]],\n",
      "\n",
      "         [[ 0.002307,  0.020124,  0.021440],\n",
      "          [-0.019259, -0.025784,  0.007199],\n",
      "          [ 0.007412,  0.022930,  0.009022]]],\n",
      "\n",
      "\n",
      "        [[[ 0.019002,  0.028701, -0.012076],\n",
      "          [-0.018464, -0.020243,  0.003256],\n",
      "          [ 0.004370,  0.016952,  0.003377]],\n",
      "\n",
      "         [[-0.009788,  0.014805, -0.000638],\n",
      "          [ 0.001830, -0.019634,  0.011775],\n",
      "          [-0.020571,  0.014451, -0.019980]],\n",
      "\n",
      "         [[-0.006840, -0.009194,  0.011406],\n",
      "          [-0.020978,  0.008531, -0.016072],\n",
      "          [ 0.026393, -0.028248,  0.015057]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.018699, -0.028256, -0.005335],\n",
      "          [ 0.005674, -0.027654,  0.022093],\n",
      "          [ 0.020603, -0.027170,  0.007561]],\n",
      "\n",
      "         [[-0.023354, -0.003405, -0.028840],\n",
      "          [-0.022588,  0.022297,  0.024093],\n",
      "          [ 0.012503, -0.020179, -0.002159]],\n",
      "\n",
      "         [[-0.026170,  0.003894, -0.022071],\n",
      "          [-0.005279, -0.021449, -0.023324],\n",
      "          [ 0.019941, -0.007215, -0.014117]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.021890,  0.015111, -0.001021],\n",
      "          [-0.016165, -0.027104,  0.005559],\n",
      "          [-0.027281, -0.000507, -0.013548]],\n",
      "\n",
      "         [[ 0.009504,  0.014260,  0.026417],\n",
      "          [-0.023773,  0.011760, -0.019433],\n",
      "          [ 0.024609,  0.000522,  0.006935]],\n",
      "\n",
      "         [[ 0.003290,  0.018182,  0.007869],\n",
      "          [ 0.000819,  0.001712, -0.021768],\n",
      "          [ 0.016675, -0.027917, -0.011321]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.016477,  0.011801, -0.000910],\n",
      "          [-0.019910,  0.020496,  0.003521],\n",
      "          [-0.017367,  0.021897,  0.001600]],\n",
      "\n",
      "         [[-0.005630,  0.004225,  0.005559],\n",
      "          [-0.006080, -0.007624, -0.018901],\n",
      "          [-0.001567,  0.005064,  0.020950]],\n",
      "\n",
      "         [[ 0.023243,  0.013992, -0.024992],\n",
      "          [ 0.007241, -0.021046,  0.027602],\n",
      "          [-0.001386,  0.013014,  0.028430]]],\n",
      "\n",
      "\n",
      "        [[[ 0.028131, -0.015815,  0.011079],\n",
      "          [-0.009042, -0.020539,  0.020763],\n",
      "          [-0.029219,  0.010197,  0.028362]],\n",
      "\n",
      "         [[ 0.027218,  0.023417, -0.009665],\n",
      "          [-0.018429, -0.003624,  0.027538],\n",
      "          [ 0.002450, -0.028656, -0.001184]],\n",
      "\n",
      "         [[-0.006722, -0.017262,  0.003716],\n",
      "          [-0.014959,  0.014490,  0.023056],\n",
      "          [-0.020881,  0.011258, -0.017412]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.017241,  0.011042, -0.019579],\n",
      "          [-0.001436, -0.023396,  0.023706],\n",
      "          [ 0.025276, -0.004438,  0.013677]],\n",
      "\n",
      "         [[-0.007070,  0.018230,  0.028984],\n",
      "          [-0.003486, -0.005811,  0.026261],\n",
      "          [-0.017698,  0.003805, -0.001811]],\n",
      "\n",
      "         [[-0.023536, -0.000367,  0.014211],\n",
      "          [ 0.005685, -0.003237, -0.014590],\n",
      "          [ 0.000846, -0.007633, -0.009147]]],\n",
      "\n",
      "\n",
      "        [[[ 0.005779, -0.012096,  0.023844],\n",
      "          [-0.006493,  0.008619,  0.009163],\n",
      "          [-0.020001,  0.007164, -0.016003]],\n",
      "\n",
      "         [[-0.017341,  0.025801, -0.024266],\n",
      "          [-0.001832, -0.008282,  0.018810],\n",
      "          [ 0.006362,  0.002823, -0.021308]],\n",
      "\n",
      "         [[ 0.014419,  0.021734, -0.019424],\n",
      "          [-0.000860,  0.027228, -0.008367],\n",
      "          [-0.013625, -0.018668, -0.014677]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.019872, -0.003546,  0.017916],\n",
      "          [ 0.001466, -0.012385, -0.016978],\n",
      "          [-0.029278,  0.011631, -0.004764]],\n",
      "\n",
      "         [[-0.007546, -0.022474, -0.016055],\n",
      "          [ 0.020701, -0.000516,  0.014858],\n",
      "          [ 0.021902,  0.028456, -0.023540]],\n",
      "\n",
      "         [[-0.006564, -0.025020, -0.012227],\n",
      "          [-0.018009,  0.013130,  0.018857],\n",
      "          [-0.016630,  0.012925,  0.004695]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.028620,  0.025932,  0.000141, -0.014695, -0.003313, -0.015215,\n",
      "         0.003898,  0.018348, -0.025100,  0.021441,  0.028931,  0.003959,\n",
      "         0.021922, -0.011009,  0.002276,  0.005995, -0.011300,  0.021487,\n",
      "        -0.025930, -0.023084,  0.028916, -0.008149, -0.015333,  0.007970,\n",
      "         0.012192,  0.019714,  0.021596,  0.021390, -0.005742,  0.017872,\n",
      "        -0.002150, -0.021846,  0.002044, -0.016065, -0.012118,  0.005098,\n",
      "        -0.020259,  0.001354,  0.004089,  0.000950, -0.003431, -0.011609,\n",
      "         0.008560,  0.002246, -0.028470, -0.001922,  0.001242,  0.009032,\n",
      "        -0.029194,  0.016254,  0.017271, -0.010714,  0.027172,  0.003134,\n",
      "        -0.012150,  0.021550, -0.005391,  0.014870,  0.020708,  0.010316,\n",
      "        -0.013389, -0.012402,  0.017256, -0.010177, -0.013190, -0.022329,\n",
      "        -0.008330,  0.023773,  0.015828, -0.005492, -0.010532, -0.016827,\n",
      "        -0.024318, -0.001229,  0.022818,  0.003250,  0.022417,  0.019156,\n",
      "         0.012962, -0.014477, -0.022848, -0.018470, -0.024146,  0.014444,\n",
      "         0.016550,  0.008085, -0.003525,  0.016371, -0.014456,  0.005220,\n",
      "        -0.020721,  0.023837, -0.005852,  0.008475, -0.001754,  0.017453,\n",
      "         0.016969,  0.023753, -0.011708, -0.014761,  0.003043, -0.000728,\n",
      "        -0.026140, -0.006700,  0.023401,  0.007147,  0.027542, -0.022643,\n",
      "         0.022839, -0.018521,  0.023050,  0.029084, -0.017233, -0.013989,\n",
      "         0.001897, -0.022318, -0.025366,  0.022966,  0.015296,  0.003369,\n",
      "         0.011997, -0.018610, -0.006670, -0.026224,  0.022310, -0.027459,\n",
      "        -0.013323, -0.008510], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 7.748513e-03,  9.285247e-03,  5.363395e-03, -1.022778e-04,\n",
      "           -6.077175e-03],\n",
      "          [-1.646927e-02,  1.633535e-02, -1.335587e-02,  8.474067e-04,\n",
      "            1.724820e-02],\n",
      "          [ 3.899213e-03, -1.533898e-02,  6.282117e-03,  1.601148e-03,\n",
      "           -1.573013e-02],\n",
      "          [-3.462368e-03,  9.807346e-03,  2.989044e-03, -1.258886e-02,\n",
      "           -8.940809e-03],\n",
      "          [ 1.379209e-02, -6.293344e-03,  1.541283e-03, -3.896137e-03,\n",
      "            1.197328e-02]],\n",
      "\n",
      "         [[ 3.994431e-03,  7.180125e-04, -1.447232e-03,  1.338379e-02,\n",
      "            1.713270e-02],\n",
      "          [-1.225082e-02, -1.059678e-02,  1.675685e-02, -1.329020e-02,\n",
      "            5.499460e-04],\n",
      "          [-7.522640e-03,  1.676956e-03, -1.426820e-03, -6.841871e-03,\n",
      "            1.162333e-02],\n",
      "          [-2.739385e-03,  4.174024e-03,  4.017416e-03,  1.245609e-03,\n",
      "            1.152960e-02],\n",
      "          [ 1.166873e-02,  1.537295e-02,  2.993252e-03,  1.755204e-02,\n",
      "            3.502766e-03]],\n",
      "\n",
      "         [[ 1.264095e-02, -9.864940e-03, -1.110441e-02, -3.587654e-03,\n",
      "            1.127195e-02],\n",
      "          [ 1.759851e-03,  1.227392e-02, -1.234570e-02,  1.706851e-02,\n",
      "            1.458632e-02],\n",
      "          [-1.016812e-02, -1.522165e-02,  1.292255e-03,  2.134163e-03,\n",
      "           -1.439606e-02],\n",
      "          [ 8.950952e-03,  9.535901e-03,  1.300366e-02, -4.041104e-03,\n",
      "           -5.423933e-03],\n",
      "          [-1.705370e-02,  6.572822e-03, -1.449784e-02,  1.269710e-02,\n",
      "           -6.223983e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.159218e-02,  4.656415e-03, -3.628319e-03, -4.321525e-03,\n",
      "           -5.776906e-03],\n",
      "          [-6.111138e-03,  7.557143e-03,  1.014885e-02, -1.314317e-02,\n",
      "            1.250425e-02],\n",
      "          [-2.050810e-03, -1.236552e-02,  6.851368e-04,  1.181583e-02,\n",
      "           -9.139858e-03],\n",
      "          [-1.283921e-04, -1.122082e-02, -1.004460e-02,  1.754886e-02,\n",
      "           -1.179857e-02],\n",
      "          [-3.671292e-03, -8.996838e-03,  3.926177e-03, -1.659501e-02,\n",
      "           -9.238958e-03]],\n",
      "\n",
      "         [[ 1.041460e-02, -9.383160e-03,  4.270300e-03, -9.193895e-03,\n",
      "            1.074418e-03],\n",
      "          [ 1.210417e-02,  1.760544e-02, -9.961587e-03, -6.842094e-03,\n",
      "           -6.047282e-03],\n",
      "          [-9.299111e-03, -1.138212e-02, -1.288737e-02,  2.826296e-03,\n",
      "            1.221969e-02],\n",
      "          [ 7.134825e-03, -1.096630e-02,  1.091698e-02, -3.189607e-03,\n",
      "           -4.754097e-03],\n",
      "          [ 1.382493e-02, -1.183448e-02,  9.450903e-03,  1.058434e-02,\n",
      "           -1.367741e-02]],\n",
      "\n",
      "         [[-1.717359e-02, -4.486066e-03, -9.056768e-03, -1.019902e-02,\n",
      "           -9.439489e-03],\n",
      "          [ 3.319677e-03,  7.348960e-03,  9.552751e-03, -1.496695e-02,\n",
      "           -2.186380e-03],\n",
      "          [ 4.502861e-03, -1.165439e-02,  1.703527e-02, -5.198275e-03,\n",
      "           -9.867046e-03],\n",
      "          [-1.629029e-02,  3.449114e-03,  1.028795e-02, -1.566880e-02,\n",
      "           -1.756633e-02],\n",
      "          [-9.865159e-03, -4.526591e-03,  1.632375e-02,  1.696089e-02,\n",
      "           -9.660101e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.860793e-03,  1.482965e-02,  8.652812e-03,  3.467221e-03,\n",
      "            1.731547e-02],\n",
      "          [ 9.595776e-03,  5.783189e-03, -4.404632e-03,  1.776660e-03,\n",
      "           -5.734863e-03],\n",
      "          [ 6.512716e-03, -7.053339e-03, -1.682780e-02, -6.194512e-03,\n",
      "           -6.728928e-03],\n",
      "          [-5.365543e-03, -1.142703e-02, -7.539772e-03, -1.711513e-02,\n",
      "           -1.309438e-02],\n",
      "          [ 1.006335e-02,  1.465826e-02, -1.256867e-02, -8.104352e-03,\n",
      "            3.613641e-03]],\n",
      "\n",
      "         [[ 3.192313e-04,  9.906571e-04, -2.413127e-03, -7.422288e-03,\n",
      "            1.366839e-02],\n",
      "          [ 7.422727e-03,  1.403680e-02, -1.133779e-02, -9.333134e-03,\n",
      "           -3.699568e-03],\n",
      "          [ 1.356247e-02, -1.011703e-02, -3.442409e-03,  1.349742e-03,\n",
      "           -1.651837e-02],\n",
      "          [ 1.572556e-02,  1.074538e-02, -5.065225e-03,  1.087804e-02,\n",
      "            1.672053e-02],\n",
      "          [-1.490260e-02,  1.208364e-02,  1.700062e-02, -1.017985e-02,\n",
      "           -2.647309e-03]],\n",
      "\n",
      "         [[ 1.681244e-02,  1.559413e-02,  5.069699e-03,  1.005988e-02,\n",
      "           -1.058901e-02],\n",
      "          [ 1.271712e-03,  1.393885e-02,  1.364720e-02,  7.712414e-03,\n",
      "            1.395558e-02],\n",
      "          [-1.222954e-02,  1.708778e-02, -5.692486e-04,  1.497739e-02,\n",
      "           -6.628383e-03],\n",
      "          [-1.033831e-02, -4.995670e-04, -1.452266e-02,  2.380831e-03,\n",
      "           -8.401772e-03],\n",
      "          [ 9.682694e-03, -1.739508e-02,  1.355695e-02,  1.753521e-02,\n",
      "           -1.208354e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.997433e-03, -5.286507e-03,  1.743537e-02,  1.835616e-03,\n",
      "           -3.689583e-03],\n",
      "          [-1.138832e-03,  3.511464e-03, -4.148860e-03,  1.298791e-02,\n",
      "           -6.459481e-03],\n",
      "          [ 4.849246e-03,  7.032052e-03, -4.022396e-03,  1.133174e-02,\n",
      "           -1.690455e-02],\n",
      "          [-6.109355e-03, -7.799963e-03, -1.185238e-04, -1.757565e-02,\n",
      "            5.339470e-03],\n",
      "          [ 7.670639e-03, -1.227793e-02, -6.996449e-04, -1.580962e-02,\n",
      "           -1.573334e-02]],\n",
      "\n",
      "         [[ 1.470687e-02, -3.239407e-03,  1.726469e-02,  1.891619e-03,\n",
      "            7.434951e-03],\n",
      "          [-1.667457e-02, -1.105168e-02,  3.811926e-03,  9.297973e-03,\n",
      "            9.289607e-04],\n",
      "          [-1.498875e-02,  1.278538e-02,  1.419977e-02,  2.990153e-03,\n",
      "           -1.689878e-02],\n",
      "          [ 1.172845e-02, -1.334127e-03,  1.106123e-03,  1.975833e-03,\n",
      "            1.126809e-02],\n",
      "          [ 1.654562e-02, -8.904068e-03, -1.550133e-02, -1.855131e-03,\n",
      "            1.202337e-02]],\n",
      "\n",
      "         [[ 9.861870e-03, -4.035146e-03, -7.680750e-03,  1.341388e-02,\n",
      "            1.298091e-02],\n",
      "          [-5.830260e-03, -6.474980e-03,  2.508832e-03,  1.155986e-02,\n",
      "            1.167101e-02],\n",
      "          [ 7.383034e-03, -1.271015e-02, -4.941185e-03, -1.068231e-02,\n",
      "           -1.880126e-03],\n",
      "          [-1.238195e-02, -1.289339e-02, -4.936382e-05,  5.041167e-03,\n",
      "           -1.294231e-02],\n",
      "          [-3.663918e-03,  2.929704e-03, -1.632878e-02, -1.425397e-02,\n",
      "           -2.799434e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.171162e-02, -2.975333e-03, -9.619732e-03,  1.527343e-02,\n",
      "           -2.006173e-03],\n",
      "          [ 8.903338e-03, -3.657481e-03, -4.049787e-03,  1.504156e-02,\n",
      "            4.988611e-03],\n",
      "          [ 1.222420e-02, -1.384816e-02,  1.305836e-02,  1.635817e-02,\n",
      "           -1.600364e-02],\n",
      "          [ 6.623928e-03,  6.279621e-03,  1.258724e-02, -1.170761e-02,\n",
      "            6.102975e-04],\n",
      "          [-1.737173e-02, -6.153164e-03, -1.249161e-03, -1.221105e-02,\n",
      "            1.295600e-02]],\n",
      "\n",
      "         [[-4.140675e-03, -1.124411e-02, -5.995598e-03,  1.708570e-02,\n",
      "           -6.021129e-03],\n",
      "          [ 2.064578e-03,  1.271911e-02,  4.799563e-03, -5.677476e-03,\n",
      "            3.329864e-03],\n",
      "          [-3.396469e-03, -6.866936e-03, -1.252077e-02,  7.132035e-03,\n",
      "           -2.470831e-03],\n",
      "          [ 1.522145e-02,  8.227428e-03,  1.317014e-02,  1.052687e-02,\n",
      "           -6.365055e-03],\n",
      "          [-1.722196e-03,  7.971248e-03,  3.584847e-05,  2.802296e-03,\n",
      "           -3.265218e-03]],\n",
      "\n",
      "         [[-3.014497e-03,  1.241835e-02, -1.710575e-02, -6.545543e-03,\n",
      "            1.635423e-02],\n",
      "          [ 1.071393e-02,  5.853727e-03, -1.361995e-02, -1.716492e-02,\n",
      "           -6.477290e-03],\n",
      "          [-1.185246e-03,  6.806392e-03,  1.360793e-02,  2.214916e-03,\n",
      "           -6.154171e-03],\n",
      "          [ 4.453531e-03, -1.760108e-02,  1.408619e-02,  4.772600e-03,\n",
      "            5.569022e-03],\n",
      "          [ 7.853813e-03, -9.036607e-03,  5.311085e-03,  4.653588e-03,\n",
      "            1.408862e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.425692e-02, -2.268834e-03, -8.652987e-03, -4.579614e-03,\n",
      "           -6.323168e-03],\n",
      "          [-1.106202e-02,  2.012150e-03,  3.705557e-03, -1.416122e-02,\n",
      "           -8.769073e-04],\n",
      "          [-5.089618e-03, -1.355389e-02, -1.029481e-02,  8.888176e-03,\n",
      "           -9.247879e-03],\n",
      "          [ 1.436820e-02, -3.214260e-03, -5.356785e-03, -9.510873e-03,\n",
      "           -2.562735e-03],\n",
      "          [ 1.244005e-02,  4.874419e-03, -1.173666e-02,  1.351441e-02,\n",
      "            1.479466e-02]],\n",
      "\n",
      "         [[ 1.638478e-02,  8.069221e-03,  6.772934e-03, -1.569549e-02,\n",
      "            1.028608e-02],\n",
      "          [-1.313940e-02,  5.109556e-03, -1.957741e-03,  3.253508e-03,\n",
      "            7.900033e-03],\n",
      "          [ 2.665741e-03, -6.804692e-03, -3.407001e-03,  5.577844e-03,\n",
      "           -1.437449e-02],\n",
      "          [ 8.767813e-03,  8.850362e-03, -1.606316e-02, -1.458910e-02,\n",
      "            4.333055e-03],\n",
      "          [ 1.082286e-02,  7.667206e-04,  1.495732e-02, -4.725182e-03,\n",
      "           -4.151170e-03]],\n",
      "\n",
      "         [[ 3.476076e-03, -1.424196e-02,  8.253656e-03,  2.480600e-03,\n",
      "           -1.277892e-02],\n",
      "          [ 5.388262e-03, -4.148742e-03,  9.049989e-03, -8.730460e-04,\n",
      "            9.018412e-03],\n",
      "          [-6.279194e-03, -1.136443e-03,  7.626953e-03, -7.092531e-03,\n",
      "            5.688950e-03],\n",
      "          [ 6.635580e-04,  1.237896e-02,  1.605411e-02, -1.594115e-02,\n",
      "            1.003851e-02],\n",
      "          [-1.149205e-02, -2.478943e-03,  2.211509e-03, -1.208863e-02,\n",
      "           -1.324430e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.108736e-02, -5.325309e-03, -1.246505e-02,  6.814396e-03,\n",
      "            1.509760e-03],\n",
      "          [-3.586986e-03, -1.046674e-02, -5.199118e-03, -4.854696e-03,\n",
      "            1.512288e-02],\n",
      "          [ 4.222896e-04,  6.170923e-03,  1.763654e-02, -1.528222e-02,\n",
      "           -4.636459e-03],\n",
      "          [ 5.974008e-03, -9.425490e-03, -1.593477e-02, -1.754456e-02,\n",
      "           -1.416747e-04],\n",
      "          [ 1.231809e-02, -8.264521e-03, -8.897614e-04, -4.289414e-03,\n",
      "           -9.339105e-03]],\n",
      "\n",
      "         [[ 1.281784e-02, -1.631830e-02,  2.284739e-03,  1.218282e-02,\n",
      "           -5.007693e-03],\n",
      "          [-1.382598e-02,  4.279187e-03,  1.184051e-02, -6.961832e-03,\n",
      "           -9.672157e-03],\n",
      "          [-1.501423e-02,  9.546198e-03, -1.409957e-02, -5.039903e-03,\n",
      "            1.533143e-02],\n",
      "          [ 1.602802e-02,  8.334171e-03, -1.471971e-02, -1.624393e-02,\n",
      "           -1.350562e-02],\n",
      "          [-1.570752e-03,  1.673498e-02,  9.393627e-03,  1.616606e-02,\n",
      "            1.499818e-02]],\n",
      "\n",
      "         [[-7.426522e-03,  8.280136e-03,  1.765172e-02, -5.022937e-03,\n",
      "           -1.765747e-02],\n",
      "          [ 1.557472e-02, -2.904924e-03, -7.395236e-03,  1.741721e-02,\n",
      "            1.580180e-02],\n",
      "          [-8.738656e-04,  7.125858e-03, -8.956998e-03, -2.089024e-03,\n",
      "           -7.559615e-03],\n",
      "          [-3.793987e-03,  1.113288e-02, -1.252832e-02,  1.731278e-02,\n",
      "           -1.333105e-02],\n",
      "          [ 4.489105e-03,  1.410181e-03, -2.838820e-03,  9.751022e-03,\n",
      "           -1.303450e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.239150e-02,  5.084742e-04, -5.879330e-03, -2.502172e-03,\n",
      "            1.419546e-02],\n",
      "          [-8.893045e-03, -1.060726e-02,  2.733205e-03, -8.486224e-03,\n",
      "            4.011218e-03],\n",
      "          [ 1.385048e-03,  2.681864e-03, -1.463697e-02,  3.915466e-04,\n",
      "            1.018720e-02],\n",
      "          [-6.225309e-03,  1.723566e-02, -1.252506e-02, -9.911070e-03,\n",
      "           -1.019080e-02],\n",
      "          [ 1.339525e-02,  2.315525e-03, -2.590381e-05,  6.752219e-04,\n",
      "           -1.232055e-02]],\n",
      "\n",
      "         [[-1.633275e-02,  1.161023e-02,  1.031779e-02, -1.661901e-02,\n",
      "           -6.399900e-04],\n",
      "          [ 8.825257e-03, -9.139412e-03, -7.231720e-04, -1.315096e-02,\n",
      "            2.153967e-03],\n",
      "          [-1.092442e-02, -8.397064e-03, -1.160298e-04, -5.987603e-03,\n",
      "            3.167378e-03],\n",
      "          [-1.615729e-02,  1.497721e-02, -1.954699e-03, -1.434595e-02,\n",
      "           -1.278168e-02],\n",
      "          [ 1.129764e-02,  1.105989e-02,  1.578528e-03,  5.312478e-03,\n",
      "            1.047963e-02]],\n",
      "\n",
      "         [[-8.482301e-03, -5.437740e-03,  9.874845e-03, -1.348726e-02,\n",
      "           -1.759619e-02],\n",
      "          [-6.622305e-03, -7.292855e-03,  9.544093e-03,  1.526417e-03,\n",
      "            1.048737e-02],\n",
      "          [-1.703198e-02,  5.056180e-03, -1.646814e-02, -1.439183e-02,\n",
      "           -5.651493e-03],\n",
      "          [-9.194221e-03, -1.055615e-02,  1.622543e-02,  7.752471e-03,\n",
      "            5.995277e-03],\n",
      "          [-2.348502e-03, -1.567803e-02,  1.516069e-02, -1.195470e-02,\n",
      "           -6.818726e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.896989e-03,  1.476321e-02,  1.391086e-02, -7.137395e-03,\n",
      "            4.102625e-04],\n",
      "          [ 1.605635e-02, -1.037842e-02,  1.043884e-02, -8.998384e-03,\n",
      "           -4.981353e-03],\n",
      "          [ 6.072333e-03,  1.319162e-02,  1.037226e-02, -3.716607e-03,\n",
      "           -1.927363e-03],\n",
      "          [-2.163667e-04, -1.484417e-02,  1.645822e-02,  1.400886e-02,\n",
      "            1.491085e-02],\n",
      "          [-9.421912e-03, -9.375586e-03,  1.241525e-02, -1.388588e-02,\n",
      "            7.989684e-03]],\n",
      "\n",
      "         [[ 1.699075e-02, -1.211534e-02,  1.612321e-02, -1.550137e-02,\n",
      "            8.165691e-03],\n",
      "          [ 1.516864e-02, -1.761573e-02,  9.681620e-04,  1.140585e-02,\n",
      "           -1.181679e-02],\n",
      "          [-1.514021e-02,  2.158862e-04,  1.303421e-02,  5.092623e-03,\n",
      "            2.856724e-03],\n",
      "          [ 1.241563e-02, -5.698189e-03,  4.512839e-03,  4.470013e-04,\n",
      "            1.025524e-02],\n",
      "          [-7.654380e-03, -1.104532e-02, -1.110668e-02,  2.453128e-03,\n",
      "            7.359033e-03]],\n",
      "\n",
      "         [[-3.595596e-03, -1.934651e-03,  1.195674e-02, -2.604066e-03,\n",
      "           -4.402710e-03],\n",
      "          [ 2.885265e-03,  1.524361e-02,  1.613449e-02,  1.464152e-02,\n",
      "            1.765145e-02],\n",
      "          [-7.933255e-03, -5.041824e-03,  6.477645e-03,  1.508101e-02,\n",
      "           -1.428443e-02],\n",
      "          [ 1.741126e-02, -2.889464e-03,  3.920278e-03, -1.466412e-02,\n",
      "            1.672874e-02],\n",
      "          [-8.472607e-03,  9.754576e-03,  1.537338e-03,  8.467853e-03,\n",
      "           -1.496180e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.279355e-03, -1.460114e-02,  1.263065e-02, -1.516160e-02,\n",
      "            5.352439e-03],\n",
      "          [ 9.736164e-03, -3.809743e-04, -4.530221e-03, -2.258984e-03,\n",
      "            8.631727e-03],\n",
      "          [ 8.915054e-03,  3.319094e-03,  7.208088e-03,  5.869893e-03,\n",
      "           -5.263895e-03],\n",
      "          [ 4.329732e-03,  3.188763e-03, -4.850808e-03,  1.650169e-03,\n",
      "            8.279318e-03],\n",
      "          [ 5.926203e-03, -4.772208e-03, -1.812972e-03,  1.454648e-02,\n",
      "            1.762848e-02]],\n",
      "\n",
      "         [[-1.599998e-02, -9.086424e-03,  1.290402e-02, -2.074569e-03,\n",
      "            1.243975e-02],\n",
      "          [-1.577383e-02, -1.552606e-02,  3.689371e-03, -1.759209e-02,\n",
      "            1.625358e-02],\n",
      "          [ 9.193202e-03, -1.069741e-02, -8.330209e-03, -6.193401e-03,\n",
      "            1.451497e-02],\n",
      "          [ 9.198166e-03, -9.366619e-03, -8.111098e-03, -7.721223e-04,\n",
      "            1.956187e-04],\n",
      "          [-6.226078e-04,  1.067706e-02, -1.216462e-02, -2.084446e-03,\n",
      "           -1.698667e-02]],\n",
      "\n",
      "         [[-4.225844e-03, -1.597463e-02, -6.498871e-03, -9.593967e-03,\n",
      "           -3.749544e-03],\n",
      "          [-1.558325e-02, -1.741378e-02, -2.475207e-03, -5.892482e-03,\n",
      "            6.783139e-04],\n",
      "          [ 1.334995e-04,  1.554312e-03,  1.743991e-03, -1.301044e-02,\n",
      "            1.228401e-02],\n",
      "          [-2.819614e-03, -1.377486e-02,  8.250857e-03,  9.911045e-03,\n",
      "            1.421230e-03],\n",
      "          [ 9.840246e-03, -8.103573e-03,  1.384528e-02, -2.100435e-03,\n",
      "           -1.239471e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.507549e-02, -1.121734e-02,  8.392928e-03, -8.556428e-03,\n",
      "            8.606523e-03],\n",
      "          [-1.300220e-02, -1.003519e-02, -6.482042e-04,  1.371656e-02,\n",
      "           -1.791492e-04],\n",
      "          [-1.019675e-03, -8.952877e-03, -1.209270e-02,  4.054282e-03,\n",
      "           -1.599696e-02],\n",
      "          [ 5.628699e-03,  1.614059e-02,  1.209761e-02, -9.687043e-03,\n",
      "           -7.945162e-03],\n",
      "          [ 1.635308e-02, -8.005125e-03,  1.184492e-02, -3.784758e-03,\n",
      "           -1.367513e-02]],\n",
      "\n",
      "         [[ 5.746434e-03,  1.080871e-02,  9.201393e-04,  2.744794e-03,\n",
      "           -1.020584e-02],\n",
      "          [ 3.496587e-03, -8.390937e-04,  3.120657e-04, -1.716318e-03,\n",
      "            4.604943e-03],\n",
      "          [ 1.213260e-02,  3.293810e-03, -1.651341e-02,  4.567243e-03,\n",
      "           -4.738825e-03],\n",
      "          [ 4.400276e-04, -7.422615e-03, -1.640661e-02,  4.431384e-03,\n",
      "            1.732155e-02],\n",
      "          [-1.290913e-02,  8.824306e-03,  6.770371e-03, -9.726009e-03,\n",
      "           -1.025603e-02]],\n",
      "\n",
      "         [[-4.549892e-03, -1.613070e-02,  4.420647e-03,  1.580290e-02,\n",
      "           -2.039300e-03],\n",
      "          [ 7.864840e-03, -4.548684e-03,  7.451694e-03, -1.679747e-02,\n",
      "            5.608505e-03],\n",
      "          [ 3.456725e-03,  1.572361e-02, -1.433148e-02, -1.684566e-02,\n",
      "            1.714927e-02],\n",
      "          [ 9.232167e-03, -8.371553e-03,  6.020186e-03,  1.536567e-02,\n",
      "            2.579866e-03],\n",
      "          [-1.529837e-02, -6.818024e-03, -1.083349e-02,  1.418898e-02,\n",
      "           -1.325006e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.945511e-03,  1.039196e-02, -1.525913e-02,  2.248999e-03,\n",
      "            7.402183e-03],\n",
      "          [-3.621924e-03,  5.825181e-04, -1.040698e-02, -7.739786e-03,\n",
      "            1.257353e-02],\n",
      "          [-8.824516e-03, -8.711603e-03,  5.246671e-03, -8.807844e-03,\n",
      "            9.635625e-03],\n",
      "          [-1.628575e-02, -1.192261e-02,  1.544373e-02,  1.057440e-02,\n",
      "            5.070126e-03],\n",
      "          [ 1.595768e-02,  9.512935e-03,  1.369808e-02,  1.632742e-02,\n",
      "            1.794361e-03]],\n",
      "\n",
      "         [[ 1.157564e-02, -1.720091e-02, -1.664501e-02,  6.924201e-03,\n",
      "           -1.344640e-02],\n",
      "          [ 1.139886e-02,  1.381400e-02, -2.041459e-04,  1.424220e-02,\n",
      "           -7.793865e-03],\n",
      "          [-7.647843e-03,  7.107982e-03, -1.492435e-02,  1.068761e-02,\n",
      "           -7.175029e-03],\n",
      "          [ 1.353884e-02, -7.614174e-03,  1.704363e-02,  5.399808e-03,\n",
      "           -5.056088e-03],\n",
      "          [-1.549166e-02, -1.476300e-02, -1.484647e-02, -1.147959e-02,\n",
      "            5.830370e-03]],\n",
      "\n",
      "         [[-9.142326e-03, -4.454448e-03, -1.642536e-02, -3.977579e-03,\n",
      "            5.002307e-03],\n",
      "          [ 1.598794e-02, -2.291570e-03, -2.755738e-03,  1.753286e-02,\n",
      "           -1.603023e-02],\n",
      "          [ 1.273480e-02,  1.685102e-02,  1.317713e-02, -6.642208e-03,\n",
      "           -6.269481e-03],\n",
      "          [ 1.562672e-02,  1.116907e-02,  1.060295e-02,  1.073185e-02,\n",
      "           -8.798242e-04],\n",
      "          [ 5.571494e-03, -6.565908e-03, -2.144345e-03, -1.358065e-02,\n",
      "           -7.077868e-03]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-4.562481e-03, -5.382083e-03,  1.223095e-02, -1.732015e-02,\n",
      "        -1.223250e-02, -1.483291e-02, -1.742494e-02, -1.738521e-02,\n",
      "         1.134344e-02,  7.178485e-04, -1.509783e-02, -2.077053e-03,\n",
      "        -1.513636e-02, -6.744936e-04,  1.928793e-03, -1.167813e-02,\n",
      "         1.297009e-02,  1.608405e-02, -3.204707e-03, -1.740699e-02,\n",
      "         1.943713e-03, -3.856264e-03, -1.730189e-02,  2.504053e-03,\n",
      "        -9.775702e-04,  5.755993e-03, -4.892214e-03,  9.574866e-03,\n",
      "        -3.268654e-03,  8.969121e-04,  1.138722e-02,  5.030118e-03,\n",
      "         2.784261e-03, -3.960175e-03,  1.500541e-02,  5.514419e-03,\n",
      "         7.548673e-03,  7.818133e-03,  1.020487e-02,  1.370357e-02,\n",
      "        -1.118114e-02, -1.704863e-02, -5.246421e-03,  7.756906e-03,\n",
      "        -1.403198e-02,  1.317536e-02,  1.328662e-02,  1.731351e-02,\n",
      "        -9.726134e-03, -1.202172e-02,  6.124914e-03,  5.250830e-03,\n",
      "        -1.793541e-05, -1.184163e-02, -8.242575e-03,  1.463948e-02,\n",
      "        -8.401208e-03,  3.879763e-03,  1.640129e-02,  1.534851e-02,\n",
      "         1.226484e-02,  1.435350e-02, -6.382531e-03,  4.809387e-03,\n",
      "         7.526077e-03,  1.362741e-02, -1.117912e-02, -3.346637e-03,\n",
      "         3.656073e-03,  1.171368e-02,  3.640089e-03,  5.913714e-03,\n",
      "         4.447941e-04,  3.710369e-03, -1.669794e-02,  1.217076e-02,\n",
      "         3.283337e-03, -7.988630e-03,  1.579268e-02,  3.096981e-03,\n",
      "        -1.735091e-02,  4.617743e-03,  6.836640e-03, -6.770832e-03,\n",
      "         1.562246e-02,  1.202342e-02, -8.139922e-03, -4.886681e-03,\n",
      "         1.206774e-02, -5.689182e-03, -8.892284e-03, -7.716774e-03,\n",
      "         1.763331e-02,  7.176366e-03,  7.841062e-03, -9.926133e-03],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 3.322830e-02,  2.177599e-02,  1.725304e-02],\n",
      "          [-1.259611e-02, -3.234321e-02,  5.810086e-03],\n",
      "          [ 9.082630e-04,  3.380947e-02,  2.873048e-02]],\n",
      "\n",
      "         [[-2.453101e-02, -2.408275e-02, -3.739052e-03],\n",
      "          [-1.450510e-02,  4.594911e-03, -1.423124e-02],\n",
      "          [-2.948035e-02,  3.396235e-02, -2.090836e-02]],\n",
      "\n",
      "         [[-2.247011e-02, -3.026067e-02, -1.785920e-02],\n",
      "          [-1.529228e-03,  3.193886e-02, -2.190823e-02],\n",
      "          [ 2.349966e-02,  3.028680e-03, -2.779578e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.379694e-02, -1.644715e-02,  2.190971e-02],\n",
      "          [ 8.695934e-03,  2.911415e-02,  5.580425e-03],\n",
      "          [-2.318097e-02,  2.682434e-02,  2.242685e-02]],\n",
      "\n",
      "         [[-6.361194e-03, -1.167085e-02, -2.711069e-02],\n",
      "          [ 1.134781e-02, -2.651561e-03, -3.329184e-02],\n",
      "          [-2.957795e-02, -2.814074e-02, -1.320105e-02]],\n",
      "\n",
      "         [[-6.597942e-03, -9.954687e-03,  9.527192e-03],\n",
      "          [-7.139035e-04, -2.782049e-02, -1.364967e-02],\n",
      "          [ 7.415954e-03, -1.024661e-02, -1.204523e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.824502e-03,  1.246556e-02, -1.371615e-03],\n",
      "          [-1.088349e-02, -3.135902e-02,  1.025763e-02],\n",
      "          [-2.464719e-02,  2.381041e-02, -2.460941e-02]],\n",
      "\n",
      "         [[-6.209657e-03, -3.270057e-02, -1.100534e-02],\n",
      "          [ 2.895377e-02, -4.933316e-03, -2.050951e-02],\n",
      "          [-1.713212e-02,  3.350500e-02,  2.287794e-02]],\n",
      "\n",
      "         [[ 2.823434e-02,  1.529885e-02,  1.967328e-02],\n",
      "          [-3.005870e-02, -3.289050e-02, -1.559552e-02],\n",
      "          [ 8.879296e-03,  1.039747e-03,  1.298841e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.628110e-03,  1.188741e-02, -2.363295e-02],\n",
      "          [ 1.827417e-02, -2.125856e-02, -9.841321e-03],\n",
      "          [ 4.118115e-03,  2.730207e-02,  5.972646e-04]],\n",
      "\n",
      "         [[-1.263408e-02, -1.257516e-02, -2.401773e-03],\n",
      "          [ 9.916205e-03, -3.994379e-03,  1.297759e-02],\n",
      "          [-2.431323e-02, -3.278608e-02, -6.325852e-03]],\n",
      "\n",
      "         [[-1.269241e-02,  3.052109e-02,  2.253123e-02],\n",
      "          [-5.211983e-03,  3.282648e-02, -1.259840e-02],\n",
      "          [-1.335498e-02,  8.284375e-04,  1.519632e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.023928e-02,  4.452460e-03,  3.256252e-02],\n",
      "          [-1.675037e-02, -2.640416e-02, -1.356360e-02],\n",
      "          [ 3.075008e-02, -5.990185e-03, -3.098061e-02]],\n",
      "\n",
      "         [[-2.068240e-02,  1.510191e-02,  2.841502e-04],\n",
      "          [ 2.712220e-02, -2.029158e-03,  2.650607e-03],\n",
      "          [-7.600704e-03,  2.978881e-02,  2.303135e-02]],\n",
      "\n",
      "         [[-1.006540e-02, -1.686228e-02, -1.626250e-02],\n",
      "          [-1.687917e-02, -2.656517e-02, -3.310557e-02],\n",
      "          [-2.940934e-02,  2.410980e-02,  7.795610e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.987897e-02, -2.390668e-02,  2.369262e-02],\n",
      "          [ 1.652000e-02,  2.320500e-02,  4.601572e-03],\n",
      "          [-6.849770e-03,  2.113053e-02,  1.796777e-02]],\n",
      "\n",
      "         [[ 8.915670e-03, -1.653552e-02, -2.385011e-02],\n",
      "          [ 2.210085e-02, -1.646874e-02,  9.227205e-03],\n",
      "          [ 3.400381e-02, -4.383294e-03, -1.569294e-02]],\n",
      "\n",
      "         [[ 1.567800e-02,  1.486514e-03,  1.282692e-03],\n",
      "          [ 2.941458e-02,  3.172664e-02, -2.345683e-02],\n",
      "          [ 1.962632e-03,  2.164964e-03,  2.297298e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.115473e-02, -1.905225e-03, -2.993781e-02],\n",
      "          [-2.771150e-02,  2.722049e-02,  2.026278e-02],\n",
      "          [-1.361343e-02,  5.666867e-03,  3.266739e-02]],\n",
      "\n",
      "         [[ 1.025632e-03,  1.483518e-02,  1.352493e-02],\n",
      "          [-3.206944e-02,  1.409208e-02,  2.959721e-02],\n",
      "          [ 1.825329e-03, -2.639193e-02, -2.492091e-02]],\n",
      "\n",
      "         [[-3.085110e-02, -1.932600e-02, -1.913910e-02],\n",
      "          [ 1.951934e-02,  2.835973e-02,  2.541978e-02],\n",
      "          [ 1.901782e-02, -1.538146e-03,  1.033881e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.291579e-03,  1.394806e-02, -2.399787e-02],\n",
      "          [-2.810735e-02, -7.275790e-04,  7.240981e-03],\n",
      "          [-2.120534e-02, -8.005254e-03,  1.095837e-02]],\n",
      "\n",
      "         [[ 3.035565e-02,  1.565790e-02,  1.117956e-02],\n",
      "          [ 7.628754e-03, -2.704590e-02,  3.096557e-02],\n",
      "          [ 3.087813e-02,  1.160113e-02,  1.130684e-02]],\n",
      "\n",
      "         [[ 1.155897e-02, -4.020713e-03,  2.919878e-02],\n",
      "          [-1.897353e-02,  1.301730e-02, -3.323347e-02],\n",
      "          [ 5.181704e-03, -3.255339e-03, -6.353382e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.042452e-02,  2.432412e-02, -2.813449e-02],\n",
      "          [ 2.144559e-02, -6.484354e-03, -1.846064e-02],\n",
      "          [ 2.938790e-02, -3.180720e-03,  2.459588e-02]],\n",
      "\n",
      "         [[-4.054954e-03, -1.275805e-02,  2.116868e-02],\n",
      "          [ 1.826290e-02,  1.371611e-03, -2.085089e-02],\n",
      "          [ 1.835488e-02, -6.617576e-03,  3.608085e-03]],\n",
      "\n",
      "         [[ 7.644687e-03, -2.722079e-02, -2.814984e-03],\n",
      "          [ 2.160791e-03,  2.385799e-03,  1.700977e-02],\n",
      "          [-1.790036e-02, -2.682228e-02,  2.603995e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.224716e-02, -3.282214e-02, -1.389868e-02],\n",
      "          [-2.640282e-02,  6.292816e-03,  1.611438e-03],\n",
      "          [-7.749658e-03, -3.975732e-03, -2.512424e-02]],\n",
      "\n",
      "         [[ 3.159595e-02,  2.099572e-02, -1.761073e-02],\n",
      "          [-1.944172e-02,  7.535532e-03,  8.761164e-03],\n",
      "          [ 2.604607e-02, -3.244970e-02, -1.451117e-02]],\n",
      "\n",
      "         [[ 5.801972e-03, -3.203780e-02, -3.217010e-03],\n",
      "          [ 3.264382e-02,  1.208252e-02, -3.214777e-02],\n",
      "          [ 1.270402e-02,  5.413629e-03, -7.037519e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.914573e-02,  6.998524e-03, -3.232168e-02],\n",
      "          [-1.623038e-02, -3.332006e-03, -1.924353e-02],\n",
      "          [ 2.749945e-02,  1.396957e-02, -3.038769e-02]],\n",
      "\n",
      "         [[ 1.421314e-02, -1.644046e-02, -3.081422e-02],\n",
      "          [-2.774101e-02,  6.099418e-03,  1.297904e-02],\n",
      "          [-3.072529e-02, -1.358427e-03, -2.659393e-02]],\n",
      "\n",
      "         [[ 1.390965e-02, -3.251974e-03,  1.431926e-02],\n",
      "          [-2.491763e-02, -1.390197e-02, -2.044546e-02],\n",
      "          [ 1.634639e-03,  8.665964e-03, -3.201964e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.012056e-02,  1.438051e-02, -1.878637e-02],\n",
      "          [-2.647610e-02, -2.073553e-02,  3.067393e-03],\n",
      "          [ 4.910171e-03,  1.978012e-02,  1.278646e-02]],\n",
      "\n",
      "         [[ 2.216638e-02, -1.990125e-04,  5.132660e-03],\n",
      "          [-3.659725e-05, -9.339117e-04,  4.061613e-03],\n",
      "          [ 7.860765e-03,  1.452633e-02, -1.554564e-02]],\n",
      "\n",
      "         [[-3.142275e-02,  1.845391e-02,  3.091432e-03],\n",
      "          [-3.232805e-02,  1.276202e-03,  8.092698e-03],\n",
      "          [ 5.627900e-03,  1.267609e-02,  6.277129e-03]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.241078e-02,  4.545003e-04,  2.010634e-02, -2.190233e-02,\n",
      "        -2.467828e-02, -3.078836e-02,  9.949215e-03,  3.190958e-02,\n",
      "         3.017023e-02, -2.044359e-02,  3.393501e-03,  5.082585e-03,\n",
      "        -1.150937e-02,  3.099369e-02, -3.091886e-02, -3.194736e-02,\n",
      "        -3.152570e-03,  5.796142e-03, -1.318231e-02, -1.048613e-02,\n",
      "        -3.084219e-02,  1.498922e-02, -1.734842e-03,  2.844174e-02,\n",
      "         1.572661e-02, -2.681812e-02,  1.581118e-03,  8.571334e-04,\n",
      "        -3.191318e-02,  2.186187e-04, -2.358150e-03, -3.176716e-02,\n",
      "         5.577978e-03,  8.580845e-03,  7.745165e-03,  6.462768e-03,\n",
      "        -9.739298e-03, -1.416342e-02,  2.727531e-02, -1.854426e-02,\n",
      "        -7.095598e-04, -1.882374e-02, -1.649193e-02,  3.264333e-02,\n",
      "         2.448012e-02, -3.032332e-02, -1.783126e-02,  1.428194e-02,\n",
      "        -1.452755e-02,  1.365054e-02,  6.332844e-04,  6.378070e-05,\n",
      "        -3.081368e-02, -3.888594e-03, -1.748637e-02,  1.321761e-02,\n",
      "        -1.537411e-02,  2.491601e-02, -2.434754e-02,  1.812234e-02,\n",
      "         4.710048e-03, -1.650472e-02,  9.368703e-03,  1.838601e-02,\n",
      "         3.025988e-02,  2.812148e-02,  2.545740e-02, -8.990342e-03,\n",
      "        -1.755895e-02,  8.139640e-03,  5.888987e-03,  1.711756e-03,\n",
      "        -9.029357e-03, -3.414962e-03,  9.669591e-03,  2.799181e-02,\n",
      "         6.206945e-03, -1.357988e-02, -2.833651e-03,  5.593002e-04,\n",
      "        -2.717626e-02,  1.077755e-02,  5.316250e-04,  3.862455e-04,\n",
      "         2.501450e-02,  3.322159e-02, -1.966008e-02, -2.915685e-02,\n",
      "         5.772404e-03,  2.148268e-02, -1.821167e-02, -3.044739e-02,\n",
      "        -2.063334e-02, -3.107013e-02,  5.159650e-03,  2.865631e-02,\n",
      "         2.609551e-03,  8.324824e-03, -1.928386e-02,  2.041776e-03,\n",
      "         2.054312e-02,  1.762567e-02, -3.077518e-03,  2.346867e-02,\n",
      "         2.089559e-02, -1.340922e-02,  1.340987e-02,  3.316052e-02,\n",
      "        -8.833632e-04, -2.361160e-02,  2.945822e-02,  7.706884e-03,\n",
      "         2.682896e-02, -1.360044e-03, -3.184943e-02, -3.014215e-02,\n",
      "         1.571086e-02,  1.819658e-02, -5.526206e-03, -1.476034e-02,\n",
      "        -3.477708e-04, -3.163652e-02,  8.249730e-04,  6.274581e-04,\n",
      "        -1.243837e-02,  2.172429e-03,  1.749905e-02,  6.694037e-03,\n",
      "         1.079420e-02, -1.729017e-02,  1.724898e-02,  1.045205e-02,\n",
      "        -6.200219e-03,  1.149944e-02,  6.913308e-03, -1.177990e-02,\n",
      "         6.887950e-03, -1.650472e-02,  1.516481e-02,  2.296719e-02,\n",
      "        -2.975414e-02,  3.008220e-02,  2.841644e-02,  2.052240e-02,\n",
      "        -2.378502e-02, -2.814940e-02, -3.157249e-02,  3.022403e-02,\n",
      "        -1.203801e-02, -2.752622e-02, -1.911987e-02,  1.779225e-02,\n",
      "        -4.306290e-03,  2.277819e-02, -3.095216e-02,  3.075287e-02,\n",
      "         2.013772e-02,  2.046208e-02,  3.328279e-02, -6.551128e-03,\n",
      "         2.284475e-02,  6.419942e-03,  7.436585e-03, -2.672088e-02,\n",
      "        -1.575325e-03, -3.839310e-03, -1.417693e-02,  3.258660e-02,\n",
      "        -8.354744e-03, -2.672301e-02,  4.398361e-03,  2.770112e-02,\n",
      "        -3.190898e-02, -1.147871e-02,  1.716295e-02,  3.144073e-02,\n",
      "         1.210269e-02,  2.300820e-02, -3.562436e-03,  2.396859e-02,\n",
      "         2.781862e-02, -2.521307e-02, -2.005094e-02,  2.418634e-02,\n",
      "        -2.768621e-03, -3.126010e-02, -2.642691e-02,  1.869753e-02,\n",
      "         2.909645e-02,  2.889403e-02,  3.421225e-03, -2.728711e-02,\n",
      "         1.446507e-02, -2.413069e-02, -2.861677e-02,  3.106966e-02,\n",
      "        -1.441303e-02,  1.988881e-02,  3.206593e-02,  2.883151e-03,\n",
      "         2.377882e-02, -4.276907e-03, -1.438614e-03,  1.988783e-03,\n",
      "        -2.273239e-03,  1.512794e-02, -3.135160e-02, -4.900608e-03,\n",
      "        -1.461362e-02, -1.104211e-02,  2.364712e-02,  3.813360e-03,\n",
      "        -2.999713e-02, -1.643096e-02,  1.755531e-02, -1.175938e-02,\n",
      "         1.946111e-02,  2.194079e-02, -2.719087e-02,  1.947146e-03,\n",
      "        -1.947828e-02,  2.635676e-02, -2.915091e-02,  2.578559e-02,\n",
      "         1.867419e-02, -9.316143e-03,  2.632590e-02,  2.628814e-02,\n",
      "         1.477943e-02,  1.338462e-02,  1.279040e-02, -2.984603e-02,\n",
      "         2.833992e-02,  2.738011e-02,  2.146278e-02, -7.366350e-03,\n",
      "        -2.327814e-02, -2.368768e-02,  3.251940e-03, -1.534684e-02,\n",
      "        -2.691535e-02,  3.281505e-02, -7.468870e-03, -4.164118e-03,\n",
      "         2.963287e-02,  3.226595e-02,  8.159474e-03, -8.827794e-03,\n",
      "        -1.633269e-02,  3.126524e-02, -5.788364e-03,  9.425722e-03,\n",
      "         4.061297e-03,  1.964834e-02, -2.740149e-02,  5.128175e-03,\n",
      "         1.193823e-02,  9.605862e-03, -3.597999e-03, -1.655071e-02,\n",
      "         1.151102e-02, -2.798558e-02, -4.663048e-03,  3.092722e-02,\n",
      "         3.357199e-02, -1.470309e-02,  1.992448e-02,  1.340872e-02,\n",
      "        -1.574469e-02, -2.468612e-02,  8.612208e-03,  1.219588e-02,\n",
      "        -3.324049e-02,  2.047084e-04, -5.129408e-03,  2.183007e-02,\n",
      "        -2.722797e-02, -4.386352e-03, -9.777656e-03,  1.184312e-02,\n",
      "         7.687747e-03,  1.652838e-02, -3.228723e-02, -1.653699e-02,\n",
      "        -9.083563e-03,  8.396354e-03,  3.055780e-02, -4.312199e-03,\n",
      "         6.765760e-04, -8.002313e-03,  1.125774e-02,  8.537564e-03,\n",
      "         3.297669e-02,  1.073159e-02,  4.853688e-03, -1.923949e-02,\n",
      "         3.391194e-02,  2.376117e-02, -2.655087e-02,  5.396262e-03,\n",
      "        -1.954146e-02,  8.923028e-03, -1.264564e-02,  2.726054e-02,\n",
      "        -2.046643e-02,  1.884112e-02,  1.361401e-02, -2.662326e-02,\n",
      "         2.022901e-02, -1.947973e-02, -1.811520e-02, -2.197448e-03,\n",
      "        -3.076030e-02, -2.967881e-02,  2.984817e-02, -7.679461e-03,\n",
      "        -2.823208e-02, -1.334887e-02, -1.706087e-02,  2.759387e-02,\n",
      "         9.954762e-03, -3.414117e-04, -2.110990e-02,  5.582757e-03,\n",
      "        -4.529875e-03,  2.270250e-02, -2.752202e-02, -1.527158e-02,\n",
      "         2.899877e-02,  2.708521e-02,  1.694063e-02, -9.176567e-03,\n",
      "        -2.547942e-02,  6.212518e-04, -2.201345e-03,  6.574653e-04,\n",
      "        -2.585558e-02,  2.174095e-02,  1.843318e-03, -1.532252e-02,\n",
      "        -6.350242e-04, -1.643407e-02, -3.074123e-02,  1.957060e-02,\n",
      "         2.162068e-02, -1.328329e-02, -2.132110e-03, -2.290938e-02,\n",
      "        -1.826804e-03, -2.242255e-02, -2.006978e-02, -1.855791e-02,\n",
      "         5.495977e-03,  1.804270e-04,  3.136050e-02, -1.649611e-02,\n",
      "        -1.682131e-02,  3.379378e-03,  5.759198e-03, -1.161087e-02,\n",
      "         8.067548e-03, -1.789418e-02,  5.521942e-03, -1.617174e-02,\n",
      "        -4.624475e-03,  2.673441e-02,  3.029788e-02, -2.241952e-02,\n",
      "         2.781761e-02, -2.559038e-02,  2.647562e-02, -2.269742e-02,\n",
      "         3.347456e-02,  1.365173e-02,  9.561449e-03, -9.374589e-03,\n",
      "         3.076143e-02,  7.890757e-03,  1.829861e-02,  2.928526e-02,\n",
      "        -3.401332e-03,  1.940910e-03,  2.166281e-02,  2.736330e-02,\n",
      "         2.179803e-02,  1.369875e-02,  1.818874e-02, -1.908298e-02,\n",
      "         2.208422e-02,  7.710982e-03, -1.603880e-02,  3.233172e-03,\n",
      "         3.390410e-02, -1.803666e-02, -4.249858e-03, -2.902819e-02,\n",
      "         1.189887e-02,  5.537260e-03,  9.907201e-03,  2.542414e-02,\n",
      "        -2.433725e-02, -2.338146e-02, -3.157341e-02,  3.098210e-02,\n",
      "        -1.974493e-02,  2.109264e-02,  2.394584e-02, -2.826782e-02,\n",
      "        -7.896917e-03,  4.531249e-03, -1.134063e-02, -9.898992e-03,\n",
      "         2.625123e-02,  3.824525e-03, -1.269862e-02, -1.550380e-03,\n",
      "        -2.923765e-02, -1.488949e-02,  2.662327e-02,  2.581023e-02,\n",
      "         1.697429e-02, -1.181127e-02,  1.434803e-02,  1.077397e-02,\n",
      "        -2.916656e-03, -2.768635e-02,  1.993576e-02,  3.056268e-02,\n",
      "         1.832597e-02, -5.409315e-03,  3.616069e-03, -1.063185e-02,\n",
      "        -2.053433e-02, -2.439348e-02,  9.359103e-03,  2.847251e-02,\n",
      "        -1.190352e-02,  1.066824e-02,  3.065909e-02, -3.197243e-02,\n",
      "        -2.067920e-03, -1.541528e-02,  2.740330e-02, -1.503286e-02,\n",
      "        -1.830345e-02,  2.830520e-02, -1.037240e-02, -1.757037e-02,\n",
      "         1.326982e-02,  2.618705e-02,  1.831992e-02, -1.668020e-02,\n",
      "         3.234844e-02,  6.374564e-03,  2.430859e-02,  3.316688e-02,\n",
      "         5.171541e-03, -2.046126e-02, -1.126963e-02,  1.952819e-02,\n",
      "         2.063468e-02, -2.668089e-02, -2.235845e-04,  2.334643e-02,\n",
      "        -3.896726e-03,  2.973562e-02,  2.378883e-02, -1.972957e-02,\n",
      "        -2.513065e-02, -1.543943e-02, -2.666514e-02,  2.268080e-02,\n",
      "         9.991698e-03,  1.549012e-02, -3.156789e-02, -1.562217e-02,\n",
      "        -2.700138e-02, -5.743837e-03, -1.839497e-02,  2.066998e-02,\n",
      "        -2.062437e-02, -1.433207e-02,  2.029845e-02, -3.394869e-02,\n",
      "        -3.008210e-02, -9.108011e-03, -4.857184e-03,  1.018319e-02,\n",
      "         1.003747e-02,  3.277867e-02,  1.474810e-02,  2.810203e-02,\n",
      "         1.666807e-02,  1.373409e-02,  2.384478e-02, -3.153490e-02,\n",
      "        -1.441215e-02,  2.262258e-02, -1.967873e-02, -1.391133e-02,\n",
      "         8.941174e-03, -4.483685e-04, -1.370073e-02,  1.800472e-02,\n",
      "         1.744447e-02,  7.259835e-03,  2.506449e-02,  1.381270e-02,\n",
      "         4.111387e-03, -2.428985e-02,  1.360108e-02, -1.090528e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-1.321162e-02,  1.821558e-02,  6.516242e-03],\n",
      "          [ 2.460644e-02,  3.953775e-03, -7.640690e-03],\n",
      "          [ 3.076717e-05,  1.862935e-02, -1.236023e-03]],\n",
      "\n",
      "         [[ 2.559396e-02,  1.289107e-02,  7.379167e-04],\n",
      "          [ 2.204174e-03, -1.368284e-03,  6.933194e-04],\n",
      "          [ 1.489685e-02, -2.431037e-02, -8.211080e-03]],\n",
      "\n",
      "         [[ 2.788855e-02,  1.070110e-02, -1.039925e-02],\n",
      "          [-1.207978e-02, -4.677344e-04,  2.881420e-02],\n",
      "          [ 5.827354e-03,  2.764674e-02, -1.157490e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.599778e-03,  1.670959e-02,  9.841932e-03],\n",
      "          [ 7.290794e-03,  2.107202e-02, -2.678309e-02],\n",
      "          [ 1.857974e-02,  1.702747e-02,  2.262347e-02]],\n",
      "\n",
      "         [[ 1.667381e-02,  7.774880e-03, -6.722931e-03],\n",
      "          [-1.561852e-02,  1.457766e-02,  1.505761e-02],\n",
      "          [ 8.581663e-03, -3.530582e-03,  9.318905e-03]],\n",
      "\n",
      "         [[ 5.369907e-03,  1.626773e-02, -1.127217e-03],\n",
      "          [-2.472793e-02, -3.940038e-03,  6.120538e-03],\n",
      "          [-1.782587e-02,  2.396525e-02,  2.073089e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.020003e-02, -8.649863e-04,  2.179139e-02],\n",
      "          [-2.932574e-02, -2.422667e-02, -1.195875e-02],\n",
      "          [ 7.493777e-03,  1.920660e-02, -2.017953e-03]],\n",
      "\n",
      "         [[-6.527362e-03, -8.652063e-03, -2.722305e-02],\n",
      "          [-1.444533e-02, -4.946979e-03, -2.541833e-02],\n",
      "          [-1.993370e-02,  4.163923e-03,  1.561411e-02]],\n",
      "\n",
      "         [[-1.088750e-02, -1.609030e-02,  1.799846e-02],\n",
      "          [-2.928943e-02,  1.013270e-03, -8.205710e-03],\n",
      "          [-1.501782e-02, -2.085860e-02, -2.808062e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.792626e-02,  8.281769e-03, -1.603713e-02],\n",
      "          [ 2.336950e-02,  2.853409e-02, -4.050028e-03],\n",
      "          [ 2.851397e-02,  1.330196e-02, -8.010752e-03]],\n",
      "\n",
      "         [[-4.723867e-03,  1.066642e-02, -1.311032e-02],\n",
      "          [ 1.808322e-02, -8.245043e-03,  2.284645e-02],\n",
      "          [ 2.133408e-02, -5.658505e-03, -1.665347e-02]],\n",
      "\n",
      "         [[ 2.921472e-02,  2.362188e-02,  1.805876e-02],\n",
      "          [-1.550695e-02,  1.420054e-02, -2.175410e-02],\n",
      "          [-1.640409e-02,  2.924672e-02,  1.394517e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.886341e-02, -8.726910e-03,  1.186056e-02],\n",
      "          [-1.557321e-02, -1.818087e-02, -2.945594e-02],\n",
      "          [ 4.447425e-03, -2.385402e-02,  1.732092e-02]],\n",
      "\n",
      "         [[ 1.084452e-02,  1.232177e-02,  2.503979e-02],\n",
      "          [-1.140656e-02, -1.393469e-03, -1.814568e-02],\n",
      "          [ 2.207734e-02,  1.436461e-02, -1.757017e-02]],\n",
      "\n",
      "         [[ 9.829683e-03,  4.884472e-03,  2.749488e-02],\n",
      "          [ 2.044617e-02,  8.164546e-03,  1.547587e-02],\n",
      "          [-1.583791e-02, -3.138931e-03, -1.497508e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.503104e-02, -7.421853e-03, -2.713961e-02],\n",
      "          [-2.314778e-02,  2.129605e-02, -2.376391e-02],\n",
      "          [ 2.199831e-02, -1.611567e-02,  1.074736e-02]],\n",
      "\n",
      "         [[ 2.111750e-02,  4.399082e-03,  4.500663e-03],\n",
      "          [-1.983013e-02,  1.599321e-03, -2.423836e-02],\n",
      "          [ 2.624911e-02,  4.278356e-03, -1.550728e-02]],\n",
      "\n",
      "         [[ 1.726691e-02, -1.484217e-02,  1.718123e-02],\n",
      "          [-2.767107e-02, -2.523578e-02,  2.459438e-02],\n",
      "          [-2.719820e-02, -2.788724e-02,  3.504192e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.064619e-02, -1.159410e-02,  1.892782e-02],\n",
      "          [ 1.440046e-03, -2.745568e-02, -1.279894e-02],\n",
      "          [ 4.186915e-03, -2.721710e-02,  1.166133e-02]],\n",
      "\n",
      "         [[-2.604299e-02, -1.145201e-03, -1.499489e-02],\n",
      "          [ 2.435056e-02, -2.419848e-02, -1.378640e-02],\n",
      "          [ 1.408857e-02, -1.162001e-02, -3.107056e-03]],\n",
      "\n",
      "         [[-2.884369e-03, -1.891336e-02,  1.028122e-02],\n",
      "          [ 1.263915e-03, -2.353411e-02, -2.714172e-02],\n",
      "          [ 8.071156e-03,  6.567204e-03, -9.707958e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.263297e-04,  4.588993e-03, -8.810274e-04],\n",
      "          [ 2.646249e-02, -3.023032e-03, -1.667321e-02],\n",
      "          [ 2.273594e-02, -1.209985e-02, -2.449957e-02]],\n",
      "\n",
      "         [[ 2.010779e-02,  2.190335e-02,  1.219527e-02],\n",
      "          [-5.453030e-03,  1.600091e-02, -1.054508e-02],\n",
      "          [-2.629552e-02, -1.619309e-03,  6.976051e-03]],\n",
      "\n",
      "         [[ 1.061568e-02,  2.278277e-02, -1.384807e-02],\n",
      "          [-1.930736e-02,  2.064044e-02,  1.383089e-02],\n",
      "          [-2.123477e-02,  2.267996e-02,  6.618621e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.613171e-02, -2.885320e-02, -2.418075e-02],\n",
      "          [-8.219060e-03,  8.792063e-03,  9.606829e-03],\n",
      "          [ 7.067118e-04,  1.793733e-02,  1.305635e-02]],\n",
      "\n",
      "         [[-1.808425e-02, -2.321862e-02, -6.578173e-04],\n",
      "          [-6.779796e-03,  1.598603e-02, -1.813372e-02],\n",
      "          [ 6.066414e-03,  2.215708e-02,  7.468807e-03]],\n",
      "\n",
      "         [[ 2.561839e-02,  2.739687e-02,  2.544644e-02],\n",
      "          [-2.198393e-02,  2.492996e-02, -2.846902e-02],\n",
      "          [ 3.776262e-03, -1.662550e-02, -1.120551e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.556174e-02,  2.322316e-02, -1.222244e-02],\n",
      "          [-1.296646e-02,  8.211026e-03, -2.135503e-02],\n",
      "          [ 1.649997e-02,  2.072158e-02,  1.874030e-02]],\n",
      "\n",
      "         [[-7.045379e-03, -1.157323e-02,  1.672788e-02],\n",
      "          [-8.901991e-03,  1.839658e-02, -1.458429e-02],\n",
      "          [ 1.855426e-02, -2.743602e-03,  5.978532e-05]],\n",
      "\n",
      "         [[ 2.641710e-02, -7.639278e-03, -3.928784e-04],\n",
      "          [ 1.833062e-02,  1.374820e-02,  2.615620e-02],\n",
      "          [ 2.174308e-02, -4.995219e-03,  3.058622e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.395971e-03,  8.989045e-03, -2.542728e-02],\n",
      "          [-1.375523e-02,  2.101360e-02, -8.273760e-03],\n",
      "          [ 9.777751e-04,  8.602543e-03,  2.705929e-02]],\n",
      "\n",
      "         [[ 2.925919e-02, -8.259887e-03,  2.229080e-02],\n",
      "          [-2.567642e-02, -2.343713e-02,  1.619208e-02],\n",
      "          [ 2.630869e-02, -8.639118e-03,  1.812423e-02]],\n",
      "\n",
      "         [[-2.493485e-02, -1.388401e-02, -1.026042e-02],\n",
      "          [-1.402208e-02,  2.871233e-02,  9.420605e-03],\n",
      "          [-1.680973e-02,  2.498242e-02,  2.902320e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.532151e-02,  2.883541e-02, -1.567919e-02],\n",
      "          [ 2.081083e-03, -1.906094e-02,  2.392227e-02],\n",
      "          [ 4.323786e-03, -6.306954e-04,  1.968578e-02]],\n",
      "\n",
      "         [[ 3.842449e-03,  2.870446e-02,  2.187361e-02],\n",
      "          [-3.499562e-03, -1.652648e-02,  2.698847e-02],\n",
      "          [-1.824899e-03,  9.022309e-03,  1.759861e-02]],\n",
      "\n",
      "         [[-1.551261e-02, -2.707387e-02,  2.394178e-02],\n",
      "          [ 1.751278e-02,  1.547599e-02, -1.495265e-02],\n",
      "          [-1.450488e-02, -1.407147e-02, -1.498668e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.009237, -0.021575, -0.005520,  0.018019, -0.017346, -0.021462,\n",
      "         0.019216,  0.009012, -0.012822, -0.004789,  0.021035, -0.021030,\n",
      "        -0.010366, -0.025002,  0.006020,  0.015554, -0.026908,  0.028827,\n",
      "         0.025023, -0.023516,  0.005275,  0.023501, -0.022002,  0.012551,\n",
      "         0.025829,  0.026256, -0.008534,  0.027971,  0.012858, -0.007201,\n",
      "        -0.023279,  0.011311,  0.022610,  0.015113,  0.019995,  0.023616,\n",
      "         0.019483, -0.005870,  0.015605,  0.023292,  0.021430,  0.025835,\n",
      "         0.010574, -0.013415, -0.000707,  0.021039,  0.015075, -0.025001,\n",
      "        -0.016897,  0.013565, -0.015635,  0.014595,  0.028108,  0.024486,\n",
      "        -0.026297,  0.007290, -0.006990, -0.020204, -0.010803, -0.006715,\n",
      "        -0.016924, -0.015528,  0.027210, -0.023984,  0.006548,  0.022216,\n",
      "        -0.003690,  0.016696,  0.021038, -0.009307,  0.028982,  0.010851,\n",
      "         0.003651,  0.029167, -0.011804,  0.018512,  0.012399,  0.028507,\n",
      "        -0.009882,  0.012646,  0.001939, -0.026230, -0.009629,  0.024626,\n",
      "        -0.023003, -0.008073, -0.025956, -0.006898, -0.017010,  0.022183,\n",
      "         0.013099,  0.026343, -0.019861,  0.027269, -0.000460,  0.004032,\n",
      "         0.017561,  0.009551,  0.029372,  0.026467,  0.000900, -0.026910,\n",
      "         0.021654,  0.006024,  0.012777, -0.018219, -0.020953,  0.022823,\n",
      "        -0.018702,  0.001082, -0.019652, -0.009807,  0.021813,  0.001922,\n",
      "        -0.014744, -0.007184, -0.024145, -0.017423, -0.007144,  0.002172,\n",
      "         0.018841,  0.007321,  0.006383,  0.019912,  0.011410, -0.020065,\n",
      "         0.002592, -0.013735, -0.003633,  0.003029,  0.013272,  0.019260,\n",
      "        -0.021018,  0.001416,  0.007783,  0.022694, -0.011045, -0.024033,\n",
      "        -0.027527, -0.022850,  0.023882,  0.000879,  0.005271, -0.015455,\n",
      "        -0.009173, -0.013076,  0.008770, -0.024226, -0.014593, -0.007917,\n",
      "         0.018003,  0.011049, -0.028856, -0.026497, -0.010604, -0.021800,\n",
      "        -0.027331,  0.013300,  0.011228, -0.024208,  0.016616, -0.006004,\n",
      "        -0.009710,  0.021162,  0.011015, -0.003811,  0.006090,  0.000640,\n",
      "         0.013024, -0.020939,  0.006780,  0.008799,  0.008234, -0.008544,\n",
      "         0.023838,  0.008519, -0.009292,  0.018368, -0.024980, -0.018594,\n",
      "        -0.004149,  0.011462, -0.002928,  0.003900,  0.025011, -0.015115,\n",
      "        -0.010628,  0.012707,  0.027617,  0.006857, -0.011054, -0.010089,\n",
      "        -0.026375, -0.002997, -0.011351,  0.026201, -0.003843,  0.019675,\n",
      "         0.013702,  0.018612, -0.017245, -0.026929,  0.025663, -0.022874,\n",
      "        -0.013751, -0.023918, -0.012434,  0.016615, -0.012587, -0.002642,\n",
      "        -0.013697,  0.027882, -0.011544, -0.025794,  0.010864,  0.019519,\n",
      "        -0.001195, -0.028145,  0.007829,  0.009678,  0.011441, -0.016241,\n",
      "         0.021853,  0.018342,  0.015910,  0.014485,  0.019637, -0.018774,\n",
      "         0.017537,  0.020111,  0.022555, -0.025893,  0.016067,  0.012123,\n",
      "        -0.006170,  0.024303, -0.002205,  0.011481,  0.017008,  0.027143,\n",
      "        -0.028939, -0.004399,  0.002263, -0.012593, -0.026473, -0.007169,\n",
      "        -0.024318,  0.026062,  0.025597, -0.015873, -0.009863, -0.024258,\n",
      "        -0.007889, -0.027734,  0.005558, -0.021132], requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.039826, -0.022517,  0.038557],\n",
      "          [ 0.006017,  0.020007,  0.018496],\n",
      "          [ 0.022000, -0.008840, -0.018412]],\n",
      "\n",
      "         [[ 0.018690,  0.002517, -0.012441],\n",
      "          [-0.027535, -0.025496, -0.017856],\n",
      "          [ 0.022552, -0.033872, -0.011709]],\n",
      "\n",
      "         [[ 0.011523,  0.004334,  0.029507],\n",
      "          [ 0.008463, -0.015124,  0.014355],\n",
      "          [ 0.008490,  0.031012, -0.027067]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.001204,  0.030462,  0.022543],\n",
      "          [ 0.004112, -0.016919, -0.013735],\n",
      "          [ 0.029594,  0.028855, -0.022754]],\n",
      "\n",
      "         [[ 0.031333,  0.016701, -0.036005],\n",
      "          [ 0.002112,  0.029695, -0.020401],\n",
      "          [-0.039663, -0.008380,  0.002749]],\n",
      "\n",
      "         [[-0.030482,  0.041270, -0.020029],\n",
      "          [ 0.021735,  0.017298, -0.015893],\n",
      "          [-0.014611, -0.003946,  0.041444]]],\n",
      "\n",
      "\n",
      "        [[[-0.005418, -0.007340,  0.023781],\n",
      "          [ 0.022192,  0.012678, -0.030706],\n",
      "          [-0.024235, -0.019500, -0.025687]],\n",
      "\n",
      "         [[-0.000729,  0.030508, -0.004001],\n",
      "          [-0.032582,  0.002873, -0.019095],\n",
      "          [-0.008883, -0.029888,  0.028603]],\n",
      "\n",
      "         [[-0.018670, -0.011643,  0.031529],\n",
      "          [ 0.019607,  0.018676,  0.039346],\n",
      "          [-0.002724,  0.027082,  0.001564]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.037146, -0.002518,  0.004039],\n",
      "          [-0.029874,  0.002123,  0.020662],\n",
      "          [ 0.009329,  0.032058,  0.029508]],\n",
      "\n",
      "         [[ 0.021890, -0.020193,  0.016534],\n",
      "          [-0.008939, -0.025937,  0.039038],\n",
      "          [-0.001953,  0.012112,  0.005460]],\n",
      "\n",
      "         [[ 0.000987, -0.041316, -0.023065],\n",
      "          [-0.013249,  0.041254,  0.032583],\n",
      "          [-0.003651, -0.036448, -0.016204]]],\n",
      "\n",
      "\n",
      "        [[[-0.021110,  0.027322,  0.007045],\n",
      "          [-0.002406, -0.016965,  0.035018],\n",
      "          [ 0.013244, -0.028792, -0.025218]],\n",
      "\n",
      "         [[-0.007439,  0.037532,  0.035342],\n",
      "          [-0.014379,  0.005520, -0.034749],\n",
      "          [ 0.026400,  0.005304, -0.040974]],\n",
      "\n",
      "         [[-0.025767,  0.022614,  0.002889],\n",
      "          [ 0.032403,  0.030780, -0.034737],\n",
      "          [-0.012658,  0.013557, -0.039439]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.005857, -0.039148, -0.021767],\n",
      "          [ 0.026445, -0.014294,  0.017449],\n",
      "          [ 0.018343,  0.008749,  0.036553]],\n",
      "\n",
      "         [[-0.015618,  0.029252, -0.038478],\n",
      "          [ 0.023838,  0.006557,  0.034950],\n",
      "          [-0.009273,  0.010495, -0.005713]],\n",
      "\n",
      "         [[ 0.005905, -0.024568, -0.036021],\n",
      "          [-0.020812, -0.014079, -0.002371],\n",
      "          [-0.037783,  0.036984, -0.002116]]],\n",
      "\n",
      "\n",
      "        [[[ 0.035333, -0.020145,  0.015181],\n",
      "          [-0.001264, -0.015582,  0.025238],\n",
      "          [-0.014429, -0.003137, -0.031377]],\n",
      "\n",
      "         [[ 0.016859,  0.022771, -0.021821],\n",
      "          [ 0.027563, -0.038684, -0.010071],\n",
      "          [ 0.017151, -0.004763, -0.041435]],\n",
      "\n",
      "         [[-0.006643,  0.021750, -0.002284],\n",
      "          [ 0.009115, -0.004054,  0.038421],\n",
      "          [ 0.001747, -0.030001,  0.018647]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.004380, -0.009903,  0.030185],\n",
      "          [-0.038744, -0.031022, -0.035989],\n",
      "          [ 0.007078, -0.010110,  0.017230]],\n",
      "\n",
      "         [[ 0.004544, -0.029799,  0.024612],\n",
      "          [ 0.028750,  0.009683,  0.021855],\n",
      "          [ 0.039739,  0.006795,  0.011102]],\n",
      "\n",
      "         [[-0.026403, -0.017902,  0.032401],\n",
      "          [-0.010719, -0.039223, -0.009734],\n",
      "          [ 0.002214,  0.024169, -0.029786]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.734256e-02, -4.107367e-02, -7.593259e-05, -4.141396e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[-5.911019e-03,  1.070539e-02, -3.018349e-03],\n",
      "          [ 1.188167e-02,  5.916366e-03,  2.354903e-03],\n",
      "          [-1.278520e-05, -1.129506e-02, -2.021728e-02]],\n",
      "\n",
      "         [[ 2.140896e-02, -1.629003e-02,  5.104693e-03],\n",
      "          [-1.213389e-02, -1.779401e-02, -2.920296e-02],\n",
      "          [ 6.279694e-03, -1.082512e-02, -1.984063e-02]],\n",
      "\n",
      "         [[ 1.344046e-03,  1.652229e-02,  2.925577e-02],\n",
      "          [-2.644503e-03, -2.693164e-02, -1.032062e-02],\n",
      "          [-1.241710e-02, -8.132806e-03,  1.673566e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.529415e-03, -4.624743e-03,  1.382096e-02],\n",
      "          [-1.006140e-02, -2.779602e-02,  1.060700e-02],\n",
      "          [-2.083277e-02,  2.484739e-02, -2.278477e-03]],\n",
      "\n",
      "         [[-2.270627e-02, -2.656572e-02, -2.765128e-02],\n",
      "          [-1.438107e-02, -1.858185e-02,  1.847841e-02],\n",
      "          [-2.911646e-02,  4.557483e-04,  1.920980e-02]],\n",
      "\n",
      "         [[-5.160654e-03,  2.717101e-02,  5.175378e-04],\n",
      "          [-2.011953e-02, -2.212466e-02, -2.256647e-02],\n",
      "          [-3.815517e-04,  2.779539e-02,  6.589117e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.875409e-02, -9.096731e-03,  2.489937e-02],\n",
      "          [ 1.421273e-02,  2.506376e-02, -2.121816e-02],\n",
      "          [-1.377506e-03, -5.944813e-03,  1.266933e-02]],\n",
      "\n",
      "         [[-1.135566e-02,  2.056727e-02, -6.824056e-03],\n",
      "          [-1.598269e-02,  6.288221e-03, -9.062676e-03],\n",
      "          [-2.739369e-02, -1.289827e-02,  2.384594e-02]],\n",
      "\n",
      "         [[-6.529829e-03, -2.684544e-02,  2.724895e-02],\n",
      "          [-1.004089e-02,  1.350941e-02, -7.314481e-03],\n",
      "          [-1.176856e-02,  2.157059e-02, -2.099525e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.717946e-03, -1.683399e-02,  1.264657e-02],\n",
      "          [ 2.086506e-02, -9.601181e-03,  1.895873e-02],\n",
      "          [-6.606255e-03,  2.462932e-02,  1.560675e-02]],\n",
      "\n",
      "         [[-1.748445e-02,  2.582893e-02, -2.440162e-03],\n",
      "          [ 2.874111e-02, -2.203004e-02, -7.618777e-05],\n",
      "          [-2.497428e-02, -2.388457e-02,  5.840046e-03]],\n",
      "\n",
      "         [[ 1.701512e-02, -9.713160e-03,  9.214057e-03],\n",
      "          [-2.589999e-02, -1.645645e-02, -4.359702e-03],\n",
      "          [-1.613904e-02,  1.376769e-02,  1.897787e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.864277e-02,  1.305671e-02, -2.832623e-03],\n",
      "          [ 7.476235e-03,  2.028411e-02, -1.310359e-02],\n",
      "          [-1.366455e-02,  2.162536e-02,  2.463650e-02]],\n",
      "\n",
      "         [[ 2.140550e-02, -1.672449e-02, -8.081974e-03],\n",
      "          [ 1.331201e-02,  1.693602e-02, -2.273335e-02],\n",
      "          [ 2.437608e-03, -2.743416e-04, -1.299989e-02]],\n",
      "\n",
      "         [[ 1.865420e-02,  1.689059e-02, -7.943440e-03],\n",
      "          [ 2.439655e-02, -3.500581e-03, -2.519210e-02],\n",
      "          [ 1.971863e-02,  2.682766e-03, -2.559676e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.814370e-03, -2.066730e-02,  1.882788e-02],\n",
      "          [-3.171055e-03, -2.875124e-02,  1.901252e-02],\n",
      "          [ 2.120691e-02,  1.422832e-02, -2.732764e-02]],\n",
      "\n",
      "         [[ 2.425472e-02, -2.744650e-02,  1.009270e-02],\n",
      "          [ 2.636409e-02,  6.175330e-03,  1.221334e-02],\n",
      "          [-5.609103e-03,  1.133964e-02,  2.051089e-02]],\n",
      "\n",
      "         [[-2.854016e-02, -2.940951e-02, -2.114342e-02],\n",
      "          [ 5.070703e-03, -8.215394e-03, -2.197098e-02],\n",
      "          [ 2.508613e-02, -3.037235e-03,  1.112584e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 8.693362e-03, -5.383821e-03, -2.127181e-02],\n",
      "          [-7.447563e-03,  2.610707e-02,  1.344481e-02],\n",
      "          [ 8.295080e-03, -3.340131e-03, -4.816342e-03]],\n",
      "\n",
      "         [[-2.666515e-02, -1.611713e-02,  1.386140e-02],\n",
      "          [ 2.656894e-02, -1.119676e-02,  2.349662e-02],\n",
      "          [ 1.800614e-02,  6.495228e-03,  1.622864e-02]],\n",
      "\n",
      "         [[-2.753118e-02, -8.035868e-03,  1.495962e-02],\n",
      "          [ 4.623344e-03, -1.374532e-02,  5.037630e-03],\n",
      "          [-2.217819e-02, -2.726514e-02, -2.555105e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.420072e-03,  2.416686e-02, -1.795971e-02],\n",
      "          [ 2.104629e-02,  2.610531e-02, -2.644589e-02],\n",
      "          [ 1.148886e-02, -2.475988e-02, -2.615722e-02]],\n",
      "\n",
      "         [[-8.695807e-03,  8.468678e-03, -1.219962e-02],\n",
      "          [ 2.060850e-02,  2.543961e-02,  4.214959e-03],\n",
      "          [-2.291461e-02,  8.264249e-03, -1.591158e-02]],\n",
      "\n",
      "         [[-2.212990e-02,  1.281947e-02, -2.156701e-02],\n",
      "          [-6.435849e-03, -1.856359e-03,  2.039018e-02],\n",
      "          [-2.083797e-02, -2.696227e-02, -1.909120e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.176673e-02,  1.377641e-02, -2.677779e-02],\n",
      "          [-4.159100e-05, -2.511285e-02, -4.846649e-03],\n",
      "          [-1.850587e-02,  1.013012e-02, -3.171196e-03]],\n",
      "\n",
      "         [[-2.523951e-02, -6.581191e-03, -1.088124e-02],\n",
      "          [-1.478962e-02,  2.199845e-03, -2.321624e-02],\n",
      "          [-3.414843e-04,  1.525603e-02,  2.442540e-02]],\n",
      "\n",
      "         [[ 3.832119e-03, -1.174423e-02,  2.859090e-02],\n",
      "          [ 1.464178e-02,  5.354164e-03, -2.283032e-02],\n",
      "          [-1.847395e-02, -2.754982e-02,  1.961950e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.982644e-02, -1.993019e-02,  1.904055e-02],\n",
      "          [ 9.336246e-03,  2.852613e-03,  2.192350e-02],\n",
      "          [ 1.061028e-02,  1.119860e-02,  7.102577e-03]],\n",
      "\n",
      "         [[-7.138196e-04, -2.708115e-02, -2.455934e-02],\n",
      "          [ 1.856845e-02,  5.365955e-03,  8.928182e-03],\n",
      "          [ 8.145478e-04,  6.388867e-03, -2.697016e-02]],\n",
      "\n",
      "         [[ 1.298225e-02, -2.254022e-02, -4.192969e-03],\n",
      "          [-1.893194e-02, -1.585089e-02, -1.616357e-02],\n",
      "          [-1.317458e-03, -2.256753e-02,  1.588323e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.658545e-03,  2.430491e-02,  7.477751e-03],\n",
      "          [-2.358966e-02, -1.346454e-03, -7.166008e-03],\n",
      "          [ 1.338871e-02, -1.950822e-02,  1.277470e-02]],\n",
      "\n",
      "         [[ 2.774498e-02, -1.546894e-02,  1.810091e-02],\n",
      "          [-9.678943e-03, -2.416826e-02,  4.154546e-03],\n",
      "          [-1.572266e-02, -2.578562e-03, -2.683474e-02]],\n",
      "\n",
      "         [[ 9.851512e-04, -8.771494e-04, -2.223141e-03],\n",
      "          [-5.131435e-03, -2.509930e-02,  1.594245e-02],\n",
      "          [-1.820762e-03,  4.772613e-03, -2.139735e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.599355e-02, -1.541823e-02,  1.478360e-02],\n",
      "          [-2.747136e-02,  1.222656e-02, -2.480649e-02],\n",
      "          [ 4.309585e-03,  2.684627e-02,  4.501963e-03]],\n",
      "\n",
      "         [[-1.969441e-02, -1.461004e-02, -2.250881e-02],\n",
      "          [-2.150768e-02, -2.000454e-02, -1.890602e-02],\n",
      "          [-7.250272e-04,  9.894235e-03, -2.098290e-02]],\n",
      "\n",
      "         [[-1.806759e-02, -1.089625e-02, -5.457828e-03],\n",
      "          [-2.670098e-02,  2.940067e-02, -8.993754e-03],\n",
      "          [-2.075028e-02, -1.510979e-02, -2.411899e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.016497,  0.027924,  0.002097,  0.011289, -0.027622, -0.010029,\n",
      "         0.019490,  0.006287,  0.023984,  0.027861, -0.013443, -0.002902,\n",
      "        -0.007366,  0.002906,  0.013754,  0.003333,  0.020607, -0.013046,\n",
      "         0.006802,  0.028044,  0.005756,  0.026803, -0.000503, -0.007816,\n",
      "        -0.022544, -0.020263,  0.020509, -0.018511, -0.029103,  0.007258,\n",
      "        -0.014698,  0.028561, -0.008988, -0.016253,  0.006111,  0.023017,\n",
      "        -0.009320,  0.010402, -0.009904, -0.014386, -0.023261, -0.019277,\n",
      "        -0.023579, -0.015120, -0.003483, -0.024236,  0.024214,  0.010617,\n",
      "         0.015914,  0.022452, -0.023119, -0.020809,  0.003424, -0.018135,\n",
      "        -0.005517, -0.012521,  0.021722, -0.013514,  0.007308,  0.005792,\n",
      "         0.000949,  0.015284, -0.018709, -0.014142,  0.006662, -0.007084,\n",
      "         0.000251,  0.014558,  0.003346,  0.025251, -0.020957, -0.019649,\n",
      "        -0.024121, -0.007738,  0.005087,  0.012569,  0.028824, -0.010213,\n",
      "         0.008498, -0.021790, -0.018768, -0.025676, -0.018790,  0.003769,\n",
      "        -0.021979, -0.005545, -0.005850, -0.005706, -0.013924,  0.027360,\n",
      "        -0.004233,  0.024708, -0.029017, -0.002280, -0.017118, -0.026515,\n",
      "        -0.008825,  0.018504, -0.026838,  0.013266,  0.014116, -0.027527,\n",
      "        -0.028790, -0.010572, -0.025396,  0.025382,  0.012307,  0.011980,\n",
      "         0.016334, -0.013399, -0.020513,  0.028858,  0.025531,  0.026265,\n",
      "        -0.007292,  0.005643,  0.011669,  0.015622,  0.012922, -0.025808,\n",
      "         0.010874,  0.006100,  0.011844,  0.009978,  0.003409,  0.025711,\n",
      "         0.024747,  0.002240], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-5.179904e-03,  4.114548e-03,  1.150010e-02],\n",
      "          [-1.874219e-02, -7.212738e-03, -2.325249e-02],\n",
      "          [-1.452076e-02, -6.695747e-03,  1.238371e-02]],\n",
      "\n",
      "         [[-2.680570e-02, -3.583523e-03,  2.926331e-02],\n",
      "          [ 2.044454e-02, -2.808022e-02, -1.501727e-02],\n",
      "          [-9.777527e-03,  8.428069e-03, -9.130044e-03]],\n",
      "\n",
      "         [[ 2.415915e-02, -1.330487e-02, -2.138360e-02],\n",
      "          [-2.144880e-02,  1.143175e-02,  1.475787e-02],\n",
      "          [ 1.056026e-02,  1.290206e-02, -2.763348e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.581469e-02, -2.693740e-02, -1.867266e-02],\n",
      "          [ 1.113987e-03, -2.485257e-02,  1.981156e-02],\n",
      "          [ 8.193405e-03,  1.066552e-02,  2.444962e-02]],\n",
      "\n",
      "         [[-2.864886e-02, -5.415402e-03,  6.050272e-03],\n",
      "          [ 1.479634e-02,  2.794942e-03,  1.718417e-02],\n",
      "          [ 1.629682e-03, -1.907645e-02, -2.381705e-03]],\n",
      "\n",
      "         [[-1.183654e-02,  1.650686e-02,  2.646411e-02],\n",
      "          [-1.702912e-02,  8.183075e-03,  1.785319e-02],\n",
      "          [-2.262810e-02, -1.502632e-02, -1.946686e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.935137e-02,  6.966067e-03, -2.601417e-02],\n",
      "          [-1.862588e-02,  2.595528e-02, -5.030546e-03],\n",
      "          [ 2.920307e-02,  1.338955e-02, -2.053514e-02]],\n",
      "\n",
      "         [[-2.923322e-02, -4.709292e-03,  7.619118e-03],\n",
      "          [-2.453189e-02,  1.582734e-03,  9.210391e-03],\n",
      "          [-9.243654e-03, -1.275562e-02,  8.817108e-03]],\n",
      "\n",
      "         [[ 1.341630e-02, -2.793837e-02, -2.468414e-02],\n",
      "          [-2.329537e-02,  1.755869e-02,  2.507888e-02],\n",
      "          [-1.919445e-02,  1.785379e-02,  2.222504e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.612651e-02,  2.372646e-02, -4.566312e-03],\n",
      "          [ 1.248976e-03,  1.863996e-02, -1.348411e-02],\n",
      "          [-2.462204e-02, -2.518412e-03,  5.727300e-03]],\n",
      "\n",
      "         [[ 1.260437e-02,  2.578793e-02, -8.914718e-03],\n",
      "          [ 1.490523e-02, -2.869257e-02,  6.131237e-03],\n",
      "          [ 5.041135e-03, -1.144964e-03,  8.025626e-03]],\n",
      "\n",
      "         [[-2.214658e-02,  5.003339e-03,  1.002150e-02],\n",
      "          [ 1.981168e-02, -2.873422e-02,  2.797922e-02],\n",
      "          [-1.027010e-02, -2.002544e-02,  2.646502e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.414030e-02, -5.238643e-03,  6.046144e-03],\n",
      "          [ 1.760861e-03,  2.282796e-02,  1.052193e-02],\n",
      "          [ 2.104971e-02,  6.451644e-05, -2.203544e-02]],\n",
      "\n",
      "         [[-2.859815e-02,  2.469897e-02,  2.221329e-02],\n",
      "          [ 1.780616e-02, -1.379309e-02,  2.344334e-03],\n",
      "          [ 2.016175e-02,  1.711647e-02, -8.257175e-03]],\n",
      "\n",
      "         [[ 1.616462e-02, -2.407301e-03,  1.987229e-02],\n",
      "          [ 1.567646e-02, -1.577694e-03, -1.364906e-02],\n",
      "          [-1.117610e-02, -1.699045e-02,  1.611528e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.737108e-02,  6.139515e-03,  2.991831e-03],\n",
      "          [ 5.324055e-04, -2.861859e-02, -2.685456e-02],\n",
      "          [-7.271603e-03,  2.213091e-02,  1.564953e-02]],\n",
      "\n",
      "         [[ 1.098189e-02,  2.220814e-02,  4.860125e-04],\n",
      "          [ 1.641260e-02,  2.738038e-02, -1.069644e-02],\n",
      "          [ 2.062033e-02, -2.438559e-02,  4.037580e-03]],\n",
      "\n",
      "         [[ 2.277237e-02, -2.195315e-02, -1.407643e-02],\n",
      "          [-1.114018e-02,  1.902783e-02, -1.447646e-03],\n",
      "          [-2.285447e-04,  2.353715e-03, -1.390822e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.910607e-02, -2.726723e-03, -4.970932e-03],\n",
      "          [ 5.769024e-03,  1.779575e-02, -2.306331e-02],\n",
      "          [-2.423815e-03,  3.249345e-03,  8.659257e-03]],\n",
      "\n",
      "         [[-1.650373e-02, -1.697395e-02,  6.297564e-03],\n",
      "          [-8.369531e-03, -1.537705e-02, -2.072206e-02],\n",
      "          [-1.525409e-02,  2.380950e-03, -9.872513e-03]],\n",
      "\n",
      "         [[ 2.439583e-02,  6.651225e-03, -8.703079e-04],\n",
      "          [-6.729439e-03, -7.550744e-03,  1.072791e-02],\n",
      "          [ 9.625966e-03,  6.509913e-03, -2.562622e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.500831e-03, -2.666868e-02, -2.869464e-02],\n",
      "          [-2.944141e-02,  2.578873e-02, -5.654998e-03],\n",
      "          [-8.739110e-03,  2.613054e-02,  1.082228e-02]],\n",
      "\n",
      "         [[-1.674196e-02, -1.024319e-02,  2.019676e-02],\n",
      "          [-2.863239e-03, -3.399603e-03, -1.102745e-02],\n",
      "          [ 1.967235e-02,  2.274540e-02, -2.581525e-02]],\n",
      "\n",
      "         [[-2.117536e-02, -2.041796e-02, -8.130373e-03],\n",
      "          [-7.455584e-03,  1.481498e-03, -8.882718e-03],\n",
      "          [ 1.607621e-02,  1.562366e-02,  7.245163e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.021525e-03,  9.451946e-03,  3.123211e-03],\n",
      "          [-8.272218e-03, -7.647317e-03,  2.676805e-02],\n",
      "          [-2.361538e-02, -1.692224e-02, -2.681287e-03]],\n",
      "\n",
      "         [[-3.741939e-03,  2.474906e-02,  1.058394e-02],\n",
      "          [-1.296860e-02,  8.109901e-04,  2.544420e-02],\n",
      "          [ 2.680009e-03, -6.489344e-04,  1.402313e-02]],\n",
      "\n",
      "         [[ 5.948646e-03, -7.499490e-03,  4.309403e-03],\n",
      "          [ 1.773796e-02,  2.603357e-02, -7.143203e-03],\n",
      "          [-2.268105e-02,  8.894788e-03, -6.921668e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.512902e-02,  1.364314e-02,  1.452848e-03],\n",
      "          [ 2.457665e-02, -1.799664e-02, -2.220037e-02],\n",
      "          [ 7.975729e-03, -2.876308e-02, -1.034894e-02]],\n",
      "\n",
      "         [[-4.514854e-03, -7.670892e-03,  7.620566e-04],\n",
      "          [-8.134089e-03, -5.820902e-03, -2.191354e-02],\n",
      "          [-7.893553e-03,  1.495342e-02, -2.940692e-02]],\n",
      "\n",
      "         [[ 2.718056e-03, -1.726441e-02,  5.805297e-03],\n",
      "          [-2.450527e-02,  2.591730e-02,  1.858007e-02],\n",
      "          [-9.900849e-03, -1.958778e-02, -1.976179e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.405019e-02,  1.872178e-02, -1.040294e-02],\n",
      "          [ 1.668127e-02,  2.194749e-02, -8.191433e-03],\n",
      "          [-6.062241e-03, -2.828639e-02,  2.523018e-02]],\n",
      "\n",
      "         [[ 1.212227e-02,  2.309371e-02, -8.612573e-04],\n",
      "          [ 2.344821e-02,  2.109013e-02, -1.615090e-02],\n",
      "          [-2.324249e-02,  5.599389e-03,  3.704892e-03]],\n",
      "\n",
      "         [[-5.846372e-03,  2.786683e-02,  1.175858e-02],\n",
      "          [-1.361389e-02, -1.459281e-02, -2.606341e-02],\n",
      "          [-2.527975e-03,  1.039862e-02, -9.508952e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.407961e-02,  8.435743e-03,  2.625095e-03],\n",
      "          [-1.158434e-02,  6.856304e-04,  3.556194e-03],\n",
      "          [ 5.687563e-03,  2.189518e-02, -6.875144e-03]],\n",
      "\n",
      "         [[ 2.608219e-03, -8.175582e-03, -2.332347e-02],\n",
      "          [ 7.433737e-03, -2.494746e-02, -9.212214e-04],\n",
      "          [-1.426741e-02, -2.846052e-02, -5.308149e-03]],\n",
      "\n",
      "         [[ 6.320132e-03, -2.847633e-02,  7.070173e-04],\n",
      "          [ 2.073678e-02,  1.155434e-02,  2.030803e-03],\n",
      "          [ 9.113139e-03,  2.195312e-03, -1.542515e-02]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.000188,  0.000575, -0.006601, -0.009402,  0.012741, -0.010671,\n",
      "        -0.022564, -0.007480,  0.028216, -0.021018, -0.026218, -0.011446,\n",
      "         0.018844, -0.011152, -0.027932, -0.028901,  0.028083, -0.005058,\n",
      "         0.022111, -0.015421, -0.004405,  0.003593, -0.007418,  0.028963,\n",
      "        -0.015530,  0.019832, -0.028843, -0.022081,  0.023960,  0.029462,\n",
      "        -0.022846,  0.022091,  0.009185,  0.015887,  0.008396, -0.022408,\n",
      "        -0.018501,  0.019906, -0.022076,  0.018089,  0.003320,  0.027569,\n",
      "         0.000668, -0.010287,  0.005515,  0.001697,  0.024199, -0.006955,\n",
      "         0.002497,  0.010145,  0.023137,  0.023823, -0.025654,  0.025009,\n",
      "         0.014608, -0.010332, -0.023542,  0.027593, -0.019795,  0.015136,\n",
      "        -0.003717,  0.027064, -0.026398,  0.005686, -0.016670,  0.012912,\n",
      "        -0.016309,  0.009452, -0.002694, -0.007195, -0.007958,  0.002280,\n",
      "         0.023382, -0.006666, -0.026438,  0.022319, -0.020785, -0.028414,\n",
      "         0.010035,  0.010255,  0.013570, -0.016060, -0.007757, -0.011878,\n",
      "         0.000607, -0.027980, -0.012383, -0.015480, -0.021678, -0.004107,\n",
      "        -0.021202, -0.012548, -0.000740,  0.014192,  0.020254, -0.005037,\n",
      "        -0.011796, -0.007574, -0.001491, -0.025095, -0.000813, -0.001225,\n",
      "         0.029246, -0.010532, -0.021968, -0.026254, -0.006173, -0.009275,\n",
      "         0.024828,  0.014810,  0.023738, -0.027481, -0.020010,  0.009479,\n",
      "        -0.022372,  0.024619, -0.007043, -0.022842,  0.012261, -0.020766,\n",
      "         0.022583,  0.008628,  0.020680, -0.019394,  0.009283, -0.001027,\n",
      "         0.017180, -0.018772], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# instanciate the model\n",
    "model = LossyCompAutoencoder()\n",
    "print(model)\n",
    "params = list(model.parameters())\n",
    "print(len(params))\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 13.110422\n",
      "running loss : 12.821613\n",
      "running loss : 12.699829\n",
      "running loss : 12.087972\n",
      "running loss : 11.004387\n",
      "running loss : 10.827159\n",
      "running loss : 10.237216\n",
      "running loss : 10.247946\n",
      "running loss : 9.947038\n",
      "running loss : 9.554226\n",
      "running loss : 9.481089\n",
      "running loss : 8.889006\n",
      "running loss : 8.504358\n",
      "running loss : 8.117556\n",
      "running loss : 7.772272\n",
      "running loss : 7.686276\n",
      "running loss : 7.227600\n",
      "running loss : 6.941518\n",
      "running loss : 6.720786\n",
      "running loss : 6.459561\n",
      "running loss : 6.160937\n",
      "running loss : 6.165912\n",
      "running loss : 5.966523\n",
      "running loss : 5.680616\n",
      "running loss : 5.574351\n",
      "running loss : 5.483196\n",
      "running loss : 5.292502\n",
      "running loss : 5.154130\n",
      "running loss : 5.070849\n",
      "running loss : 4.916364\n",
      "running loss : 4.778482\n",
      "running loss : 4.662082\n",
      "running loss : 4.677721\n",
      "running loss : 4.613502\n",
      "running loss : 4.427719\n",
      "running loss : 4.387122\n",
      "running loss : 4.277127\n",
      "running loss : 4.225882\n",
      "running loss : 4.193786\n",
      "running loss : 4.109037\n",
      "running loss : 4.090614\n",
      "running loss : 4.068547\n",
      "running loss : 4.146887\n",
      "running loss : 3.982817\n",
      "running loss : 3.908633\n",
      "running loss : 3.988716\n",
      "running loss : 3.923130\n",
      "running loss : 3.927616\n",
      "running loss : 3.870122\n",
      "running loss : 3.938318\n",
      "running loss : 3.930311\n",
      "running loss : 3.756452\n",
      "running loss : 3.826843\n",
      "running loss : 3.861021\n",
      "running loss : 3.803593\n",
      "running loss : 3.765918\n",
      "running loss : 3.778510\n",
      "running loss : 3.739408\n",
      "running loss : 3.745234\n",
      "running loss : 3.666138\n",
      "running loss : 3.705802\n",
      "running loss : 3.682652\n",
      "running loss : 3.740801\n",
      "running loss : 3.636563\n",
      "running loss : 3.589002\n",
      "running loss : 3.587375\n",
      "running loss : 3.588744\n",
      "running loss : 3.519949\n",
      "running loss : 3.564996\n",
      "running loss : 3.576676\n",
      "running loss : 3.450890\n",
      "running loss : 3.488588\n",
      "running loss : 3.468744\n",
      "running loss : 3.390768\n",
      "running loss : 3.393732\n",
      "running loss : 3.385256\n",
      "running loss : 3.355088\n",
      "running loss : 3.300862\n",
      "running loss : 3.391426\n",
      "running loss : 3.342971\n",
      "running loss : 3.322029\n",
      "running loss : 3.281685\n",
      "running loss : 3.305891\n",
      "running loss : 3.286986\n",
      "running loss : 3.245543\n",
      "running loss : 3.295884\n",
      "running loss : 3.312233\n",
      "running loss : 3.239021\n",
      "running loss : 3.187131\n",
      "running loss : 3.166162\n",
      "running loss : 3.253421\n",
      "running loss : 3.269194\n",
      "running loss : 3.209852\n",
      "running loss : 3.182221\n",
      "running loss : 3.116164\n",
      "running loss : 3.127940\n",
      "running loss : 3.148996\n",
      "running loss : 3.073739\n",
      "running loss : 3.094671\n",
      "running loss : 3.066765\n",
      "running loss : 3.125011\n",
      "running loss : 3.037357\n",
      "running loss : 3.077622\n",
      "running loss : 3.106840\n",
      "running loss : 3.087597\n",
      "running loss : 3.016538\n",
      "running loss : 3.069441\n",
      "running loss : 3.046494\n",
      "running loss : 3.017217\n",
      "running loss : 2.990969\n",
      "running loss : 2.998576\n",
      "running loss : 3.013077\n",
      "running loss : 3.040390\n",
      "running loss : 2.993968\n",
      "running loss : 2.940524\n",
      "running loss : 2.997013\n",
      "running loss : 2.935408\n",
      "running loss : 2.958627\n",
      "running loss : 3.005814\n",
      "running loss : 2.942074\n",
      "running loss : 2.971000\n",
      "running loss : 2.951274\n",
      "running loss : 2.955943\n",
      "running loss : 2.925489\n",
      "running loss : 2.961573\n",
      "running loss : 2.948703\n",
      "running loss : 2.872606\n",
      "running loss : 2.963349\n",
      "running loss : 2.892547\n",
      "running loss : 2.908113\n",
      "running loss : 2.905097\n",
      "running loss : 2.927288\n",
      "running loss : 2.921448\n",
      "running loss : 2.873268\n",
      "running loss : 2.917189\n",
      "running loss : 2.849290\n",
      "running loss : 2.869503\n",
      "running loss : 2.903273\n",
      "running loss : 2.893084\n",
      "running loss : 2.835759\n",
      "running loss : 2.869678\n",
      "running loss : 2.856724\n",
      "running loss : 2.854332\n",
      "running loss : 2.840424\n",
      "running loss : 2.787413\n",
      "running loss : 2.811789\n",
      "running loss : 2.881273\n",
      "running loss : 2.822963\n",
      "running loss : 2.850269\n",
      "running loss : 2.759827\n",
      "running loss : 2.794163\n",
      "running loss : 2.782082\n",
      "running loss : 2.813951\n",
      "running loss : 2.819996\n",
      "running loss : 2.865248\n",
      "running loss : 2.772570\n",
      "running loss : 2.811269\n",
      "running loss : 2.731199\n",
      "running loss : 2.794581\n",
      "running loss : 2.797156\n",
      "running loss : 2.805488\n",
      "running loss : 2.744518\n",
      "running loss : 2.759474\n",
      "running loss : 2.801360\n",
      "running loss : 2.709698\n",
      "running loss : 2.735000\n",
      "running loss : 2.688200\n",
      "running loss : 2.676479\n",
      "running loss : 2.713198\n",
      "running loss : 2.673791\n",
      "running loss : 2.741614\n",
      "running loss : 2.675066\n",
      "running loss : 2.667448\n",
      "running loss : 2.665184\n",
      "running loss : 2.670294\n",
      "running loss : 2.648345\n",
      "running loss : 2.621509\n",
      "running loss : 2.665775\n",
      "running loss : 2.694934\n",
      "running loss : 2.671382\n",
      "running loss : 2.684075\n",
      "running loss : 2.639320\n",
      "running loss : 2.587129\n",
      "running loss : 2.649286\n",
      "running loss : 2.642663\n",
      "running loss : 2.677036\n",
      "running loss : 2.594797\n",
      "running loss : 2.631017\n",
      "running loss : 2.617784\n",
      "running loss : 2.605818\n",
      "running loss : 2.640911\n",
      "running loss : 2.591849\n",
      "running loss : 2.576285\n",
      "running loss : 2.577061\n",
      "running loss : 2.605694\n",
      "running loss : 2.580045\n",
      "running loss : 2.578433\n",
      "running loss : 2.573903\n",
      "running loss : 2.529949\n",
      "running loss : 2.529620\n",
      "running loss : 2.535715\n",
      "running loss : 2.605134\n",
      "running loss : 2.529698\n",
      "running loss : 2.544560\n",
      "running loss : 2.521815\n",
      "running loss : 2.537312\n",
      "running loss : 2.486482\n",
      "running loss : 2.553379\n",
      "running loss : 2.593303\n",
      "running loss : 2.525402\n",
      "running loss : 2.546589\n",
      "running loss : 2.460937\n",
      "running loss : 2.552737\n",
      "running loss : 2.511781\n",
      "running loss : 2.526687\n",
      "running loss : 2.446639\n",
      "running loss : 2.448807\n",
      "running loss : 2.487630\n",
      "running loss : 2.444631\n",
      "running loss : 2.447978\n",
      "running loss : 2.488738\n",
      "running loss : 2.469435\n",
      "running loss : 2.473675\n",
      "running loss : 2.421178\n",
      "running loss : 2.470207\n",
      "running loss : 2.460459\n",
      "running loss : 2.469645\n",
      "running loss : 2.503854\n",
      "running loss : 2.390518\n",
      "running loss : 2.438857\n",
      "running loss : 2.423167\n",
      "running loss : 2.459512\n",
      "running loss : 2.497536\n",
      "running loss : 2.411467\n",
      "running loss : 2.370866\n",
      "running loss : 2.424270\n",
      "running loss : 2.403176\n",
      "running loss : 2.402298\n",
      "running loss : 2.434686\n",
      "running loss : 2.416979\n",
      "running loss : 2.414025\n",
      "running loss : 2.385096\n",
      "running loss : 2.417149\n",
      "running loss : 2.373813\n",
      "running loss : 2.397125\n",
      "running loss : 2.393284\n",
      "running loss : 2.358431\n",
      "running loss : 2.378947\n",
      "running loss : 2.427082\n",
      "running loss : 2.370722\n",
      "running loss : 2.391969\n",
      "running loss : 2.391636\n",
      "running loss : 2.416543\n",
      "running loss : 2.385684\n",
      "running loss : 2.391737\n",
      "running loss : 2.339951\n",
      "running loss : 2.371656\n",
      "running loss : 2.376623\n",
      "running loss : 2.324416\n",
      "running loss : 2.339192\n",
      "running loss : 2.377255\n",
      "running loss : 2.406398\n",
      "running loss : 2.355149\n",
      "running loss : 2.349282\n",
      "running loss : 2.346601\n",
      "running loss : 2.328851\n",
      "running loss : 2.342945\n",
      "running loss : 2.340136\n",
      "running loss : 2.329121\n",
      "running loss : 2.248681\n",
      "running loss : 2.339705\n",
      "running loss : 2.318254\n",
      "running loss : 2.283310\n",
      "running loss : 2.339108\n",
      "running loss : 2.286034\n",
      "running loss : 2.355939\n",
      "running loss : 2.306004\n",
      "running loss : 2.330567\n",
      "running loss : 2.334160\n",
      "running loss : 2.368860\n",
      "running loss : 2.306036\n",
      "running loss : 2.323577\n",
      "running loss : 2.300129\n",
      "running loss : 2.250293\n",
      "running loss : 2.301899\n",
      "running loss : 2.309738\n",
      "running loss : 2.290441\n",
      "running loss : 2.297405\n",
      "running loss : 2.234432\n",
      "running loss : 2.324609\n",
      "running loss : 2.266746\n",
      "running loss : 2.244191\n",
      "running loss : 2.251147\n",
      "running loss : 2.261201\n",
      "running loss : 2.271052\n",
      "running loss : 2.263234\n",
      "running loss : 2.253825\n",
      "running loss : 2.263672\n",
      "running loss : 2.259287\n",
      "running loss : 2.212210\n",
      "running loss : 2.325243\n",
      "running loss : 2.278629\n",
      "running loss : 2.276089\n",
      "running loss : 2.281091\n",
      "running loss : 2.240360\n",
      "running loss : 2.227746\n",
      "running loss : 2.264534\n",
      "running loss : 2.226979\n",
      "running loss : 2.212451\n",
      "running loss : 2.210297\n",
      "running loss : 2.234041\n",
      "running loss : 2.214505\n",
      "running loss : 2.238099\n",
      "running loss : 2.208031\n",
      "running loss : 2.235215\n",
      "running loss : 2.197715\n",
      "running loss : 2.215742\n",
      "running loss : 2.243164\n",
      "running loss : 2.192494\n",
      "running loss : 2.211807\n",
      "running loss : 2.228940\n",
      "running loss : 2.253140\n",
      "running loss : 2.241519\n",
      "running loss : 2.207050\n",
      "running loss : 2.187329\n",
      "running loss : 2.174350\n",
      "running loss : 2.189242\n",
      "running loss : 2.196856\n",
      "running loss : 2.236603\n",
      "running loss : 2.156464\n",
      "running loss : 2.179631\n",
      "running loss : 2.163550\n",
      "running loss : 2.216785\n",
      "running loss : 2.185547\n",
      "running loss : 2.169576\n",
      "running loss : 2.176351\n",
      "running loss : 2.163223\n",
      "running loss : 2.192008\n",
      "running loss : 2.181248\n",
      "running loss : 2.151160\n",
      "running loss : 2.171340\n",
      "running loss : 2.166520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 2.160338\n",
      "running loss : 2.158389\n",
      "running loss : 2.182407\n",
      "running loss : 2.118132\n",
      "running loss : 2.163751\n",
      "running loss : 2.168315\n",
      "running loss : 2.178533\n",
      "running loss : 2.164979\n",
      "running loss : 2.157520\n",
      "running loss : 2.105127\n",
      "running loss : 2.117109\n",
      "running loss : 2.130358\n",
      "running loss : 2.166527\n",
      "running loss : 2.138882\n",
      "running loss : 2.156538\n",
      "running loss : 2.178836\n",
      "running loss : 2.140216\n",
      "running loss : 2.132592\n",
      "running loss : 2.137639\n",
      "running loss : 2.128965\n",
      "running loss : 2.092594\n",
      "running loss : 2.127406\n",
      "running loss : 2.126577\n",
      "running loss : 2.113502\n",
      "running loss : 2.096445\n",
      "running loss : 2.123373\n",
      "running loss : 2.134740\n",
      "running loss : 2.094349\n",
      "running loss : 2.121315\n",
      "running loss : 2.092197\n",
      "running loss : 2.082008\n",
      "running loss : 2.106860\n",
      "running loss : 2.112056\n",
      "running loss : 2.083858\n",
      "running loss : 2.050967\n",
      "running loss : 2.099520\n",
      "running loss : 2.057623\n",
      "running loss : 2.063986\n",
      "running loss : 2.112212\n",
      "running loss : 2.074196\n",
      "running loss : 2.081490\n",
      "running loss : 2.071071\n",
      "running loss : 2.052665\n",
      "running loss : 2.081896\n",
      "running loss : 2.053432\n",
      "running loss : 2.055639\n",
      "running loss : 2.048421\n",
      "running loss : 2.075864\n",
      "running loss : 2.062127\n",
      "running loss : 2.059722\n",
      "running loss : 2.107758\n",
      "running loss : 2.094177\n",
      "running loss : 2.038887\n",
      "running loss : 2.032619\n",
      "running loss : 2.014230\n",
      "running loss : 2.071177\n",
      "running loss : 2.046579\n",
      "running loss : 2.057167\n",
      "running loss : 2.044838\n",
      "running loss : 2.013657\n",
      "running loss : 2.044010\n",
      "running loss : 2.011637\n",
      "running loss : 2.005306\n",
      "running loss : 2.026648\n",
      "running loss : 2.043553\n",
      "running loss : 2.059441\n",
      "running loss : 2.019064\n",
      "running loss : 2.054868\n",
      "running loss : 2.053899\n",
      "running loss : 2.048152\n",
      "running loss : 2.004842\n",
      "running loss : 2.016615\n",
      "running loss : 2.053758\n",
      "running loss : 2.045201\n",
      "running loss : 2.033435\n",
      "running loss : 2.029541\n",
      "running loss : 2.007585\n",
      "running loss : 2.014295\n",
      "running loss : 2.021536\n",
      "running loss : 2.048766\n",
      "running loss : 2.024219\n",
      "running loss : 1.975419\n",
      "running loss : 2.042445\n",
      "running loss : 2.006271\n",
      "running loss : 2.039527\n",
      "running loss : 2.020584\n",
      "running loss : 1.996813\n",
      "running loss : 2.019382\n",
      "running loss : 1.985591\n",
      "running loss : 1.978288\n",
      "running loss : 1.999658\n",
      "running loss : 1.963296\n",
      "running loss : 1.997000\n",
      "running loss : 1.976106\n",
      "running loss : 1.981128\n",
      "running loss : 1.993978\n",
      "running loss : 1.953444\n",
      "running loss : 1.988914\n",
      "running loss : 1.973990\n",
      "running loss : 2.013521\n",
      "running loss : 1.964932\n",
      "running loss : 1.991574\n",
      "running loss : 1.982189\n",
      "running loss : 1.963708\n",
      "running loss : 1.960249\n",
      "running loss : 2.030155\n",
      "running loss : 2.003329\n",
      "running loss : 1.945481\n",
      "running loss : 1.963071\n",
      "running loss : 1.982416\n",
      "running loss : 1.947501\n",
      "running loss : 1.981280\n",
      "running loss : 1.955092\n",
      "running loss : 1.916102\n",
      "running loss : 1.940808\n",
      "running loss : 1.932942\n",
      "running loss : 1.921099\n",
      "running loss : 1.930923\n",
      "running loss : 1.926343\n",
      "running loss : 1.955882\n",
      "running loss : 1.934768\n",
      "running loss : 1.974939\n",
      "running loss : 1.930125\n",
      "running loss : 1.929187\n",
      "running loss : 1.935885\n",
      "running loss : 1.972011\n",
      "running loss : 1.912861\n",
      "running loss : 1.919648\n",
      "running loss : 1.917931\n",
      "running loss : 1.937714\n",
      "running loss : 1.921585\n",
      "running loss : 1.914694\n",
      "running loss : 1.923416\n",
      "running loss : 1.967408\n",
      "running loss : 1.930500\n",
      "running loss : 1.894451\n",
      "running loss : 1.929158\n",
      "running loss : 1.907178\n",
      "running loss : 1.884792\n",
      "running loss : 1.929989\n",
      "running loss : 1.896533\n",
      "running loss : 1.912675\n",
      "running loss : 1.942185\n",
      "running loss : 1.915403\n",
      "running loss : 1.904700\n",
      "running loss : 1.903136\n",
      "running loss : 1.896553\n",
      "running loss : 1.890912\n",
      "running loss : 1.881834\n",
      "running loss : 1.868362\n",
      "running loss : 1.899957\n",
      "running loss : 1.899373\n",
      "running loss : 1.907032\n",
      "running loss : 1.879930\n",
      "running loss : 1.902262\n",
      "running loss : 1.880667\n",
      "running loss : 1.861521\n",
      "running loss : 1.897311\n",
      "running loss : 1.867597\n",
      "running loss : 1.870751\n",
      "running loss : 1.883916\n",
      "running loss : 1.851882\n",
      "running loss : 1.886329\n",
      "running loss : 1.886302\n",
      "running loss : 1.889795\n",
      "running loss : 1.854500\n",
      "running loss : 1.849776\n",
      "running loss : 1.863593\n",
      "running loss : 1.846537\n",
      "running loss : 1.868596\n",
      "running loss : 1.863412\n",
      "running loss : 1.876680\n",
      "running loss : 1.866238\n",
      "running loss : 1.859618\n",
      "running loss : 1.828815\n",
      "running loss : 1.852952\n",
      "running loss : 1.837882\n",
      "running loss : 1.826370\n",
      "running loss : 1.845808\n",
      "running loss : 1.845109\n",
      "running loss : 1.838866\n",
      "running loss : 1.830700\n",
      "running loss : 1.831403\n",
      "running loss : 1.857637\n",
      "running loss : 1.839917\n",
      "running loss : 1.836327\n",
      "running loss : 1.822934\n",
      "running loss : 1.826452\n",
      "running loss : 1.849820\n",
      "running loss : 1.829397\n",
      "running loss : 1.827230\n",
      "running loss : 1.811259\n",
      "running loss : 1.825714\n",
      "running loss : 1.809684\n",
      "running loss : 1.849171\n",
      "running loss : 1.791070\n",
      "running loss : 1.790585\n",
      "running loss : 1.827660\n",
      "running loss : 1.782032\n",
      "running loss : 1.782269\n",
      "running loss : 1.823242\n",
      "running loss : 1.808090\n",
      "running loss : 1.819845\n",
      "running loss : 1.806380\n",
      "running loss : 1.778521\n",
      "running loss : 1.765798\n",
      "running loss : 1.782280\n",
      "running loss : 1.797545\n",
      "running loss : 1.802169\n",
      "running loss : 1.800070\n",
      "running loss : 1.797903\n",
      "running loss : 1.810911\n",
      "running loss : 1.788765\n",
      "running loss : 1.802998\n",
      "running loss : 1.792172\n",
      "running loss : 1.782354\n",
      "running loss : 1.811306\n",
      "running loss : 1.787553\n",
      "running loss : 1.803313\n",
      "running loss : 1.769732\n",
      "running loss : 1.785926\n",
      "running loss : 1.780041\n",
      "running loss : 1.770209\n",
      "running loss : 1.761639\n",
      "running loss : 1.775908\n",
      "running loss : 1.774786\n",
      "running loss : 1.745668\n",
      "running loss : 1.732616\n",
      "running loss : 1.764439\n",
      "running loss : 1.779729\n",
      "running loss : 1.784414\n",
      "running loss : 1.780415\n",
      "running loss : 1.726496\n",
      "running loss : 1.728503\n",
      "running loss : 1.756949\n",
      "running loss : 1.738028\n",
      "running loss : 1.764757\n",
      "running loss : 1.777781\n",
      "running loss : 1.771969\n",
      "running loss : 1.729628\n",
      "running loss : 1.742558\n",
      "running loss : 1.781276\n",
      "running loss : 1.750538\n",
      "running loss : 1.777382\n",
      "running loss : 1.752450\n",
      "running loss : 1.751379\n",
      "running loss : 1.740975\n",
      "running loss : 1.763693\n",
      "running loss : 1.734918\n",
      "running loss : 1.770210\n",
      "running loss : 1.765556\n",
      "running loss : 1.733237\n",
      "running loss : 1.740748\n",
      "running loss : 1.740526\n",
      "running loss : 1.732925\n",
      "running loss : 1.755461\n",
      "running loss : 1.748184\n",
      "running loss : 1.746429\n",
      "running loss : 1.774166\n",
      "running loss : 1.726406\n",
      "running loss : 1.725249\n",
      "running loss : 1.749282\n",
      "running loss : 1.767095\n",
      "running loss : 1.738763\n",
      "running loss : 1.742542\n",
      "running loss : 1.727343\n",
      "running loss : 1.702772\n",
      "running loss : 1.754431\n",
      "running loss : 1.745891\n",
      "running loss : 1.742499\n",
      "running loss : 1.733364\n",
      "running loss : 1.686342\n",
      "running loss : 1.724494\n",
      "running loss : 1.745525\n",
      "running loss : 1.742802\n",
      "running loss : 1.748069\n",
      "running loss : 1.701968\n",
      "running loss : 1.748507\n",
      "running loss : 1.748969\n",
      "running loss : 1.721058\n",
      "running loss : 1.723289\n",
      "running loss : 1.702092\n",
      "running loss : 1.703658\n",
      "running loss : 1.705133\n",
      "running loss : 1.726726\n",
      "running loss : 1.710448\n",
      "running loss : 1.689744\n",
      "running loss : 1.668126\n",
      "running loss : 1.693099\n",
      "running loss : 1.703582\n",
      "running loss : 1.688458\n",
      "running loss : 1.706829\n",
      "running loss : 1.727697\n",
      "running loss : 1.653621\n",
      "running loss : 1.685590\n",
      "running loss : 1.694312\n",
      "running loss : 1.688564\n",
      "running loss : 1.687954\n",
      "running loss : 1.698381\n",
      "running loss : 1.688836\n",
      "running loss : 1.685251\n",
      "running loss : 1.716659\n",
      "running loss : 1.704712\n",
      "running loss : 1.673396\n",
      "running loss : 1.690760\n",
      "running loss : 1.709598\n",
      "running loss : 1.686696\n",
      "running loss : 1.702342\n",
      "running loss : 1.700034\n",
      "running loss : 1.705079\n",
      "running loss : 1.713727\n",
      "running loss : 1.699716\n",
      "running loss : 1.720424\n",
      "running loss : 1.690913\n",
      "running loss : 1.706146\n",
      "running loss : 1.690610\n",
      "running loss : 1.669416\n",
      "running loss : 1.665350\n",
      "running loss : 1.669462\n",
      "running loss : 1.657787\n",
      "running loss : 1.651801\n",
      "running loss : 1.684798\n",
      "running loss : 1.676885\n",
      "running loss : 1.674365\n",
      "running loss : 1.685719\n",
      "running loss : 1.663476\n",
      "running loss : 1.658077\n",
      "running loss : 1.657890\n",
      "running loss : 1.627034\n",
      "running loss : 1.648931\n",
      "running loss : 1.658026\n",
      "running loss : 1.641289\n",
      "running loss : 1.624298\n",
      "running loss : 1.673361\n",
      "running loss : 1.643997\n",
      "running loss : 1.635971\n",
      "running loss : 1.657225\n",
      "running loss : 1.656323\n",
      "running loss : 1.646373\n",
      "running loss : 1.655196\n",
      "running loss : 1.692644\n",
      "running loss : 1.619964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 1.635359\n",
      "running loss : 1.666507\n",
      "running loss : 1.664374\n",
      "running loss : 1.650467\n",
      "running loss : 1.634543\n",
      "running loss : 1.650947\n",
      "running loss : 1.682420\n",
      "running loss : 1.645712\n",
      "running loss : 1.626064\n",
      "running loss : 1.655769\n",
      "running loss : 1.620151\n",
      "running loss : 1.653210\n",
      "running loss : 1.638193\n",
      "running loss : 1.613701\n",
      "running loss : 1.637059\n",
      "running loss : 1.625701\n",
      "running loss : 1.630009\n",
      "running loss : 1.640170\n",
      "running loss : 1.629768\n",
      "running loss : 1.596877\n",
      "running loss : 1.612869\n",
      "running loss : 1.655863\n",
      "running loss : 1.655614\n",
      "running loss : 1.609635\n",
      "running loss : 1.655991\n",
      "running loss : 1.633943\n",
      "running loss : 1.617577\n",
      "running loss : 1.617262\n",
      "running loss : 1.632571\n",
      "running loss : 1.657285\n",
      "running loss : 1.636087\n",
      "running loss : 1.618877\n",
      "running loss : 1.618834\n",
      "running loss : 1.626161\n",
      "running loss : 1.628575\n",
      "running loss : 1.596633\n",
      "running loss : 1.576171\n",
      "running loss : 1.619639\n",
      "running loss : 1.605476\n",
      "running loss : 1.594048\n",
      "running loss : 1.622933\n",
      "running loss : 1.614174\n",
      "running loss : 1.629118\n",
      "running loss : 1.635644\n",
      "running loss : 1.622495\n",
      "running loss : 1.603349\n",
      "running loss : 1.569417\n",
      "running loss : 1.599481\n",
      "running loss : 1.587583\n",
      "running loss : 1.572931\n",
      "running loss : 1.604821\n",
      "running loss : 1.593139\n",
      "running loss : 1.612000\n",
      "running loss : 1.614147\n",
      "running loss : 1.584199\n",
      "running loss : 1.597183\n",
      "running loss : 1.571245\n",
      "running loss : 1.602361\n",
      "running loss : 1.565621\n",
      "running loss : 1.550634\n",
      "running loss : 1.539910\n",
      "running loss : 1.561181\n",
      "running loss : 1.576379\n",
      "running loss : 1.563053\n",
      "running loss : 1.547328\n",
      "running loss : 1.584510\n",
      "running loss : 1.565679\n",
      "running loss : 1.559475\n",
      "running loss : 1.584263\n",
      "running loss : 1.553659\n",
      "running loss : 1.623616\n",
      "running loss : 1.563842\n",
      "running loss : 1.568421\n",
      "running loss : 1.577567\n",
      "running loss : 1.537105\n",
      "running loss : 1.547106\n",
      "running loss : 1.581114\n",
      "running loss : 1.564151\n",
      "running loss : 1.555871\n",
      "running loss : 1.528701\n",
      "running loss : 1.573278\n",
      "running loss : 1.552801\n",
      "running loss : 1.572287\n",
      "running loss : 1.550550\n",
      "running loss : 1.572613\n",
      "running loss : 1.543575\n",
      "running loss : 1.544404\n",
      "running loss : 1.559049\n",
      "running loss : 1.576414\n",
      "running loss : 1.558155\n",
      "running loss : 1.541814\n",
      "running loss : 1.549593\n",
      "running loss : 1.504970\n",
      "running loss : 1.561655\n",
      "running loss : 1.539298\n",
      "running loss : 1.527228\n",
      "running loss : 1.539826\n",
      "running loss : 1.531201\n",
      "running loss : 1.561821\n",
      "running loss : 1.543470\n",
      "running loss : 1.537018\n",
      "running loss : 1.502675\n",
      "running loss : 1.549995\n",
      "running loss : 1.507624\n",
      "running loss : 1.555065\n",
      "running loss : 1.537082\n",
      "running loss : 1.560523\n",
      "running loss : 1.553289\n",
      "running loss : 1.551129\n",
      "running loss : 1.544202\n",
      "running loss : 1.520543\n",
      "running loss : 1.492537\n",
      "running loss : 1.500904\n",
      "running loss : 1.510602\n",
      "running loss : 1.493055\n",
      "running loss : 1.533842\n",
      "running loss : 1.518805\n",
      "running loss : 1.532498\n",
      "running loss : 1.552496\n",
      "running loss : 1.516988\n",
      "running loss : 1.507617\n",
      "running loss : 1.509823\n",
      "running loss : 1.521880\n",
      "running loss : 1.489001\n",
      "running loss : 1.506580\n",
      "running loss : 1.526451\n",
      "running loss : 1.515847\n",
      "running loss : 1.518983\n",
      "running loss : 1.493813\n",
      "running loss : 1.503162\n",
      "running loss : 1.514602\n",
      "running loss : 1.486206\n",
      "running loss : 1.502735\n",
      "running loss : 1.485001\n",
      "running loss : 1.503862\n",
      "running loss : 1.492852\n",
      "running loss : 1.483818\n",
      "running loss : 1.498976\n",
      "running loss : 1.508383\n",
      "running loss : 1.493139\n",
      "running loss : 1.473129\n",
      "running loss : 1.490626\n",
      "running loss : 1.475248\n",
      "running loss : 1.491809\n",
      "running loss : 1.498270\n",
      "running loss : 1.489490\n",
      "running loss : 1.513076\n",
      "running loss : 1.456754\n",
      "running loss : 1.502389\n",
      "running loss : 1.477192\n",
      "running loss : 1.503747\n",
      "running loss : 1.476185\n",
      "running loss : 1.474603\n",
      "running loss : 1.475201\n",
      "running loss : 1.473163\n",
      "running loss : 1.479974\n",
      "running loss : 1.463389\n",
      "running loss : 1.458240\n",
      "running loss : 1.498057\n",
      "running loss : 1.505017\n",
      "running loss : 1.469172\n",
      "running loss : 1.457684\n",
      "running loss : 1.491071\n",
      "running loss : 1.471699\n",
      "running loss : 1.475055\n",
      "running loss : 1.467025\n",
      "running loss : 1.456886\n",
      "running loss : 1.463745\n",
      "running loss : 1.452812\n",
      "running loss : 1.435899\n",
      "running loss : 1.437087\n",
      "running loss : 1.447931\n",
      "running loss : 1.466964\n",
      "running loss : 1.433874\n",
      "running loss : 1.453901\n",
      "running loss : 1.468479\n",
      "running loss : 1.444382\n",
      "running loss : 1.434783\n",
      "running loss : 1.458071\n",
      "running loss : 1.454580\n",
      "running loss : 1.434695\n",
      "running loss : 1.424148\n",
      "running loss : 1.422640\n",
      "running loss : 1.411471\n",
      "running loss : 1.436798\n",
      "running loss : 1.401045\n",
      "running loss : 1.443342\n",
      "running loss : 1.428336\n",
      "running loss : 1.437206\n",
      "running loss : 1.436569\n",
      "running loss : 1.415770\n",
      "running loss : 1.422390\n",
      "running loss : 1.406547\n",
      "running loss : 1.435154\n",
      "running loss : 1.401057\n",
      "running loss : 1.424526\n",
      "running loss : 1.420049\n",
      "running loss : 1.428761\n",
      "running loss : 1.443244\n",
      "running loss : 1.455558\n",
      "running loss : 1.433378\n",
      "running loss : 1.402063\n",
      "running loss : 1.409731\n",
      "running loss : 1.423847\n",
      "running loss : 1.436195\n",
      "running loss : 1.423732\n",
      "running loss : 1.425341\n",
      "running loss : 1.395826\n",
      "running loss : 1.399639\n",
      "running loss : 1.429402\n",
      "running loss : 1.427339\n",
      "running loss : 1.400311\n",
      "running loss : 1.380240\n",
      "running loss : 1.430647\n",
      "running loss : 1.436030\n",
      "running loss : 1.412328\n",
      "running loss : 1.416356\n",
      "running loss : 1.374503\n",
      "running loss : 1.398454\n",
      "running loss : 1.400934\n",
      "running loss : 1.386718\n",
      "running loss : 1.402166\n",
      "running loss : 1.411738\n",
      "running loss : 1.405346\n",
      "running loss : 1.416784\n",
      "running loss : 1.381329\n",
      "running loss : 1.383731\n",
      "running loss : 1.416070\n",
      "running loss : 1.352341\n",
      "running loss : 1.376979\n",
      "running loss : 1.409704\n",
      "running loss : 1.407374\n",
      "running loss : 1.403940\n",
      "running loss : 1.422556\n",
      "running loss : 1.389575\n",
      "running loss : 1.386479\n",
      "running loss : 1.345342\n",
      "running loss : 1.400696\n",
      "running loss : 1.381717\n",
      "running loss : 1.411814\n",
      "running loss : 1.398246\n",
      "running loss : 1.378830\n",
      "running loss : 1.389004\n",
      "running loss : 1.379994\n",
      "running loss : 1.405271\n",
      "running loss : 1.355042\n",
      "running loss : 1.390013\n",
      "running loss : 1.376588\n",
      "running loss : 1.393847\n",
      "running loss : 1.348227\n",
      "running loss : 1.386400\n",
      "running loss : 1.381657\n",
      "running loss : 1.386215\n",
      "running loss : 1.374889\n",
      "running loss : 1.398802\n",
      "running loss : 1.367152\n",
      "running loss : 1.349567\n",
      "running loss : 1.381267\n",
      "running loss : 1.364717\n",
      "running loss : 1.360006\n",
      "running loss : 1.359166\n",
      "running loss : 1.362177\n",
      "running loss : 1.382621\n",
      "running loss : 1.377728\n",
      "running loss : 1.350968\n",
      "running loss : 1.356807\n",
      "running loss : 1.374620\n",
      "running loss : 1.383788\n",
      "running loss : 1.350701\n",
      "running loss : 1.360742\n",
      "running loss : 1.360562\n",
      "running loss : 1.386310\n",
      "running loss : 1.342437\n",
      "running loss : 1.371892\n",
      "running loss : 1.365797\n",
      "running loss : 1.367241\n",
      "running loss : 1.354381\n",
      "running loss : 1.354711\n",
      "running loss : 1.361899\n",
      "running loss : 1.366993\n",
      "running loss : 1.364235\n",
      "running loss : 1.360139\n",
      "running loss : 1.347403\n",
      "running loss : 1.344930\n",
      "running loss : 1.340169\n",
      "running loss : 1.377304\n",
      "running loss : 1.327125\n",
      "running loss : 1.372951\n",
      "running loss : 1.355149\n",
      "running loss : 1.309327\n",
      "running loss : 1.341998\n",
      "running loss : 1.367417\n",
      "running loss : 1.345060\n",
      "running loss : 1.324101\n",
      "running loss : 1.342035\n",
      "running loss : 1.324265\n",
      "running loss : 1.337367\n",
      "running loss : 1.354602\n",
      "running loss : 1.338882\n",
      "running loss : 1.350997\n",
      "running loss : 1.360449\n",
      "running loss : 1.333090\n",
      "running loss : 1.327826\n",
      "running loss : 1.318205\n",
      "running loss : 1.292693\n",
      "running loss : 1.336474\n",
      "running loss : 1.341200\n",
      "running loss : 1.335918\n",
      "running loss : 1.337552\n",
      "running loss : 1.323791\n",
      "running loss : 1.349981\n",
      "running loss : 1.330052\n",
      "running loss : 1.328990\n",
      "running loss : 1.346010\n",
      "running loss : 1.311888\n",
      "running loss : 1.318912\n",
      "running loss : 1.337582\n",
      "running loss : 1.323450\n",
      "running loss : 1.304713\n",
      "running loss : 1.305789\n",
      "running loss : 1.342473\n",
      "running loss : 1.337379\n",
      "running loss : 1.310434\n",
      "running loss : 1.323002\n",
      "running loss : 1.303437\n",
      "running loss : 1.296209\n",
      "running loss : 1.344315\n",
      "running loss : 1.321290\n",
      "running loss : 1.301551\n",
      "running loss : 1.318372\n",
      "running loss : 1.293262\n",
      "running loss : 1.297476\n",
      "running loss : 1.292885\n",
      "running loss : 1.290263\n",
      "running loss : 1.291407\n",
      "running loss : 1.294086\n",
      "running loss : 1.300489\n",
      "running loss : 1.299254\n",
      "running loss : 1.319690\n",
      "running loss : 1.300737\n",
      "running loss : 1.292853\n",
      "running loss : 1.291094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 1.256720\n",
      "running loss : 1.291654\n",
      "running loss : 1.297204\n",
      "running loss : 1.274231\n",
      "running loss : 1.274499\n",
      "running loss : 1.290106\n",
      "running loss : 1.290103\n",
      "running loss : 1.298043\n",
      "running loss : 1.271291\n",
      "running loss : 1.294165\n",
      "running loss : 1.308510\n",
      "running loss : 1.276988\n",
      "running loss : 1.291955\n",
      "running loss : 1.307582\n",
      "running loss : 1.280659\n",
      "running loss : 1.265998\n",
      "running loss : 1.287793\n",
      "running loss : 1.282004\n",
      "running loss : 1.283125\n",
      "running loss : 1.276342\n",
      "running loss : 1.271399\n",
      "running loss : 1.282933\n",
      "running loss : 1.271933\n",
      "running loss : 1.256123\n",
      "running loss : 1.276628\n",
      "running loss : 1.266218\n",
      "running loss : 1.261841\n",
      "running loss : 1.247386\n",
      "running loss : 1.271868\n",
      "running loss : 1.292599\n",
      "running loss : 1.254858\n",
      "running loss : 1.274965\n",
      "running loss : 1.281697\n",
      "running loss : 1.261672\n",
      "running loss : 1.274813\n",
      "running loss : 1.284568\n",
      "running loss : 1.272777\n",
      "running loss : 1.277351\n",
      "running loss : 1.262207\n",
      "running loss : 1.241845\n",
      "running loss : 1.259690\n",
      "running loss : 1.237408\n",
      "running loss : 1.229311\n",
      "running loss : 1.255892\n",
      "running loss : 1.227767\n",
      "running loss : 1.228608\n",
      "running loss : 1.250705\n",
      "running loss : 1.240716\n",
      "running loss : 1.237286\n",
      "running loss : 1.251261\n",
      "running loss : 1.242009\n",
      "running loss : 1.242848\n",
      "running loss : 1.241917\n",
      "running loss : 1.230287\n",
      "running loss : 1.202546\n",
      "running loss : 1.242978\n",
      "running loss : 1.230034\n",
      "running loss : 1.230731\n",
      "running loss : 1.224767\n",
      "running loss : 1.227034\n",
      "running loss : 1.243430\n",
      "running loss : 1.215947\n",
      "running loss : 1.224714\n",
      "running loss : 1.251923\n",
      "running loss : 1.232030\n",
      "running loss : 1.244291\n",
      "running loss : 1.214693\n",
      "running loss : 1.244545\n",
      "running loss : 1.188785\n",
      "running loss : 1.221831\n",
      "running loss : 1.194353\n",
      "running loss : 1.250590\n",
      "running loss : 1.272037\n",
      "running loss : 1.223006\n",
      "running loss : 1.219051\n",
      "running loss : 1.222231\n",
      "running loss : 1.209733\n",
      "running loss : 1.229385\n",
      "running loss : 1.258470\n",
      "running loss : 1.231326\n",
      "running loss : 1.223861\n",
      "running loss : 1.240758\n",
      "running loss : 1.244803\n",
      "running loss : 1.215485\n",
      "running loss : 1.229398\n",
      "running loss : 1.194176\n",
      "running loss : 1.205396\n",
      "running loss : 1.229388\n",
      "running loss : 1.210283\n",
      "running loss : 1.208748\n",
      "running loss : 1.220610\n",
      "running loss : 1.222525\n",
      "running loss : 1.217555\n",
      "running loss : 1.194831\n",
      "running loss : 1.205127\n",
      "running loss : 1.223890\n",
      "running loss : 1.195833\n",
      "running loss : 1.199094\n",
      "running loss : 1.214869\n",
      "running loss : 1.206069\n",
      "running loss : 1.207898\n",
      "running loss : 1.230215\n",
      "running loss : 1.216277\n",
      "running loss : 1.200514\n",
      "running loss : 1.189941\n",
      "running loss : 1.223989\n",
      "running loss : 1.211170\n",
      "running loss : 1.227511\n",
      "running loss : 1.241142\n",
      "running loss : 1.200033\n",
      "running loss : 1.208802\n",
      "running loss : 1.206813\n",
      "running loss : 1.218097\n",
      "running loss : 1.215759\n",
      "running loss : 1.201867\n",
      "running loss : 1.184438\n",
      "running loss : 1.190732\n",
      "running loss : 1.195790\n",
      "running loss : 1.219229\n",
      "running loss : 1.181696\n",
      "running loss : 1.201028\n",
      "running loss : 1.212918\n",
      "running loss : 1.205611\n",
      "running loss : 1.195234\n",
      "running loss : 1.183667\n",
      "running loss : 1.166044\n",
      "running loss : 1.201785\n",
      "running loss : 1.220166\n",
      "running loss : 1.180214\n",
      "running loss : 1.187792\n",
      "running loss : 1.187993\n",
      "running loss : 1.218084\n",
      "running loss : 1.186620\n",
      "running loss : 1.193320\n",
      "running loss : 1.186981\n",
      "running loss : 1.214619\n",
      "running loss : 1.193804\n",
      "running loss : 1.178551\n",
      "running loss : 1.169890\n",
      "running loss : 1.177538\n",
      "running loss : 1.173213\n",
      "running loss : 1.190062\n",
      "running loss : 1.183447\n",
      "running loss : 1.175733\n",
      "running loss : 1.159881\n",
      "running loss : 1.196954\n",
      "running loss : 1.188621\n",
      "running loss : 1.162594\n",
      "running loss : 1.166862\n",
      "running loss : 1.153136\n",
      "running loss : 1.184737\n",
      "running loss : 1.188850\n",
      "running loss : 1.160138\n",
      "running loss : 1.155172\n",
      "running loss : 1.170890\n",
      "running loss : 1.175907\n",
      "running loss : 1.175670\n",
      "running loss : 1.157178\n",
      "running loss : 1.178984\n",
      "running loss : 1.186030\n",
      "running loss : 1.175804\n",
      "running loss : 1.159397\n",
      "running loss : 1.179507\n",
      "running loss : 1.176646\n",
      "running loss : 1.167013\n",
      "running loss : 1.186668\n",
      "running loss : 1.136204\n",
      "running loss : 1.162004\n",
      "running loss : 1.173376\n",
      "running loss : 1.168995\n",
      "running loss : 1.163303\n",
      "running loss : 1.151109\n",
      "running loss : 1.158166\n",
      "running loss : 1.163035\n",
      "running loss : 1.161752\n",
      "running loss : 1.154342\n",
      "running loss : 1.154213\n",
      "running loss : 1.148166\n",
      "running loss : 1.169995\n",
      "running loss : 1.154302\n",
      "running loss : 1.164243\n",
      "running loss : 1.148172\n",
      "running loss : 1.158206\n",
      "running loss : 1.165543\n",
      "running loss : 1.154934\n",
      "running loss : 1.128196\n",
      "running loss : 1.160675\n",
      "running loss : 1.158944\n",
      "running loss : 1.185964\n",
      "running loss : 1.138749\n",
      "running loss : 1.129550\n",
      "running loss : 1.159841\n",
      "running loss : 1.153039\n",
      "running loss : 1.201154\n",
      "running loss : 1.154511\n",
      "running loss : 1.143437\n",
      "running loss : 1.144232\n",
      "running loss : 1.174779\n",
      "running loss : 1.137578\n",
      "running loss : 1.145710\n",
      "running loss : 1.159600\n",
      "running loss : 1.147874\n",
      "running loss : 1.147788\n",
      "running loss : 1.126837\n",
      "running loss : 1.136882\n",
      "running loss : 1.133577\n",
      "running loss : 1.157748\n",
      "running loss : 1.141332\n",
      "running loss : 1.127841\n",
      "running loss : 1.130892\n",
      "running loss : 1.137954\n",
      "running loss : 1.159889\n",
      "running loss : 1.149797\n",
      "running loss : 1.154283\n",
      "running loss : 1.123618\n",
      "running loss : 1.134848\n",
      "running loss : 1.132103\n",
      "running loss : 1.146344\n",
      "running loss : 1.142277\n",
      "running loss : 1.126989\n",
      "running loss : 1.134964\n",
      "running loss : 1.127051\n",
      "running loss : 1.109952\n",
      "running loss : 1.156481\n",
      "running loss : 1.135826\n",
      "running loss : 1.134832\n",
      "running loss : 1.128424\n",
      "running loss : 1.123650\n",
      "running loss : 1.123061\n",
      "running loss : 1.123560\n",
      "running loss : 1.129342\n",
      "running loss : 1.114883\n",
      "running loss : 1.114125\n",
      "running loss : 1.127412\n",
      "running loss : 1.128706\n",
      "running loss : 1.121774\n",
      "running loss : 1.123890\n",
      "running loss : 1.124113\n",
      "running loss : 1.126745\n",
      "running loss : 1.110951\n",
      "running loss : 1.132344\n",
      "running loss : 1.124455\n",
      "running loss : 1.116997\n",
      "running loss : 1.126534\n",
      "running loss : 1.127445\n",
      "running loss : 1.119447\n",
      "running loss : 1.144363\n",
      "running loss : 1.121966\n",
      "running loss : 1.110660\n",
      "running loss : 1.100543\n",
      "running loss : 1.120242\n",
      "running loss : 1.108142\n",
      "running loss : 1.114456\n",
      "running loss : 1.121518\n",
      "running loss : 1.114343\n",
      "running loss : 1.111632\n",
      "running loss : 1.100044\n",
      "running loss : 1.128951\n",
      "running loss : 1.124875\n",
      "running loss : 1.086151\n",
      "running loss : 1.112802\n",
      "running loss : 1.104769\n",
      "running loss : 1.113202\n",
      "running loss : 1.112151\n",
      "running loss : 1.121347\n",
      "running loss : 1.118632\n",
      "running loss : 1.113886\n",
      "running loss : 1.091558\n",
      "running loss : 1.101128\n",
      "running loss : 1.109199\n",
      "running loss : 1.110045\n",
      "running loss : 1.093009\n",
      "running loss : 1.105065\n",
      "running loss : 1.116170\n",
      "running loss : 1.088634\n",
      "running loss : 1.102434\n",
      "running loss : 1.087059\n",
      "running loss : 1.093561\n",
      "running loss : 1.097159\n",
      "running loss : 1.066909\n",
      "running loss : 1.105266\n",
      "running loss : 1.079103\n",
      "running loss : 1.100633\n",
      "running loss : 1.098504\n",
      "running loss : 1.083716\n",
      "running loss : 1.078515\n",
      "running loss : 1.074020\n",
      "running loss : 1.095972\n",
      "running loss : 1.088779\n",
      "running loss : 1.086439\n",
      "running loss : 1.080265\n",
      "running loss : 1.103504\n",
      "running loss : 1.087753\n",
      "running loss : 1.077322\n",
      "running loss : 1.103450\n",
      "running loss : 1.086920\n",
      "running loss : 1.078293\n",
      "running loss : 1.089607\n",
      "running loss : 1.072763\n",
      "running loss : 1.099640\n",
      "running loss : 1.097505\n",
      "running loss : 1.089143\n",
      "running loss : 1.072178\n",
      "running loss : 1.090482\n",
      "running loss : 1.099867\n",
      "running loss : 1.084524\n",
      "running loss : 1.113024\n",
      "running loss : 1.068730\n",
      "running loss : 1.053861\n",
      "running loss : 1.101966\n",
      "running loss : 1.079867\n",
      "running loss : 1.089555\n",
      "running loss : 1.072920\n",
      "running loss : 1.088114\n",
      "running loss : 1.066631\n",
      "running loss : 1.063276\n",
      "running loss : 1.077868\n",
      "running loss : 1.073214\n",
      "running loss : 1.090016\n",
      "running loss : 1.081089\n",
      "running loss : 1.103230\n",
      "running loss : 1.089552\n",
      "running loss : 1.106388\n",
      "running loss : 1.072888\n",
      "running loss : 1.072454\n",
      "running loss : 1.075036\n",
      "running loss : 1.080790\n",
      "running loss : 1.063010\n",
      "running loss : 1.080096\n",
      "running loss : 1.078866\n",
      "running loss : 1.033671\n",
      "running loss : 1.070150\n",
      "running loss : 1.046359\n",
      "running loss : 1.075578\n",
      "running loss : 1.082414\n",
      "running loss : 1.066760\n",
      "running loss : 1.062507\n",
      "running loss : 1.064012\n",
      "running loss : 1.077604\n",
      "running loss : 1.055660\n",
      "running loss : 1.047115\n",
      "running loss : 1.065026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 1.049081\n",
      "running loss : 1.043036\n",
      "running loss : 1.058996\n",
      "running loss : 1.060834\n",
      "running loss : 1.049981\n",
      "running loss : 1.056951\n",
      "running loss : 1.065939\n",
      "running loss : 1.088529\n",
      "running loss : 1.072982\n",
      "running loss : 1.060125\n",
      "running loss : 1.061493\n",
      "running loss : 1.059206\n",
      "running loss : 1.069671\n",
      "running loss : 1.064702\n",
      "running loss : 1.066943\n",
      "running loss : 1.050768\n",
      "running loss : 1.068267\n",
      "running loss : 1.044585\n",
      "running loss : 1.064350\n",
      "running loss : 1.085931\n",
      "running loss : 1.064620\n",
      "running loss : 1.054868\n",
      "running loss : 1.050648\n",
      "running loss : 1.050042\n",
      "running loss : 1.067071\n",
      "running loss : 1.046812\n",
      "running loss : 1.068872\n",
      "running loss : 1.074711\n",
      "running loss : 1.071061\n",
      "running loss : 1.064234\n",
      "running loss : 1.053156\n",
      "running loss : 1.021284\n",
      "running loss : 1.034532\n",
      "running loss : 1.052108\n",
      "running loss : 1.048483\n",
      "running loss : 1.031680\n",
      "running loss : 1.043517\n",
      "running loss : 1.057241\n",
      "running loss : 1.064896\n",
      "running loss : 1.054471\n",
      "running loss : 1.044548\n",
      "running loss : 1.040406\n",
      "running loss : 1.036026\n",
      "running loss : 1.044138\n",
      "running loss : 1.051869\n",
      "running loss : 1.031841\n",
      "running loss : 1.064665\n",
      "running loss : 1.040808\n",
      "running loss : 1.023357\n",
      "running loss : 1.040060\n",
      "running loss : 1.040934\n",
      "running loss : 1.037388\n",
      "running loss : 1.062777\n",
      "running loss : 1.036089\n",
      "running loss : 1.045476\n",
      "running loss : 1.058515\n",
      "running loss : 1.025282\n",
      "running loss : 1.044174\n",
      "running loss : 1.023303\n",
      "running loss : 1.035288\n",
      "running loss : 1.055148\n",
      "running loss : 1.024539\n",
      "running loss : 1.048941\n",
      "running loss : 1.042346\n",
      "running loss : 1.041591\n",
      "running loss : 1.030575\n",
      "running loss : 1.047360\n",
      "running loss : 1.003233\n",
      "running loss : 1.044217\n",
      "running loss : 1.032227\n",
      "running loss : 1.034291\n",
      "running loss : 1.047565\n",
      "running loss : 1.036759\n",
      "running loss : 1.043382\n",
      "running loss : 1.021109\n",
      "running loss : 1.038551\n",
      "running loss : 1.039636\n",
      "running loss : 1.046084\n",
      "running loss : 1.050482\n",
      "running loss : 1.033927\n",
      "running loss : 1.034719\n",
      "running loss : 1.016263\n",
      "running loss : 1.039033\n",
      "running loss : 1.019814\n",
      "running loss : 1.037186\n",
      "running loss : 1.061486\n",
      "running loss : 1.032709\n",
      "running loss : 1.033002\n",
      "running loss : 1.044403\n",
      "running loss : 1.022915\n",
      "running loss : 1.036466\n",
      "running loss : 1.034576\n",
      "running loss : 1.043516\n",
      "running loss : 1.013967\n",
      "running loss : 1.035859\n",
      "running loss : 1.026104\n",
      "running loss : 1.017590\n",
      "running loss : 1.046832\n",
      "running loss : 1.038702\n",
      "running loss : 1.015910\n",
      "running loss : 0.984683\n",
      "running loss : 1.028971\n",
      "running loss : 0.998767\n",
      "running loss : 1.026741\n",
      "running loss : 1.028558\n",
      "running loss : 1.017397\n",
      "running loss : 1.014094\n",
      "running loss : 1.022368\n",
      "running loss : 1.033270\n",
      "running loss : 1.032940\n",
      "running loss : 1.026676\n",
      "running loss : 1.032988\n",
      "running loss : 1.043373\n",
      "running loss : 1.021022\n",
      "running loss : 1.023538\n",
      "running loss : 1.018669\n",
      "running loss : 1.023564\n",
      "running loss : 1.022053\n",
      "running loss : 1.013077\n",
      "running loss : 1.010498\n",
      "running loss : 1.005326\n",
      "running loss : 1.037920\n",
      "running loss : 1.004780\n",
      "running loss : 1.005919\n",
      "running loss : 1.019310\n",
      "running loss : 1.022626\n",
      "running loss : 1.010352\n",
      "running loss : 1.021352\n",
      "running loss : 1.024248\n",
      "running loss : 1.027434\n",
      "running loss : 1.017139\n",
      "running loss : 1.018518\n",
      "running loss : 1.027177\n",
      "running loss : 1.029658\n",
      "running loss : 1.015273\n",
      "running loss : 1.020996\n",
      "running loss : 1.010088\n",
      "running loss : 1.009941\n",
      "running loss : 1.019431\n",
      "running loss : 0.985799\n",
      "running loss : 1.050948\n",
      "running loss : 1.005753\n",
      "running loss : 1.012851\n",
      "running loss : 1.012830\n",
      "running loss : 0.995592\n",
      "running loss : 1.009934\n",
      "running loss : 1.004392\n",
      "running loss : 0.995257\n",
      "running loss : 0.992792\n",
      "running loss : 1.001694\n",
      "running loss : 1.019248\n",
      "running loss : 1.012400\n",
      "running loss : 0.997825\n",
      "running loss : 0.988392\n",
      "running loss : 1.005496\n",
      "running loss : 1.009902\n",
      "running loss : 1.019873\n",
      "running loss : 1.001402\n",
      "running loss : 0.992366\n",
      "running loss : 0.992091\n",
      "running loss : 0.990721\n",
      "running loss : 1.006017\n",
      "running loss : 1.002256\n",
      "running loss : 0.988115\n",
      "running loss : 0.979804\n",
      "running loss : 1.019090\n",
      "running loss : 1.012391\n",
      "running loss : 1.011456\n",
      "running loss : 1.013110\n",
      "running loss : 0.990530\n",
      "running loss : 1.011045\n",
      "running loss : 1.022893\n",
      "running loss : 0.995526\n",
      "running loss : 0.999590\n",
      "running loss : 1.001796\n",
      "running loss : 1.008472\n",
      "running loss : 0.980269\n",
      "running loss : 0.997050\n",
      "running loss : 0.996933\n",
      "running loss : 1.000803\n",
      "running loss : 0.993065\n",
      "running loss : 0.989241\n",
      "running loss : 0.981888\n",
      "running loss : 0.987876\n",
      "running loss : 0.983573\n",
      "running loss : 0.988491\n",
      "running loss : 0.996086\n",
      "running loss : 0.979330\n",
      "running loss : 0.988883\n",
      "running loss : 0.988160\n",
      "running loss : 0.994881\n",
      "running loss : 1.009908\n",
      "running loss : 1.002508\n",
      "running loss : 1.003332\n",
      "running loss : 0.992802\n",
      "running loss : 0.976567\n",
      "running loss : 0.966084\n",
      "running loss : 0.975486\n",
      "running loss : 0.997131\n",
      "running loss : 1.002224\n",
      "running loss : 0.961788\n",
      "running loss : 0.973752\n",
      "running loss : 0.996172\n",
      "running loss : 0.989183\n",
      "running loss : 0.966016\n",
      "running loss : 0.999518\n",
      "running loss : 0.972413\n",
      "running loss : 0.979580\n",
      "running loss : 0.963749\n",
      "running loss : 0.987705\n",
      "running loss : 0.967833\n",
      "running loss : 1.000830\n",
      "running loss : 0.956806\n",
      "running loss : 0.955143\n",
      "running loss : 0.997598\n",
      "running loss : 0.978514\n",
      "running loss : 1.003209\n",
      "running loss : 1.003903\n",
      "running loss : 0.989096\n",
      "running loss : 1.001464\n",
      "running loss : 0.973573\n",
      "running loss : 0.964385\n",
      "running loss : 0.969818\n",
      "running loss : 0.988635\n",
      "running loss : 0.976962\n",
      "running loss : 0.977423\n",
      "running loss : 0.966217\n",
      "running loss : 0.981370\n",
      "running loss : 0.967460\n",
      "running loss : 0.971581\n",
      "running loss : 0.973403\n",
      "running loss : 0.981128\n",
      "running loss : 0.957244\n",
      "running loss : 0.985267\n",
      "running loss : 0.985340\n",
      "running loss : 0.962857\n",
      "running loss : 0.975816\n",
      "running loss : 0.970349\n",
      "running loss : 0.986743\n",
      "running loss : 0.970595\n",
      "running loss : 0.979639\n",
      "running loss : 0.966831\n",
      "running loss : 0.972721\n",
      "running loss : 0.983442\n",
      "running loss : 0.976519\n",
      "running loss : 0.991557\n",
      "running loss : 0.986827\n",
      "running loss : 0.962683\n",
      "running loss : 0.961042\n",
      "running loss : 0.975518\n",
      "running loss : 0.964115\n",
      "running loss : 0.955866\n",
      "running loss : 0.979246\n",
      "running loss : 0.963259\n",
      "running loss : 0.973840\n",
      "running loss : 0.950329\n",
      "running loss : 0.969664\n",
      "running loss : 0.967081\n",
      "running loss : 0.975378\n",
      "running loss : 0.954544\n",
      "running loss : 0.954769\n",
      "running loss : 0.941868\n",
      "running loss : 0.963258\n",
      "running loss : 0.983823\n",
      "running loss : 0.972362\n",
      "running loss : 0.964295\n",
      "running loss : 1.001001\n",
      "running loss : 0.958590\n",
      "running loss : 0.970870\n",
      "running loss : 0.962206\n",
      "running loss : 0.978740\n",
      "running loss : 0.976471\n",
      "running loss : 0.953856\n",
      "running loss : 0.975008\n",
      "running loss : 0.957223\n",
      "running loss : 0.990373\n",
      "running loss : 0.938932\n",
      "running loss : 0.963399\n",
      "running loss : 0.961472\n",
      "running loss : 0.969980\n",
      "running loss : 0.969268\n",
      "running loss : 0.958014\n",
      "running loss : 0.969872\n",
      "running loss : 0.943666\n",
      "running loss : 0.943863\n",
      "running loss : 0.977849\n",
      "running loss : 0.972237\n",
      "running loss : 0.971528\n",
      "running loss : 0.951690\n",
      "running loss : 0.939519\n",
      "running loss : 0.961237\n",
      "running loss : 0.963039\n",
      "running loss : 0.954941\n",
      "running loss : 0.967514\n",
      "running loss : 0.949102\n",
      "running loss : 0.943364\n",
      "running loss : 0.968855\n",
      "running loss : 0.966039\n",
      "running loss : 0.959151\n",
      "running loss : 0.961319\n",
      "running loss : 0.957237\n",
      "running loss : 0.927287\n",
      "running loss : 0.949771\n",
      "running loss : 0.952061\n",
      "running loss : 0.974628\n",
      "running loss : 0.955227\n",
      "running loss : 0.944315\n",
      "running loss : 0.948240\n",
      "running loss : 0.944225\n",
      "running loss : 0.963599\n",
      "running loss : 0.952946\n",
      "running loss : 0.925824\n",
      "running loss : 0.944979\n",
      "running loss : 0.939120\n",
      "running loss : 0.953725\n",
      "running loss : 0.949163\n",
      "running loss : 0.960607\n",
      "running loss : 0.955332\n",
      "running loss : 0.960328\n",
      "running loss : 0.954958\n",
      "running loss : 0.939900\n",
      "running loss : 0.941536\n",
      "running loss : 0.949159\n",
      "running loss : 0.947711\n",
      "running loss : 0.943196\n",
      "running loss : 0.941151\n",
      "running loss : 0.964028\n",
      "running loss : 0.939461\n",
      "running loss : 0.954690\n",
      "running loss : 0.951528\n",
      "running loss : 0.923851\n",
      "running loss : 0.934001\n",
      "running loss : 0.929803\n",
      "running loss : 0.940406\n",
      "running loss : 0.940530\n",
      "running loss : 0.939746\n",
      "running loss : 0.947756\n",
      "running loss : 0.951976\n",
      "running loss : 0.939805\n",
      "running loss : 0.932141\n",
      "running loss : 0.946177\n",
      "running loss : 0.924515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.943599\n",
      "running loss : 0.943045\n",
      "running loss : 0.944456\n",
      "running loss : 0.940207\n",
      "running loss : 0.941844\n",
      "running loss : 0.923169\n",
      "running loss : 0.933559\n",
      "running loss : 0.927064\n",
      "running loss : 0.930007\n",
      "running loss : 0.903551\n",
      "running loss : 0.928935\n",
      "running loss : 0.936989\n",
      "running loss : 0.915153\n",
      "running loss : 0.938136\n",
      "running loss : 0.945433\n",
      "running loss : 0.943376\n",
      "running loss : 0.915643\n",
      "running loss : 0.932519\n",
      "running loss : 0.922671\n",
      "running loss : 0.907455\n",
      "running loss : 0.923164\n",
      "running loss : 0.935636\n",
      "running loss : 0.933821\n",
      "running loss : 0.927147\n",
      "running loss : 0.937654\n",
      "running loss : 0.919069\n",
      "running loss : 0.926094\n",
      "running loss : 0.922812\n",
      "running loss : 0.919425\n",
      "running loss : 0.924658\n",
      "running loss : 0.932985\n",
      "running loss : 0.926574\n",
      "running loss : 0.919877\n",
      "running loss : 0.936301\n",
      "running loss : 0.922730\n",
      "running loss : 0.928510\n",
      "running loss : 0.920342\n",
      "running loss : 0.931118\n",
      "running loss : 0.941157\n",
      "running loss : 0.928310\n",
      "running loss : 0.939500\n",
      "running loss : 0.920711\n",
      "running loss : 0.929839\n",
      "running loss : 0.922838\n",
      "running loss : 0.934416\n",
      "running loss : 0.934127\n",
      "running loss : 0.917260\n",
      "running loss : 0.919486\n",
      "running loss : 0.927864\n",
      "running loss : 0.911516\n",
      "running loss : 0.906832\n",
      "running loss : 0.930295\n",
      "running loss : 0.902421\n",
      "running loss : 0.940052\n",
      "running loss : 0.949667\n",
      "running loss : 0.922455\n",
      "running loss : 0.939213\n",
      "running loss : 0.932596\n",
      "running loss : 0.913852\n",
      "running loss : 0.915009\n",
      "running loss : 0.923071\n",
      "running loss : 0.916558\n",
      "running loss : 0.920089\n",
      "running loss : 0.933903\n",
      "running loss : 0.916830\n",
      "running loss : 0.923194\n",
      "running loss : 0.880902\n",
      "running loss : 0.943701\n",
      "running loss : 0.917867\n",
      "running loss : 0.899753\n",
      "running loss : 0.909022\n",
      "running loss : 0.923254\n",
      "running loss : 0.918505\n",
      "running loss : 0.925843\n",
      "running loss : 0.910850\n",
      "running loss : 0.905356\n",
      "running loss : 0.915823\n",
      "running loss : 0.915407\n",
      "running loss : 0.911985\n",
      "running loss : 0.908570\n",
      "running loss : 0.925045\n",
      "running loss : 0.920739\n",
      "running loss : 0.908400\n",
      "running loss : 0.901185\n",
      "running loss : 0.917533\n",
      "running loss : 0.902514\n",
      "running loss : 0.929424\n",
      "running loss : 0.915642\n",
      "running loss : 0.908307\n",
      "running loss : 0.894704\n",
      "running loss : 0.896886\n",
      "running loss : 0.918568\n",
      "running loss : 0.900524\n",
      "running loss : 0.908351\n",
      "running loss : 0.903216\n",
      "running loss : 0.912915\n",
      "running loss : 0.887523\n",
      "running loss : 0.884099\n",
      "running loss : 0.899724\n",
      "running loss : 0.903058\n",
      "running loss : 0.909403\n",
      "running loss : 0.903196\n",
      "running loss : 0.910784\n",
      "running loss : 0.904253\n",
      "running loss : 0.897539\n",
      "running loss : 0.880336\n",
      "running loss : 0.911437\n",
      "running loss : 0.917330\n",
      "running loss : 0.898941\n",
      "running loss : 0.910983\n",
      "running loss : 0.896036\n",
      "running loss : 0.916355\n",
      "running loss : 0.901689\n",
      "running loss : 0.920703\n",
      "running loss : 0.904027\n",
      "running loss : 0.928348\n",
      "running loss : 0.899872\n",
      "running loss : 0.915110\n",
      "running loss : 0.904842\n",
      "running loss : 0.893748\n",
      "running loss : 0.886039\n",
      "running loss : 0.901663\n",
      "running loss : 0.899345\n",
      "running loss : 0.899960\n",
      "running loss : 0.905381\n",
      "running loss : 0.901720\n",
      "running loss : 0.890008\n",
      "running loss : 0.910751\n",
      "running loss : 0.889683\n",
      "running loss : 0.911598\n",
      "running loss : 0.879634\n",
      "running loss : 0.907735\n",
      "running loss : 0.901637\n",
      "running loss : 0.895480\n",
      "running loss : 0.897724\n",
      "running loss : 0.904371\n",
      "running loss : 0.914379\n",
      "running loss : 0.900306\n",
      "running loss : 0.910551\n",
      "running loss : 0.901759\n",
      "running loss : 0.893959\n",
      "running loss : 0.883451\n",
      "running loss : 0.891922\n",
      "running loss : 0.895994\n",
      "running loss : 0.911666\n",
      "running loss : 0.910764\n",
      "running loss : 0.902219\n",
      "running loss : 0.892234\n",
      "running loss : 0.880018\n",
      "running loss : 0.873032\n",
      "running loss : 0.887557\n",
      "running loss : 0.895509\n",
      "running loss : 0.881013\n",
      "running loss : 0.901601\n",
      "running loss : 0.877246\n",
      "running loss : 0.887933\n",
      "running loss : 0.898021\n",
      "running loss : 0.890979\n",
      "running loss : 0.889565\n",
      "running loss : 0.889978\n",
      "running loss : 0.896450\n",
      "running loss : 0.904492\n",
      "running loss : 0.901708\n",
      "running loss : 0.884671\n",
      "running loss : 0.878965\n",
      "running loss : 0.900098\n",
      "running loss : 0.887540\n",
      "running loss : 0.895758\n",
      "running loss : 0.874236\n",
      "running loss : 0.874131\n",
      "running loss : 0.894598\n",
      "running loss : 0.893234\n",
      "running loss : 0.898058\n",
      "running loss : 0.877528\n",
      "running loss : 0.871016\n",
      "running loss : 0.897852\n",
      "running loss : 0.878888\n",
      "running loss : 0.888750\n",
      "running loss : 0.882404\n",
      "running loss : 0.888396\n",
      "running loss : 0.884348\n",
      "running loss : 0.867438\n",
      "running loss : 0.895595\n",
      "running loss : 0.875677\n",
      "running loss : 0.874881\n",
      "running loss : 0.889116\n",
      "running loss : 0.886372\n",
      "running loss : 0.889385\n",
      "running loss : 0.885561\n",
      "running loss : 0.901526\n",
      "running loss : 0.870862\n",
      "running loss : 0.883829\n",
      "running loss : 0.880724\n",
      "running loss : 0.894656\n",
      "running loss : 0.894665\n",
      "running loss : 0.889541\n",
      "running loss : 0.894503\n",
      "running loss : 0.900847\n",
      "running loss : 0.877628\n",
      "running loss : 0.884438\n",
      "running loss : 0.906302\n",
      "running loss : 0.898738\n",
      "running loss : 0.876679\n",
      "running loss : 0.892327\n",
      "running loss : 0.893076\n",
      "running loss : 0.891362\n",
      "running loss : 0.876524\n",
      "running loss : 0.881657\n",
      "running loss : 0.886464\n",
      "running loss : 0.871426\n",
      "running loss : 0.879619\n",
      "running loss : 0.902769\n",
      "running loss : 0.875436\n",
      "running loss : 0.875262\n",
      "running loss : 0.866443\n",
      "running loss : 0.884765\n",
      "running loss : 0.887134\n",
      "running loss : 0.882856\n",
      "running loss : 0.898999\n",
      "running loss : 0.881481\n",
      "running loss : 0.863970\n",
      "running loss : 0.856107\n",
      "running loss : 0.876999\n",
      "running loss : 0.877806\n",
      "running loss : 0.873652\n",
      "running loss : 0.877483\n",
      "running loss : 0.870151\n",
      "running loss : 0.879115\n",
      "running loss : 0.880858\n",
      "running loss : 0.879545\n",
      "running loss : 0.861618\n",
      "running loss : 0.873445\n",
      "running loss : 0.883335\n",
      "running loss : 0.862382\n",
      "running loss : 0.853484\n",
      "running loss : 0.863324\n",
      "running loss : 0.866934\n",
      "running loss : 0.873776\n",
      "running loss : 0.865656\n",
      "running loss : 0.862307\n",
      "running loss : 0.878110\n",
      "running loss : 0.874109\n",
      "running loss : 0.861512\n",
      "running loss : 0.876508\n",
      "running loss : 0.891051\n",
      "running loss : 0.873462\n",
      "running loss : 0.849807\n",
      "running loss : 0.868399\n",
      "running loss : 0.863133\n",
      "running loss : 0.873699\n",
      "running loss : 0.869627\n",
      "running loss : 0.857170\n",
      "running loss : 0.888176\n",
      "running loss : 0.862984\n",
      "running loss : 0.884042\n",
      "running loss : 0.900431\n",
      "running loss : 0.870728\n",
      "running loss : 0.878385\n",
      "running loss : 0.886427\n",
      "running loss : 0.866557\n",
      "running loss : 0.867697\n",
      "running loss : 0.860658\n",
      "running loss : 0.852748\n",
      "running loss : 0.869866\n",
      "running loss : 0.878806\n",
      "running loss : 0.878369\n",
      "running loss : 0.877455\n",
      "running loss : 0.867096\n",
      "running loss : 0.872791\n",
      "running loss : 0.865635\n",
      "running loss : 0.885457\n",
      "running loss : 0.877383\n",
      "running loss : 0.876968\n",
      "running loss : 0.861117\n",
      "running loss : 0.868860\n",
      "running loss : 0.868733\n",
      "running loss : 0.849389\n",
      "running loss : 0.875840\n",
      "running loss : 0.872644\n",
      "running loss : 0.855418\n",
      "running loss : 0.863195\n",
      "running loss : 0.854863\n",
      "running loss : 0.852427\n",
      "running loss : 0.862310\n",
      "running loss : 0.852707\n",
      "running loss : 0.860623\n",
      "running loss : 0.861591\n",
      "running loss : 0.858848\n",
      "running loss : 0.855419\n",
      "running loss : 0.857964\n",
      "running loss : 0.853671\n",
      "running loss : 0.855418\n",
      "running loss : 0.864205\n",
      "running loss : 0.861281\n",
      "running loss : 0.873157\n",
      "running loss : 0.869198\n",
      "running loss : 0.876850\n",
      "running loss : 0.858919\n",
      "running loss : 0.873591\n",
      "running loss : 0.879373\n",
      "running loss : 0.854592\n",
      "running loss : 0.858111\n",
      "running loss : 0.850429\n",
      "running loss : 0.864127\n",
      "running loss : 0.874761\n",
      "running loss : 0.845478\n",
      "running loss : 0.853545\n",
      "running loss : 0.871927\n",
      "running loss : 0.869655\n",
      "running loss : 0.854874\n",
      "running loss : 0.848757\n",
      "running loss : 0.859443\n",
      "running loss : 0.850350\n",
      "running loss : 0.866946\n",
      "running loss : 0.860019\n",
      "running loss : 0.845656\n",
      "running loss : 0.840722\n",
      "running loss : 0.871665\n",
      "running loss : 0.869853\n",
      "running loss : 0.870695\n",
      "running loss : 0.860489\n",
      "running loss : 0.863194\n",
      "running loss : 0.860786\n",
      "running loss : 0.868013\n",
      "running loss : 0.863447\n",
      "running loss : 0.856033\n",
      "running loss : 0.883428\n",
      "running loss : 0.854627\n",
      "running loss : 0.852243\n",
      "running loss : 0.850097\n",
      "running loss : 0.854877\n",
      "running loss : 0.847741\n",
      "running loss : 0.857818\n",
      "running loss : 0.841929\n",
      "running loss : 0.870748\n",
      "running loss : 0.856422\n",
      "running loss : 0.851265\n",
      "running loss : 0.850357\n",
      "running loss : 0.848854\n",
      "running loss : 0.849540\n",
      "running loss : 0.856115\n",
      "running loss : 0.857281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.847416\n",
      "running loss : 0.839533\n",
      "running loss : 0.853826\n",
      "running loss : 0.847388\n",
      "running loss : 0.845005\n",
      "running loss : 0.843089\n",
      "running loss : 0.862838\n",
      "running loss : 0.850811\n",
      "running loss : 0.860281\n",
      "running loss : 0.848698\n",
      "running loss : 0.859243\n",
      "running loss : 0.848638\n",
      "running loss : 0.860577\n",
      "running loss : 0.867182\n",
      "running loss : 0.866752\n",
      "running loss : 0.838167\n",
      "running loss : 0.845845\n",
      "running loss : 0.851140\n",
      "running loss : 0.842018\n",
      "running loss : 0.836037\n",
      "running loss : 0.852229\n",
      "running loss : 0.874159\n",
      "running loss : 0.849307\n",
      "running loss : 0.848909\n",
      "running loss : 0.842903\n",
      "running loss : 0.839965\n",
      "running loss : 0.856694\n",
      "running loss : 0.845258\n",
      "running loss : 0.866037\n",
      "running loss : 0.854826\n",
      "running loss : 0.841093\n",
      "running loss : 0.841443\n",
      "running loss : 0.834608\n",
      "running loss : 0.830982\n",
      "running loss : 0.836932\n",
      "running loss : 0.846992\n",
      "running loss : 0.856520\n",
      "running loss : 0.842753\n",
      "running loss : 0.839875\n",
      "running loss : 0.817022\n",
      "running loss : 0.821312\n",
      "running loss : 0.839793\n",
      "running loss : 0.832788\n",
      "running loss : 0.834693\n",
      "running loss : 0.850260\n",
      "running loss : 0.834177\n",
      "running loss : 0.841418\n",
      "running loss : 0.827760\n",
      "running loss : 0.834981\n",
      "running loss : 0.834492\n",
      "running loss : 0.831698\n",
      "running loss : 0.835422\n",
      "running loss : 0.834248\n",
      "running loss : 0.833597\n",
      "running loss : 0.841665\n",
      "running loss : 0.818938\n",
      "running loss : 0.844416\n",
      "running loss : 0.840404\n",
      "running loss : 0.853732\n",
      "running loss : 0.821631\n",
      "running loss : 0.833642\n",
      "running loss : 0.826871\n",
      "running loss : 0.831877\n",
      "running loss : 0.833461\n",
      "running loss : 0.838510\n",
      "running loss : 0.831142\n",
      "running loss : 0.847434\n",
      "running loss : 0.845718\n",
      "running loss : 0.857277\n",
      "running loss : 0.841343\n",
      "running loss : 0.846678\n",
      "running loss : 0.826242\n",
      "running loss : 0.832044\n",
      "running loss : 0.842218\n",
      "running loss : 0.852961\n",
      "running loss : 0.848044\n",
      "running loss : 0.833698\n",
      "running loss : 0.833983\n",
      "running loss : 0.840846\n",
      "running loss : 0.844838\n",
      "running loss : 0.843583\n",
      "running loss : 0.848772\n",
      "running loss : 0.849460\n",
      "running loss : 0.834680\n",
      "running loss : 0.850311\n",
      "running loss : 0.853027\n",
      "running loss : 0.845293\n",
      "running loss : 0.849302\n",
      "running loss : 0.829549\n",
      "running loss : 0.824087\n",
      "running loss : 0.833790\n",
      "running loss : 0.840369\n",
      "running loss : 0.844004\n",
      "running loss : 0.842466\n",
      "running loss : 0.861457\n",
      "running loss : 0.828998\n",
      "running loss : 0.834602\n",
      "running loss : 0.839589\n",
      "running loss : 0.845108\n",
      "running loss : 0.842092\n",
      "running loss : 0.846806\n",
      "running loss : 0.837008\n",
      "running loss : 0.810748\n",
      "running loss : 0.830494\n",
      "running loss : 0.824618\n",
      "running loss : 0.823102\n",
      "running loss : 0.839026\n",
      "running loss : 0.832659\n",
      "running loss : 0.823660\n",
      "running loss : 0.832161\n",
      "running loss : 0.808243\n",
      "running loss : 0.817993\n",
      "running loss : 0.836299\n",
      "running loss : 0.816757\n",
      "running loss : 0.812219\n",
      "running loss : 0.815979\n",
      "running loss : 0.825858\n",
      "running loss : 0.823657\n",
      "running loss : 0.823500\n",
      "running loss : 0.825221\n",
      "running loss : 0.818032\n",
      "running loss : 0.823575\n",
      "running loss : 0.818304\n",
      "running loss : 0.818340\n",
      "running loss : 0.819871\n",
      "running loss : 0.817626\n",
      "running loss : 0.837987\n",
      "running loss : 0.819058\n",
      "running loss : 0.821912\n",
      "running loss : 0.829106\n",
      "running loss : 0.834918\n",
      "running loss : 0.813492\n",
      "running loss : 0.817594\n",
      "running loss : 0.827668\n",
      "running loss : 0.819280\n",
      "running loss : 0.824665\n",
      "running loss : 0.811272\n",
      "running loss : 0.821115\n",
      "running loss : 0.824787\n",
      "running loss : 0.824963\n",
      "running loss : 0.806896\n",
      "running loss : 0.818847\n",
      "running loss : 0.843576\n",
      "running loss : 0.824116\n",
      "running loss : 0.821322\n",
      "running loss : 0.832502\n",
      "running loss : 0.805519\n",
      "running loss : 0.812545\n",
      "running loss : 0.820990\n",
      "running loss : 0.802826\n",
      "running loss : 0.801114\n",
      "running loss : 0.823437\n",
      "running loss : 0.813420\n",
      "running loss : 0.809171\n",
      "running loss : 0.822734\n",
      "running loss : 0.802122\n",
      "running loss : 0.815304\n",
      "running loss : 0.799431\n",
      "running loss : 0.833092\n",
      "running loss : 0.830063\n",
      "running loss : 0.801252\n",
      "running loss : 0.822058\n",
      "running loss : 0.793602\n",
      "running loss : 0.807155\n",
      "running loss : 0.811875\n",
      "running loss : 0.818026\n",
      "running loss : 0.819168\n",
      "running loss : 0.812915\n",
      "running loss : 0.813884\n",
      "running loss : 0.824328\n",
      "running loss : 0.811555\n",
      "running loss : 0.804414\n",
      "running loss : 0.808606\n",
      "running loss : 0.807990\n",
      "running loss : 0.834881\n",
      "running loss : 0.797559\n",
      "running loss : 0.813860\n",
      "running loss : 0.810111\n",
      "running loss : 0.804813\n",
      "running loss : 0.799488\n",
      "running loss : 0.802919\n",
      "running loss : 0.810731\n",
      "running loss : 0.816259\n",
      "running loss : 0.800463\n",
      "running loss : 0.803318\n",
      "running loss : 0.806960\n",
      "running loss : 0.811287\n",
      "running loss : 0.803854\n",
      "running loss : 0.837609\n",
      "running loss : 0.821599\n",
      "running loss : 0.790299\n",
      "running loss : 0.816446\n",
      "running loss : 0.811020\n",
      "running loss : 0.796594\n",
      "running loss : 0.801193\n",
      "running loss : 0.807932\n",
      "running loss : 0.813807\n",
      "running loss : 0.811532\n",
      "running loss : 0.808005\n",
      "running loss : 0.794104\n",
      "running loss : 0.801686\n",
      "running loss : 0.812299\n",
      "running loss : 0.813558\n",
      "running loss : 0.808138\n",
      "running loss : 0.798164\n",
      "running loss : 0.799823\n",
      "running loss : 0.793997\n",
      "running loss : 0.820515\n",
      "running loss : 0.812505\n",
      "running loss : 0.800125\n",
      "running loss : 0.811381\n",
      "running loss : 0.811865\n",
      "running loss : 0.791264\n",
      "running loss : 0.808917\n",
      "running loss : 0.800677\n",
      "running loss : 0.813530\n",
      "running loss : 0.780446\n",
      "running loss : 0.787530\n",
      "running loss : 0.796981\n",
      "running loss : 0.799279\n",
      "running loss : 0.793874\n",
      "running loss : 0.809509\n",
      "running loss : 0.817500\n",
      "running loss : 0.812427\n",
      "running loss : 0.787136\n",
      "running loss : 0.806442\n",
      "running loss : 0.797860\n",
      "running loss : 0.799672\n",
      "running loss : 0.800851\n",
      "running loss : 0.804735\n",
      "running loss : 0.805682\n",
      "running loss : 0.810038\n",
      "running loss : 0.806794\n",
      "running loss : 0.810390\n",
      "running loss : 0.812391\n",
      "running loss : 0.801922\n",
      "running loss : 0.802667\n",
      "running loss : 0.805518\n",
      "running loss : 0.797559\n",
      "running loss : 0.810222\n",
      "running loss : 0.806602\n",
      "running loss : 0.806208\n",
      "running loss : 0.784414\n",
      "running loss : 0.797696\n",
      "running loss : 0.779773\n",
      "running loss : 0.801677\n",
      "running loss : 0.806897\n",
      "running loss : 0.792910\n",
      "running loss : 0.802196\n",
      "running loss : 0.804845\n",
      "running loss : 0.801029\n",
      "running loss : 0.808208\n",
      "running loss : 0.799650\n",
      "running loss : 0.791348\n",
      "running loss : 0.795351\n",
      "running loss : 0.793063\n",
      "running loss : 0.788625\n",
      "running loss : 0.789091\n",
      "running loss : 0.797147\n",
      "running loss : 0.790073\n",
      "running loss : 0.800361\n",
      "running loss : 0.801136\n",
      "running loss : 0.791376\n",
      "running loss : 0.794523\n",
      "running loss : 0.782916\n",
      "running loss : 0.788875\n",
      "running loss : 0.793691\n",
      "running loss : 0.788324\n",
      "running loss : 0.790824\n",
      "running loss : 0.800744\n",
      "running loss : 0.800194\n",
      "running loss : 0.796010\n",
      "running loss : 0.791522\n",
      "running loss : 0.792150\n",
      "running loss : 0.778496\n",
      "running loss : 0.793099\n",
      "running loss : 0.807321\n",
      "running loss : 0.802079\n",
      "running loss : 0.792985\n",
      "running loss : 0.804308\n",
      "running loss : 0.790835\n",
      "running loss : 0.776808\n",
      "running loss : 0.778852\n",
      "running loss : 0.805570\n",
      "running loss : 0.774367\n",
      "running loss : 0.790650\n",
      "running loss : 0.785334\n",
      "running loss : 0.790135\n",
      "running loss : 0.782378\n",
      "running loss : 0.790176\n",
      "running loss : 0.785897\n",
      "running loss : 0.802043\n",
      "running loss : 0.787414\n",
      "running loss : 0.798854\n",
      "running loss : 0.788732\n",
      "running loss : 0.786701\n",
      "running loss : 0.794540\n",
      "running loss : 0.794497\n",
      "running loss : 0.799891\n",
      "running loss : 0.801704\n",
      "running loss : 0.783730\n",
      "running loss : 0.798796\n",
      "running loss : 0.812909\n",
      "running loss : 0.806960\n",
      "running loss : 0.815100\n",
      "running loss : 0.790448\n",
      "running loss : 0.812345\n",
      "running loss : 0.808317\n",
      "running loss : 0.793259\n",
      "running loss : 0.784503\n",
      "running loss : 0.786510\n",
      "running loss : 0.802876\n",
      "running loss : 0.797311\n",
      "running loss : 0.789059\n",
      "running loss : 0.813866\n",
      "running loss : 0.787626\n",
      "running loss : 0.779939\n",
      "running loss : 0.779942\n",
      "running loss : 0.794328\n",
      "running loss : 0.807883\n",
      "running loss : 0.772472\n",
      "running loss : 0.790788\n",
      "running loss : 0.774738\n",
      "running loss : 0.791069\n",
      "running loss : 0.798709\n",
      "running loss : 0.791665\n",
      "running loss : 0.786724\n",
      "running loss : 0.791268\n",
      "running loss : 0.784246\n",
      "running loss : 0.785610\n",
      "running loss : 0.773952\n",
      "running loss : 0.792187\n",
      "running loss : 0.778299\n",
      "running loss : 0.786619\n",
      "running loss : 0.791057\n",
      "running loss : 0.777598\n",
      "running loss : 0.792378\n",
      "running loss : 0.778033\n",
      "running loss : 0.777657\n",
      "running loss : 0.789707\n",
      "running loss : 0.780234\n",
      "running loss : 0.779022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.784582\n",
      "running loss : 0.794122\n",
      "running loss : 0.784817\n",
      "running loss : 0.776310\n",
      "running loss : 0.779197\n",
      "running loss : 0.784882\n",
      "running loss : 0.786361\n",
      "running loss : 0.776712\n",
      "running loss : 0.778101\n",
      "running loss : 0.787324\n",
      "running loss : 0.781495\n",
      "running loss : 0.791882\n",
      "running loss : 0.770947\n",
      "running loss : 0.790442\n",
      "running loss : 0.767398\n",
      "running loss : 0.784366\n",
      "running loss : 0.767323\n",
      "running loss : 0.783188\n",
      "running loss : 0.765291\n",
      "running loss : 0.781446\n",
      "running loss : 0.778332\n",
      "running loss : 0.779662\n",
      "running loss : 0.764563\n",
      "running loss : 0.775850\n",
      "running loss : 0.789114\n",
      "running loss : 0.774302\n",
      "running loss : 0.769007\n",
      "running loss : 0.778017\n",
      "running loss : 0.766882\n",
      "running loss : 0.791725\n",
      "running loss : 0.764094\n",
      "running loss : 0.790014\n",
      "running loss : 0.782007\n",
      "running loss : 0.777582\n",
      "running loss : 0.774236\n",
      "running loss : 0.780622\n",
      "running loss : 0.780737\n",
      "running loss : 0.773075\n",
      "running loss : 0.769299\n",
      "running loss : 0.774803\n",
      "running loss : 0.778580\n",
      "running loss : 0.774131\n",
      "running loss : 0.763823\n",
      "running loss : 0.768729\n",
      "running loss : 0.787960\n",
      "running loss : 0.778699\n",
      "running loss : 0.784542\n",
      "running loss : 0.764290\n",
      "running loss : 0.769953\n",
      "running loss : 0.785318\n",
      "running loss : 0.768295\n",
      "running loss : 0.779265\n",
      "running loss : 0.786573\n",
      "running loss : 0.769258\n",
      "running loss : 0.776207\n",
      "running loss : 0.768403\n",
      "running loss : 0.756911\n",
      "running loss : 0.786404\n",
      "running loss : 0.779537\n",
      "running loss : 0.767042\n",
      "running loss : 0.774040\n",
      "running loss : 0.755548\n",
      "running loss : 0.758696\n",
      "running loss : 0.762646\n",
      "running loss : 0.773729\n",
      "running loss : 0.779781\n",
      "running loss : 0.775746\n",
      "running loss : 0.758436\n",
      "running loss : 0.775561\n",
      "running loss : 0.778552\n",
      "running loss : 0.756155\n",
      "running loss : 0.762538\n",
      "running loss : 0.783208\n",
      "running loss : 0.775228\n",
      "running loss : 0.760506\n",
      "running loss : 0.772841\n",
      "running loss : 0.763369\n",
      "running loss : 0.768369\n",
      "running loss : 0.779736\n",
      "running loss : 0.760687\n",
      "running loss : 0.768596\n",
      "running loss : 0.756667\n",
      "running loss : 0.774345\n",
      "running loss : 0.776022\n",
      "running loss : 0.763821\n",
      "running loss : 0.756981\n",
      "running loss : 0.769610\n",
      "running loss : 0.756565\n",
      "running loss : 0.758861\n",
      "running loss : 0.780784\n",
      "running loss : 0.785853\n",
      "running loss : 0.766596\n",
      "running loss : 0.770218\n",
      "running loss : 0.784946\n",
      "running loss : 0.763059\n",
      "running loss : 0.771987\n",
      "running loss : 0.778943\n",
      "running loss : 0.768839\n",
      "running loss : 0.757895\n",
      "running loss : 0.765488\n",
      "running loss : 0.776540\n",
      "running loss : 0.753152\n",
      "running loss : 0.793256\n",
      "running loss : 0.771658\n",
      "running loss : 0.771861\n",
      "running loss : 0.770113\n",
      "running loss : 0.758100\n",
      "running loss : 0.760711\n",
      "running loss : 0.766255\n",
      "running loss : 0.758658\n",
      "running loss : 0.761815\n",
      "running loss : 0.760572\n",
      "running loss : 0.755390\n",
      "running loss : 0.764537\n",
      "running loss : 0.762662\n",
      "running loss : 0.768957\n",
      "running loss : 0.751378\n",
      "running loss : 0.754485\n",
      "running loss : 0.747870\n",
      "running loss : 0.755002\n",
      "running loss : 0.758250\n",
      "running loss : 0.767995\n",
      "running loss : 0.784160\n",
      "running loss : 0.786244\n",
      "running loss : 0.770382\n",
      "running loss : 0.776874\n",
      "running loss : 0.776611\n",
      "running loss : 0.755045\n",
      "running loss : 0.771482\n",
      "running loss : 0.786715\n",
      "running loss : 0.754857\n",
      "running loss : 0.755499\n",
      "running loss : 0.762408\n",
      "running loss : 0.751721\n",
      "running loss : 0.765493\n",
      "running loss : 0.755411\n",
      "running loss : 0.753446\n",
      "running loss : 0.772581\n",
      "running loss : 0.770252\n",
      "running loss : 0.761537\n",
      "running loss : 0.765647\n",
      "running loss : 0.766555\n",
      "running loss : 0.769496\n",
      "running loss : 0.767784\n",
      "running loss : 0.773009\n",
      "running loss : 0.768134\n",
      "running loss : 0.770040\n",
      "running loss : 0.769341\n",
      "running loss : 0.760817\n",
      "running loss : 0.766100\n",
      "running loss : 0.767233\n",
      "running loss : 0.756557\n",
      "running loss : 0.761642\n",
      "running loss : 0.754428\n",
      "running loss : 0.761543\n",
      "running loss : 0.756965\n",
      "running loss : 0.751400\n",
      "running loss : 0.765054\n",
      "running loss : 0.774744\n",
      "running loss : 0.779703\n",
      "running loss : 0.752985\n",
      "running loss : 0.747022\n",
      "running loss : 0.749386\n",
      "running loss : 0.752257\n",
      "running loss : 0.754178\n",
      "running loss : 0.770472\n",
      "running loss : 0.773059\n",
      "running loss : 0.756732\n",
      "running loss : 0.749202\n",
      "running loss : 0.750754\n",
      "running loss : 0.750801\n",
      "running loss : 0.741995\n",
      "running loss : 0.768650\n",
      "running loss : 0.744103\n",
      "running loss : 0.748568\n",
      "running loss : 0.759566\n",
      "running loss : 0.738247\n",
      "running loss : 0.753334\n",
      "running loss : 0.747248\n",
      "running loss : 0.748010\n",
      "running loss : 0.771917\n",
      "running loss : 0.759631\n",
      "running loss : 0.749264\n",
      "running loss : 0.747862\n",
      "running loss : 0.757913\n",
      "running loss : 0.742378\n",
      "running loss : 0.759082\n",
      "running loss : 0.752387\n",
      "running loss : 0.745316\n",
      "running loss : 0.749211\n",
      "running loss : 0.754326\n",
      "running loss : 0.737435\n",
      "running loss : 0.750002\n",
      "running loss : 0.737648\n",
      "running loss : 0.742131\n",
      "running loss : 0.752845\n",
      "running loss : 0.758190\n",
      "running loss : 0.758494\n",
      "running loss : 0.757607\n",
      "running loss : 0.763603\n",
      "running loss : 0.756464\n",
      "running loss : 0.749982\n",
      "running loss : 0.756205\n",
      "running loss : 0.740400\n",
      "running loss : 0.739891\n",
      "running loss : 0.754702\n",
      "running loss : 0.750372\n",
      "running loss : 0.767314\n",
      "running loss : 0.752555\n",
      "running loss : 0.763595\n",
      "running loss : 0.744920\n",
      "running loss : 0.744519\n",
      "running loss : 0.751332\n",
      "running loss : 0.757195\n",
      "running loss : 0.759077\n",
      "running loss : 0.734382\n",
      "running loss : 0.748146\n",
      "running loss : 0.749897\n",
      "running loss : 0.759238\n",
      "running loss : 0.758853\n",
      "running loss : 0.750390\n",
      "running loss : 0.765800\n",
      "running loss : 0.772523\n",
      "running loss : 0.759328\n",
      "running loss : 0.751170\n",
      "running loss : 0.750689\n",
      "running loss : 0.765350\n",
      "running loss : 0.755888\n",
      "running loss : 0.752382\n",
      "running loss : 0.753343\n",
      "running loss : 0.752622\n",
      "running loss : 0.753152\n",
      "running loss : 0.760883\n",
      "running loss : 0.783353\n",
      "running loss : 0.786879\n",
      "running loss : 0.762850\n",
      "running loss : 0.774910\n",
      "running loss : 0.800101\n",
      "running loss : 0.769040\n",
      "running loss : 0.754927\n",
      "running loss : 0.761487\n",
      "running loss : 0.739490\n",
      "running loss : 0.758104\n",
      "running loss : 0.766831\n",
      "running loss : 0.772886\n",
      "running loss : 0.769767\n",
      "running loss : 0.754151\n",
      "running loss : 0.748791\n",
      "running loss : 0.755257\n",
      "running loss : 0.745400\n",
      "running loss : 0.751298\n",
      "running loss : 0.748624\n",
      "running loss : 0.768570\n",
      "running loss : 0.740746\n",
      "running loss : 0.725402\n",
      "running loss : 0.761809\n",
      "running loss : 0.739343\n",
      "running loss : 0.740426\n",
      "running loss : 0.733572\n",
      "running loss : 0.752159\n",
      "running loss : 0.753388\n",
      "running loss : 0.750223\n",
      "running loss : 0.753203\n",
      "running loss : 0.737621\n",
      "running loss : 0.757663\n",
      "running loss : 0.738306\n",
      "running loss : 0.734678\n",
      "running loss : 0.740621\n",
      "running loss : 0.739046\n",
      "running loss : 0.742141\n",
      "running loss : 0.748312\n",
      "running loss : 0.747759\n",
      "running loss : 0.741114\n",
      "running loss : 0.748370\n",
      "running loss : 0.754756\n",
      "running loss : 0.752814\n",
      "running loss : 0.733087\n",
      "running loss : 0.741642\n",
      "running loss : 0.749299\n",
      "running loss : 0.733638\n",
      "running loss : 0.744063\n",
      "running loss : 0.751129\n",
      "running loss : 0.751533\n",
      "running loss : 0.748850\n",
      "running loss : 0.754365\n",
      "running loss : 0.748206\n",
      "running loss : 0.743403\n",
      "running loss : 0.755239\n",
      "running loss : 0.751093\n",
      "running loss : 0.747720\n",
      "running loss : 0.740545\n",
      "running loss : 0.756146\n",
      "running loss : 0.739961\n",
      "running loss : 0.755086\n",
      "running loss : 0.752083\n",
      "running loss : 0.749325\n",
      "running loss : 0.736520\n",
      "running loss : 0.733202\n",
      "running loss : 0.751094\n",
      "running loss : 0.745777\n",
      "running loss : 0.735007\n",
      "running loss : 0.739033\n",
      "running loss : 0.736134\n",
      "running loss : 0.742031\n",
      "running loss : 0.732534\n",
      "running loss : 0.728028\n",
      "running loss : 0.733450\n",
      "running loss : 0.744021\n",
      "running loss : 0.727437\n",
      "running loss : 0.736830\n",
      "running loss : 0.732205\n",
      "running loss : 0.755812\n",
      "running loss : 0.738264\n",
      "running loss : 0.723126\n",
      "running loss : 0.723811\n",
      "running loss : 0.741370\n",
      "running loss : 0.728141\n",
      "running loss : 0.734052\n",
      "running loss : 0.722578\n",
      "running loss : 0.742075\n",
      "running loss : 0.734361\n",
      "running loss : 0.738978\n",
      "running loss : 0.718937\n",
      "running loss : 0.734384\n",
      "running loss : 0.731057\n",
      "running loss : 0.726257\n",
      "running loss : 0.738725\n",
      "running loss : 0.738371\n",
      "running loss : 0.723653\n",
      "running loss : 0.726930\n",
      "running loss : 0.734389\n",
      "running loss : 0.747625\n",
      "running loss : 0.723805\n",
      "running loss : 0.745704\n",
      "running loss : 0.725150\n",
      "running loss : 0.726787\n",
      "running loss : 0.734731\n",
      "running loss : 0.726009\n",
      "running loss : 0.727450\n",
      "running loss : 0.730185\n",
      "running loss : 0.735960\n",
      "running loss : 0.722361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.735314\n",
      "running loss : 0.739988\n",
      "running loss : 0.727760\n",
      "running loss : 0.736740\n",
      "running loss : 0.723004\n",
      "running loss : 0.749917\n",
      "running loss : 0.723698\n",
      "running loss : 0.735176\n",
      "running loss : 0.739472\n",
      "running loss : 0.745212\n",
      "running loss : 0.735636\n",
      "running loss : 0.743831\n",
      "running loss : 0.728174\n",
      "running loss : 0.730982\n",
      "running loss : 0.724195\n",
      "running loss : 0.725571\n",
      "running loss : 0.740965\n",
      "running loss : 0.744270\n",
      "running loss : 0.740916\n",
      "running loss : 0.741266\n",
      "running loss : 0.752869\n",
      "running loss : 0.734605\n",
      "running loss : 0.734982\n",
      "running loss : 0.734297\n",
      "running loss : 0.731254\n",
      "running loss : 0.729686\n",
      "running loss : 0.727021\n",
      "running loss : 0.731789\n",
      "running loss : 0.731315\n",
      "running loss : 0.736012\n",
      "running loss : 0.732017\n",
      "running loss : 0.730873\n",
      "running loss : 0.745124\n",
      "running loss : 0.734697\n",
      "running loss : 0.733368\n",
      "running loss : 0.720181\n",
      "running loss : 0.720173\n",
      "running loss : 0.735697\n",
      "running loss : 0.727550\n",
      "running loss : 0.735690\n",
      "running loss : 0.728448\n",
      "running loss : 0.718377\n",
      "running loss : 0.731284\n",
      "running loss : 0.746649\n",
      "running loss : 0.729317\n",
      "running loss : 0.744528\n",
      "running loss : 0.743689\n",
      "running loss : 0.737997\n",
      "running loss : 0.769740\n",
      "running loss : 0.734294\n",
      "running loss : 0.746239\n",
      "running loss : 0.708868\n",
      "running loss : 0.723917\n",
      "running loss : 0.720900\n",
      "running loss : 0.728030\n",
      "running loss : 0.717324\n",
      "running loss : 0.739280\n",
      "running loss : 0.730515\n",
      "running loss : 0.724355\n",
      "running loss : 0.727926\n",
      "running loss : 0.731349\n",
      "running loss : 0.723660\n",
      "running loss : 0.730212\n",
      "running loss : 0.732733\n",
      "running loss : 0.727568\n",
      "running loss : 0.722551\n",
      "running loss : 0.731580\n",
      "running loss : 0.738213\n",
      "running loss : 0.730758\n",
      "running loss : 0.719615\n",
      "running loss : 0.733060\n",
      "running loss : 0.728916\n",
      "running loss : 0.733989\n",
      "running loss : 0.734431\n",
      "running loss : 0.707100\n",
      "running loss : 0.715502\n",
      "running loss : 0.716885\n",
      "running loss : 0.728222\n",
      "running loss : 0.732681\n",
      "running loss : 0.714893\n",
      "running loss : 0.721584\n",
      "running loss : 0.731534\n",
      "running loss : 0.710913\n",
      "running loss : 0.729231\n",
      "running loss : 0.727673\n",
      "running loss : 0.726426\n",
      "running loss : 0.727647\n",
      "running loss : 0.737350\n",
      "running loss : 0.711815\n",
      "running loss : 0.724121\n",
      "running loss : 0.723962\n",
      "running loss : 0.722654\n",
      "running loss : 0.724065\n",
      "running loss : 0.722122\n",
      "running loss : 0.719471\n",
      "running loss : 0.732085\n",
      "running loss : 0.727208\n",
      "running loss : 0.724175\n",
      "running loss : 0.727884\n",
      "running loss : 0.721199\n",
      "running loss : 0.724783\n",
      "running loss : 0.736148\n",
      "running loss : 0.721980\n",
      "running loss : 0.726225\n",
      "running loss : 0.714739\n",
      "running loss : 0.732525\n",
      "running loss : 0.720287\n",
      "running loss : 0.713256\n",
      "running loss : 0.711770\n",
      "running loss : 0.708663\n",
      "running loss : 0.730677\n",
      "running loss : 0.725376\n",
      "running loss : 0.731141\n",
      "running loss : 0.718957\n",
      "running loss : 0.725542\n",
      "running loss : 0.727407\n",
      "running loss : 0.728758\n",
      "running loss : 0.712349\n",
      "running loss : 0.731544\n",
      "running loss : 0.722008\n",
      "running loss : 0.727973\n",
      "running loss : 0.721419\n",
      "running loss : 0.715193\n",
      "running loss : 0.719878\n",
      "running loss : 0.726164\n",
      "running loss : 0.727420\n",
      "running loss : 0.721179\n",
      "running loss : 0.724141\n",
      "running loss : 0.733429\n",
      "running loss : 0.742506\n",
      "running loss : 0.721190\n",
      "running loss : 0.729665\n",
      "running loss : 0.705877\n",
      "running loss : 0.714039\n",
      "running loss : 0.719610\n",
      "running loss : 0.734420\n",
      "running loss : 0.724647\n",
      "running loss : 0.713616\n",
      "running loss : 0.713819\n",
      "running loss : 0.723168\n",
      "running loss : 0.737262\n",
      "running loss : 0.705624\n",
      "running loss : 0.719520\n",
      "running loss : 0.715581\n",
      "running loss : 0.716854\n",
      "running loss : 0.717524\n",
      "running loss : 0.711048\n",
      "running loss : 0.718920\n",
      "running loss : 0.722542\n",
      "running loss : 0.743756\n",
      "running loss : 0.725040\n",
      "running loss : 0.725176\n",
      "running loss : 0.734908\n",
      "running loss : 0.741330\n",
      "running loss : 0.723927\n",
      "running loss : 0.711463\n",
      "running loss : 0.718557\n",
      "running loss : 0.711502\n",
      "running loss : 0.703296\n",
      "running loss : 0.719541\n",
      "running loss : 0.722402\n",
      "running loss : 0.708674\n",
      "running loss : 0.704725\n",
      "running loss : 0.701155\n",
      "running loss : 0.720063\n",
      "running loss : 0.727427\n",
      "running loss : 0.722147\n",
      "running loss : 0.705494\n",
      "running loss : 0.707760\n",
      "running loss : 0.711000\n",
      "running loss : 0.723491\n",
      "running loss : 0.726254\n",
      "running loss : 0.729093\n",
      "running loss : 0.712609\n",
      "running loss : 0.717241\n",
      "running loss : 0.721696\n",
      "running loss : 0.728209\n",
      "running loss : 0.709862\n",
      "running loss : 0.717815\n",
      "running loss : 0.725568\n",
      "running loss : 0.715205\n",
      "running loss : 0.711624\n",
      "running loss : 0.713745\n",
      "running loss : 0.715936\n",
      "running loss : 0.705609\n",
      "running loss : 0.709005\n",
      "running loss : 0.712037\n",
      "running loss : 0.709303\n",
      "running loss : 0.730664\n",
      "running loss : 0.710501\n",
      "running loss : 0.725953\n",
      "running loss : 0.713571\n",
      "running loss : 0.716169\n",
      "running loss : 0.732953\n",
      "running loss : 0.713380\n",
      "running loss : 0.719581\n",
      "running loss : 0.725627\n",
      "running loss : 0.729053\n",
      "running loss : 0.722467\n",
      "running loss : 0.741683\n",
      "running loss : 0.729483\n",
      "running loss : 0.724054\n",
      "running loss : 0.715391\n",
      "running loss : 0.715156\n",
      "running loss : 0.726674\n",
      "running loss : 0.721162\n",
      "running loss : 0.717449\n",
      "running loss : 0.709178\n",
      "running loss : 0.711226\n",
      "running loss : 0.702453\n",
      "running loss : 0.717847\n",
      "running loss : 0.716546\n",
      "running loss : 0.709159\n",
      "running loss : 0.727254\n",
      "running loss : 0.711167\n",
      "running loss : 0.699938\n",
      "running loss : 0.710605\n",
      "running loss : 0.700875\n",
      "running loss : 0.711776\n",
      "running loss : 0.716369\n",
      "running loss : 0.713617\n",
      "running loss : 0.710356\n",
      "running loss : 0.713909\n",
      "running loss : 0.727754\n",
      "running loss : 0.704075\n",
      "running loss : 0.714631\n",
      "running loss : 0.712239\n",
      "running loss : 0.700439\n",
      "running loss : 0.701155\n",
      "running loss : 0.712119\n",
      "running loss : 0.712701\n",
      "running loss : 0.710524\n",
      "running loss : 0.722460\n",
      "running loss : 0.718217\n",
      "running loss : 0.707486\n",
      "running loss : 0.710981\n",
      "running loss : 0.695770\n",
      "running loss : 0.702793\n",
      "running loss : 0.706706\n",
      "running loss : 0.701059\n",
      "running loss : 0.718290\n",
      "running loss : 0.701775\n",
      "running loss : 0.704407\n",
      "running loss : 0.710950\n",
      "running loss : 0.706477\n",
      "running loss : 0.712512\n",
      "running loss : 0.704994\n",
      "running loss : 0.723363\n",
      "running loss : 0.708875\n",
      "running loss : 0.710062\n",
      "running loss : 0.709025\n",
      "running loss : 0.703899\n",
      "running loss : 0.711783\n",
      "running loss : 0.715323\n",
      "running loss : 0.706578\n",
      "running loss : 0.709680\n",
      "running loss : 0.711342\n",
      "running loss : 0.719440\n",
      "running loss : 0.719489\n",
      "running loss : 0.705883\n",
      "running loss : 0.710752\n",
      "running loss : 0.699152\n",
      "running loss : 0.716993\n",
      "running loss : 0.711634\n",
      "running loss : 0.713859\n",
      "running loss : 0.704141\n",
      "running loss : 0.710413\n",
      "running loss : 0.695858\n",
      "running loss : 0.718574\n",
      "running loss : 0.715209\n",
      "running loss : 0.711873\n",
      "running loss : 0.702337\n",
      "running loss : 0.688638\n",
      "running loss : 0.718013\n",
      "running loss : 0.713475\n",
      "running loss : 0.685445\n",
      "running loss : 0.716094\n",
      "running loss : 0.705826\n",
      "running loss : 0.704430\n",
      "running loss : 0.720289\n",
      "running loss : 0.712732\n",
      "running loss : 0.720154\n",
      "running loss : 0.719241\n",
      "running loss : 0.713124\n",
      "running loss : 0.711065\n",
      "running loss : 0.707220\n",
      "running loss : 0.708516\n",
      "running loss : 0.713395\n",
      "running loss : 0.713088\n",
      "running loss : 0.709143\n",
      "running loss : 0.723015\n",
      "running loss : 0.713625\n",
      "running loss : 0.708601\n",
      "running loss : 0.719706\n",
      "running loss : 0.707194\n",
      "running loss : 0.727677\n",
      "running loss : 0.724791\n",
      "running loss : 0.701258\n",
      "running loss : 0.703296\n",
      "running loss : 0.719042\n",
      "running loss : 0.710561\n",
      "running loss : 0.707365\n",
      "running loss : 0.712767\n",
      "running loss : 0.715346\n",
      "running loss : 0.706522\n",
      "running loss : 0.689114\n",
      "running loss : 0.705555\n",
      "running loss : 0.700749\n",
      "running loss : 0.712122\n",
      "running loss : 0.706560\n",
      "running loss : 0.713124\n",
      "running loss : 0.714218\n",
      "running loss : 0.710480\n",
      "running loss : 0.706488\n",
      "running loss : 0.723993\n",
      "running loss : 0.721093\n",
      "running loss : 0.712014\n",
      "running loss : 0.715950\n",
      "running loss : 0.714828\n",
      "running loss : 0.717009\n",
      "running loss : 0.749060\n",
      "running loss : 0.701222\n",
      "running loss : 0.711281\n",
      "running loss : 0.728327\n",
      "running loss : 0.709172\n",
      "running loss : 0.717999\n",
      "running loss : 0.710575\n",
      "running loss : 0.708781\n",
      "running loss : 0.695575\n",
      "running loss : 0.700229\n",
      "running loss : 0.709520\n",
      "running loss : 0.710850\n",
      "running loss : 0.707811\n",
      "running loss : 0.710211\n",
      "running loss : 0.713831\n",
      "running loss : 0.705236\n",
      "running loss : 0.699262\n",
      "running loss : 0.702914\n",
      "running loss : 0.709417\n",
      "running loss : 0.715060\n",
      "running loss : 0.702509\n",
      "running loss : 0.708384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.708282\n",
      "running loss : 0.712760\n",
      "running loss : 0.688401\n",
      "running loss : 0.709143\n",
      "running loss : 0.684233\n",
      "running loss : 0.696364\n",
      "running loss : 0.700790\n",
      "running loss : 0.689280\n",
      "running loss : 0.702695\n",
      "running loss : 0.695429\n",
      "running loss : 0.694166\n",
      "running loss : 0.714090\n",
      "running loss : 0.695990\n",
      "running loss : 0.704430\n",
      "running loss : 0.696524\n",
      "running loss : 0.701731\n",
      "running loss : 0.708844\n",
      "running loss : 0.714466\n",
      "running loss : 0.713113\n",
      "running loss : 0.723785\n",
      "running loss : 0.711265\n",
      "running loss : 0.711590\n",
      "running loss : 0.708499\n",
      "running loss : 0.690955\n",
      "running loss : 0.711865\n",
      "running loss : 0.699289\n",
      "running loss : 0.705391\n",
      "running loss : 0.705053\n",
      "running loss : 0.709222\n",
      "running loss : 0.696744\n",
      "running loss : 0.694689\n",
      "running loss : 0.697277\n",
      "running loss : 0.697438\n",
      "running loss : 0.692021\n",
      "running loss : 0.687229\n",
      "running loss : 0.695772\n",
      "running loss : 0.687696\n",
      "running loss : 0.704307\n",
      "running loss : 0.691020\n",
      "running loss : 0.704125\n",
      "running loss : 0.683802\n",
      "running loss : 0.697075\n",
      "running loss : 0.698209\n",
      "running loss : 0.694200\n",
      "running loss : 0.684308\n",
      "running loss : 0.682686\n",
      "running loss : 0.693181\n",
      "running loss : 0.698645\n",
      "running loss : 0.688604\n",
      "running loss : 0.677175\n",
      "running loss : 0.693874\n",
      "running loss : 0.686246\n",
      "running loss : 0.687754\n",
      "running loss : 0.694499\n",
      "running loss : 0.693395\n",
      "running loss : 0.704790\n",
      "running loss : 0.675375\n",
      "running loss : 0.693502\n",
      "running loss : 0.696779\n",
      "running loss : 0.692619\n",
      "running loss : 0.694603\n",
      "running loss : 0.696795\n",
      "running loss : 0.692505\n",
      "running loss : 0.694932\n",
      "running loss : 0.694223\n",
      "running loss : 0.689222\n",
      "running loss : 0.698887\n",
      "running loss : 0.674353\n",
      "running loss : 0.690067\n",
      "running loss : 0.705340\n",
      "running loss : 0.703803\n",
      "running loss : 0.694022\n",
      "running loss : 0.697558\n",
      "running loss : 0.690706\n",
      "running loss : 0.698787\n",
      "running loss : 0.681631\n",
      "running loss : 0.693658\n",
      "running loss : 0.687367\n",
      "running loss : 0.690199\n",
      "running loss : 0.691742\n",
      "running loss : 0.684534\n",
      "running loss : 0.701434\n",
      "running loss : 0.683474\n",
      "running loss : 0.695016\n",
      "running loss : 0.676076\n",
      "running loss : 0.673720\n",
      "running loss : 0.689204\n",
      "running loss : 0.693828\n",
      "running loss : 0.677372\n",
      "running loss : 0.690114\n",
      "running loss : 0.689716\n",
      "running loss : 0.680936\n",
      "running loss : 0.678246\n",
      "running loss : 0.676195\n",
      "running loss : 0.691235\n",
      "running loss : 0.684706\n",
      "running loss : 0.684032\n",
      "running loss : 0.688375\n",
      "running loss : 0.688962\n",
      "running loss : 0.680051\n",
      "running loss : 0.679606\n",
      "running loss : 0.684077\n",
      "running loss : 0.683101\n",
      "running loss : 0.682256\n",
      "running loss : 0.679262\n",
      "running loss : 0.685585\n",
      "running loss : 0.682076\n",
      "running loss : 0.682490\n",
      "running loss : 0.678795\n",
      "running loss : 0.683445\n",
      "running loss : 0.672396\n",
      "running loss : 0.678156\n",
      "running loss : 0.675130\n",
      "running loss : 0.676663\n",
      "running loss : 0.683943\n",
      "running loss : 0.665646\n",
      "running loss : 0.678912\n",
      "running loss : 0.679871\n",
      "running loss : 0.678985\n",
      "running loss : 0.680444\n",
      "running loss : 0.677154\n",
      "running loss : 0.685735\n",
      "running loss : 0.682953\n",
      "running loss : 0.691228\n",
      "running loss : 0.687227\n",
      "running loss : 0.673489\n",
      "running loss : 0.680565\n",
      "running loss : 0.675708\n",
      "running loss : 0.679851\n",
      "running loss : 0.671638\n",
      "running loss : 0.681296\n",
      "running loss : 0.684762\n",
      "running loss : 0.673285\n",
      "running loss : 0.684566\n",
      "running loss : 0.671453\n",
      "running loss : 0.690578\n",
      "running loss : 0.678814\n",
      "running loss : 0.673534\n",
      "running loss : 0.684038\n",
      "running loss : 0.685332\n",
      "running loss : 0.672815\n",
      "running loss : 0.686412\n",
      "running loss : 0.671870\n",
      "running loss : 0.680272\n",
      "running loss : 0.677305\n",
      "running loss : 0.685243\n",
      "running loss : 0.681817\n",
      "running loss : 0.684235\n",
      "running loss : 0.684062\n",
      "running loss : 0.689955\n",
      "running loss : 0.673197\n",
      "running loss : 0.672732\n",
      "running loss : 0.674563\n",
      "running loss : 0.679675\n",
      "running loss : 0.678969\n",
      "running loss : 0.691189\n",
      "running loss : 0.678754\n",
      "running loss : 0.692657\n",
      "running loss : 0.686377\n",
      "running loss : 0.683528\n",
      "running loss : 0.693322\n",
      "running loss : 0.701314\n",
      "running loss : 0.684787\n",
      "running loss : 0.681569\n",
      "running loss : 0.697581\n",
      "running loss : 0.687262\n",
      "running loss : 0.684627\n",
      "running loss : 0.690672\n",
      "running loss : 0.686668\n",
      "running loss : 0.685399\n",
      "running loss : 0.684313\n",
      "running loss : 0.691907\n",
      "running loss : 0.682221\n",
      "running loss : 0.680538\n",
      "running loss : 0.682571\n",
      "running loss : 0.684389\n",
      "running loss : 0.664704\n",
      "running loss : 0.685909\n",
      "running loss : 0.680051\n",
      "running loss : 0.695094\n",
      "running loss : 0.691552\n",
      "running loss : 0.676388\n",
      "running loss : 0.670230\n",
      "running loss : 0.684250\n",
      "running loss : 0.681723\n",
      "running loss : 0.692671\n",
      "running loss : 0.696446\n",
      "running loss : 0.682937\n",
      "running loss : 0.670151\n",
      "running loss : 0.670692\n",
      "running loss : 0.679416\n",
      "running loss : 0.690560\n",
      "running loss : 0.689703\n",
      "running loss : 0.679913\n",
      "running loss : 0.687168\n",
      "running loss : 0.692749\n",
      "running loss : 0.688932\n",
      "running loss : 0.675102\n",
      "running loss : 0.675514\n",
      "running loss : 0.668886\n",
      "running loss : 0.681287\n",
      "running loss : 0.684368\n",
      "running loss : 0.690876\n",
      "running loss : 0.680391\n",
      "running loss : 0.689380\n",
      "running loss : 0.683363\n",
      "running loss : 0.685023\n",
      "running loss : 0.680146\n",
      "running loss : 0.673465\n",
      "running loss : 0.679917\n",
      "running loss : 0.681758\n",
      "running loss : 0.681120\n",
      "running loss : 0.661960\n",
      "running loss : 0.688584\n",
      "running loss : 0.675367\n",
      "running loss : 0.683580\n",
      "running loss : 0.677724\n",
      "running loss : 0.676262\n",
      "running loss : 0.681888\n",
      "running loss : 0.691331\n",
      "running loss : 0.684584\n",
      "running loss : 0.683727\n",
      "running loss : 0.684064\n",
      "running loss : 0.679174\n",
      "running loss : 0.688008\n",
      "running loss : 0.675591\n",
      "running loss : 0.694165\n",
      "running loss : 0.669863\n",
      "running loss : 0.670587\n",
      "running loss : 0.670428\n",
      "running loss : 0.674283\n",
      "running loss : 0.681171\n",
      "running loss : 0.682693\n",
      "running loss : 0.684826\n",
      "running loss : 0.681884\n",
      "running loss : 0.685952\n",
      "running loss : 0.680588\n",
      "running loss : 0.683766\n",
      "running loss : 0.679330\n",
      "running loss : 0.661828\n",
      "running loss : 0.668939\n",
      "running loss : 0.669385\n",
      "running loss : 0.659942\n",
      "running loss : 0.668549\n",
      "running loss : 0.672828\n",
      "running loss : 0.668121\n",
      "running loss : 0.669775\n",
      "running loss : 0.665496\n",
      "running loss : 0.679447\n",
      "running loss : 0.674204\n",
      "running loss : 0.672562\n",
      "running loss : 0.667102\n",
      "running loss : 0.665248\n",
      "running loss : 0.663131\n",
      "running loss : 0.671827\n",
      "running loss : 0.654393\n",
      "running loss : 0.671099\n",
      "running loss : 0.658323\n",
      "running loss : 0.674459\n",
      "running loss : 0.658670\n",
      "running loss : 0.663142\n",
      "running loss : 0.665401\n",
      "running loss : 0.666037\n",
      "running loss : 0.668162\n",
      "running loss : 0.672341\n",
      "running loss : 0.677211\n",
      "running loss : 0.678660\n",
      "running loss : 0.672205\n",
      "running loss : 0.679678\n",
      "running loss : 0.676390\n",
      "running loss : 0.672578\n",
      "running loss : 0.661985\n",
      "running loss : 0.668462\n",
      "running loss : 0.672105\n",
      "running loss : 0.660869\n",
      "running loss : 0.655973\n",
      "running loss : 0.674292\n",
      "running loss : 0.665281\n",
      "running loss : 0.657463\n",
      "running loss : 0.668056\n",
      "running loss : 0.667453\n",
      "running loss : 0.664946\n",
      "running loss : 0.657338\n",
      "running loss : 0.668645\n",
      "running loss : 0.660059\n",
      "running loss : 0.669367\n",
      "running loss : 0.672792\n",
      "running loss : 0.680540\n",
      "running loss : 0.689194\n",
      "running loss : 0.698870\n",
      "running loss : 0.674950\n",
      "running loss : 0.687287\n",
      "running loss : 0.692309\n",
      "running loss : 0.674372\n",
      "running loss : 0.662382\n",
      "running loss : 0.660024\n",
      "running loss : 0.672527\n",
      "running loss : 0.682110\n",
      "running loss : 0.668708\n",
      "running loss : 0.683987\n",
      "running loss : 0.669633\n",
      "running loss : 0.670060\n",
      "running loss : 0.676398\n",
      "running loss : 0.665355\n",
      "running loss : 0.670131\n",
      "running loss : 0.668793\n",
      "running loss : 0.682555\n",
      "running loss : 0.686224\n",
      "running loss : 0.659405\n",
      "running loss : 0.671362\n",
      "running loss : 0.667260\n",
      "running loss : 0.673407\n",
      "running loss : 0.666177\n",
      "running loss : 0.665864\n",
      "running loss : 0.665202\n",
      "running loss : 0.671401\n",
      "running loss : 0.663779\n",
      "running loss : 0.663300\n",
      "running loss : 0.667364\n",
      "running loss : 0.666512\n",
      "running loss : 0.662474\n",
      "running loss : 0.663385\n",
      "running loss : 0.649489\n",
      "running loss : 0.654975\n",
      "running loss : 0.668946\n",
      "running loss : 0.656640\n",
      "running loss : 0.659819\n",
      "running loss : 0.653274\n",
      "running loss : 0.661670\n",
      "running loss : 0.665962\n",
      "running loss : 0.657300\n",
      "running loss : 0.662189\n",
      "running loss : 0.652142\n",
      "running loss : 0.658330\n",
      "running loss : 0.660599\n",
      "running loss : 0.661450\n",
      "running loss : 0.661604\n",
      "running loss : 0.673038\n",
      "running loss : 0.661305\n",
      "running loss : 0.661083\n",
      "running loss : 0.649571\n",
      "running loss : 0.657449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.654541\n",
      "running loss : 0.660080\n",
      "running loss : 0.667391\n",
      "running loss : 0.663497\n",
      "running loss : 0.658961\n",
      "running loss : 0.665281\n",
      "running loss : 0.669017\n",
      "running loss : 0.664923\n",
      "running loss : 0.669832\n",
      "running loss : 0.659373\n",
      "running loss : 0.657656\n",
      "running loss : 0.656205\n",
      "running loss : 0.661500\n",
      "running loss : 0.661486\n",
      "running loss : 0.657067\n",
      "running loss : 0.669021\n",
      "running loss : 0.651800\n",
      "running loss : 0.650689\n",
      "running loss : 0.666443\n",
      "running loss : 0.669810\n",
      "running loss : 0.663816\n",
      "running loss : 0.661562\n",
      "running loss : 0.649204\n",
      "running loss : 0.663644\n",
      "running loss : 0.658667\n",
      "running loss : 0.648211\n",
      "running loss : 0.653987\n",
      "running loss : 0.656420\n",
      "running loss : 0.665174\n",
      "running loss : 0.659607\n",
      "running loss : 0.670582\n",
      "running loss : 0.660261\n",
      "running loss : 0.668188\n",
      "running loss : 0.661569\n",
      "running loss : 0.654558\n",
      "running loss : 0.665539\n",
      "running loss : 0.675192\n",
      "running loss : 0.663641\n",
      "running loss : 0.672882\n",
      "running loss : 0.672221\n",
      "running loss : 0.661926\n",
      "running loss : 0.653113\n",
      "running loss : 0.658114\n",
      "running loss : 0.665074\n",
      "running loss : 0.654104\n",
      "running loss : 0.656131\n",
      "running loss : 0.663773\n",
      "running loss : 0.676617\n",
      "running loss : 0.669001\n",
      "running loss : 0.663800\n",
      "running loss : 0.668119\n",
      "running loss : 0.674844\n",
      "running loss : 0.663997\n",
      "running loss : 0.663778\n",
      "running loss : 0.670388\n",
      "running loss : 0.677052\n",
      "running loss : 0.667552\n",
      "running loss : 0.675136\n",
      "running loss : 0.685033\n",
      "running loss : 0.683399\n",
      "running loss : 0.676388\n",
      "running loss : 0.681613\n",
      "running loss : 0.679877\n",
      "running loss : 0.678304\n",
      "running loss : 0.678034\n",
      "running loss : 0.671851\n",
      "running loss : 0.673423\n",
      "running loss : 0.672448\n",
      "running loss : 0.679743\n",
      "running loss : 0.685528\n",
      "running loss : 0.689737\n",
      "running loss : 0.686051\n",
      "running loss : 0.680003\n",
      "running loss : 0.692454\n",
      "running loss : 0.689115\n",
      "running loss : 0.684196\n",
      "running loss : 0.680104\n",
      "running loss : 0.687894\n",
      "running loss : 0.680613\n",
      "running loss : 0.676394\n",
      "running loss : 0.672758\n",
      "running loss : 0.680371\n",
      "running loss : 0.697073\n",
      "running loss : 0.677787\n",
      "running loss : 0.683436\n",
      "running loss : 0.674742\n",
      "running loss : 0.677616\n",
      "running loss : 0.673279\n",
      "running loss : 0.675517\n",
      "running loss : 0.671637\n",
      "running loss : 0.672450\n",
      "running loss : 0.675511\n",
      "running loss : 0.672957\n",
      "running loss : 0.680528\n",
      "running loss : 0.678021\n",
      "running loss : 0.693998\n",
      "running loss : 0.672856\n",
      "running loss : 0.679186\n",
      "running loss : 0.670649\n",
      "running loss : 0.678874\n",
      "running loss : 0.663815\n",
      "running loss : 0.679761\n",
      "running loss : 0.661736\n",
      "running loss : 0.676034\n",
      "running loss : 0.667315\n",
      "running loss : 0.660971\n",
      "running loss : 0.671528\n",
      "running loss : 0.675329\n",
      "running loss : 0.668598\n",
      "running loss : 0.669879\n",
      "running loss : 0.681043\n",
      "running loss : 0.674397\n",
      "running loss : 0.664531\n",
      "running loss : 0.667851\n",
      "running loss : 0.662986\n",
      "running loss : 0.670534\n",
      "running loss : 0.674369\n",
      "running loss : 0.669372\n",
      "running loss : 0.664393\n",
      "running loss : 0.664336\n",
      "running loss : 0.677395\n",
      "running loss : 0.657113\n",
      "running loss : 0.672397\n",
      "running loss : 0.657208\n",
      "running loss : 0.662067\n",
      "running loss : 0.654927\n",
      "running loss : 0.671232\n",
      "running loss : 0.660398\n",
      "running loss : 0.671208\n",
      "running loss : 0.675272\n",
      "running loss : 0.658845\n",
      "running loss : 0.662476\n",
      "running loss : 0.649173\n",
      "running loss : 0.649901\n",
      "running loss : 0.661294\n",
      "running loss : 0.663639\n",
      "running loss : 0.648260\n",
      "running loss : 0.658515\n",
      "running loss : 0.656780\n",
      "running loss : 0.671238\n",
      "running loss : 0.658662\n",
      "running loss : 0.660312\n",
      "running loss : 0.661976\n",
      "running loss : 0.648301\n",
      "running loss : 0.657097\n",
      "running loss : 0.651265\n",
      "running loss : 0.645447\n",
      "running loss : 0.647860\n",
      "running loss : 0.660548\n",
      "running loss : 0.650991\n",
      "running loss : 0.665584\n",
      "running loss : 0.658178\n",
      "running loss : 0.651304\n",
      "running loss : 0.661089\n",
      "running loss : 0.654781\n",
      "running loss : 0.646640\n",
      "running loss : 0.657722\n",
      "running loss : 0.660112\n",
      "running loss : 0.650004\n",
      "running loss : 0.658028\n",
      "running loss : 0.650074\n",
      "running loss : 0.670951\n",
      "running loss : 0.663150\n",
      "running loss : 0.655550\n",
      "running loss : 0.662613\n",
      "running loss : 0.665140\n",
      "running loss : 0.659774\n",
      "running loss : 0.661494\n",
      "running loss : 0.665100\n",
      "running loss : 0.665493\n",
      "running loss : 0.673428\n",
      "running loss : 0.659849\n",
      "running loss : 0.667302\n",
      "running loss : 0.663261\n",
      "running loss : 0.667659\n",
      "running loss : 0.670606\n",
      "running loss : 0.672946\n",
      "running loss : 0.671714\n",
      "running loss : 0.671384\n",
      "running loss : 0.658079\n",
      "running loss : 0.663333\n",
      "running loss : 0.654520\n",
      "running loss : 0.649211\n",
      "running loss : 0.667284\n",
      "running loss : 0.659562\n",
      "running loss : 0.671797\n",
      "running loss : 0.653668\n",
      "running loss : 0.647652\n",
      "running loss : 0.638791\n",
      "running loss : 0.642917\n",
      "running loss : 0.665591\n",
      "running loss : 0.660626\n",
      "running loss : 0.653172\n",
      "running loss : 0.645140\n",
      "running loss : 0.651240\n",
      "running loss : 0.652726\n",
      "running loss : 0.640222\n",
      "running loss : 0.657964\n",
      "running loss : 0.647920\n",
      "running loss : 0.649764\n",
      "running loss : 0.647373\n",
      "running loss : 0.647919\n",
      "running loss : 0.647332\n",
      "running loss : 0.649433\n",
      "running loss : 0.651879\n",
      "running loss : 0.641688\n",
      "running loss : 0.646486\n",
      "running loss : 0.650056\n",
      "running loss : 0.650766\n",
      "running loss : 0.645042\n",
      "running loss : 0.651027\n",
      "running loss : 0.642363\n",
      "running loss : 0.635279\n",
      "running loss : 0.647444\n",
      "running loss : 0.619801\n",
      "running loss : 0.646293\n",
      "running loss : 0.633968\n",
      "running loss : 0.646225\n",
      "running loss : 0.647427\n",
      "running loss : 0.631077\n",
      "running loss : 0.634953\n",
      "running loss : 0.644637\n",
      "running loss : 0.645829\n",
      "running loss : 0.641932\n",
      "running loss : 0.639453\n",
      "running loss : 0.647824\n",
      "running loss : 0.647598\n",
      "running loss : 0.638969\n",
      "running loss : 0.647389\n",
      "running loss : 0.648435\n",
      "running loss : 0.650919\n",
      "running loss : 0.641714\n",
      "running loss : 0.630231\n",
      "running loss : 0.633763\n",
      "running loss : 0.650616\n",
      "running loss : 0.633954\n",
      "running loss : 0.648727\n",
      "running loss : 0.650967\n",
      "running loss : 0.631443\n",
      "running loss : 0.634959\n",
      "running loss : 0.640619\n",
      "running loss : 0.650105\n",
      "running loss : 0.631254\n",
      "running loss : 0.646006\n",
      "running loss : 0.639725\n",
      "running loss : 0.654540\n",
      "running loss : 0.649931\n",
      "running loss : 0.649465\n",
      "running loss : 0.643437\n",
      "running loss : 0.638147\n",
      "running loss : 0.630577\n",
      "running loss : 0.651046\n",
      "running loss : 0.649111\n",
      "running loss : 0.626763\n",
      "running loss : 0.640455\n",
      "running loss : 0.653243\n",
      "running loss : 0.633686\n",
      "running loss : 0.638286\n",
      "running loss : 0.634797\n",
      "running loss : 0.648579\n",
      "running loss : 0.652217\n",
      "running loss : 0.643383\n",
      "running loss : 0.641700\n",
      "running loss : 0.640735\n",
      "running loss : 0.642211\n",
      "running loss : 0.635745\n",
      "running loss : 0.635807\n",
      "running loss : 0.643260\n",
      "running loss : 0.645386\n",
      "running loss : 0.640717\n",
      "running loss : 0.638692\n",
      "running loss : 0.642926\n",
      "running loss : 0.652629\n",
      "running loss : 0.636583\n",
      "running loss : 0.635818\n",
      "running loss : 0.641503\n",
      "running loss : 0.655580\n",
      "running loss : 0.644506\n",
      "running loss : 0.646293\n",
      "running loss : 0.627567\n",
      "running loss : 0.626324\n",
      "running loss : 0.640654\n",
      "running loss : 0.642416\n",
      "running loss : 0.640913\n",
      "running loss : 0.648961\n",
      "running loss : 0.631228\n",
      "running loss : 0.641750\n",
      "running loss : 0.639092\n",
      "running loss : 0.632223\n",
      "running loss : 0.635088\n",
      "running loss : 0.634117\n",
      "running loss : 0.639930\n",
      "running loss : 0.638521\n",
      "running loss : 0.646175\n",
      "running loss : 0.640810\n",
      "running loss : 0.628592\n",
      "running loss : 0.633592\n",
      "running loss : 0.652062\n",
      "running loss : 0.644535\n",
      "running loss : 0.643737\n",
      "running loss : 0.648365\n",
      "running loss : 0.649851\n",
      "running loss : 0.645220\n",
      "running loss : 0.630207\n",
      "running loss : 0.631619\n",
      "running loss : 0.641262\n",
      "running loss : 0.634264\n",
      "running loss : 0.643045\n",
      "running loss : 0.634136\n",
      "running loss : 0.624406\n",
      "running loss : 0.638473\n",
      "running loss : 0.639997\n",
      "running loss : 0.638305\n",
      "running loss : 0.639241\n",
      "running loss : 0.634012\n",
      "running loss : 0.641217\n",
      "running loss : 0.644486\n",
      "running loss : 0.636216\n",
      "running loss : 0.631772\n",
      "running loss : 0.640510\n",
      "running loss : 0.640712\n",
      "running loss : 0.639217\n",
      "running loss : 0.637758\n",
      "running loss : 0.652722\n",
      "running loss : 0.635288\n",
      "running loss : 0.643153\n",
      "running loss : 0.631859\n",
      "running loss : 0.631978\n",
      "running loss : 0.637385\n",
      "running loss : 0.652965\n",
      "running loss : 0.640139\n",
      "running loss : 0.637779\n",
      "running loss : 0.646157\n",
      "running loss : 0.638091\n",
      "running loss : 0.641966\n",
      "running loss : 0.637941\n",
      "running loss : 0.653536\n",
      "running loss : 0.639803\n",
      "running loss : 0.639760\n",
      "running loss : 0.644933\n",
      "running loss : 0.649078\n",
      "running loss : 0.641780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.640197\n",
      "running loss : 0.658338\n",
      "running loss : 0.646722\n",
      "running loss : 0.642072\n",
      "running loss : 0.642446\n",
      "running loss : 0.642795\n",
      "running loss : 0.640608\n",
      "running loss : 0.639857\n",
      "running loss : 0.641461\n",
      "running loss : 0.637646\n",
      "running loss : 0.625564\n",
      "running loss : 0.633700\n",
      "running loss : 0.644242\n",
      "running loss : 0.635594\n",
      "running loss : 0.644756\n",
      "running loss : 0.649701\n",
      "running loss : 0.644969\n",
      "running loss : 0.646774\n",
      "running loss : 0.650794\n",
      "running loss : 0.644609\n",
      "running loss : 0.643030\n",
      "running loss : 0.631454\n",
      "running loss : 0.631762\n",
      "running loss : 0.640668\n",
      "running loss : 0.651860\n",
      "running loss : 0.648746\n",
      "running loss : 0.638907\n",
      "running loss : 0.647845\n",
      "running loss : 0.671057\n",
      "running loss : 0.654591\n",
      "running loss : 0.662969\n",
      "running loss : 0.657131\n",
      "running loss : 0.653993\n",
      "running loss : 0.651880\n",
      "running loss : 0.662055\n",
      "running loss : 0.666510\n",
      "running loss : 0.643907\n",
      "running loss : 0.650199\n",
      "running loss : 0.649121\n",
      "running loss : 0.645396\n",
      "running loss : 0.657804\n",
      "running loss : 0.649573\n",
      "running loss : 0.660104\n",
      "running loss : 0.657288\n",
      "running loss : 0.655529\n",
      "running loss : 0.641980\n",
      "running loss : 0.651172\n",
      "running loss : 0.657708\n",
      "running loss : 0.646914\n",
      "running loss : 0.647705\n",
      "running loss : 0.652458\n",
      "running loss : 0.663005\n",
      "running loss : 0.643170\n",
      "running loss : 0.646464\n",
      "running loss : 0.646215\n",
      "running loss : 0.659981\n",
      "running loss : 0.659750\n",
      "running loss : 0.660645\n",
      "running loss : 0.663648\n",
      "running loss : 0.653060\n",
      "running loss : 0.652250\n",
      "running loss : 0.640128\n",
      "running loss : 0.658532\n",
      "running loss : 0.643283\n",
      "running loss : 0.643156\n",
      "running loss : 0.648733\n",
      "running loss : 0.642664\n",
      "running loss : 0.648620\n",
      "running loss : 0.644410\n",
      "running loss : 0.667686\n",
      "running loss : 0.652666\n",
      "running loss : 0.650421\n",
      "running loss : 0.647794\n",
      "running loss : 0.650989\n",
      "running loss : 0.667596\n",
      "running loss : 0.663693\n",
      "running loss : 0.662852\n",
      "running loss : 0.654082\n",
      "running loss : 0.653872\n",
      "running loss : 0.650151\n",
      "running loss : 0.655464\n",
      "running loss : 0.641084\n",
      "running loss : 0.659771\n",
      "running loss : 0.643976\n",
      "running loss : 0.652736\n",
      "running loss : 0.654025\n",
      "running loss : 0.661472\n",
      "running loss : 0.652792\n",
      "running loss : 0.647691\n",
      "running loss : 0.639105\n",
      "running loss : 0.651426\n",
      "running loss : 0.657449\n",
      "running loss : 0.643826\n",
      "running loss : 0.649116\n",
      "running loss : 0.649742\n",
      "running loss : 0.639159\n",
      "running loss : 0.648621\n",
      "running loss : 0.654047\n",
      "running loss : 0.656340\n",
      "running loss : 0.657716\n",
      "running loss : 0.657310\n",
      "running loss : 0.650059\n",
      "running loss : 0.648786\n",
      "running loss : 0.652926\n",
      "running loss : 0.644746\n",
      "running loss : 0.648609\n",
      "running loss : 0.645376\n",
      "running loss : 0.651243\n",
      "running loss : 0.649918\n",
      "running loss : 0.643693\n",
      "running loss : 0.655871\n",
      "running loss : 0.638361\n",
      "running loss : 0.634837\n",
      "running loss : 0.631969\n",
      "running loss : 0.647374\n",
      "running loss : 0.634762\n",
      "running loss : 0.637597\n",
      "running loss : 0.631681\n",
      "running loss : 0.643368\n",
      "running loss : 0.634394\n",
      "running loss : 0.653362\n",
      "running loss : 0.638646\n",
      "running loss : 0.632913\n",
      "running loss : 0.632226\n",
      "running loss : 0.636154\n",
      "running loss : 0.638301\n",
      "running loss : 0.642448\n",
      "running loss : 0.644804\n",
      "running loss : 0.627501\n",
      "running loss : 0.639521\n",
      "running loss : 0.656740\n",
      "running loss : 0.645280\n",
      "running loss : 0.655572\n",
      "running loss : 0.655064\n",
      "running loss : 0.654117\n",
      "running loss : 0.647987\n",
      "running loss : 0.650437\n",
      "running loss : 0.648360\n",
      "running loss : 0.645009\n",
      "running loss : 0.639730\n",
      "running loss : 0.638400\n",
      "running loss : 0.643973\n",
      "running loss : 0.650085\n",
      "running loss : 0.644740\n",
      "running loss : 0.633574\n",
      "running loss : 0.647712\n",
      "running loss : 0.654527\n",
      "running loss : 0.639702\n",
      "running loss : 0.653486\n",
      "running loss : 0.662266\n",
      "running loss : 0.651490\n",
      "running loss : 0.652154\n",
      "running loss : 0.660821\n",
      "running loss : 0.661743\n",
      "running loss : 0.656406\n",
      "running loss : 0.653798\n",
      "running loss : 0.651159\n",
      "running loss : 0.653012\n",
      "running loss : 0.645088\n",
      "running loss : 0.642322\n",
      "running loss : 0.643903\n",
      "running loss : 0.643734\n",
      "running loss : 0.659569\n",
      "running loss : 0.658785\n",
      "running loss : 0.638175\n",
      "running loss : 0.646845\n",
      "running loss : 0.639307\n",
      "running loss : 0.649799\n",
      "running loss : 0.663972\n",
      "running loss : 0.654964\n",
      "running loss : 0.647777\n",
      "running loss : 0.642736\n",
      "running loss : 0.637176\n",
      "running loss : 0.629599\n",
      "running loss : 0.645704\n",
      "running loss : 0.650036\n",
      "running loss : 0.642127\n",
      "running loss : 0.639792\n",
      "running loss : 0.641796\n",
      "running loss : 0.641193\n",
      "running loss : 0.641627\n",
      "running loss : 0.642420\n",
      "running loss : 0.646057\n",
      "running loss : 0.638538\n",
      "running loss : 0.656914\n",
      "running loss : 0.661486\n",
      "running loss : 0.653610\n",
      "running loss : 0.663481\n",
      "running loss : 0.661141\n",
      "running loss : 0.664131\n",
      "running loss : 0.664788\n",
      "running loss : 0.655907\n",
      "running loss : 0.640448\n",
      "running loss : 0.648726\n",
      "running loss : 0.661579\n",
      "running loss : 0.654605\n",
      "running loss : 0.654467\n",
      "running loss : 0.644126\n",
      "running loss : 0.657986\n",
      "running loss : 0.653004\n",
      "running loss : 0.655453\n",
      "running loss : 0.645652\n",
      "running loss : 0.642832\n",
      "running loss : 0.641131\n",
      "running loss : 0.641236\n",
      "running loss : 0.644863\n",
      "running loss : 0.637823\n",
      "running loss : 0.648391\n",
      "running loss : 0.642448\n",
      "running loss : 0.639116\n",
      "running loss : 0.642736\n",
      "running loss : 0.641953\n",
      "running loss : 0.633401\n",
      "running loss : 0.643553\n",
      "running loss : 0.634667\n",
      "running loss : 0.624692\n",
      "running loss : 0.636223\n",
      "running loss : 0.641122\n",
      "running loss : 0.639667\n",
      "running loss : 0.636427\n",
      "running loss : 0.633675\n",
      "running loss : 0.629179\n",
      "running loss : 0.626015\n",
      "running loss : 0.637032\n",
      "running loss : 0.647868\n",
      "running loss : 0.652199\n",
      "running loss : 0.647203\n",
      "running loss : 0.636997\n",
      "running loss : 0.647191\n",
      "running loss : 0.628614\n",
      "running loss : 0.630561\n",
      "running loss : 0.627890\n",
      "running loss : 0.638814\n",
      "running loss : 0.627587\n",
      "running loss : 0.627353\n",
      "running loss : 0.636201\n",
      "running loss : 0.624384\n",
      "running loss : 0.632388\n",
      "running loss : 0.635385\n",
      "running loss : 0.636426\n",
      "running loss : 0.625053\n",
      "running loss : 0.629457\n",
      "running loss : 0.623558\n",
      "running loss : 0.629246\n",
      "running loss : 0.633483\n",
      "running loss : 0.631325\n",
      "running loss : 0.625920\n",
      "running loss : 0.636302\n",
      "running loss : 0.628846\n",
      "running loss : 0.625357\n",
      "running loss : 0.626599\n",
      "running loss : 0.629609\n",
      "running loss : 0.630460\n",
      "running loss : 0.630684\n",
      "running loss : 0.624424\n",
      "running loss : 0.625820\n",
      "running loss : 0.630176\n",
      "running loss : 0.645342\n",
      "running loss : 0.633438\n",
      "running loss : 0.636617\n",
      "running loss : 0.639218\n",
      "running loss : 0.634591\n",
      "running loss : 0.629344\n",
      "running loss : 0.641085\n",
      "running loss : 0.637520\n",
      "running loss : 0.632966\n",
      "running loss : 0.633870\n",
      "running loss : 0.634136\n",
      "running loss : 0.633012\n",
      "running loss : 0.630476\n",
      "running loss : 0.633510\n",
      "running loss : 0.625873\n",
      "running loss : 0.632689\n",
      "running loss : 0.645489\n",
      "running loss : 0.624768\n",
      "running loss : 0.628624\n",
      "running loss : 0.622994\n",
      "running loss : 0.628693\n",
      "running loss : 0.624255\n",
      "running loss : 0.636482\n",
      "running loss : 0.631107\n",
      "running loss : 0.636632\n",
      "running loss : 0.628316\n",
      "running loss : 0.637126\n",
      "running loss : 0.635222\n",
      "running loss : 0.633079\n",
      "running loss : 0.618983\n",
      "running loss : 0.634934\n",
      "running loss : 0.629285\n",
      "running loss : 0.633694\n",
      "running loss : 0.627127\n",
      "running loss : 0.627528\n",
      "running loss : 0.632899\n",
      "running loss : 0.636764\n",
      "running loss : 0.626461\n",
      "running loss : 0.631179\n",
      "running loss : 0.614790\n",
      "running loss : 0.630844\n",
      "running loss : 0.624683\n",
      "running loss : 0.632117\n",
      "running loss : 0.624267\n",
      "running loss : 0.622345\n",
      "running loss : 0.624042\n",
      "running loss : 0.634276\n",
      "running loss : 0.618046\n",
      "running loss : 0.614977\n",
      "running loss : 0.630940\n",
      "running loss : 0.620616\n",
      "running loss : 0.635704\n",
      "running loss : 0.646275\n",
      "running loss : 0.639697\n",
      "running loss : 0.633382\n",
      "running loss : 0.626493\n",
      "running loss : 0.632851\n",
      "running loss : 0.635933\n",
      "running loss : 0.647959\n",
      "running loss : 0.625850\n",
      "running loss : 0.625955\n",
      "running loss : 0.635756\n",
      "running loss : 0.630732\n",
      "running loss : 0.626420\n",
      "running loss : 0.621487\n",
      "running loss : 0.614652\n",
      "running loss : 0.615640\n",
      "running loss : 0.639099\n",
      "running loss : 0.634238\n",
      "running loss : 0.619254\n",
      "running loss : 0.627125\n",
      "running loss : 0.627677\n",
      "running loss : 0.628631\n",
      "running loss : 0.617471\n",
      "running loss : 0.623913\n",
      "running loss : 0.628527\n",
      "running loss : 0.616969\n",
      "running loss : 0.619571\n",
      "running loss : 0.626012\n",
      "running loss : 0.632125\n",
      "running loss : 0.619207\n",
      "running loss : 0.638778\n",
      "running loss : 0.631277\n",
      "running loss : 0.634419\n",
      "running loss : 0.624396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running loss : 0.633303\n",
      "running loss : 0.624892\n",
      "running loss : 0.624473\n",
      "running loss : 0.619719\n",
      "running loss : 0.621178\n",
      "running loss : 0.621511\n",
      "running loss : 0.623231\n",
      "running loss : 0.619137\n",
      "running loss : 0.607705\n",
      "running loss : 0.614081\n",
      "running loss : 0.613529\n",
      "running loss : 0.626539\n",
      "running loss : 0.610098\n",
      "running loss : 0.624751\n",
      "running loss : 0.616352\n",
      "running loss : 0.617660\n",
      "running loss : 0.614456\n",
      "running loss : 0.612030\n",
      "running loss : 0.613427\n",
      "running loss : 0.617565\n",
      "running loss : 0.621229\n",
      "running loss : 0.619611\n",
      "running loss : 0.633535\n",
      "running loss : 0.634257\n",
      "running loss : 0.628406\n",
      "running loss : 0.626572\n",
      "running loss : 0.632657\n",
      "running loss : 0.632053\n",
      "running loss : 0.637643\n",
      "running loss : 0.630611\n",
      "running loss : 0.640447\n",
      "running loss : 0.648322\n",
      "running loss : 0.636600\n",
      "running loss : 0.633232\n",
      "running loss : 0.647778\n",
      "running loss : 0.644561\n",
      "running loss : 0.641680\n",
      "running loss : 0.634435\n",
      "running loss : 0.640911\n",
      "running loss : 0.634801\n",
      "running loss : 0.643712\n",
      "running loss : 0.646587\n",
      "running loss : 0.639468\n",
      "running loss : 0.647503\n",
      "running loss : 0.647634\n",
      "running loss : 0.651608\n",
      "running loss : 0.660218\n",
      "running loss : 0.655579\n",
      "running loss : 0.654601\n",
      "running loss : 0.648980\n",
      "running loss : 0.658468\n",
      "running loss : 0.651821\n",
      "running loss : 0.653682\n",
      "running loss : 0.654169\n",
      "running loss : 0.647521\n",
      "running loss : 0.654900\n",
      "running loss : 0.644304\n",
      "running loss : 0.651766\n",
      "running loss : 0.652069\n",
      "running loss : 0.647969\n",
      "running loss : 0.653396\n",
      "running loss : 0.642468\n",
      "running loss : 0.633188\n",
      "running loss : 0.652679\n",
      "running loss : 0.639422\n",
      "running loss : 0.633434\n",
      "running loss : 0.622922\n",
      "running loss : 0.633571\n",
      "running loss : 0.637622\n",
      "running loss : 0.643010\n",
      "running loss : 0.626754\n",
      "running loss : 0.631620\n",
      "running loss : 0.627260\n",
      "running loss : 0.633722\n",
      "running loss : 0.626469\n",
      "running loss : 0.635096\n",
      "running loss : 0.629727\n",
      "running loss : 0.627697\n",
      "running loss : 0.622013\n",
      "running loss : 0.610882\n",
      "running loss : 0.621308\n",
      "running loss : 0.642407\n",
      "running loss : 0.626102\n",
      "running loss : 0.600654\n",
      "running loss : 0.616213\n",
      "running loss : 0.626760\n",
      "running loss : 0.637602\n",
      "running loss : 0.642475\n",
      "running loss : 0.649263\n",
      "running loss : 0.632566\n",
      "running loss : 0.640451\n",
      "running loss : 0.629813\n",
      "running loss : 0.637059\n",
      "running loss : 0.650658\n",
      "running loss : 0.638189\n",
      "running loss : 0.642512\n",
      "running loss : 0.632118\n",
      "running loss : 0.625972\n",
      "running loss : 0.630499\n",
      "running loss : 0.634509\n",
      "running loss : 0.639814\n",
      "running loss : 0.620963\n",
      "running loss : 0.625864\n",
      "running loss : 0.635533\n",
      "running loss : 0.626080\n",
      "running loss : 0.630623\n",
      "running loss : 0.623588\n",
      "running loss : 0.629817\n",
      "running loss : 0.622604\n",
      "running loss : 0.623453\n",
      "running loss : 0.635925\n",
      "running loss : 0.619918\n",
      "running loss : 0.625500\n",
      "running loss : 0.636447\n",
      "running loss : 0.633088\n",
      "running loss : 0.619272\n",
      "running loss : 0.623943\n",
      "running loss : 0.610889\n",
      "running loss : 0.625712\n",
      "running loss : 0.626016\n",
      "running loss : 0.631388\n",
      "running loss : 0.632725\n",
      "running loss : 0.628378\n",
      "running loss : 0.630082\n",
      "running loss : 0.634804\n",
      "running loss : 0.628228\n",
      "running loss : 0.639549\n",
      "running loss : 0.638706\n",
      "running loss : 0.648156\n",
      "running loss : 0.655678\n",
      "running loss : 0.657978\n",
      "running loss : 0.641854\n",
      "running loss : 0.647237\n",
      "running loss : 0.637547\n",
      "running loss : 0.639362\n",
      "running loss : 0.647481\n",
      "running loss : 0.639269\n",
      "running loss : 0.635474\n",
      "running loss : 0.638025\n",
      "running loss : 0.642550\n",
      "running loss : 0.643506\n",
      "running loss : 0.638283\n",
      "running loss : 0.636650\n",
      "running loss : 0.617871\n",
      "running loss : 0.627876\n",
      "running loss : 0.629784\n",
      "running loss : 0.625700\n",
      "running loss : 0.616208\n",
      "running loss : 0.628123\n",
      "running loss : 0.612318\n",
      "running loss : 0.603435\n",
      "running loss : 0.619002\n",
      "running loss : 0.613345\n",
      "running loss : 0.617335\n",
      "running loss : 0.614416\n",
      "running loss : 0.615866\n",
      "running loss : 0.608342\n",
      "running loss : 0.624856\n",
      "running loss : 0.617201\n",
      "running loss : 0.614807\n",
      "running loss : 0.622769\n",
      "running loss : 0.619419\n",
      "running loss : 0.609561\n",
      "running loss : 0.605611\n",
      "running loss : 0.604237\n",
      "running loss : 0.614295\n",
      "running loss : 0.621002\n",
      "running loss : 0.615520\n",
      "running loss : 0.600055\n",
      "running loss : 0.609265\n",
      "running loss : 0.607420\n",
      "running loss : 0.613388\n",
      "running loss : 0.596400\n",
      "running loss : 0.605289\n",
      "running loss : 0.608290\n",
      "running loss : 0.599524\n",
      "running loss : 0.605316\n",
      "running loss : 0.618070\n",
      "running loss : 0.619254\n",
      "running loss : 0.617769\n",
      "running loss : 0.609804\n",
      "running loss : 0.617379\n",
      "running loss : 0.598389\n",
      "running loss : 0.607194\n",
      "running loss : 0.605216\n",
      "running loss : 0.605077\n",
      "running loss : 0.612037\n",
      "running loss : 0.614812\n",
      "running loss : 0.601404\n",
      "running loss : 0.598169\n",
      "running loss : 0.610976\n",
      "running loss : 0.589740\n",
      "running loss : 0.602096\n",
      "running loss : 0.597256\n",
      "running loss : 0.590504\n",
      "running loss : 0.600813\n",
      "running loss : 0.603258\n",
      "running loss : 0.606540\n",
      "running loss : 0.598024\n",
      "running loss : 0.602737\n",
      "running loss : 0.602639\n",
      "running loss : 0.606984\n",
      "running loss : 0.618077\n",
      "running loss : 0.615565\n",
      "running loss : 0.604654\n",
      "running loss : 0.618726\n",
      "running loss : 0.610814\n",
      "running loss : 0.603506\n",
      "running loss : 0.616112\n",
      "running loss : 0.611446\n",
      "running loss : 0.601932\n",
      "running loss : 0.611877\n",
      "running loss : 0.612085\n",
      "running loss : 0.603415\n",
      "running loss : 0.606892\n",
      "running loss : 0.600930\n",
      "running loss : 0.610875\n",
      "running loss : 0.590224\n",
      "running loss : 0.593160\n",
      "running loss : 0.591344\n",
      "running loss : 0.604588\n",
      "running loss : 0.585302\n",
      "running loss : 0.600105\n",
      "running loss : 0.603856\n",
      "running loss : 0.602661\n",
      "running loss : 0.594240\n",
      "running loss : 0.602094\n",
      "running loss : 0.601408\n",
      "running loss : 0.601606\n",
      "running loss : 0.599041\n",
      "running loss : 0.593735\n",
      "running loss : 0.605093\n",
      "running loss : 0.606530\n",
      "running loss : 0.603556\n",
      "running loss : 0.603017\n",
      "running loss : 0.616869\n",
      "running loss : 0.592548\n",
      "running loss : 0.607890\n",
      "running loss : 0.610670\n",
      "running loss : 0.611511\n",
      "running loss : 0.615663\n",
      "running loss : 0.601431\n",
      "running loss : 0.611136\n",
      "running loss : 0.601862\n",
      "running loss : 0.610366\n",
      "running loss : 0.609576\n",
      "running loss : 0.612496\n",
      "running loss : 0.608179\n",
      "running loss : 0.610702\n",
      "running loss : 0.607539\n",
      "running loss : 0.601816\n",
      "running loss : 0.602737\n",
      "running loss : 0.607166\n",
      "running loss : 0.603931\n",
      "running loss : 0.607731\n",
      "running loss : 0.610085\n",
      "running loss : 0.593547\n",
      "running loss : 0.602282\n",
      "running loss : 0.609668\n",
      "running loss : 0.602791\n",
      "running loss : 0.601319\n",
      "running loss : 0.612233\n",
      "running loss : 0.602917\n",
      "running loss : 0.605198\n",
      "running loss : 0.608572\n",
      "running loss : 0.601911\n",
      "running loss : 0.622638\n",
      "running loss : 0.614273\n",
      "running loss : 0.622983\n",
      "running loss : 0.613747\n",
      "running loss : 0.610676\n",
      "running loss : 0.606076\n",
      "running loss : 0.604368\n",
      "running loss : 0.627255\n",
      "running loss : 0.633149\n",
      "running loss : 0.618095\n",
      "running loss : 0.621808\n",
      "running loss : 0.618401\n",
      "running loss : 0.622564\n",
      "running loss : 0.617425\n",
      "running loss : 0.615212\n",
      "running loss : 0.621317\n",
      "running loss : 0.608780\n",
      "running loss : 0.615956\n",
      "running loss : 0.611765\n",
      "running loss : 0.608989\n",
      "running loss : 0.615131\n",
      "running loss : 0.617895\n",
      "running loss : 0.610381\n",
      "running loss : 0.609322\n",
      "running loss : 0.621123\n",
      "running loss : 0.618553\n",
      "running loss : 0.614584\n",
      "running loss : 0.609403\n",
      "running loss : 0.615767\n",
      "running loss : 0.611374\n",
      "running loss : 0.620600\n",
      "running loss : 0.614273\n",
      "running loss : 0.611567\n",
      "running loss : 0.632754\n",
      "running loss : 0.615164\n",
      "running loss : 0.610334\n",
      "running loss : 0.614519\n",
      "running loss : 0.622957\n",
      "running loss : 0.613459\n",
      "running loss : 0.624841\n",
      "running loss : 0.630995\n",
      "running loss : 0.623568\n",
      "running loss : 0.631664\n",
      "running loss : 0.611508\n"
     ]
    }
   ],
   "source": [
    "# transfert du model au gpu\n",
    "model.to(device)\n",
    "\n",
    "#define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# define loss function\n",
    "distortion = nn.MSELoss().cuda()\n",
    "        \n",
    "# incremental update of coefficients        \n",
    "\n",
    "# define beta\n",
    "beta = 0.00001\n",
    "# define threshold and loss_init\n",
    "threshold = 0.95\n",
    "loss_init = float(\"Inf\")\n",
    "nb_ones = 1\n",
    "iteration = 0\n",
    "mask=(compute_mask(1, (96, 16, 16)).unsqueeze(0)).cuda()\n",
    "dim_latent = 16*16*96\n",
    "output_flag = False\n",
    "\n",
    "#Epochs\n",
    "n_epochs = 6150\n",
    "\n",
    "\n",
    "# Training the network\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    \"\"\"\n",
    "    if epoch==100:\n",
    "        # define a new learning rate and so a new optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    \"\"\"\n",
    "        \n",
    "    #Training\n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        batch_images = data.to(device).float()\n",
    "        [decoded_images, x_quantized] = model(batch_images, mask, True)\n",
    "        optimizer.zero_grad()\n",
    "        loss_dist = distortion(decoded_images, batch_images)\n",
    "        loss_bit = mean_bit_per_px(x_quantized, model.phi, model.var)\n",
    "        #print(\" loss distortion : \", loss_dist)\n",
    "        #print(\"loss bit : \", loss_bit)\n",
    "        loss = beta * loss_dist + loss_bit\n",
    "        #print(loss)\n",
    "        \n",
    "        # check the value of the loss to see if another coefficient can be enabled\n",
    "        if (loss.item() < loss_init*threshold or iteration > 5):\n",
    "            if (nb_ones<dim_latent):\n",
    "                nb_ones +=1\n",
    "                loss_init = loss.item()\n",
    "                iteration = 0\n",
    "                mask = (compute_mask(nb_ones, tuple(x_quantized.size()[1:])).unsqueeze(0)).cuda()\n",
    "            else:\n",
    "                output_flag = True\n",
    "                break\n",
    "            \n",
    "        loss.backward()\n",
    "        #print(\"conv1.weights grad: \", params[0].grad)\n",
    "        #print(model.conv1.bias.grad)\n",
    "        #print(model.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        iteration += 1\n",
    "\n",
    "    if output_flag:\n",
    "        break\n",
    "    running_loss = running_loss/len(dataloader)\n",
    "    print('running loss : {:.06f}'.format(running_loss), )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model parameters\n",
    "torch.save(model.state_dict(), './model_parameters/mean_bit_ppx/lossy_comp_depthmap2_beta000001.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refinement of the incremental model\n",
    "model = LossyCompAutoencoder()\n",
    "model.load_state_dict(torch.load('./model_parameters/mean_bit_ppx/lossy_comp_params_with_rate_beta005_incremental.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# transfert du model au gpu\n",
    "model.to(device)\n",
    "\n",
    "# general update of coefficients    \n",
    "    #define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    # define loss function\n",
    "distortion = nn.MSELoss().cuda()\n",
    "    #Epochs\n",
    "n_epochs = 600\n",
    "beta = 0.05\n",
    "\n",
    "    # Training the network\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "          \n",
    "    #Training\n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        batch_images = data.to(device).float()\n",
    "        [decoded_images, x_quantized] = model(batch_images, 1, True)\n",
    "        optimizer.zero_grad()\n",
    "        loss_dist = distortion(decoded_images, batch_images)\n",
    "        loss_bit = mean_bit_per_px(x_quantized, model.phi, model.var)\n",
    "        loss = beta * loss_dist + loss_bit\n",
    "        #print(loss)\n",
    "            \n",
    "        loss.backward()\n",
    "        #print(\"conv1.weights grad: \", params[0].grad)\n",
    "        #print(model.conv1.bias.grad)\n",
    "        #print(model.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss = running_loss/len(dataloader)\n",
    "    print('running loss : {:.06f}'.format(running_loss), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb parameters of the model :  20\n",
      "size of gaussian parameters :  torch.Size([6, 96]) torch.Size([6, 96])\n",
      "size of weights of layer  2  :  torch.Size([64, 1, 5, 5])\n",
      "size of bias of layer  2  :  torch.Size([64])\n",
      "size of weights of layer  3  :  torch.Size([128, 64, 5, 5])\n",
      "size of bias of layer  3  :  torch.Size([128])\n",
      "size of weights of layer  4  :  torch.Size([128, 128, 3, 3])\n",
      "size of bias of layer  4  :  torch.Size([128])\n",
      "size of weights of layer  5  :  torch.Size([96, 128, 5, 5])\n",
      "size of bias of layer  5  :  torch.Size([96])\n",
      "size of weights of layer  6  :  torch.Size([512, 96, 3, 3])\n",
      "size of bias of layer  6  :  torch.Size([512])\n",
      "size of weights of layer  7  :  torch.Size([256, 128, 3, 3])\n",
      "size of bias of layer  7  :  torch.Size([256])\n",
      "size of weights of layer  8  :  torch.Size([4, 64, 3, 3])\n",
      "size of bias of layer  8  :  torch.Size([4])\n",
      "size of weights of layer  9  :  torch.Size([128, 128, 3, 3])\n",
      "size of bias of layer  9  :  torch.Size([128])\n",
      "size of weights of layer  10  :  torch.Size([128, 128, 3, 3])\n",
      "size of bias of layer  10  :  torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# variable bit rate\n",
    "    # get back network parameters obtained by first training (eg for a fixed value of beta and no lambda)\n",
    "    # these parameters are used to initialize the new network and won't be changed after. \n",
    "    # The only parameter that is optimized in the new network is lambda \n",
    "    # The new network is trained each time we want to change the rate-distortion tradeoff beta\n",
    "model = LossyCompAutoencoder()\n",
    "model.load_state_dict(torch.load('./model_parameters/mean_bit_ppx/lossy_comp_depthmap2_beta000001.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "weights_model = list(model.parameters())\n",
    "print(\"nb parameters of the model : \", len(weights_model))\n",
    "for i in range(0, len(weights_model), 2):\n",
    "    if i < 2:\n",
    "        print(\"size of gaussian parameters : \", weights_model[i].size(), weights_model[i+1].size())\n",
    "    else :\n",
    "        print(\"size of weights of layer \", str(i//2+1), \" : \", weights_model[i].size())\n",
    "        print(\"size of bias of layer \", str(i//2+1), \" : \", weights_model[i+1].size())\n",
    "    #print(\"weights of the layer \", str(i+1), \" : \", weights_model[i])\n",
    "#print(\"weights model : \" ,weights_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 48 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test set \n",
    "\n",
    "#test_dataset = ImageDataset(root_dir='./data/kodac/', transform=transforms.Compose([RandomCrop(128), ToTensor()]))\n",
    "test_dataset = ImageDataset(root_dir='D:/autoencoder_data/depthmaps/test', transform=transforms.Compose([RandomCrop((480, 640)), ToTensor()]))\n",
    "fig, axes = plt.subplots(nrows=4, ncols=6, sharex=True, sharey=True, figsize=(8,8))\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        if test_image.size(2)>test_image.size(3):\n",
    "            test_image = test_image.permute(0, 1, 3, 2)\n",
    "        \n",
    "        reconstructed_image = model(test_image)\n",
    "        ax = fig.add_subplot(4, 6, i+1, xticks=[], yticks=[])\n",
    "        plt.imshow(torch.squeeze(reconstructed_image.int().cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        reconstructed_image = model(test_image)\n",
    "        reconstructed_depthmap = np.squeeze(reconstructed_image.cpu()).numpy()\n",
    "        cv2.imwrite(\"D:\\\\autoencoder_data\\\\depthmaps2\\\\reconstructed\\\\beta_000001\\\\\" + \"img\" + str(i)+\".png\", reconstructed_depthmap.astype(np.uint16))\n",
    "        #save_image(reconstructed_depthmap, \"D:\\\\autoencoder_data\\\\depthmaps\\\\reconstructed\\\\beta_0001\\\\\" + \"img\" + str(i)+\".png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy :  tensor(0.349899, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.524849, device='cuda:0')\n",
      "psnr :  tensor(59.187355)\n",
      "entropy :  tensor(0.426014, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.639022, device='cuda:0')\n",
      "psnr :  tensor(55.545891)\n",
      "entropy :  tensor(0.346363, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.519545, device='cuda:0')\n",
      "psnr :  tensor(61.006439)\n",
      "entropy :  tensor(0.348571, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.522856, device='cuda:0')\n",
      "psnr :  tensor(56.008266)\n",
      "entropy :  tensor(0.384229, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.576343, device='cuda:0')\n",
      "psnr :  tensor(55.692062)\n",
      "entropy :  tensor(0.350737, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.526105, device='cuda:0')\n",
      "psnr :  tensor(60.428406)\n",
      "entropy :  tensor(0.414963, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.622444, device='cuda:0')\n",
      "psnr :  tensor(55.716301)\n",
      "entropy :  tensor(0.423974, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.635961, device='cuda:0')\n",
      "psnr :  tensor(53.956360)\n",
      "entropy :  tensor(0.361870, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.542805, device='cuda:0')\n",
      "psnr :  tensor(60.292603)\n",
      "entropy :  tensor(0.377286, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.565928, device='cuda:0')\n",
      "psnr :  tensor(58.874317)\n",
      "entropy :  tensor(0.372846, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.559270, device='cuda:0')\n",
      "psnr :  tensor(56.969715)\n",
      "entropy :  tensor(0.407866, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.611800, device='cuda:0')\n",
      "psnr :  tensor(55.851562)\n",
      "entropy :  tensor(0.335663, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.503495, device='cuda:0')\n",
      "psnr :  tensor(59.282997)\n",
      "entropy :  tensor(0.364567, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.546850, device='cuda:0')\n",
      "psnr :  tensor(60.170361)\n",
      "entropy :  tensor(0.337651, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.506477, device='cuda:0')\n",
      "psnr :  tensor(60.207390)\n",
      "entropy :  tensor(0.370239, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.555359, device='cuda:0')\n",
      "psnr :  tensor(59.837044)\n",
      "entropy :  tensor(0.447461, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.671191, device='cuda:0')\n",
      "psnr :  tensor(57.355389)\n",
      "entropy :  tensor(0.496451, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.744677, device='cuda:0')\n",
      "psnr :  tensor(51.006985)\n",
      "entropy :  tensor(0.373368, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.560052, device='cuda:0')\n",
      "psnr :  tensor(49.855278)\n",
      "entropy :  tensor(0.442520, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.663780, device='cuda:0')\n",
      "psnr :  tensor(48.062263)\n",
      "entropy :  tensor(0.419793, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.629690, device='cuda:0')\n",
      "psnr :  tensor(49.271198)\n",
      "entropy :  tensor(0.523995, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.785993, device='cuda:0')\n",
      "psnr :  tensor(53.260838)\n",
      "entropy :  tensor(0.466014, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.699021, device='cuda:0')\n",
      "psnr :  tensor(55.693062)\n",
      "entropy :  tensor(0.450245, device='cuda:0')\n",
      "nb bits per pixel :  tensor(0.675368, device='cuda:0')\n",
      "psnr :  tensor(48.632904)\n",
      "mean nb bits per pixel :  tensor(0.599537, device='cuda:0')\n",
      "psnr mean :  tensor(55.923550)\n"
     ]
    }
   ],
   "source": [
    "# compute PSNR for each image of the test set and its reconstruction\n",
    "\n",
    "def write_data(filepath , tensor_data):\n",
    "    batch, channel, h, w = tensor_data.size()\n",
    "    matrix = tensor_data.cpu().numpy()\n",
    "    file = open(filepath, \"w\")\n",
    "    for image in range(batch):\n",
    "        np.savetxt(file, matrix[image, :, :, :].reshape(channel*h, w), fmt ='%.0f')\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "def compute_entropy(tensor_data):\n",
    "    min_val = tensor_data.min()\n",
    "    max_val = tensor_data.max()\n",
    "    nb_bins = max_val - min_val + 1\n",
    "    hist = torch.histc(tensor_data, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "    hist_prob = hist/hist.sum()\n",
    "    hist_prob[hist_prob == 0] = 1\n",
    "    entropy = -(hist_prob*torch.log2(hist_prob)).sum()\n",
    "    return entropy\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "def psnr(original, compressed, max_pixel): \n",
    "    mse = torch.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse)) \n",
    "    return psnr \n",
    "\n",
    "\n",
    "test_dataset = ImageDataset(root_dir='D:/autoencoder_data/depthmaps/test', transform=transforms.Compose([RandomCrop((480, 640)), ToTensor()]))\n",
    "psnr_sum = 0.0\n",
    "bit_rate_sum = 0.0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        [reconstructed_image, im_quantized] = model(test_image, 1, True)\n",
    "        #write_data('.\\\\reconstructed_data\\\\kodac\\\\loss_distortion_and_bitrate\\\\beta_2\\\\latent_vect\\\\' + 'vec' + str(i) +'.txt', im_quantized)\n",
    "        nb_symbols = im_quantized.size(0)*im_quantized.size(1)*im_quantized.size(2)*im_quantized.size(3)\n",
    "        entropy = compute_entropy(im_quantized)\n",
    "        nbpp = nb_symbols*entropy/float(test_image.size(0)*test_image.size(2)*test_image.size(3))\n",
    "        psnr_sum+= psnr(test_image.cpu(), reconstructed_image.cpu(), 2**16-1.0)\n",
    "        bit_rate_sum += nbpp\n",
    "        print(\"entropy : \", entropy)\n",
    "        print( \"nb bits per pixel : \", nbpp)\n",
    "        print(\"psnr : \" , psnr(test_image.cpu(), reconstructed_image.cpu(), 2**16-1.0))\n",
    "print( \"mean nb bits per pixel : \", bit_rate_sum/len(test_dataset))\n",
    "print(\"psnr mean : \", psnr_sum/len(test_dataset) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(tensor_data):\n",
    "    min_val = tensor_data.min()\n",
    "    max_val = tensor_data.max()\n",
    "    nb_bins = max_val - min_val + 1\n",
    "    hist = torch.histc(tensor_data, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "    hist_prob = hist/hist.sum()\n",
    "    hist_prob[hist_prob == 0] = 1\n",
    "    entropy = -(hist_prob*torch.log2(hist_prob)).sum()\n",
    "    return entropy\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "def psnr(original, compressed, max_pixel): \n",
    "    mse = torch.mean((original - compressed) ** 2) \n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
    "                  # Therefore PSNR have no importance. \n",
    "        return 100\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse)) \n",
    "    return psnr \n",
    "\n",
    "\n",
    "# Load previous model\n",
    "model_prev = LossyCompAutoencoder()\n",
    "model_prev.load_state_dict(torch.load('./model_parameters/lossy_comp_params_with_rate_beta2_incremental_2.pth'))\n",
    "model_prev.eval()\n",
    "model_prev.to(device)\n",
    "\n",
    "\n",
    "# And run test \n",
    "test_dataset = ImageDataset(root_dir='./data/kodac/', transform=ToTensor())\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        [reconstructed_image, im_quantized] = model_prev(test_image,1, True)\n",
    "        nb_symbols = im_quantized.size(0)*im_quantized.size(1)*im_quantized.size(2)*im_quantized.size(3)\n",
    "        entropy = compute_entropy(im_quantized)\n",
    "        nbpp = nb_symbols*entropy/float(test_image.size(0)*test_image.size(1)*test_image.size(2)*test_image.size(3))\n",
    "        print(\"nb_symbols : \", nb_symbols)\n",
    "        print(\"entropy : \", entropy)\n",
    "        print( \"nb bits per pixel : \", nbpp)\n",
    "        print(\"psnr : \" , psnr(test_image.cpu(), reconstructed_image.cpu(), 255.0))\n",
    "    \n",
    "# And print figures\n",
    "fig, axes = plt.subplots(nrows=4, ncols=6, sharex=True, sharey=True, figsize=(8,8))\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        if test_image.size(2)<test_image.size(3):\n",
    "            test_image = test_image.permute(0, 1, 3, 2)\n",
    "        \n",
    "        reconstructed_image = model_prev(test_image, 1,  False)\n",
    "        ax = fig.add_subplot(4, 6, i+1, xticks=[], yticks=[])\n",
    "        plt.imshow(np.squeeze(reconstructed_image.int().cpu()).permute(1, 2, 0))\n",
    "        \n",
    "# And save figures\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        \n",
    "        reconstructed_image = np.squeeze(model_prev(test_image).cpu())\n",
    "        print(reconstructed_image.type())\n",
    "        save_image(reconstructed_image, \".\\\\reconstructed_data\\\\kodac\\\\loss_distortion_and_bitrate\\\\beta_2_incremental_bis\\\\\" + \"img\" + str(i)+\".png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_rate(x_quantized, phi, var):\n",
    "    u = torch.arange(-0.5, 0.5+0.01, 0.01).cuda()        \n",
    "    gsm_sum = torch.zeros(len(u)).cuda()\n",
    "    for i in range(len(u)):\n",
    "        x = x_quantized + u[i]\n",
    "        gsm_sum_i = sum_gsm(x, var, phi, 6)\n",
    "        gsm_sum[i] = gsm_sum_i\n",
    "\n",
    "    entropy = torch.trapz(gsm_sum, u)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "\n",
    "# Load incremental model\n",
    "incremental_model = LossyCompAutoencoder()\n",
    "incremental_model.load_state_dict(torch.load('./model_parameters/lossy_comp_params_with_rate_beta2_incremental.pth'))\n",
    "incremental_model.eval()\n",
    "incremental_model.to(device)\n",
    "\n",
    "# train again the model starting form incremental-learned weights\n",
    "    #define optimizer\n",
    "optimizer = torch.optim.Adam(incremental_model.parameters(), lr=0.0001)\n",
    "\n",
    "# define loss function\n",
    "distortion = nn.MSELoss().cuda()\n",
    "\n",
    "\n",
    "# define beta\n",
    "beta = 2.0\n",
    "\n",
    "#Epochs\n",
    "n_epochs = 600\n",
    "\n",
    "\n",
    "# Training the network\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "           \n",
    "    #Training\n",
    "    for i_batch, data in enumerate(dataloader):\n",
    "        batch_images = data.to(device).float()\n",
    "        [decoded_images, x_quantized] = incremental_model(batch_images, False, True)\n",
    "        optimizer.zero_grad()\n",
    "        entropy = entropy_rate(x_quantized, incremental_model.phi, incremental_model.var)\n",
    "        print(\"entropy : \", entropy)\n",
    "        dist = distortion(decoded_images, batch_images)\n",
    "        print(\"distortion : \", dist)\n",
    "        loss = beta * dist + entropy\n",
    "        loss.backward()\n",
    "        #print(\"conv1.weights grad: \", params[0].grad)\n",
    "        #print(model.conv1.bias.grad)\n",
    "        #print(model.conv1.weight.grad)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    running_loss = running_loss/len(dataloader)\n",
    "    print('running loss : {:.06f}'.format(running_loss), )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from range_coder import RangeEncoder, RangeDecoder, prob_to_cum_freq\n",
    "import os\n",
    "\n",
    "# Load previous model\n",
    "model = LossyCompAutoencoder()\n",
    "model.load_state_dict(torch.load('./model_parameters/mean_bit_ppx/lossy_comp_params_with_rate_beta0005_incremental.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "nb_bits = 0.0\n",
    "test_dataset = ImageDataset(root_dir='./data/kodac/', transform=ToTensor())\n",
    "with torch.no_grad():  \n",
    "    for i in range(len(test_dataset)):\n",
    "        test_image = test_dataset[i].unsqueeze(0).to(device).float()\n",
    "        [reconstructed_image, data_comp] = model(test_image, 1, True)\n",
    "            # compute symbol probabilities\n",
    "        min_val = data_comp.min()\n",
    "        if min_val <0:\n",
    "            data_comp -= min_val\n",
    "            min_val = 0\n",
    "        max_val = data_comp.max()\n",
    "        nb_bins = max_val - min_val + 1\n",
    "        hist = torch.histc(data_comp, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "        prob = hist/hist.sum()\n",
    "        #print(\"data comp : \", data_comp)\n",
    "        #print(prob)\n",
    "        \n",
    "        \"\"\"\n",
    "        if len(torch.nonzero(prob)) != len(prob):\n",
    "            zero_indices = ((prob == 0).nonzero())\n",
    "            for j in reversed(range(0, len(zero_indices), 1)):\n",
    "                data_comp[data_comp > int(zero_indices[j])+min_val] -=1\n",
    "            min_val = data_comp.min()\n",
    "            max_val = data_comp.max()\n",
    "            nb_bins = max_val - min_val + 1\n",
    "            hist = torch.histc(data_comp, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "            prob = hist/hist.sum()\n",
    "            print(min_val)\n",
    "            print(max_val)\n",
    "            print(\"data comp : \", data_comp)\n",
    "            print(prob)\n",
    "         \"\"\" \n",
    "            \n",
    "            # convert probabilities to cumulative integer frequency table\n",
    "        #cumFreq = prob_to_cum_freq(torch.clamp(prob, min=np.finfo(np.float32).eps).cpu(), resolution=128)\n",
    "        cumFreq = prob_to_cum_freq(prob.cpu(), resolution=128)\n",
    "        #print(cumFreq)\n",
    "        \n",
    "        # encode data\n",
    "        filepath_to_write = \"D:\\\\lossy_autoencoder\\\\latent_vect_encoded\\\\\" + \"img\" + str(i) + \".bin\"\n",
    "        encoder = RangeEncoder(filepath_to_write)\n",
    "        #print(torch.flatten(data_comp).cpu().tolist())\n",
    "        encoder.encode(torch.flatten(data_comp.int()).cpu().tolist(), cumFreq)\n",
    "        encoder.close()\n",
    "        \n",
    "        \n",
    "        file_size = os.path.getsize(filepath_to_write)*8 #number of bits in the file\n",
    "        print(file_size)\n",
    "        nb_bits += file_size\n",
    "        \n",
    "    nb_bits_per_image = nb_bits/len(test_dataset)\n",
    "    print(nb_bits_per_image)\n",
    "    nb_bits_per_pixel = nb_bits_per_image/(512*768)\n",
    "    print(nb_bits_per_pixel)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "    test_image = test_dataset[1].unsqueeze(0).to(device).float()\n",
    "    [reconstructed_image, data_comp] = model(test_image, 1, True)\n",
    "        # compute symbol probabilities\n",
    "    min_val = data_comp.min()\n",
    "    print(min_val)\n",
    "    print(data_comp.max())\n",
    "    if min_val <0:\n",
    "        data_comp -= min_val\n",
    "        min_val = 0\n",
    "    max_val = data_comp.max()\n",
    "    \n",
    "    print(max_val)\n",
    "    nb_bins = max_val - min_val + 1\n",
    "    print(nb_bins)\n",
    "    hist = torch.histc(data_comp, bins=nb_bins.int(), min=min_val, max=max_val)\n",
    "    prob = hist/hist.sum()\n",
    "    print(prob)\n",
    "         # convert probabilities to cumulative integer frequency table\n",
    "    cumFreq = prob_to_cum_freq(prob.cpu(), resolution=128)\n",
    "    #print(cumFreq)\n",
    "\n",
    "    print(torch.flatten(data_comp).cpu().tolist())\n",
    "    \n",
    "    \n",
    "        # encode data\n",
    "    filepath_to_write = \"D:\\\\lossy_autoencoder\\\\latent_vect_encoded\\\\\" + \"img\" + str(1) + \".bin\"\n",
    "    encoder = RangeEncoder(filepath_to_write)\n",
    "    print(torch.flatten(data_comp).cpu().tolist())\n",
    "    encoder.encode(torch.flatten(data_comp.int()).cpu().tolist(), cumFreq)\n",
    "    encoder.close()   \n",
    "\"\"\" \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
